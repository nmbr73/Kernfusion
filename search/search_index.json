{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to total ConFusion","text":"<p>Everything VFx and such.</p> <p>Status</p> <p>Current status is: Not much in here yet, but already a total mess. Long term goal is: To shred it all in favor of a better solution.</p>"},{"location":"#quickstart-guide","title":"Quickstart Guide","text":""},{"location":"#clone-the-repository","title":"Clone the repository","text":"<p>Working on the Wiki is currently coordinated and version controlled using Git. Get your own full copy by cloning the repository:</p> ghgit <pre><code>gh repo clone nmbr73/Kernfusion\n</code></pre> <pre><code>git clone https://github.com/nmbr73/Kernfusion\n</code></pre> <p>Or you may want to fork it on GitHub first ... that's if you are considering to contribute ... and you really should consider to contribute!</p>"},{"location":"#install-obsidianmd","title":"Install Obsidian.md","text":"<p>Obsidian is a cross platform note taking app, that behind the scenes works with Markdown. This makes it an okay choice for editing the Wiki content.</p> macOS (Homebrew)macOS/Windows/Linux <pre><code>brew install --cask obsidian\n</code></pre> <p>Download and run the Installer from Obsidian.md.</p> <p>Open the <code>Wiki/</code> folder as a so called \"Vault\" in Obsidian. Use Cmd+E (on a Mac) or ??? (on Windows) to switch between edit/preview mode. Note that not all Markdown features used for the Wiki are supported in Obsidian.</p>"},{"location":"#get-mkdocs-up-and-running","title":"Get MkDocs up and running","text":"<p>MkDocs creates static HTML pages out of the Markdown files - and in the end that exactly is what you see when you open confusion.nmbr73.net</p> macOSWindowsLinux <pre><code>cd Kernfusion\nchmod +x ./mk\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> <p>Curious to hear if someone was brave enough to try to run th following it via MINGW64 / Git Bash, WSL2, or whatever. <pre><code>cd Kernfusion\nchmod +x ./mk\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> ... good luck!</p> <p>In theory it should be the same as for macOS: <pre><code>cd Kernfusion\nchmod +x ./mk\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> ... let me know if it works!</p> <p>Now you can run <code>./mk docs serve</code> to locally check the MkDocs output of your working copy. Whenever you make a change to the Wiki you want to inspect, do a <code>./mk docs create</code> in another terminal window.</p>"},{"location":"About/","title":"About","text":"<p>The following text is nonsense I guess - a good opportunity for someone who has a clue about the subject and can write in English: please go ahead and replace it!</p>"},{"location":"About/#motivation","title":"Motivation","text":"<p>Finding a \"how to do this simple thing\" all to often seems to be like searching the VFXPedia mirror, reading not only multiple articles the information is distributed across, but also the discussion pages, to then jump into some threads on the wesuckless and bmd forums to finally try a google search to maybe complement the whole picture by some (excellent but sometimes ancient) blog posts.</p> <p>As done with VFxPedia, suggested by nmbr73, picked up by LearnNowFX, and supported by Andrew Hazelden: A MediaWiki is probably best suited to maintain such information and to make it some ever evolving and living documentation. We truly are a long way from that, but you have to start somewhere.</p>"},{"location":"About/#vision","title":"Vision","text":"<p>Simply put, the idea is to build a Wiki of ConFusion to become the next gen VFxPedia; to revive the approach of building up a community driven knowledge base around VFx in general and the BMD tooling in particular. And yes, I know that this is impossible, totally ridiculous and absolutely insane, but ... I have no clue - I'm a beginner enough that I just don't care.</p> <p>Quote</p> <p>The day before something is a breakthrough, it\u2019s a crazy idea. -- Peter Diamandis</p>"},{"location":"About/#approach","title":"Approach","text":"<p>Most probably some 'critical mass' in terms of useful content is needed to attract people to use the information and to be willing to put own efforts in updating and complementing it.</p> <p>Therefore the attempt is to first collect some existing documentation and rearrange it to be used as a foundation for a future Wiki.</p>"},{"location":"About/#tools","title":"Tools","text":"<p>The Kernfusion repository is here to compile, sort, structure and reformat content from different sources. Besides some tooling and experiments, the Wiki/ folder is the place where things mainly happen.</p> <p>This folder is an Obsidian vault, which - for the time being - seems to be well suited for the purpose: Obsidian is a free and easy to use note taking app, and behind the scenes it is file based with all content in MarkDown format. MarkDown files, in turn, can be easily managed, read, converted and allow for collaborating and versioning via Git. Currently MkDocs is used to provide a user friendly output of the content on GitHub Pages. If - and only if - the repository's content evolves to something useful that's worth it to open up for editing by a broader community, it should be considered to abandon it - that is after exporting the repo's content some day as a basis for the to-be MediaWiki instance. But until then and unless this thing flies, a Git repo should perfectly do to get organized.</p>"},{"location":"About/#getting-started","title":"Getting started","text":"<p>If you only want to use the documentation, then (for the time being) you can just access its latest version on confusion.nmbr73.net. But this documentation won't be all too useful unless there are people who volunteer to complement and update it. Find here what's needed to get involved ...</p>"},{"location":"About/#tools-installation","title":"Tools installation","text":"<p>Tools you should have in your belt are at least Git, GitHub, and Obsidian for editing the documentation; you may want to install Python, VSCode, and maybe Lua if you are interested in working on the scripts.</p> Tool installation on macOS <p>For macOS it's recommended to use Homebrew to manage the installation of third party tools. You may want to use one or the other of the following commands ...</p> <pre><code># install homebrew\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# install git and github cli\nbrew install git\nbrew install gh\n\n# install obsidian and/or vscode editors\nbrew install --cask obsidian\nbrew install --cask visual-studio-code\n\n# install python and (maybe) lua for scripting\nbrew install python@3.10\nbrew install lua\n</code></pre> <p>First clone the Kernfusion repository by doing a <code>gh repo clone nmbr73/Kernfusion</code> (or alternatively by a  <code>git clone https://github.com/nmbr73/Kernfusion</code>).</p> <p>Download Obsidian from obsidian.md (or install via <code>brew install --cask obsidian</code> if you are on a Mac). Obsidian is used to edit the files in the <code>Wiki/</code> subfolder. To do so just open this folder in Obsidian as a vault (select \"Open folder as vault\" and then chose the 'Kernfusion/Wiki/' subdirectory).</p> <p>You should then see the exact documentation you are currently reading in Obsidian:</p> <p></p>"},{"location":"About/#editing-in-obsidian","title":"Editing in Obsidian","text":"<p>...</p>"},{"location":"About/#git-to-apply-your-edits","title":"Git to apply your edits","text":"<p>Git and GitHub are used not only for versioning, but also in the sense of a collaboration tool. The <code>main</code>branch will soon be \"protected\" against direct modifications. This means: Even if you just want to edit some text or fix some typos you (currently) must use Git and its key functionalities like branches and synchronization with remotes. But knowing a little bit of Git is totally worth it in so many situations so you should definitely give it a try ...</p> Correct and complement the Git description <p>It's meant to be a very(!) short \"howto\", to allow people not familiar with git to get quickly started to work on this repo, but by no means as a full introduction to Git. Still it needs some rework.</p> <p>Before working on Kernfusion: <pre><code>git switch main\ngit fetch\ngit branch &lt;NAME&gt;\ngit switch &lt;NAME&gt;\ngit push --set-upstream origin &lt;NAME&gt;\n</code></pre></p> <p>Do create a snapshots of your local changes whenever you finished a piece of work: <pre><code>git status # to see your changes\ngit add . # to add all your changes\ngit commit -m &lt;DESCRIPTION&gt; # commit these changes your local repo\n</code></pre> Use a description that could be read as \"If applied, this commit will\u00a0&lt;DESCRIPTION&gt;\" (see How to Write a Git Commit Message).</p> <p>This is to build up a documented version history.</p> <p>Push your changes on your branch to the origin\u2019s main from time to time <pre><code>git pull # get any changes, that might have been made to your branch\ngit push\n</code></pre></p> <p>...</p>"},{"location":"About/#file-and-directory-structure","title":"File and directory structure","text":"<p>tl;dr</p> <ul> <li>Group articles, but don't try to put them in a linear order</li> <li>Obsidian tags are considered to be categories</li> <li>All pages in a folder are considered subpages</li> <li>A folder subpage is a Markdown file in that folder with the folders name</li> <li>The <code>Wiki/</code> folder and only the <code>Wiki/</code> folder must have a <code>README.md</code></li> <li>Do not name any file <code>index.md</code></li> <li><code>.pages</code> files are meant to be eliminated (remember: don't put articles in a linear order)</li> </ul> <p>Intention is to build up a collection of articles to eventually transfer them into a Wiki some day (most probably based on MediaWiki).</p> <p>A Wiki has no \"linear\" structure, but is more a network of linked articles. This being said, it must be avoided to try to put the pages into an order - even though the file navigation panel (on the left in Obsidian, or the MkDocs's static output) may tempt you to do so. As a compensation for this, links must be embedded in a meaningful way whenever possible in order to let the information network emerge.</p> <p>Still there is a way for a rough structuring of Wiki articles by assigning them a category. As an article can belong to multiple categories, Obsidian's tags mechanism should be well suited to mimic categories.</p> <p>Another way to organise articles in a (Media)Wiki are subpages. In this repository subpages are realized by folders. To provide the text the folder itself should be associated with, every folder must contain a Markdown file with its filename matching the folders name.</p> <p>index.md files</p> <p>MkDocs can use <code>index.md</code> files as a folders page. But these are a pain to use, i.e. when setting links to such pages in Obsidian (we end up with tons of pages named 'index' and have to set alternative link texts for all of them). A usable compromise has still to be found here!</p>"},{"location":"About/#authoring","title":"Authoring","text":""},{"location":"About/#write-with-davinci-resolve-fusion-in-mind","title":"Write with DaVinci Resolve / Fusion in mind","text":"<p>Topics of the articles should be all around visual effect tools in general and the BMD products in particular. It's worth to mention Blender, Houdini, After Effects, and whatever the market has to offer in this area - but they are well covered by other communities, and therefore focus here is on DaVinci Resolve and Fusion and how such tools integrate with these in a workflow for visual artists.</p>"},{"location":"About/#write-with-an-audience-in-mind","title":"Write with an audience in mind","text":"<p>Target audience of the articles is (maybe) ...</p> <ul> <li>users / vfx artists, using the different tools</li> <li>administrators / operators / engineers / pipeline TDs, provisioning and maintaining a vfx toolchain</li> <li>developers, writing tools, coding scripts, implementing drivers and programming visual effects</li> </ul> <p>... with a focus on the latter two (in general very good and extensive manuals exist for the end-users of the tools) and blurred borders between the three.</p> <p>Please organize / structure your articles with the different audiences in mind; complete articles dedicated to a specific audiences may be tagged as such ... maybe by <code>#artist</code>, <code>#admin</code>, <code>#automation</code>, <code>#scripting</code>, <code>#dev</code>, or the like? But I can't (and don't want to) set the rules how to do this: I think (hope) that it will just happen with some good examples that others copy and evolve.</p>"},{"location":"About/#write-with-a-wiki-in-mind","title":"Write with a Wiki in mind","text":"<p>Depending on the source, we will have some material structured like a book - and people tend to build documentation this way. But whenever you ask yourself \"how can I bring the files in the Obsidian folder into the right order\", or \"the order of the articles on the left hand side of MkDocs output is not correct\", you are probably on the wrong track! A Wiki is a \"network\" of articles and not designed to be read from a beginning to an end.</p> <p>Content will hardly be publishable as a book!</p> <p>It's really nice, to have manuals as a PDF or an ePub. But, it must be clear that this will unfortunately hardly be possible with the approach pursued here. This is a serious disadvantage of which one must be aware.</p>"},{"location":"About/#write-with-style","title":"Write with Style","text":"<p>Make sure that you write your text to have a meaning, not a nice formatting. The formatting comes for free and is very flexible if you got the semantics right. If for example you write using tools like Word, Pages, Scrivener, or such, then you are probably on the wrong track as soon as you set a font, its size, a color, or something similar. You almost always want to use a \"Style\" for that! This way you can set and change the formatting of such elements easily and for each target output format individually.</p>"},{"location":"About/#folders-vs-tags-subpages-vs-categories","title":"Folders vs Tags (Subpages vs Categories)","text":"<p>Subpages help to group articles that belong together. For example all Kartaverse core technologies are placed in a 'Kartaverse' folder. Categories are a different kind of grouping: Articles from very different subpages can belong to the same category and a single article can belong to multiple categories. There might be for example articles of a 'Reference' kind in very different folders (subpages). In some cases even both groupings can make sense: All the Kartaverse workflows are grouped by a 'Workflows' subpage in the Kartaverse and each such article is tagged as a 'Workflow' (each Kartaverse Workflow is a Workflow, but not every Workflow has to be a Kartaverse Workflow).</p>"},{"location":"Featured%20Articles/","title":"Featured","text":"<p>Currently experimenting with integrating Kartaverse/Workflows into the Wiki. See the Kartaverse/Workflows/Creating Volumetric NeRFs and OpenDisplayXR/VDD as an example for the reformatting. Started to work on DEV The Ultimate Guide to OpenUSD Pipeline Development as another (a bit painful) example. The Krokodove conversion seems pretty complete I think.</p> <p>Imported from Andrew's Scrivener source: - Immersive Pipeline Integration Guide - KartaVision - Vonk Ultra - Krokodove Essentials - Kartaverse Workflows</p> <p>Did a quick and dirty copy of the Kernfusion's Fuses/Comps/Macros part into the Wiki ... but it definitely needs some explanation what this 'Fusion' folder is good for and why it is here in this repository \ud83d\ude2c</p> <p>And with FusionScript a first output of an old (incomplete) script based on Roger Magnusson's Class Browser.</p>"},{"location":"OpenFX/","title":"OpenFX","text":"<p>just some first notes / copypasta</p> <p>An OpenFX package is placed in ... Windows: <code>C:\\Program Files (x86)\\Common Files\\OFX\\Plugins</code> macOS: <code>/Library/OFX/Plugins</code> Linux: <code>/usr/OFX/Plugins</code> ... and is thereby available to all OpenFX aware applications (so called OFX hosts).</p>"},{"location":"OpenFX/#macos","title":"macOS","text":"<pre><code>cd '/Library/Application Support/Blackmagic Design/'\ncd 'DaVinci Resolve/Developer/OpenFX'\n\nless README.txt # for lots of information\n\nsudo mkdir -p /Library/OFX/Plugins\nsudo chmod a+w /Library/OFX/Plugins\n\n# create the example 'Gain' plugin:\ncd GainPlugin\nmake\nmake install\n\n# now you shoud find \"GainPlugin\" in\n# DaVinci Resolve 'Effects -&gt; Open FX -&gt; Filters'\n</code></pre> <p>See also: - The Open Effects Association - OFX Association on GitHub - OpenFX documentation - Burning Question: What in the heck is OFX? - ASWF OpenFX - An Open Standard for Visual-Effects Plugins - Gary Oberbrunner, Dark Star Systems &amp; Pierre Jasmin, RE:Vision Effects  on YouTube - https://github.com/NatronGitHub/openfx-misc ... (!) - https://www.steakunderwater.com/wesuckless/viewtopic.php?f=6&amp;t=5787 - https://www.steakunderwater.com/wesuckless/viewtopic.php?t=4706</p> <p>OpenGL in OpenFX: - https://github.com/AcademySoftwareFoundation/openfx/blob/main/Examples/OpenGL/opengl.cpp - https://forum.blackmagicdesign.com/viewtopic.php?t=62002&amp;p=384511 - https://discuss.pixls.us/t/open-seperate-opengl-context-with-openfx/7974</p>"},{"location":"Pages/","title":"Pages","text":"3ABCDEFHIJKLMNOPRSTUVWY <p>360VR Stitching Tools</p> <p>About About ACES Color Management Acknowledgements Add Tool context menu AddControlPage Adding Data Nodes to a Composite Adding KartaVR via Reactor Adding Vonk Ultra via Reactor AddInput Apple Compressor Command-Line Syntax Atom AudioWaveform AudioWaveform AudioWaveform Automated Reactor PathMaps in Resolve Studio and Fusion Studio Automation Tools AWS Deadline Deployment</p> <p>Blender bmd Bokeh Bokeh Bokeh_AChroma Bokeh_Image</p> <p>Categories Choosing Your Installation Packages clamp() Class Types Closing Thoughts Computer Vision Computer Vision and Machine Learning Tools Config/ Configuring Fusion Centric Environment Variables Configuring Fusion Render Node PathMaps Conversion Conversion Crash Course Create() Creating ST Maps Creating Volumetric NeRFs CT_3D CT_3DFilter CT_3DFilterSource CT_AnimSegment CT_Any CT_ApplyMode CT_BinItem CT_BrushMode CT_BrushShape CT_Camera3D CT_CameraData3D CT_ConsoleUtility CT_Converter CT_Curve3D CT_CurveData3D CT_Event CT_EventControl CT_ExternalControl CT_FileFormat3D CT_FlowType CT_FuMenu CT_GLTexture CT_GLViewer CT_ImageFormat CT_InputControl CT_LayoutItem CT_Light3D CT_LightData3D CT_LightSW3D CT_Locale CT_LUTFormat CT_Mask CT_MergeTool CT_Modifier CT_MtlData3D CT_MtlInputs3D CT_MtlParticle3D CT_MtlSW3D CT_Operator CT_PaintTool CT_Parameter CT_ParticleMergeTool CT_ParticleSource CT_ParticleStyle CT_ParticleTool CT_Prefs CT_Preview CT_PreviewControl CT_PreviewMedia CT_Protocol CT_Region3D CT_RenderContext3D CT_Renderer3D CT_RendererInputs3D CT_Shader3D CT_ShadowClass3D CT_SinkTool CT_SourceTool CT_Spline CT_SurfaceData3D CT_SurfaceInputs3D CT_Tool CT_ToolViewInfo CT_Transition CT_UserControl CT_Utility CT_View CT_ViewLUTPlugin CubeMapColorizer CubeMapEquirectangular CubeMapLoader CubeMapUnfold</p> <p>DCTL DEV Building an Effective nVP (Neural Virtual Production) Sound Stage DEV The Ultimate Guide to OpenUSD Pipeline Development Development Directory Structure Display Solutions, GPUs, Video Cables, Converters/Adapters distance() Domemaster Photoshop Actions Pack dot() Download Links</p> <p>Embed Videos Environment Variables Essential Reactor Atom Packages Essential Reactor Atom Packages Event-Functions Example Compositions Experiments Expressions</p> <p>Fast Fourier Transform (FFT) FastGlow Featured Articles FFMpeg Command-Line Syntax fileexists Folder 0 Folder 1 Folder 1/img Folder 2 Folder 2/img Folder 3 Folder 3/img fract() Fulldome FuScript Fuse Fuse Writing Manual Fuse-Settings Fusion Fusion built in Tools Fusion Render Node Customization Fusion Render Node Customization FusionScript FusionSDK</p> <p>Hardware Control Surfaces and HID Devices</p> <p>Immersive Pipeline Integration Guide index Install Reactor Package Manager Install Vonk Installing a Local Content Staging Web Server Installing Common Utilities Installing Data Backup and Disaster Recovery Tools Installing Digital Content Creation Apps Installing Hardware Virtualization Tools Installing Operating Systems From Scratch Installing the BMD Resolve / Fusion Software IP Based Video Workflows</p> <p>Jupyter Notebook for Resolve/Fusion</p> <p>KartaLink Kartaverse Kartaverse Development Reference Hardware Kartaverse Learning Resources Kartaverse Project Assistance KartaVision - Node Based Reverse Image Search KartaVR KickAss ShaderZ for Fusion Krokodove</p> <p>Lab Learning Resources Library Links Lua LuaJIT</p> <p>Math Functions max() mod() Modifier Reference Guide MultiButtonControl MultiButtonControl</p> <p>Node Categories Node Cookbook Node Reference Guide Novel-view synthesis</p> <p>OpenDisplayXR/VDD OpenFX Overview</p> <p>Photogrammetry Tools Pipeline Guide - intentions Pixar Tractor Deployment Plugins pow()</p> <p>radians() RAW and HDRI Image Processing Tools Reactor README README README README README README README README README README README README reflect() REGB_ControlView REGB_CreateFramePreview REGB_CreateStaticPreview REGB_EightBitOnly REGB_ForceCommonCtrls REGB_ImageFormat_CanLoadFields REGB_ImageFormat_CanSave24bit REGB_ImageFormat_CanSave32bit REGB_ImageFormat_CanSave8bit REGB_ImageFormat_CanSaveField REGB_ImageFormat_CanScale REGB_MediaFormat_CanLoad REGB_MediaFormat_CanLoadAudio REGB_MediaFormat_CanLoadImages REGB_MediaFormat_CanLoadMIDI REGB_MediaFormat_CanLoadMulti REGB_MediaFormat_CanLoadText REGB_MediaFormat_CanSave REGB_MediaFormat_CanSaveAudio REGB_MediaFormat_CanSaveCompressed REGB_MediaFormat_CanSaveImages REGB_MediaFormat_CanSaveMIDI REGB_MediaFormat_CanSaveMulti REGB_MediaFormat_CanSaveText REGB_MediaFormat_ClipSpecificInputValues REGB_MediaFormat_LoadLinearOnly REGB_MediaFormat_OneShotLoad REGB_MediaFormat_OneShotSave REGB_MediaFormat_SaveLinearOnly REGB_MediaFormat_WantsIOClass REGB_MediaFormat_WantsUnbufferedIOClass REGB_NoAutoProxy REGB_NoAuxChannels REGB_NoBlendCtrls REGB_NoMotionBlurCtrls REGB_NoObjMatCtrls REGB_NoSplineAnimation REGB_OperatorControl REGB_OpNoMask REGB_Particle_AgeRangeCtrls REGB_Particle_EmitterCtrls REGB_Particle_ProbabilityCtrls REGB_Particle_RandomSeedCtrls REGB_Particle_RegionCtrls REGB_Particle_RegionModeCtrls REGB_Particle_SetCtrls REGB_Particle_StyleCtrls REGB_Preview_CanCopyAnim REGB_Preview_CanCopyImage REGB_Preview_CanCreateAnim REGB_Preview_CanDisplayImage REGB_Preview_CanNetRender REGB_Preview_CanPlayAnim REGB_Preview_CanRecord REGB_Preview_CanSaveAnim REGB_Preview_CanSaveImage REGB_Preview_UsesFilenames REGB_Source_AspectCtrls REGB_Source_GlobalCtrls REGB_Source_SizeCtrls REGB_Unpredictable REGI_ClassType REGI_ClassType2 REGI_DataType REGI_HelpID REGI_InputDataType REGI_Logo REGI_MediaFormat_Priority REGI_MergeDataType REGI_OpIcon REGI_Particle_DefaultRegion REGI_Particle_DefaultStyle REGI_PI_DataSize REGI_Priority REGI_TileID REGI_Version Registry Attributes REGS_Category REGS_HelpFile REGS_HelpTopic REGS_IconID REGS_ID REGS_MediaFormat_FormatName REGS_Name REGS_OpDescription REGS_OpIconString REGS_OpToolTip REGS_ScriptName REGST_MediaFormat_Extension Render Fusion Comps in Houdini TOPs Resources Running Scripts From Fusion Expression Fields</p> <p>Scripting Guide SDF_Font_Example sign() SketchFab in VR Via QuestLink Software Packaging and Deployment Tools Software Required Spatial Audio Tools Swizzling System Admin Resources</p> <p>The Karta Development Journey The Kartaverse Packages TitleBurnEffect Todo Tool Troubleshooting Guide for Fusion Studio Freeze Ups</p> <p>Using BBEdit on macOS Using Notepad++ for Fusion on Windows</p> <p>Video Village Virtual Production Vonk Essentials Vonk Node Cookbook Vonk Node Reference Guide Vonk Scripts Vonk Ultra Voronoi Diagram VS Code</p> <p>WebGL to DCTL Workflows Working With Environment Variables Writing and publishing packages</p> <p>YouTube 360 to Equirectangular Conversions</p>"},{"location":"Todo/","title":"Todo","text":"<p>This is more kind of nmbr73's personal notes and to-do list. Maybe better to organize them as Github issues or something similar.</p>"},{"location":"Todo/#potential-sources","title":"Potential Sources","text":"<p>There's a lot of material we could start with and which is available. But it must be checked what of it may be used under which conditions! Then each option needs to be examined, if and how an initial import can be done - but most of it will probably require some scripting and/or lots of manual effort. Anyways, feel free to extend this list with interesting sources you know of:</p> <ul> <li>Andrew Hazelden has written hundreds of pages of documentation that he shared with the community</li> <li>Roger Magnusson's Fusion Class Browser could deliver lots of API definitions</li> <li>rne1223 has structured a lot of information for his fuse-snippets</li> <li>VFxPedia contains a lot of (still valid) information that could serve as a basis</li> <li>There are many threads in the WSL forum that are written and structured in the format of an article or  documentation - and others that would deserve it to get rewritten as a more digestible article</li> <li>The BMD ASCII files in the developers examples could be a good start to extend and experiment</li> </ul>"},{"location":"Todo/#status","title":"Status","text":"<p>Scrivener exports:</p> <ul> <li> Immersive Pipeline Integration Guide</li> <li> KartaVision</li> <li> Vonk Ultra</li> <li> Krokodove Essentials</li> <li> Kartaverse Workflows</li> </ul> <p>WSL-Posts worth it (and allowed) to be copied:</p> <ul> <li> Running Scripts From Fusion Expression Fields \u2192 Running Scripts From Fusion Expression Fields</li> </ul>"},{"location":"Todo/#tasks","title":"Tasks","text":"<p>I'm currently investigating - how to import the different sources into Obsidian, - how to make the vault well prepared for MkDocs, - how to structure the MkDocs so that it is well suited for a (Media)Wiki.</p> <ul> <li> Import all the Scrivener document (no reformatting, only get everything in here to be able to get things going). Status: done so far; \"only\" the pipeline guide left to be exported into the Wiki (seems to be done already?!? see Immersive Pipeline Integration Guide).</li> <li> Find a soluton for 'index.md' file. The 'Folder/Folder.md' files should act as such.</li> <li> Find a better rendering for the navigation - <code>awesome-pages</code> is nice, but does not really work for this wiki. I want to see only the items of the current subpage (files and folder), with the main article (index, aka 'Folder/Folder.md') on top and the subfolders not expanding, but lading to the navigation of that subfolder.</li> <li> Checkout if there is a way to integrate some breadcrump navigation with MkDoc in general or Material for MkDocs in particular.</li> <li> The <code>roamlinks</code> have an error: they substitute URLs in code blocks with Markdown link markup, which then is - being within a code block - shown as Markdown markup and not as a link (see for example Running Scripts From Fusion Expression Fields).</li> <li> Checkout the different export options of Scrivener (used by Andrew; <code>brew install --cask scrivener</code>)</li> <li> Allow for an easy local run of what currently the GitHub Action does; to allow everyone to test the scripts and the MkDocs output. Guess running a simple Docker container would be the best option for this.</li> <li> Write a script to split a large .md file into single files on the basis of top-level headlines; this would allow to generate an index / toc file that lists each file in the correct order</li> <li> Should think about what I use and how to map it to a MediaWiki afterwards; e.g. folders could serve as categories and the index.md files as description of the respective category. Folder == Subpages; Tags == Categories.</li> <li> Write a script to make the Obsidian files better suited for MkDocs: Convert file names in URL friendly names whilst maintaining the links in the MarkDown; Add the original filename as a top level heading in each file; rename the foldername.md to an index.md whilst maintaining the links; etc.</li> <li> Some time ago I played with the Fusion Class Browser to make it export some MarkDown files; have not yet got far with that solution, but still I believe its better to make the code create a clean export instead of cleaning it up afterwards; idk, however, first I have to find my old code on my hard disk</li> <li> Would be good to have some custom MarkDown extensions; i.e. having API descriptions integrated in a format that could be scanned for reuse it for intellisense and such would be great; trying to cleanly embed YouTube videos could be an experiment to start with ... first these must be implemented for Obsidian (see maybe obsidian-simple-embeds and in particular obsidian-thumbnails to play with it), and then maybe a MkDocs extension is needed to render it (or a quick and dirty script that patches the .md before it gets processed by MkDocs - not clean, but would work for other tools too).</li> </ul>"},{"location":"Foundations/Bokeh/","title":"Bokeh","text":"<p>...</p> <ul> <li>Bokeh (Wikipedia)</li> <li>Kernel (image processing) (Wikipedia)</li> <li>Bokeh Depth of Field (Unreal Development Kit)</li> </ul>"},{"location":"Foundations/Computer%20Vision/","title":"Computer Vision","text":"<p>Computer Vision Awesome Computer Vision</p>"},{"location":"Foundations/Fast%20Fourier%20Transform%20%28FFT%29/","title":"Fast Fourier Transform (FFT)","text":"<p>The following YouTube video provides some digestible explanation and interesting background information on the Fast Fourier transform:</p>","tags":["Theory"]},{"location":"Foundations/Novel-view%20synthesis/","title":"Novel view synthesis","text":"<p>View synthesis takes a pictures (or a number of pictures) of a subject and aims to create new views, or so to say novel views, of that subject. 3D reconstruction, the creation of three-dimensional models from a set of images, is a view synthesis that tries to reverse the process of obtaining 2D images from 3D scenes. The task of generating new images that render a subject from a different viewpoint than the one given is called a novel view synthesis.</p> <p>Approaches to synthesize novel views are for example NeRF and Photogrammetry.</p> <ul> <li>The Difference Between NeRF And Photogrammetry 3D Scan</li> </ul>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#photogrammetry-3d-scan","title":"Photogrammetry 3D Scan","text":"<p>...</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#sdf","title":"SDF","text":"<p>Single Distance Functions</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#neural-graphics-primitives-ngp","title":"Neural Graphics Primitives (NGP)","text":"<p>NeRFs, SDFs, neural images, neural volumes ... are all NGPs</p> <p>Paper: Instant Neural Graphics Primitives with a Multiresolution Hash Encoding Project Page: https://nvlabs.github.io/instant-ngp/ GitHub: https://github.com/NVlabs/instant-ngp</p> <p>Installation: Instant-NGP Windows Installation Tutorial</p> <p>Neural Scene Flow Fields</p> <p>...</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#radiance-fields","title":"Radiance Fields","text":"<p>...</p> <ul> <li>Apple: Learning to Generate Radiance Fields of Indoor Scenes</li> </ul>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#plenoxels","title":"Plenoxels","text":"<p>Radiance Fields without Neural Networks</p> <p>https://alexyu.net/plenoxels/</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#neural-radiance-fields-nerfs","title":"Neural Radiance Fields (NeRFs)","text":"<p>Awesome List: Awesome Neural Radiance Fields - A curated list of awesome neural radiance fields papers Die Studie: https://www.matthewtancik.com/nerf gut erkl\u00e4rt: https://www.youtube.com/watch?v=CRlN-cYFxTk weniger gut erkl\u00e4rt, aber trotzdem: https://youtu.be/WSfEfZ0ilw4 Die Geschichte, Varianten, etc. https://youtu.be/IDMiMKWucaI Mal angucken: Jon Barron - Understanding and Extending Neural Radiance Fields</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#novel-sota-in-ultra-high-resolution-nerf","title":"novel SOTA in Ultra High Resolution NeRF","text":"<p>SOTA?</p> <p>4K resolution interactive NeRF rendering support is now possible via work by Alibaba's research team: https://github.com/frozoul/4K-NeRF</p> <p>LinkedIn post about it: https://www.linkedin.com/feed/update/urn:li:activity:7008109018070044674/</p> <p>Clips in 4K: https://github.com/frozoul/4K-NeRF/blob/main/4K_results/horns_compare.mp4</p> <p>The research paper itself: http://arxiv.org/pdf/2212.04701.pdf</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#adop","title":"ADOP","text":"<p>Approximate Differentiable One-Pixel Point Rendering, a novel point-based, differentiable neural rendering pipeline.</p> <p>Video: ADOP: Approximate Differentiable One-Pixel Point Rendering Video: AI Creates Smooth Videos from Images! Paper: https://arxiv.org/abs/2110.06635 GitHub: https://github.com/darglein/ADOP</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#instant-nerf","title":"Instant NeRF","text":"<p>Instant NeRF by NVIDIA (see https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/, and https://www.nvidia.com/en-us/on-demand/session/siggraph2022-sigg22-s-16/)</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#direct-voxel-grid-optimization","title":"Direct Voxel Grid Optimization","text":"<p>Direct Voxel Grid Optimization (short: DVGO; aka DirectVoxGO). Super-fast Convergence for Radiance Fields Reconstruction.</p> <p>GitHub: https://github.com/sunset1995/DirectVoxGO Page: https://sunset1995.github.io/dvgo/ Video: Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#stereo-radiance-fields-srf","title":"Stereo Radiance Fields (SRF)","text":"<p>Stereo Radiance Fields (SRF) is neural view synthesis approach that is trained end-to-end, generalizes to new scenes in a single forward pass, and requires only sparse views at test time.</p> <p>Video: Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes Page: https://virtualhumans.mpi-inf.mpg.de/srf/ Code: https://github.com/jchibane/srf</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#turbonerf","title":"TurboNeRF","text":"<p>jperldev: - https://youtu.be/TeWYAbhgaiU ... video explaining TurboNeRF for Blender - https://github.com/JamesPerlman/TurboNeRF-Blender - https://docs.google.com/document/d/1ilywYoQZ9SuD69yE5Pw-fOlJ-lDAAYigG_tIStacP-8/edit ... install guide by Andrew</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#meganerf","title":"MegaNeRF","text":"<p>Mega-NeRF: Scalable Construction of Large-Scale NeRFs for Virtual Fly-Throughs</p> <ul> <li>https://github.com/cmusatyalab/mega-nerf</li> <li>https://github.com/cmusatyalab/mega-nerf-viewer</li> </ul>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#plenoctrees","title":"PlenOctrees","text":"<p>Video: PlenOctrees for Real-time Rendering of Neural Radiance Fields Video: Real-time rendering of NeRFs with PlenOctrees - Angjoo Kanazawa Page: https://alexyu.net/plenoctrees/ Code: sxyu/volrend PlenOctree Volume Rendering Code: sxyu/nerfvis (readthedocs()</p> <p>Darauf basiert wohl der MegaNerf Viewer</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#compile-sxyuvolrend-on-m1-macs","title":"Compile sxyu/volrend on M1 Macs","text":"<p>Build instructions are staight forward - only two minor changes needed to build on ARM: <pre><code>export LIBRARY_PATH=$LIBRARY_PATH:/opt/homebrew/lib/; export ```\n</code></pre></p> <pre><code>CPLUS_INCLUDE_PATH=\"/usr/local/Cellar/glfw/3.3.4/include\"; make -j8\n</code></pre> <p>Texture size of the full resolution tree files does exceed some OpenGL limit on Apple silicon ... found some smaller resolution variants (for the web viewer iirc) that work - but I can't recall from where I had them.</p> <p></p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#nerf","title":"NeRF++","text":"<p>Video: Vladlen Koltun: Towards Photorealism (September 2020)</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#pixelnerf","title":"pixelNeRF","text":"<p>Video: pixelNeRF: Neural Radiance Fields from One or Few Images</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#donerf","title":"DONeRF","text":"<p>Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks</p> <p>Video: https://www.youtube.com/watch?v=6UE1dMUjN_E Paper: https://arxiv.org/abs/2103.03231 Page: https://depthoraclenerf.github.io</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Novel-view%20synthesis/#nerfies","title":"nerfies","text":"<p>https://nerfies.github.io</p>","tags":["3D-Scan","Research","Glossary"]},{"location":"Foundations/Video%20Village/","title":"Video Village","text":"<p>https://www.evercast.us/blog/video-village-on-set</p>","tags":["Glossary"]},{"location":"Foundations/Voronoi%20Diagram/","title":"Voronoi Diagram","text":"<p>A Voronoi diagram ....</p> <p>smooth voroni by Inigo Quilez</p> <p>voroni lines by Inigo Quilez</p>","tags":["Theory"]},{"location":"Fusion/Config/","title":"Config/","text":"<p>Information and examples can be found here:</p> <ul> <li>Hotkey Configuration in Fusion 8: https://www.steakunderwater.com/wesuckless/viewtopic.php?f=16&amp;t=724</li> <li>Menu configuration in Fusion 8.1: https://www.steakunderwater.com/wesuckless/viewtopic.php?f=16&amp;t=1246</li> <li>Log Enabler: https://www.steakunderwater.com/wesuckless/viewtopic.php?p=37161#p37161</li> </ul> <p>... which could be a good basis to start an article\u00a0:-)</p> <p>See also: - Environment Variables</p>"},{"location":"Fusion/DCTL/","title":"DCTL","text":"<p>The DaVinci Resolve Color Transformation Language (better known under its abbreviation DCTL) is ...</p> <p>See also: - Fusion/WebGL to DCTL/Conversion</p>","tags":["glossary"]},{"location":"Fusion/Directory%20Structure/","title":"Directory Structure","text":"<p>On macOS find the user specific extensions under</p> macOSWindows <pre><code>~/Library/Application Support/Blackmagic Design/\n</code></pre> <p>and for system wide files in</p> <pre><code>/Library/Application Support/Blackmagic Design\n</code></pre> <pre><code>...\n</code></pre> <p>In the user folder ...</p> <p>Fusion  \u251c\u2500\u2500 [[Bins|Bins/]]  \u251c\u2500\u2500  [[Brushes]]  \u251c\u2500\u2500  Config/  \u251c\u2500\u2500  [[Scripts|Scripts/]]  \u2502   \u251c\u2500\u2500  Comp/  \u2502   \u251c\u2500\u2500  Job/  \u2502   \u2514\u2500\u2500  RenderNode/</p>"},{"location":"Fusion/Download%20Links/","title":"Download Links","text":"<p>For your convenience, please find below all the download links for Resolve (with Fusion page) releases that are available on the Blackmagic Design\u00a0support page</p> <p>Todo</p> <p>It would be great to be allowed to incorporate SecondMans's Fusion official download links to complement this page.</p>"},{"location":"Fusion/Download%20Links/#latest","title":"Latest","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-studio","title":"DaVinci Resolve Studio","text":"<p>Resolve Studio 18.1.2 for Mac OS X Resolve Studio 18.1.2 for Windows Resolve Studio 18.1.2 for Linux</p>"},{"location":"Fusion/Download%20Links/#davinci-resolve","title":"DaVinci Resolve","text":"<p>Resolve 18.1.2 for Mac OS X Resolve 18.1.2 for Windows Resolve 18.1.2 for Linux</p>"},{"location":"Fusion/Download%20Links/#fusion-studio","title":"Fusion Studio","text":"<p>...</p>"},{"location":"Fusion/Download%20Links/#fusion","title":"Fusion","text":"<p>...</p>"},{"location":"Fusion/Download%20Links/#fusion-connetc","title":"Fusion Connetc","text":"<p>...</p>"},{"location":"Fusion/Download%20Links/#resolve-project-server","title":"Resolve Project Server","text":"<p>DaVinci Resolve Project Server 18.1.1 for Mac OS X DaVinci Resolve Project Server 18.1.1 for Windows</p>"},{"location":"Fusion/Download%20Links/#blackmagic-fairlight-sound-library","title":"Blackmagic Fairlight Sound Library","text":"<p>Fairlight Sound Library 1 for Mac OS X Fairlight Sound Library 1 for Windows Fairlight Sound Library 1 for Linux</p>"},{"location":"Fusion/Download%20Links/#pdf-documentation","title":"PDF Documentation","text":"<p>Fusion 18 GPU Accelerated Tool Comparison Guide DaVinci Resolve Studio 18 Features DaVinci Resolve Studio 18 Supported Codecs DaVinci Resolve 18 Manual Fusion 18 User Manual Fuse Plugin Guide and Reference DaVinci Resolve Wide Gamut Intermediate Fusion 8 Scripting Guide</p>"},{"location":"Fusion/Download%20Links/#video-ddocumentation","title":"Video Ddocumentation","text":"<p>What\u2019s New in DaVinci Resolve 18.1</p>"},{"location":"Fusion/Download%20Links/#archive","title":"Archive","text":""},{"location":"Fusion/Download%20Links/#resolve-studio","title":"RESOLVE STUDIO","text":"<p>Resolve Studio 18.1.2 for Mac OS X Resolve Studio 18.1.2 for Windows Resolve Studio 18.1.2 for Linux</p> <p>Resolve Studio 18.1 for Mac OS X Resolve Studio 18.1 for Windows Resolve Studio 18.1 for Linux</p> <p>Resolve Studio 18.0.4 for Mac OS X Resolve Studio 18.0.4 for Windows Resolve Studio 18.0.4 for Linux</p> <p>Resolve Studio 18.0.3 for Mac OS X Resolve Studio 18.0.3 for Windows Resolve Studio 18.0.3 for Linux</p> <p>Resolve Studio 18.0.2 for Mac OS X Resolve Studio 18.0.2 for Windows Resolve Studio 18.0.2 for Linux</p> <p>Resolve Studio 18.0.1 for Mac OS X Resolve Studio 18.0.1 for Windows Resolve Studio 18.0.1 for Linux</p> <p>Resolve Studio 18.0 for Mac OS X Resolve Studio 18.0 for Windows Resolve Studio 18.0 for Linux</p> <p>Resolve Studio 17.4.6 for Mac OS X Resolve Studio 17.4.6 for Windows Resolve Studio 17.4.6 for Linux</p> <p>Resolve Studio 17.4.5 for Mac OS X Resolve Studio 17.4.5 for Windows Resolve Studio 17.4.5 for Linux</p> <p>Resolve Studio 17.4.4 for Mac OS X Resolve Studio 17.4.4 for Windows Resolve Studio 17.4.4 for Linux</p> <p>Resolve Studio 17.4.3 for Mac OS X Resolve Studio 17.4.3 for Windows Resolve Studio 17.4.3 for Linux</p> <p>Resolve Studio 17.4.3 for Mac OS X Resolve Studio 17.4.3 for Windows Resolve Studio 17.4.3 for Linux</p> <p>Resolve Studio 17.4.2 for Mac OS X Resolve Studio 17.4.2 for Windows Resolve Studio 17.4.2 for Linux</p> <p>Resolve Studio 17.4.1 for Mac OS X Resolve Studio 17.4.1 for Windows Resolve Studio 17.4.1 for Linux</p> <p>Resolve Studio 17.4 for Mac OS X Resolve Studio 17.4 for Windows Resolve Studio 17.4 for Linux</p> <p>Resolve Studio 17.3.2 for Mac OS X Resolve Studio 17.3.2 for Windows Resolve Studio 17.3.2 for Linux</p> <p>Resolve Studio 17.3.1 for Mac OS X Resolve Studio 17.3.1 for Windows Resolve Studio 17.3.1 for Linux</p> <p>Resolve Studio 17.3 for Mac OS X Resolve Studio 17.3 for Windows Resolve Studio 17.3 for Linux</p> <p>Resolve Studio 17.2.2 for Mac OS X Resolve Studio 17.2.2 for Windows Resolve Studio 17.2.2 for Linux</p> <p>Resolve Studio 17.2.1 for Mac OS X Resolve Studio 17.2.1 for Windows Resolve Studio 17.2.1 for Linux</p> <p>Resolve Studio 17.2 for Mac OS X Resolve Studio 17.2 for Windows Resolve Studio 17.2 for Linux</p> <p>Resolve Studio 17.1.1 for Mac OS X Resolve Studio 17.1.1 for Windows Resolve Studio 17.1.1 for Linux</p> <p>Resolve Studio 17.1 for Mac OS X Resolve Studio 17.1 for Windows Resolve Studio 17.1 for Linux</p> <p>Resolve Studio 17 for Mac OS X Resolve Studio 17 for Windows Resolve Studio 17 for Linux</p> <p>Resolve Studio 16.2.8 for Mac OS X Resolve Studio 16.2.8 for Windows Resolve Studio 16.2.8 for Linux</p> <p>Resolve Studio 16.2.7 for Mac OS X Resolve Studio 16.2.7 for Windows Resolve Studio 16.2.7 for Linux</p> <p>Resolve Studio 16.2.6 for Mac OS X Resolve Studio 16.2.6 for Windows Resolve Studio 16.2.6 for Linux</p> <p>Resolve Studio 16.2.5 for Mac OS X Resolve Studio 16.2.5 for Windows Resolve Studio 16.2.5 for Linux</p> <p>Resolve Studio 16.2.4 for Mac OS X Resolve Studio 16.2.4 for Windows Resolve Studio 16.2.4 for Linux</p> <p>Resolve Studio 16.2.3 for Mac OS X Resolve Studio 16.2.3 for Windows Resolve Studio 16.2.3 for Linux</p> <p>Resolve Studio 16.2.2 for Mac OS X Resolve Studio 16.2.2 for Windows Resolve Studio 16.2.2 for Linux</p> <p>Resolve Studio 16.2.1 for Mac OS X Resolve Studio 16.2.1 for Windows Resolve Studio 16.2.1 for Linux</p> <p>Resolve Studio 16.2 for Mac OS X Resolve Studio 16.2 for Windows Resolve Studio 16.2 for Linux</p> <p>Resolve Studio 16.1.2 for Mac OS X Resolve Studio 16.1.2 for Windows Resolve Studio 16.1.2 for Linux</p> <p>Resolve Studio 16.1.1 for Mac OS X Resolve Studio 16.1.1 for Windows Resolve Studio 16.1.1 for Linux</p> <p>Resolve Studio 16.1 for Mac OS X Resolve Studio 16.1 for Windows Resolve Studio 16.1 for Linux</p> <p>Resolve Studio 16 for Mac OS X Resolve Studio 16 for Windows Resolve Studio 16 for Linux</p> <p>Resolve Studio 15.3.1 for Mac OS X Resolve Studio 15.3.1 for Windows Resolve Studio 15.3.1 for Linux</p> <p>Resolve Studio 15.3 for Mac OS X Resolve Studio 15.3 for Windows Resolve Studio 15.3 for Linux</p> <p>Resolve Studio 15.2.4 for Mac OS X Resolve Studio 15.2.4 for Windows Resolve Studio 15.2.4 for Linux</p> <p>Resolve Studio 15.2.3 for Mac OS X Resolve Studio 15.2.3 for Windows Resolve Studio 15.2.3 for Linux</p> <p>Resolve Studio 15.2.2 for Mac OS X Resolve Studio 15.2.2 for Windows Resolve Studio 15.2.2 for Linux</p> <p>Resolve Studio 15.2.1 for Mac OS X Resolve Studio 15.2.1 for Windows Resolve Studio 15.2.1 for Linux</p> <p>Resolve Studio 15.2 for Mac OS X Resolve Studio 15.2 for Windows Resolve Studio 15.2 for Linux</p> <p>Resolve Studio 15.1.2 for Mac OS X Resolve Studio 15.1.2 for Windows Resolve Studio 15.1.2 for Linux</p> <p>Resolve Studio 15.1.1 for Mac OS X Resolve Studio 15.1.1 for Windows Resolve Studio 15.1.1 for Linux</p> <p>Resolve Studio 15.1 for Mac OS X Resolve Studio 15.1 for Windows Resolve Studio 15.1 for Linux</p> <p>Resolve Studio 15.0.1 for Mac OS X Resolve Studio 15.0.1 for Windows Resolve Studio 15.0.1 for Linux</p> <p>Resolve Studio 15 for Mac OS X Resolve Studio 15 for Windows Resolve Studio 15 for Linux</p>"},{"location":"Fusion/Download%20Links/#resolve","title":"RESOLVE","text":"<p>Resolve 18.1.2 for Mac OS X Resolve 18.1.2 for Windows Resolve 18.1.2 for Linux</p> <p>Resolve 18.1 for Mac OS X Resolve 18.1 for Windows Resolve 18.1 for Linux</p> <p>Resolve 18.0.4 for Mac OS X Resolve 18.0.4 for Windows Resolve 18.0.4 for Linux</p> <p>Resolve 18.0.3 for Mac OS X Resolve 18.0.3 for Windows Resolve 18.0.3 for Linux</p> <p>Resolve 18.0.2 for Mac OS X Resolve 18.0.2 for Windows Resolve 18.0.2 for Linux</p> <p>Resolve 18.0.1 for Mac OS X Resolve 18.0.1 for Windows Resolve 18.0.1 for Linux</p> <p>Resolve 18.0 for Mac OS X Resolve 18.0 for Windows Resolve 18.0 for Linux</p> <p>Resolve 17.4.6 for Mac OS X Resolve 17.4.6 for Windows Resolve 17.4.6 for Linux</p> <p>Resolve 17.4.5 for Mac OS X Resolve 17.4.5 for Windows Resolve 17.4.5 for Linux</p> <p>Resolve 17.4.4 for Mac OS X Resolve 17.4.4 for Windows Resolve 17.4.4 for Linux</p> <p>Resolve 17.4.3 for Mac OS X Resolve 17.4.3 for Windows Resolve 17.4.3 for Linux</p> <p>Resolve 17.4.3 for Mac OS X Resolve 17.4.3 for Windows Resolve 17.4.3 for Linux</p> <p>Resolve 17.4.2 for Mac OS X Resolve 17.4.2 for Windows Resolve 17.4.2 for Linux</p> <p>Resolve 17.4.1 for Mac OS X Resolve 17.4.1 for Windows Resolve 17.4.1 for Linux</p> <p>Resolve 17.4 for Mac OS X Resolve 17.4 for Windows Resolve 17.4 for Linux</p> <p>Resolve 17.3.2 for Mac OS X Resolve 17.3.2 for Windows Resolve 17.3.2 for Linux</p> <p>Resolve 17.3.1 for Mac OS X Resolve 17.3.1 for Windows Resolve 17.3.1 for Linux</p> <p>Resolve 17.3 for Mac OS X Resolve 17.3 for Windows Resolve 17.3 for Linux</p> <p>Resolve 17.2.2 for Mac OS X Resolve 17.2.2 for Windows Resolve 17.2.2 for Linux</p> <p>Resolve 17.2.1 for Mac OS X Resolve 17.2.1 for Windows Resolve 17.2.1 for Linux</p> <p>Resolve 17.2 for Mac OS X Resolve 17.2 for Windows Resolve 17.2 for Linux</p> <p>Resolve 17.1.1 for Mac OS X Resolve 17.1.1 for Windows Resolve 17.1.1 for Linux</p> <p>Resolve 17.1 for Mac OS X Resolve 17.1 for Windows Resolve 17.1 for Linux</p> <p>Resolve 17 for Mac OS X Resolve 17 for Windows Resolve 17 for Linux</p> <p>Resolve 16.2.8 for Mac OS X Resolve 16.2.8 for Windows Resolve 16.2.8 for Linux</p> <p>Resolve 16.2.7 for Mac OS X Resolve 16.2.7 for Windows Resolve 16.2.7 for Linux</p> <p>Resolve 16.2.6 for Mac OS X Resolve 16.2.6 for Windows Resolve 16.2.6 for Linux</p> <p>Resolve 16.2.5 for Mac OS X Resolve 16.2.5 for Windows Resolve 16.2.5 for Linux</p> <p>Resolve 16.2.4 for Mac OS X Resolve 16.2.4 for Windows Resolve 16.2.4 for Linux</p> <p>Resolve 16.2.3 for Mac OS X Resolve 16.2.3 for Windows Resolve 16.2.3 for Linux</p> <p>Resolve 16.2.2 for Mac OS X Resolve 16.2.2 for Windows Resolve 16.2.2 for Linux</p> <p>Resolve 16.2.1 for Mac OS X Resolve 16.2.1 for Windows Resolve 16.2.1 for Linux</p> <p>Resolve 16.2 for Mac OS X Resolve 16.2 for Windows Resolve 16.2 for Linux</p> <p>Resolve 16.1.2 for Mac OS X Resolve 16.1.2 for Windows Resolve 16.1.2 for Linux</p> <p>Resolve 16.1.1 for Mac OS X Resolve 16.1.1 for Windows Resolve 16.1.1 for Linux</p> <p>Resolve 16.1 for Mac OS X Resolve 16.1 for Windows Resolve 16.1 for Linux</p> <p>Resolve 16 for Mac OS X Resolve 16 for Windows Resolve 16 for Linux</p> <p>Resolve 15.3.1 for Mac OS X Resolve 15.3.1 for Windows Resolve 15.3.1 for Linux</p> <p>Resolve 15.3 for Mac OS X Resolve 15.3 for Windows Resolve 15.3 for Linux</p> <p>Resolve 15.2.4 for Mac OS X Resolve 15.2.4 for Windows Resolve 15.2.4 for Linux</p> <p>Resolve 15.2.3 for Mac OS X Resolve 15.2.3 for Windows Resolve 15.2.3 for Linux</p> <p>Resolve 15.2.2 for Mac OS X Resolve 15.2.2 for Windows Resolve 15.2.2 for Linux</p> <p>Resolve 15.2.1 for Mac OS X Resolve 15.2.1 for Windows Resolve 15.2.1 for Linux</p> <p>Resolve 15.2 for Mac OS X Resolve 15.2 for Windows Resolve 15.2 for Linux</p> <p>Resolve 15.1.2 for Mac OS X Resolve 15.1.2 for Windows Resolve 15.1.2 for Linux</p> <p>Resolve 15.1.1 for Mac OS X Resolve 15.1.1 for Windows Resolve 15.1.1 for Linux</p> <p>Resolve 15.1 for Mac OS X Resolve 15.1 for Windows Resolve 15.1 for Linux</p> <p>Resolve 15.0.1 for Mac OS X Resolve 15.0.1 for Windows Resolve 15.0.1 for Linux</p> <p>Resolve 15 for Mac OS X Resolve 15 for Windows Resolve 15 for Linux</p>"},{"location":"Fusion/Download%20Links/#resolve-project-server_1","title":"RESOLVE PROJECT SERVER","text":"<p>DaVinci Resolve Project Server 18.1.1 for Mac OS X DaVinci Resolve Project Server 18.1.1 for Windows</p> <p>DaVinci Resolve Project Server 18.1 for Mac OS X DaVinci Resolve Project Server 18.1 for Windows</p> <p>DaVinci Resolve Project Server 18.0.2 for Mac OS X DaVinci Resolve Project Server 18.0.2 for Windows</p> <p>DaVinci Resolve Project Server 18.0.1 for Mac OS X DaVinci Resolve Project Server 18.0.1 for Windows</p> <p>DaVinci Resolve Project Server 18.0 for Mac OS X DaVinci Resolve Project Server 18.0 for Windows</p> <p>DaVinci Resolve Project Server 17.4.1 for Mac OS X DaVinci Resolve Project Server 17.4.1 for Windows</p> <p>DaVinci Resolve Project Server 17.3 for Mac OS X DaVinci Resolve Project Server 17.3 for Windows</p> <p>DaVinci Resolve Project Server 17.1 for Mac OS X DaVinci Resolve Project Server 17.1 for Windows</p> <p>DaVinci Resolve Project Server 17 for Mac OS X DaVinci Resolve Project Server 17 for Windows</p>"},{"location":"Fusion/Download%20Links/#blackmagic-fairlight-sound-library_1","title":"BLACKMAGIC FAIRLIGHT SOUND LIBRARY","text":"<p>Fairlight Sound Library 1 for Mac OS X Fairlight Sound Library 1 for Windows Fairlight Sound Library 1 for Linux</p>"},{"location":"Fusion/Download%20Links/#video-documentation","title":"Video DOCUMENTATION","text":"<p>What\u2019s New in DaVinci Resolve 18.1</p>"},{"location":"Fusion/Download%20Links/#pdf-documentation_1","title":"PDF DOCUMENTATION","text":"<p>Fusion 18 GPU Accelerated Tool Comparison Guide DaVinci Resolve Studio 18 Features DaVinci Resolve Studio 18 Supported Codecs DaVinci Resolve 18 Manual Fusion 18 User Manual Fuse Plugin Guide and Reference DaVinci Resolve 17 Manual Fusion 17 User Manual DaVinci Resolve 17 New Features Guide DaVinci Resolve Wide Gamut Intermediate DaVinci Resolve 16 Manual DaVinci Resolve 16 Supported Codecs DaVinci Resolve 15 Configuration Guide DaVinci Resolve 16 New Features Guide DaVinci Resolve 15 Manual Fusion 8 Scripting Guide</p>"},{"location":"Fusion/Download%20Links/#other-list","title":"Other list","text":"<p>Incorporate / rework (maybe)</p>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-17","title":"Davinci Resolve &amp; Fusion 17","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-10","title":"Davinci Resolve &amp; Fusion 17.1 Beta 10","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-10-free-version","title":"Davinci Resolve 17.1 Beta 10 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-10-studio","title":"Davinci Resolve 17.1 Beta 10 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-10","title":"Fusion Standalone 17.1 Beta 10","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-17_1","title":"Davinci Resolve &amp; Fusion 17","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-17-stable-release-free-version","title":"Davinci Resolve 17 Stable Release Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-17-stable-release-studio","title":"Davinci Resolve 17 Stable Release Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-17-stable-release-version","title":"Fusion Standalone 17 Stable Release Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-9","title":"Davinci Resolve &amp; Fusion 17.1 Beta 9","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-9-free-version","title":"Davinci Resolve 17.1 Beta 9 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-9-studio","title":"Davinci Resolve 17.1 Beta 9 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-9-version","title":"Fusion Standalone 17.1 Beta 9 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-8","title":"Davinci Resolve &amp; Fusion 17.1 Beta 8","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-8-free-version","title":"Davinci Resolve 17.1 Beta 8 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-8-studio","title":"Davinci Resolve 17.1 Beta 8 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-8-version","title":"Fusion Standalone 17.1 Beta 8 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-7","title":"Davinci Resolve &amp; Fusion 17.1 Beta 7","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-7-free-version","title":"Davinci Resolve 17.1 Beta 7 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-7-studio","title":"Davinci Resolve 17.1 Beta 7 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-7-version","title":"Fusion Standalone 17.1 Beta 7 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-6","title":"Davinci Resolve &amp; Fusion 17.1 Beta 6","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-6-free-version","title":"Davinci Resolve 17.1 Beta 6 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-6-studio","title":"Davinci Resolve 17.1 Beta 6 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-6-version","title":"Fusion Standalone 17.1 Beta 6 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-5","title":"Davinci Resolve &amp; Fusion 17.1 Beta 5","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-5-free-version","title":"Davinci Resolve 17.1 Beta 5 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-5-studio","title":"Davinci Resolve 17.1 Beta 5 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-5-version","title":"Fusion Standalone 17.1 Beta 5 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-4","title":"Davinci Resolve &amp; Fusion 17.1 Beta 4","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-4-free-version","title":"Davinci Resolve 17.1 Beta 4 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-4-studio","title":"Davinci Resolve 17.1 Beta 4 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-4-version","title":"Fusion Standalone 17.1 Beta 4 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-171-beta-3","title":"Davinci Resolve &amp; Fusion 17.1 Beta 3","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-3-free-version","title":"Davinci Resolve 17.1 Beta 3 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-3-studio","title":"Davinci Resolve 17.1 Beta 3 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-171-beta-3-version","title":"Fusion Standalone 17.1 Beta 3 Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-2","title":"Davinci Resolve 17.1 Beta 2","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-2-free-version","title":"Davinci Resolve 17.1 Beta 2 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-2-studio","title":"Davinci Resolve 17.1 Beta 2 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-1","title":"Davinci Resolve 17.1 Beta 1","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-1-free-version","title":"Davinci Resolve 17.1 Beta 1 Free Version","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-171-beta-1-studio","title":"Davinci Resolve 17.1 Beta 1 Studio","text":"<ul> <li>macOS</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-16","title":"Davinci Resolve &amp; Fusion 16","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1628-update","title":"Davinci Resolve &amp; Fusion 16.2.8 Update","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1628-free-version","title":"Davinci Resolve 16.2.8 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1628-studio","title":"Davinci Resolve 16.2.8 Studio","text":"<ul> <li> <p>Windows [https://www.blackmagicdesign.com/support/download/7e8656e2d76240ef8923609655d70fb6/Windows MacOS]</p> </li> <li> <p>Linux</p> </li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1627","title":"Davinci Resolve &amp; Fusion 16.2.7","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1627-free-version","title":"Davinci Resolve 16.2.7 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1627-studio","title":"Davinci Resolve 16.2.7 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1626","title":"Davinci Resolve &amp; Fusion 16.2.6","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1626-free-version","title":"Davinci Resolve 16.2.6 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1626-studio","title":"Davinci Resolve 16.2.6 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1625","title":"Davinci Resolve &amp; Fusion 16.2.5","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1625-free-version","title":"Davinci Resolve 16.2.5 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1625-studio","title":"Davinci Resolve 16.2.5 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1624","title":"Davinci Resolve &amp; 16.2.4","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1624-free-version","title":"Davinci Resolve 16.2.4 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1624-studio","title":"Davinci Resolve 16.2.4 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-1624","title":"Fusion Standalone 16.2.4","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1623","title":"Davinci Resolve &amp; Fusion 16.2.3","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1623-free-version","title":"Davinci Resolve 16.2.3 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1623-studio","title":"Davinci Resolve 16.2.3 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-1623","title":"Fusion Standalone 16.2.3","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1622","title":"Davinci Resolve &amp; Fusion 16.2.2","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1622-free-version","title":"Davinci Resolve 16.2.2 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1622-studio","title":"Davinci Resolve 16.2.2 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-1622","title":"Fusion Standalone 16.2.2","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1621","title":"Davinci Resolve &amp; Fusion 16.2.1","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1621-free-version","title":"Davinci Resolve 16.2.1 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1621-studio","title":"Davinci Resolve 16.2.1 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-1621","title":"Fusion Standalone 16.2.1","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-162","title":"Davinci Resolve &amp; Fusion 16.2","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-162-free-version","title":"Davinci Resolve 16.2 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-162-studio","title":"Davinci Resolve 16.2 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-162","title":"Fusion Standalone 16.2","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1612","title":"Davinci Resolve 16.1.2","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1612-free-version","title":"Davinci Resolve 16.1.2 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1612-studio","title":"Davinci Resolve 16.1.2 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-1611","title":"Davinci Resolve &amp; Fusion 16.1.1","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-1611-free-version","title":"Davinci Resolve 16.1.1 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-1611-studio","title":"Davinci Resolve 16.1.1 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-1611","title":"Fusion Standalone 16.1.1","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-161","title":"Davinci Resolve &amp; Fusion 16.1","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-161-free-version","title":"Davinci Resolve 16.1 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-161-studio","title":"Davinci Resolve 16.1 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-161","title":"Fusion Standalone 16.1","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-fusion-16_1","title":"Davinci Resolve &amp; Fusion 16","text":""},{"location":"Fusion/Download%20Links/#davinci-resolve-16-free-version","title":"Davinci Resolve 16 Free Version","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#davinci-resolve-16-studio","title":"Davinci Resolve 16 Studio","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Download%20Links/#fusion-standalone-16","title":"Fusion Standalone 16","text":"<ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"Fusion/Environment%20Variables/","title":"Environment Variables","text":"<p>In Lua you can access system ENV variables via: <pre><code> os.getenv(\"NAME\")\n````\nYou can use ...\n```lua\n OBJECT:SetPrefs('Global.EnvironmentVars.NAME',VALUE)\n OBJECT:GetPrefs('Global.EnvironmentVars.NAME')\n</code></pre> ... to set, resp. get preferences.</p> <p>Where OBJECT is ... <pre><code> GetPrefs('Global.EnvironmentVars.NAME')                         -- ...\n app:GetPrefs('Global.EnvironmentVars.NAME')                     -- in a Fusion Script\n comp:GetPrefs('Global.EnvironmentVars.NAME')                    -- ...\n composition:GetPrefs('Global.EnvironmentVars.NAME')             -- ...\n Comp():GetPrefs('Global.EnvironmentVars.NAME')                  -- ...\n fusion:GetCurrentComp():GetPrefs('Global.EnvironmentVars.NAME') -- ...\n fusion:GetPrefs('Global.EnvironmentVars.NAME')                  -- ...\n self.Comp:GetPrefs('Global.EnvironmentVars.NAME')               -- in the Process() callback of a Fuse\n</code></pre> ... see [[Global Variables and Scopes]]</p> <p>See also: - Config</p>"},{"location":"Fusion/FuScript/","title":"FuScript","text":"<p>Complex workflows can be automated in Fusion through the use of the FuScript command line process which runs from the command prompt and allows you to execute Lua and [[Python]] code. FuScript also allows remote network socket-based app intercommunication to other copies of Resolve Studio, Fusion Studio, Fusion Render Node, Fusion Render Manager, Fusion Bin Server, and Generation that are active on your local network subnet.</p>"},{"location":"Fusion/Fuse%20Writing%20Manual/","title":"Fuse Writing Manual","text":"<p>A Fuse is a script plug-in for Fusion that is written in Lua language.</p> <p>Fuses are not compiled plug-ins, and can also work in the free version of Fusion.</p> <p>Developers do not need to obtain the Fusion SDK in order to write fuses.</p> <p>This is a guide on how to write your own Fuses.</p>"},{"location":"Fusion/Fuse%20Writing%20Manual/#getting-started","title":"Getting Started","text":"<p>Fuses are standard text file that contain Lua code that does the operation that the fuse is meant to do.</p> <p>The text file has to be named with a .fuse file extension in order for Fusion to recognize it as a tool.</p> <p>Fuse files to be placed into a special folder so that Fusion can load the Fuse when you start.</p> <p>In order to know which folder the fuses need to be placed in, copy and paste the following script into your Fusion console and hit Enter on your keyboard.  bmd.openfileexternal(\"Open\", comp:MapPath(\"Fuses:/\")) This script will open the folder where you should keep your fuses. Once the folder is open, you can add it to your quick access so that you can find it easily.</p>"},{"location":"Fusion/Fuse%20Writing%20Manual/#registering-a-fuse","title":"Registering a Fuse","text":"<p>...</p>"},{"location":"Fusion/Fuse/","title":"Fuse","text":"<p>A ''Fuse'' is a script [[Plug-in|plug-in]] for Fusion that is written in the Lua scripting language.</p> <p>Fuses are not pre-compiled plug-ins but integrate with Fusion like any other Tool, and can also work in the free version of Fusion.</p> <p>Here is a list of some things that fuses can do:</p> <ul> <li>Apply Color Correction Effects</li> <li>Apply Transform and Warping Effects</li> <li>Apply Blur and Glow Effects</li> <li>Draw Shapes and Patterns</li> <li>Modify Parameters on other Fusion Tools</li> <li>And More</li> </ul> <p>To learn more about how to write fuses our Fuse Writing Manual.</p> <p>You can download some very useful Fuses from Reactor and our [[Third Party Fuses]] page.</p>","tags":["Glossary"]},{"location":"Fusion/Fusion%20built%20in%20Tools/","title":"Fusion built in Tools","text":"<p>Find here each Tool that comes built into Fusion. Most Tools can be used in the free version of Fusion, while some Tools can only be used in the Studio Versions of Fusion and Davinci Resolve.</p>","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#3d-tools","title":"3D Tools","text":"<p>[[Alembic Mesh 3D]] (ABc)</p> <p>[[Bender 3D]] (3Bn)</p> <p>[[Camera 3D]] (3Cm)</p> <p>[[Cube 3D]] (3Cb)</p> <p>[[Custom Vertex 3D]] (3Cv)</p> <p>[[Displace 3D]] (3Di)</p> <p>[[Duplicate 3D]] (3Dp)</p> <p>[[FBX Exporter 3D]] (FBX)</p> <p>[[FBX Mesh 3D]] (FBX)</p> <p>[[Fog 3D]] (3Fo)</p> <p>[[Image Plane 3D]] (3Im)</p> <p>[[Locator 3D]] (3Lo)</p> <p>[[Merge 3D]] (3Mg)</p> <p>[[Override 3D]] (3Ov)</p> <p>[[Point Cloud 3D]] (3PC)</p> <p>[[Projector 3D]] (3Pj)</p> <p>[[Renderer 3D]] (3Rn)</p> <p>[[Replace Material 3D]] (3Rpl)</p> <p>[[Replace Normals 3D]] (3Rn)</p> <p>[[Replicate 3D]] (3Rep)</p> <p>[[Ribbon 3D]] (3Ri)</p> <p>[[Shape 3D]] (3Sh)</p> <p>[[SoftClip]] (3Sc)</p> <p>[[Text 3D]] (3Txt)</p> <p>[[Transform 3D]] (3Xf)</p> <p>[[Triangulate 3D]] (3Tri)</p> <p>[[UV Map 3D]] (3UV)</p> <p>[[Weld 3D]] (3We)</p>","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#3d-light-tools","title":"3D Light Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#3d-material-tools","title":"3D Material Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#3d-texture-tools","title":"3D Texture Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#blur-tools","title":"Blur Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#color-tools","title":"Color Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#composite-tools","title":"Composite Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#creator-tools","title":"Creator Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#deep-pixel-tools","title":"Deep Pixel Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#effect-tools","title":"Effect Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#film-tools","title":"Film Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#filter-tools","title":"Filter Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#flow-tools","title":"Flow Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#flow-org-tools","title":"Flow Org Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#fuses","title":"Fuses","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#io-tools","title":"I/O Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#lut-tools","title":"LUT Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#mask-tool","title":"Mask Tool","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#matte-tools","title":"Matte Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#metadata-tools","title":"Metadata Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#miscellaneous-tools","title":"Miscellaneous Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#modifiers","title":"Modifiers","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#optical-flow-tools","title":"Optical Flow Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#paint-tools","title":"Paint Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#particle-tools","title":"Particle Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#position-tools","title":"Position Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#shape-tools","title":"Shape Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#stereo-tools","title":"Stereo Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#tracker-tools","title":"Tracker Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#transform-tools","title":"Transform Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#vr-tools","title":"VR Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion%20built%20in%20Tools/#warp-tools","title":"Warp Tools","text":"","tags":["Reference"]},{"location":"Fusion/Fusion/","title":"Fusion","text":"<p>Blackmagic Fusion is a state of the art compositing software that is used by Hollywood VFX artists, Professional content creators and Hobbyists alike.</p> <p>Fusion is used for 3D and 2D compositing and Visual FX, Virtual Reality Production, Motion Graphics and more.</p>"},{"location":"Fusion/Fusion/#getting-started-with-fusion","title":"Getting Started with Fusion","text":"<p>It's recommend to start with the\u00a0Tutorial\u00a0on the\u00a0Official Blackmagic Design YouTube Channel.</p> <p>After that you can check out the YouTube channels on our\u00a0Krokodove\u00a0page.</p> <p>If you are coming from an After Effects or Nuke environment, check out our\u00a0[[After Effects to Fusion]]\u00a0and\u00a0[[Nuke to Fusion]]\u00a0Pages.</p>"},{"location":"Fusion/Fusion/#fusion-communities","title":"Fusion Communities","text":""},{"location":"Fusion/Fusion/#we-suck-less","title":"We Suck Less","text":"<p>There is a wonderful Fusion users community over at the\u00a0Steak Under Water\u00a0website.</p> <p>This forum is full of very knowledgeable and friendly Fusion users that might have gone through the same thing you're going through,</p> <p>so if you have any questions that you want to ask, then this will be the best place to ask.</p>"},{"location":"Fusion/Fusion/#the-blackmagic-design-forum","title":"The Blackmagic Design Forum","text":"<p>This is the\u00a0Official Forum\u00a0that is managed by the developers of Fusion,</p> <p>it isn't as active as WSL but it can be a great place to grab the attention of the developers to report bugs or issues with the software.</p>"},{"location":"Fusion/Fusion/#reactor","title":"Reactor","text":"<p>This is an amazing extension manager for Fusion.</p> <p>It allows you to install Scripts, Presets, Plug-ins and Comps that were created for the Community by the Community.</p> <p>Reactor is home to hundreds of Extensions that make Fusion more powerful than it already is.</p> <p>Here is that page where you can\u00a0Download Reactor</p>"},{"location":"Fusion/FusionSDK/","title":"FusionSDK","text":"<p>The FusionSDK is a BMD's software development kit to create Fusion Plugins using C/C++ code.</p> <p>The FusionSDK must be licensed under an NDA!</p> <p>The FusionSDK must be license from BMD under an NDA (Non Disclosure Agreement). The FusionSDK costs you $0 but has a signed PDF contract where you agree not to share BMDs header files from the SDK with others.</p> <p>The <code>.plugin</code> format allows low level access to Fusion's 3D workspace. You can also make plugins that have similar features to what is possible with an OpenFX plugin for 2D graphics.</p> <p>A Fuse  and an OFX (OpenFX) addon are a great way to get started with making custom node based tools in Resolve/Fusion.</p> <p>Plugins do work only in the Studio editions.</p> <p>The <code>.plugin</code> files only work in the payed \"DaVinci Resolve Studio\" and \"Fusion Studio\", not in \"DaVinci Resolve\" (free).</p> <p>The Krokodove plugin in Reactor is an example of a compiled FusionSDK based Tool, and so is LearnNowFX's AccuShaders PBR surface material system which is available on Gumroad. Both of those tools make excellent use of the Fusion page's 3D workspace.</p> <p>Being compiled software OpenFX plugins and FusionSDK plugins makes it easier to put a paid license management feature in place if releasing paid commercial software.</p>","tags":["Development"]},{"location":"Fusion/Resources/","title":"Resources","text":"<p>Real names of persons are listed on this page if and only if they are easily accessible on their internet presence anyway. Please make sure that you do not expose any personal information here otherwise!</p>","tags":["Resource"]},{"location":"Fusion/Resources/#documentation","title":"Documentation","text":"<ul> <li> <p>Scripting Guide</p> </li> <li> <p>Compositing with Blackmagic Fusion: Table of Contents and Glossary by Bryan Ray</p> </li> <li> <p>ResolveDevDoc is an unofficial documentation for scripting using Python and workflow integration with\u00a0Davinci Resolve</p> </li> <li> <p>Formatted Resolve Python API Docs (PDF, HTML) by Julian B\u00f6hme - links in the Blackmagic forum post</p> </li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#forums","title":"Forums","text":"<ul> <li> <p>We Suck Less\u00a0- The Friendliest Blackmagic Fusion Studio Community Online.</p> </li> <li> <p>The Blackmagic Design Forum\u00a0- The Official Fusion forum that is managed by the developers</p> </li> <li> <p>DaVinci Resolve Forum (German)</p> </li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#wsl-dev-threads","title":"WSL Dev Threads","text":"<ul> <li>Building GUIs With Fusion's UI Manager</li> <li>Macro Building Essentials</li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#facebook-groups","title":"Facebook Groups","text":"<ul> <li> <p>Fusion for Davinci Resolve Users\u00a0- A Group for people using the Fusion page Inside of Davinci Resolve. Managed by yours truly</p> </li> <li> <p>Fusion Artists\u00a0- A Group for Professional Fusion Artists</p> </li> <li> <p>Blackmagic Fusion User Group\u00a0- An Unofficial User Group Where You Can Discuss Fusion, Post Works, Share Info, and Ask for Help</p> </li> <li> <p>DaVinci Resolve Fusion\u00a0- This Group is for DaVinci Resolve Fusion Users. Welcome!</p> </li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#discord-servers","title":"Discord Servers","text":"<ul> <li> <p>Davinci Resolve Community\u00a0- A Great place to get quick answers to your questions. Managed by Jake Wipp</p> </li> <li> <p>Blackmagic Design Community\u00a0- A Large Server for Davinci Resolve and Fusion Users</p> </li> <li> <p>Pirates of Confusion\u00a0- A Ship Server of Professional Fusion VFX Artists</p> </li> <li> <p>Davinci Resolve Plug-in Developers</p> </li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#blogs","title":"Blogs","text":"<p>There are some really great blogs out there that can help you learn Fusion. Here is a list of some of them:</p> <ul> <li>Bryan Ray Visual FX\u00a0- The Everyday Life of Hollywood VFX Artist Bryan Ray</li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#wikis","title":"Wikis","text":"<ul> <li> <p>VFXPedia ... The WSL advanced search page allows searching of the VFXPedia pages by keyword. The Internet Archive \"Wayback Machine\" site has a full VFXPedia snapshot that is downloadable in a single archive.</p> </li> <li> <p>WikiFusion</p> </li> <li> <p>DaVinci Resolve Wiki (German)</p> </li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#git-repositories","title":"Git Repositories","text":"<ul> <li>We Suck Less / Reactor</li> <li>Alexey 'movalex' Bogomolov<ul> <li>BMD_requests - The most friendly list of requests for Blackmagic Design Fusion</li> <li>fusion - Fusion tools I use</li> </ul> </li> <li>bfloch / fusionscript</li> <li>Ember Light (EmberLightVFX) maintains some DaVinci Resolve / Fusion related repositories:</li> <li>Gyroflow to CSV - Convert your GyroFlow stabilization to a CSV file</li> <li>FuBar - A better searchbar for BMD Fusion</li> <li>Resolve Scripts - Collection of small scripts for BMD Davinci Resolve</li> <li>Tetrahedral Interpolation for Fusion</li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#youtube-channels","title":"YouTube Channels","text":"","tags":["Resource"]},{"location":"Fusion/Resources/#dedicated-dafusion-channels","title":"Dedicated DaFusion channels ...","text":"<ul> <li>Blackmagic Design</li> <li>eyeonsoftware with its last upload in 2014</li> <li>William Justice does a lot of crazy stuff in particular with scripting in DaFusion</li> <li>Chris Ridings' Improving Resolve is the de facto go to place when it comes to Fusion scripting</li> <li>Igor Ri\u0111anovi\u0107 gets you into scripting DaVinci Resolve</li> <li>David Kohen provides you on Learn Now FX with action packed DR tutorials for VFx and motion graphics</li> <li>Patrick Stirling has tons of awesome ideas on what you can do with Fusion</li> <li>VFXstudy</li> <li>The Pirates of Confusion</li> <li>Jake Wipp</li> <li>Simon Stansfield</li> <li>Casey Faris</li> <li>MrAlexTech</li> <li>Jamie Fenn</li> <li>A Blackbird Called Sue focused on delivering in-depth Blackmagic Fusion tutorials with all tutorials based on the free version</li> <li>Billy Rybka teaches you how to edit BOMB videos in Davinci Resolve</li> <li>JayAreTV mainly focuses around DaVinci Resolve and Fusion</li> <li>Josh Hanes</li> <li>Video Branding DIY</li> <li>The Modern Filmmaker</li> <li>Power Tips by David Power</li> <li>JiPi does demos of shaders implemented using DCTL</li> <li>Tida demos</li> <li>Resolve Training</li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#dafusion-and-such","title":"DaFusion and such ...","text":"<ul> <li>Nick Carter is That Modern Dude doing DR tutorials and other stuff</li> <li>Skyline Motions does Ae and DR</li> <li>The HowToGuy has single uploads on DR</li> <li>Creative Video Tips</li> </ul>","tags":["Resource"]},{"location":"Fusion/Resources/#other-languages","title":"Other Languages","text":"","tags":["Resource"]},{"location":"Fusion/Resources/#german","title":"German","text":"<ul> <li>MeinVideoStudio does mainly Fusion tutorials</li> <li>Sofjas DaVinci Tutorials</li> <li>Kai voll abgedreht does Fusion tutorials</li> <li>Davinci Resolve Tutorials</li> <li>Captain Sauerland</li> <li>Michael J. M\u00fcller</li> <li>Farbkanal focusses on color grading</li> </ul>","tags":["Resource"]},{"location":"Fusion/Scripting%20Guide/","title":"Scripting Guide","text":"<p>The Fusion 8 Scripting Guide and Reference Manual published in February 2016 explains the scripting API of Fusion called FusionScript.</p> <p>The Fuse Plugin Guide and Reference (aka Fusion Fuse SDK) published in July 2022 explains the development of Fusion PlugIns via Lua scription.</p>","tags":["Resource"]},{"location":"Fusion/Tool/","title":"Tool","text":"<p>Every node you place in the working area of Fusion is called a Tool. Such Tools are  - Fuses which are script plugins for Fusion written in the Lua scripting language, - OpenFX plugins, which are compiled component that can be used in every graphics software bale to act as an OFX host, or - Fusion Plugins, which are written as dynamic shared objects using the FusionSDK</p> <p>Tools can be added to the [[Nodes panel]] by accessing them via the [[Effects panel]], the Add Tool context menu, the [[Tools menu]], or the [[Select Tool dialog]].</p> <p>See also: - Fusion built in Tools</p>","tags":["Glossary"]},{"location":"Fusion/Expressions/Expressions/","title":"Expressions","text":"<p>Expressions are Lua code. Create for example a [[Text+]] [[Node]]. In the [[Inspector panel]] of the Text+ open the context menu for the text field and select 'Expression'. As an expression copy'n'paste the following code ... <pre><code>Text(\"This is Frame \"..time..\" of \" ..comp.RenderEnd..\".\\n\"..\"In der realen Welt ist es gerade\\n\"..os.date(\"%H Uhr %M und %S Sekunden\")..\".\\nI'm running on\\n\"..jit.os..\" on a \"..jit.arch..\" architecture.\\nMy current font size is \\nat about \"..string.format(\"%.2f\",self.Size)..\".\")\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/","title":"Running Scripts From Fusion Expression Fields","text":"<p>As you start to create more complex macros, you will eventually \"hit the wall\" of what is possible, if you are simply using Expressions to apply math formulas, and read values from user controls and node input attributes.\u00a0</p> <p>If you start an code block with a \":\" colon symbol, you are able to run inline chunks of LuaJIT code directly. When running Lua script based expressions, you do need to \"return\" a value at the end of the code block . This gives the input control that hosts the expression gets a final number/string value to work with when the code finishes.</p> <p>Included below are several examples of what can be done with \"simple expressions\" that start with a colon symbol \":\", and LuaJIT scripting.</p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-comp-object","title":"Fusion Comp Object","text":"<p>If you want to access the current Fusion comp object from an expression or intool script based code block you can use: <pre><code>self.Comp.\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-node-name","title":"Fusion Node Name","text":"<p>If you want to access the current Fusion node name from an expression or intool script based code block you can use: <pre><code>:return Text(self.Name or \"\")\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#debugging-expression-values","title":"Debugging Expression Values","text":"<p>The \"trace()\" function can be used inside an expressions field to print debugging information directly to the Console window. <pre><code>:trace(5); return Text([[Hello World!]])\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#pathmaps","title":"PathMaps","text":"<p>A Fusion PathMap (relative filepath) can be expanded into an absolute file path in an expression using: <pre><code>:return Text(self.Comp:MapPath([Reactor:/Deploy/](&lt;../../Reactor:/Deploy/.md&gt;)))\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#running-actions","title":"Running Actions","text":"<p>A Fusion \"Action\" can be run asynchronously in a separate thread from an expression using: <pre><code>:self.Comp:Execute([[comp:DoAction(\"Comp_Save\", {})]]);return Text([[DoAction Comp_Save]])\n</code></pre> The \"Comp_Save\" action tells Fusion to re-save the existing .comp file to disk.</p> <p>The following code will display list of the available actions in the Console window: <pre><code>-- Track the actions that are available in Fusion\nlocal actionList = fu.ActionManager:GetActions()\n\n-- Count the total number of actions\nactionCount = 0\nfor i, act in ipairs(actionList) do\n    if not act:Get('Parent') then\n        actionCount = actionCount + 1\n    end\nend\nprint('[' .. actionCount .. ' Actions Found]')\n\n-- List each action sequentially\nfor i, act in ipairs(actionList) do\n    if not act:Get('Parent') then\n        print(act.ID)\n    end\nend\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#run-a-shell-task-via-iopopen","title":"Run a shell task via io.popen","text":"<p>The <code>io.popen()</code> lua function tells LuaJIT to run an external command line tool from inside the main render thread. The popen tool captures the return value from the shell's standard I/O stdout buffer.</p> WindowsmacOS/Linux <pre><code>:local commandString = [[C:\\Windows\\System32\\where.exe curl.exe]]; local handler = io.popen(commandString); local response = tostring(handler:read('*a')); handler:close(); return Text(response:sub(1,-2) or \"\")\n</code></pre> <pre><code>:local commandString = [[which curl]]; local handler = io.popen(commandString); local response = tostring(handler:read('*a')); handler:close(); return Text(response:sub(1,-2) or \"\")\n</code></pre>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#run-a-shell-task-via-osexecute","title":"Run a shell task via os.execute","text":"<p>The <code>os.execute()</code> lua function tells LuaJIT to run an external command line tool from inside the main render thread. With <code>os.execute()</code> you may have to use the \"tee\" utility, or shell redirection techniques to capture a return value from the shell's standard I/O stdout buffer.\u00a0</p> WindowsmacOSLinux <pre><code>:local url = [https://www.steakunderwater.com/](&lt;https://www.steakunderwater.com/&gt;);os.execute(\"explorer \\\"\" .. url .. \"\\\"\");return Text(\"Opening WSL\")\n</code></pre> <pre><code>:local url = [https://www.steakunderwater.com/](&lt;https://www.steakunderwater.com/&gt;);os.execute(\"open \\\"\" .. url .. \"\\\" &amp;\");return Text(\"Opening WSL\")\n</code></pre> <pre><code>:local url = [https://www.steakunderwater.com/](&lt;https://www.steakunderwater.com/&gt;);os.execute(\"xdg-open \\\"\" .. url .. \"\\\" &amp;\");return Text(\"Opening WSL\")\n</code></pre>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#run-luajit-inline-code-via-dostring","title":"Run LuaJIT Inline Code via dostring","text":"<p>The dostring function tells LuaJIT to run a block of code, in the main render thread: <pre><code>:local str = [[print(\"Hello World\")]];return Text(dostring(str or \"\"))\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#run-python-inline-code-asynchronous-via-execute","title":"Run Python Inline Code Asynchronous via Execute","text":"<p>Fusion is able to run a block of Python code asynchronously in a separate thread using the expression: <pre><code>:local py_script = [[!Py: import sys;print(sys.version)]]; self.Comp:Execute(py_script); return Text(\"Running Python!\")\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#run-luajit-inline-code-asynchronous-via-execute","title":"Run LuaJIT Inline Code Asynchronous via Execute","text":"<p>Fusion is able to run a block of LuaJIT code asynchronously in a separate thread using the expression: <pre><code>:local lua_script = [[print(jit.version)]]; self.Comp:Execute(lua_script); return Text(\"Running LuaJIT!\")\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#lua-modules-usage","title":"Lua Modules Usage","text":"<p>A Lua Module can be accessed in an expression. Lua Modules allow you to reuse common utility functions in a shared lua script file. This cuts down on code duplication. The Reactor package manager's LuaModules PathMap folder location is: \"<code>Reactor:/Deploy/Modules/Lua/</code>\"</p> <p>Note: The example expression below uses a Lua Module that is provided by the Reactor Package Manager atom package called the \"Vonk Data Nodes\". What is returned in an XML document as a block of text.</p> <pre><code>:local url = \"https://www.steakunderwater.com/wesuckless/feed\"; local textutils = self and require(\"vtextutils\") or nil; return Text(textutils.read_url(url))\n</code></pre> <p>The Reactor installer can be live downloaded and run from an expression using:\u00a0 <pre><code>:local url = \"https://gitlab.com/WeSuckLess/Reactor/-/raw/master/Reactor-Installer.lua?inline=false\"; local textutils = self and require(\"vtextutils\") or nil; reactor_script_str = textutils.read_url(url); self.Comp:Execute(reactor_script_str); return Text(\"Running the Reactor Installer!\")\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#uuid","title":"UUID","text":"<p>The current Fusion program's UUID value can be accessed in an expression using: <pre><code>:return Text(bmd.getappuuid())\n</code></pre></p> <p>The result is: <code>9ec0e65e-9137-4552-90cc-7ef9a9cd91b9</code></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#zero-padding-a-number","title":"Zero Padding a Number","text":"<p>If you need to add leading zero digit based frame padding to a number, this can be achieved in an expression using: <pre><code>:local num = 120;local padding = 4;return Text(string.format([[%0]] .. tostring(padding or 4) .. [[d]], tonumber(num)))\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-comp-name","title":"Fusion Comp Name","text":"<p>The current Fusion Studio Standalone composite name can be accessed in an expression using: <pre><code>:return Text(self.Comp.Name)\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-comp-filename","title":"Fusion Comp Filename","text":"<p>The current Fusion Studio Standalone composite filename can be accessed in an expression using: <pre><code>:return Text(self.Comp.Filename)\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-host-operating-system-platform","title":"Fusion Host Operating System Platform","text":"<p>The LuaJIT interpreter is able to report the current operating system platform in an expression using: <pre><code>:return Text(jit.os)\n</code></pre></p> <p>The values returned by \"jit.os\" are typically: - <code>jit.os == \"Windows\"</code> -  <code>jit.os == \"Linux\"</code> - <code>jit.os == \"OSX\"</code></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#fusion-host-cpu-architecture","title":"Fusion Host CPU Architecture","text":"<p>The LuaJIT interpreter is able to report the current CPU architecture in an expression using: <pre><code>:return Text(jit.arch)\n</code></pre></p> <p>The values returned by \"jit.arch\" are typically:</p> Running on... Value Windows x86 32-bit CPU <code>jit.arch == \"x86\"</code> Intel or AMD64 CPU <code>jit.arch == \"x64\"</code> Apple Silicon or Windows on ARM CPU <code>jit.arch == \"arm64\"</code> <p>Note: A legacy release of eyeon Digital Fusion, like v6.4, is required to see the <code>x86</code> arch value</p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#date","title":"Date","text":"<p>The current date can be accessed in an expression using: Note: Date and Time docs:\u00a0https://www.lua.org/pil/22.1.html <pre><code>:return Text(os.date([[%Y-%m-%d]]) or [](&lt;#&gt;))\n</code></pre> or <pre><code>:return Text(os.date([[%Y-%m-%d %H.%M.%S]]) or [](&lt;#&gt;))\n</code></pre></p>"},{"location":"Fusion/Expressions/Running%20Scripts%20From%20Fusion%20Expression%20Fields/#clipboard-contents","title":"Clipboard Contents","text":"<p>The current copy/paste clipboard contents can be accessed in an expression using: <pre><code>:return Text(bmd.getclipboard() or [](&lt;#&gt;))\n</code></pre></p>"},{"location":"Fusion/FusionScript/FusionScript/","title":"FusionScript","text":"<ul> <li>Class Types</li> <li>Registry Attributes</li> </ul>"},{"location":"Fusion/FusionScript/Class%20Types/CT_3D/","title":"CT_3D","text":"<p>CT_3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_3DFilter/","title":"CT_3DFilter","text":"<p>CT_3DFilter is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_3DFilterSource/","title":"CT_3DFilterSource","text":"<p>CT_3DFilterSource is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_AnimSegment/","title":"CT_AnimSegment","text":"<p>CT_AnimSegment is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Any/","title":"CT_Any","text":"<p>CT_Any is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ApplyMode/","title":"CT_ApplyMode","text":"<p>CT_ApplyMode is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_BinItem/","title":"CT_BinItem","text":"<p>CT_BinItem is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_BrushMode/","title":"CT_BrushMode","text":"<p>CT_BrushMode is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_BrushShape/","title":"CT_BrushShape","text":"<p>CT_BrushShape is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Camera3D/","title":"CT_Camera3D","text":"<p>CT_Camera3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_CameraData3D/","title":"CT_CameraData3D","text":"<p>CT_CameraData3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ConsoleUtility/","title":"CT_ConsoleUtility","text":"<p>CT_ConsoleUtility is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Converter/","title":"CT_Converter","text":"<p>CT_Converter is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Curve3D/","title":"CT_Curve3D","text":"<p>CT_Curve3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_CurveData3D/","title":"CT_CurveData3D","text":"<p>CT_CurveData3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Event/","title":"CT_Event","text":"<p>CT_Event is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_EventControl/","title":"CT_EventControl","text":"<p>CT_EventControl is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ExternalControl/","title":"CT_ExternalControl","text":"<p>CT_ExternalControl is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_FileFormat3D/","title":"CT_FileFormat3D","text":"<p>CT_FileFormat3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_FlowType/","title":"CT_FlowType","text":"<p>CT_FlowType is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_FuMenu/","title":"CT_FuMenu","text":"<p>CT_FuMenu is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_GLTexture/","title":"CT_GLTexture","text":"<p>CT_GLTexture is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_GLViewer/","title":"CT_GLViewer","text":"<p>CT_GLViewer is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ImageFormat/","title":"CT_ImageFormat","text":"<p>CT_ImageFormat is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_InputControl/","title":"CT_InputControl","text":"<p>CT_InputControl is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_LUTFormat/","title":"CT_LUTFormat","text":"<p>CT_LUTFormat is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_LayoutItem/","title":"CT_LayoutItem","text":"<p>CT_LayoutItem is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Light3D/","title":"CT_Light3D","text":"<p>CT_Light3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_LightData3D/","title":"CT_LightData3D","text":"<p>CT_LightData3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_LightSW3D/","title":"CT_LightSW3D","text":"<p>CT_LightSW3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Locale/","title":"CT_Locale","text":"<p>CT_Locale is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Mask/","title":"CT_Mask","text":"<p>CT_Mask is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_MergeTool/","title":"CT_MergeTool","text":"<p>CT_MergeTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Modifier/","title":"CT_Modifier","text":"<p>CT_Modifier is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_MtlData3D/","title":"CT_MtlData3D","text":"<p>CT_MtlData3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_MtlInputs3D/","title":"CT_MtlInputs3D","text":"<p>CT_MtlInputs3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_MtlParticle3D/","title":"CT_MtlParticle3D","text":"<p>CT_MtlParticle3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_MtlSW3D/","title":"CT_MtlSW3D","text":"<p>CT_MtlSW3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Operator/","title":"CT_Operator","text":"<p>CT_Operator is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_PaintTool/","title":"CT_PaintTool","text":"<p>CT_PaintTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Parameter/","title":"CT_Parameter","text":"<p>CT_Parameter is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ParticleMergeTool/","title":"CT_ParticleMergeTool","text":"<p>CT_ParticleMergeTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ParticleSource/","title":"CT_ParticleSource","text":"<p>CT_ParticleSource is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ParticleStyle/","title":"CT_ParticleStyle","text":"<p>CT_ParticleStyle is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ParticleTool/","title":"CT_ParticleTool","text":"<p>CT_ParticleTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Prefs/","title":"CT_Prefs","text":"<p>CT_Prefs is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Preview/","title":"CT_Preview","text":"<p>CT_Preview is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_PreviewControl/","title":"CT_PreviewControl","text":"<p>CT_PreviewControl is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_PreviewMedia/","title":"CT_PreviewMedia","text":"<p>CT_PreviewMedia is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Protocol/","title":"CT_Protocol","text":"<p>CT_Protocol is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Region3D/","title":"CT_Region3D","text":"<p>CT_Region3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_RenderContext3D/","title":"CT_RenderContext3D","text":"<p>CT_RenderContext3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Renderer3D/","title":"CT_Renderer3D","text":"<p>CT_Renderer3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_RendererInputs3D/","title":"CT_RendererInputs3D","text":"<p>CT_RendererInputs3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Shader3D/","title":"CT_Shader3D","text":"<p>CT_Shader3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ShadowClass3D/","title":"CT_ShadowClass3D","text":"<p>CT_ShadowClass3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_SinkTool/","title":"CT_SinkTool","text":"<p>CT_SinkTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_SourceTool/","title":"CT_SourceTool","text":"<p>CT_SourceTool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Spline/","title":"CT_Spline","text":"<p>CT_Spline is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_SurfaceData3D/","title":"CT_SurfaceData3D","text":"<p>CT_SurfaceData3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_SurfaceInputs3D/","title":"CT_SurfaceInputs3D","text":"<p>CT_SurfaceInputs3D is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Tool/","title":"CT_Tool","text":"<p>CT_Tool is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ToolViewInfo/","title":"CT_ToolViewInfo","text":"<p>CT_ToolViewInfo is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Transition/","title":"CT_Transition","text":"<p>CT_Transition is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_UserControl/","title":"CT_UserControl","text":"<p>CT_UserControl is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_Utility/","title":"CT_Utility","text":"<p>CT_Utility is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_View/","title":"CT_View","text":"<p>CT_View is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/CT_ViewLUTPlugin/","title":"CT_ViewLUTPlugin","text":"<p>CT_ViewLUTPlugin is a Class Type</p>"},{"location":"Fusion/FusionScript/Class%20Types/Class%20Types/","title":"Class Types","text":"<ul> <li>CT_3D</li> <li>CT_3DFilter</li> <li>CT_3DFilterSource</li> <li>CT_AnimSegment</li> <li>CT_Any</li> <li>CT_ApplyMode</li> <li>CT_BinItem</li> <li>CT_BrushMode</li> <li>CT_BrushShape</li> <li>CT_Camera3D</li> <li>CT_CameraData3D</li> <li>CT_ConsoleUtility</li> <li>CT_Converter</li> <li>CT_Curve3D</li> <li>CT_CurveData3D</li> <li>CT_Event</li> <li>CT_EventControl</li> <li>CT_ExternalControl</li> <li>CT_FileFormat3D</li> <li>CT_FlowType</li> <li>CT_FuMenu</li> <li>CT_GLTexture</li> <li>CT_GLViewer</li> <li>CT_ImageFormat</li> <li>CT_InputControl</li> <li>CT_LUTFormat</li> <li>CT_LayoutItem</li> <li>CT_Light3D</li> <li>CT_LightData3D</li> <li>CT_LightGL3D (depricated)</li> <li>CT_LightSW3D</li> <li>CT_Locale</li> <li>CT_Mask</li> <li>CT_MergeTool</li> <li>CT_Modifier</li> <li>CT_MtlData3D</li> <li>CT_MtlGL3D (depricated)</li> <li>CT_MtlInputs3D</li> <li>CT_MtlParticle3D</li> <li>CT_MtlSW3D</li> <li>CT_Operator</li> <li>CT_PaintTool</li> <li>CT_Parameter</li> <li>CT_ParticleMergeTool</li> <li>CT_ParticleSource</li> <li>CT_ParticleStyle</li> <li>CT_ParticleTool</li> <li>CT_Prefs</li> <li>CT_Preview</li> <li>CT_PreviewControl</li> <li>CT_PreviewMedia</li> <li>CT_Protocol</li> <li>CT_Region3D</li> <li>CT_RenderContext3D</li> <li>CT_Renderer3D</li> <li>CT_RendererInputs3D</li> <li>CT_Shader3D</li> <li>CT_ShadowClass3D</li> <li>CT_SinkTool</li> <li>CT_SourceTool</li> <li>CT_Spline</li> <li>CT_SurfaceData3D</li> <li>CT_SurfaceInputs3D</li> <li>CT_Tool</li> <li>CT_ToolViewInfo</li> <li>CT_Transition</li> <li>CT_UserControl</li> <li>CT_Utility</li> <li>CT_View</li> <li>CT_ViewLUTPlugin</li> </ul>","tags":["Reference"]},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ControlView/","title":"REGB_ControlView","text":"<p>ControlView (<code>REGB_ControlView</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this class is a control view class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_CreateFramePreview/","title":"REGB_CreateFramePreview","text":"<p>CreateFramePreview (<code>REGB_CreateFramePreview</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates that a preview object is to be created for each new frame window.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_CreateStaticPreview/","title":"REGB_CreateStaticPreview","text":"<p>CreateStaticPreview (<code>REGB_CreateStaticPreview</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates that a preview object is to be created at startup of this type.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_EightBitOnly/","title":"REGB_EightBitOnly","text":"<p>EightBitOnly (<code>REGB_EightBitOnly</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class cannot deal with being given greater than 8 bit per channel images.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ForceCommonCtrls/","title":"REGB_ForceCommonCtrls","text":"<p>ForceCommonCtrls (<code>REGB_ForceCommonCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Forces the tool to have common controls like motion blur, blend etc, even on modifiers.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanLoadFields/","title":"REGB_ImageFormat_CanLoadFields","text":"<p>ImageFormat_CanLoadFields (<code>REGB_ImageFormat_CanLoadFields</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanSave24bit/","title":"REGB_ImageFormat_CanSave24bit","text":"<p>ImageFormat_CanSave24bit (<code>REGB_ImageFormat_CanSave24bit</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanSave32bit/","title":"REGB_ImageFormat_CanSave32bit","text":"<p>ImageFormat_CanSave32bit (<code>REGB_ImageFormat_CanSave32bit</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanSave8bit/","title":"REGB_ImageFormat_CanSave8bit","text":"<p>ImageFormat_CanSave8bit (<code>REGB_ImageFormat_CanSave8bit</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanSaveField/","title":"REGB_ImageFormat_CanSaveField","text":"<p>ImageFormat_CanSaveField (<code>REGB_ImageFormat_CanSaveField</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_ImageFormat_CanScale/","title":"REGB_ImageFormat_CanScale","text":"<p>ImageFormat_CanScale (<code>REGB_ImageFormat_CanScale</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of an [[Image Format Class|image format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoad/","title":"REGB_MediaFormat_CanLoad","text":"<p>MediaFormat_CanLoad (<code>REGB_MediaFormat_CanLoad</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoadAudio/","title":"REGB_MediaFormat_CanLoadAudio","text":"<p>MediaFormat_CanLoadAudio (<code>REGB_MediaFormat_CanLoadAudio</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoadImages/","title":"REGB_MediaFormat_CanLoadImages","text":"<p>MediaFormat_CanLoadImages (<code>REGB_MediaFormat_CanLoadImages</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoadMIDI/","title":"REGB_MediaFormat_CanLoadMIDI","text":"<p>MediaFormat_CanLoadMIDI (<code>REGB_MediaFormat_CanLoadMIDI</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoadMulti/","title":"REGB_MediaFormat_CanLoadMulti","text":"<p>MediaFormat_CanLoadMulti (<code>REGB_MediaFormat_CanLoadMulti</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanLoadText/","title":"REGB_MediaFormat_CanLoadText","text":"<p>MediaFormat_CanLoadText (<code>REGB_MediaFormat_CanLoadText</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSave/","title":"REGB_MediaFormat_CanSave","text":"<p>MediaFormat_CanSave (<code>REGB_MediaFormat_CanSave</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveAudio/","title":"REGB_MediaFormat_CanSaveAudio","text":"<p>MediaFormat_CanSaveAudio (<code>REGB_MediaFormat_CanSaveAudio</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveCompressed/","title":"REGB_MediaFormat_CanSaveCompressed","text":"<p>MediaFormat_CanSaveCompressed (<code>REGB_MediaFormat_CanSaveCompressed</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveImages/","title":"REGB_MediaFormat_CanSaveImages","text":"<p>MediaFormat_CanSaveImages (<code>REGB_MediaFormat_CanSaveImages</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveMIDI/","title":"REGB_MediaFormat_CanSaveMIDI","text":"<p>MediaFormat_CanSaveMIDI (<code>REGB_MediaFormat_CanSaveMIDI</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveMulti/","title":"REGB_MediaFormat_CanSaveMulti","text":"<p>MediaFormat_CanSaveMulti (<code>REGB_MediaFormat_CanSaveMulti</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_CanSaveText/","title":"REGB_MediaFormat_CanSaveText","text":"<p>MediaFormat_CanSaveText (<code>REGB_MediaFormat_CanSaveText</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_ClipSpecificInputValues/","title":"REGB_MediaFormat_ClipSpecificInputValues","text":"<p>MediaFormat_ClipSpecificInputValues (<code>REGB_MediaFormat_ClipSpecificInputValues</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_LoadLinearOnly/","title":"REGB_MediaFormat_LoadLinearOnly","text":"<p>MediaFormat_LoadLinearOnly (<code>REGB_MediaFormat_LoadLinearOnly</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_OneShotLoad/","title":"REGB_MediaFormat_OneShotLoad","text":"<p>MediaFormat_OneShotLoad (<code>REGB_MediaFormat_OneShotLoad</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_OneShotSave/","title":"REGB_MediaFormat_OneShotSave","text":"<p>MediaFormat_OneShotSave (<code>REGB_MediaFormat_OneShotSave</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_SaveLinearOnly/","title":"REGB_MediaFormat_SaveLinearOnly","text":"<p>MediaFormat_SaveLinearOnly (<code>REGB_MediaFormat_SaveLinearOnly</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_WantsIOClass/","title":"REGB_MediaFormat_WantsIOClass","text":"<p>MediaFormat_WantsIOClass (<code>REGB_MediaFormat_WantsIOClass</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_MediaFormat_WantsUnbufferedIOClass/","title":"REGB_MediaFormat_WantsUnbufferedIOClass","text":"<p>MediaFormat_WantsUnbufferedIOClass (<code>REGB_MediaFormat_WantsUnbufferedIOClass</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specify various capabilities of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoAutoProxy/","title":"REGB_NoAutoProxy","text":"<p>NoAutoProxy (<code>REGB_NoAutoProxy</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class does not want things to be autoproxied when it is adjusted.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoAuxChannels/","title":"REGB_NoAuxChannels","text":"<p>NoAuxChannels (<code>REGB_NoAuxChannels</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class cannot deal with being given Auxiliary channels (such as Z, ObjID, etc)</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoBlendCtrls/","title":"REGB_NoBlendCtrls","text":"<p>NoBlendCtrls (<code>REGB_NoBlendCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class does not have blend controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoMotionBlurCtrls/","title":"REGB_NoMotionBlurCtrls","text":"<p>NoMotionBlurCtrls (<code>REGB_NoMotionBlurCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class does not have Motion Blur controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoObjMatCtrls/","title":"REGB_NoObjMatCtrls","text":"<p>NoObjMatCtrls (<code>REGB_NoObjMatCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class does not have Object/Material selection controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_NoSplineAnimation/","title":"REGB_NoSplineAnimation","text":"<p>NoSplineAnimation (<code>REGB_NoSplineAnimation</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that this data type (parameter class) cannot be animated using a spline.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_OpNoMask/","title":"REGB_OpNoMask","text":"<p>OpNoMask (<code>REGB_OpNoMask</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this Tool class cannot deal with being masked.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_OperatorControl/","title":"REGB_OperatorControl","text":"<p>OperatorControl (<code>REGB_OperatorControl</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class provides custom overlay control handling.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_AgeRangeCtrls/","title":"REGB_Particle_AgeRangeCtrls","text":"<p>Particle_AgeRangeCtrls (<code>REGB_Particle_AgeRangeCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_EmitterCtrls/","title":"REGB_Particle_EmitterCtrls","text":"<p>Particle_EmitterCtrls (<code>REGB_Particle_EmitterCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_ProbabilityCtrls/","title":"REGB_Particle_ProbabilityCtrls","text":"<p>Particle_ProbabilityCtrls (<code>REGB_Particle_ProbabilityCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_RandomSeedCtrls/","title":"REGB_Particle_RandomSeedCtrls","text":"<p>Particle_RandomSeedCtrls (<code>REGB_Particle_RandomSeedCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_RegionCtrls/","title":"REGB_Particle_RegionCtrls","text":"<p>Particle_RegionCtrls (<code>REGB_Particle_RegionCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_RegionModeCtrls/","title":"REGB_Particle_RegionModeCtrls","text":"<p>Particle_RegionModeCtrls (<code>REGB_Particle_RegionModeCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_SetCtrls/","title":"REGB_Particle_SetCtrls","text":"<p>Particle_SetCtrls (<code>REGB_Particle_SetCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Particle_StyleCtrls/","title":"REGB_Particle_StyleCtrls","text":"<p>Particle_StyleCtrls (<code>REGB_Particle_StyleCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanCopyAnim/","title":"REGB_Preview_CanCopyAnim","text":"<p>Preview_CanCopyAnim (<code>REGB_Preview_CanCopyAnim</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanCopyImage/","title":"REGB_Preview_CanCopyImage","text":"<p>Preview_CanCopyImage (<code>REGB_Preview_CanCopyImage</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanCreateAnim/","title":"REGB_Preview_CanCreateAnim","text":"<p>Preview_CanCreateAnim (<code>REGB_Preview_CanCreateAnim</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanDisplayImage/","title":"REGB_Preview_CanDisplayImage","text":"<p>Preview_CanDisplayImage (<code>REGB_Preview_CanDisplayImage</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanNetRender/","title":"REGB_Preview_CanNetRender","text":"<p>Preview_CanNetRender (<code>REGB_Preview_CanNetRender</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanPlayAnim/","title":"REGB_Preview_CanPlayAnim","text":"<p>Preview_CanPlayAnim (<code>REGB_Preview_CanPlayAnim</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanRecord/","title":"REGB_Preview_CanRecord","text":"<p>Preview_CanRecord (<code>REGB_Preview_CanRecord</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanSaveAnim/","title":"REGB_Preview_CanSaveAnim","text":"<p>Preview_CanSaveAnim (<code>REGB_Preview_CanSaveAnim</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_CanSaveImage/","title":"REGB_Preview_CanSaveImage","text":"<p>Preview_CanSaveImage (<code>REGB_Preview_CanSaveImage</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Preview_UsesFilenames/","title":"REGB_Preview_UsesFilenames","text":"<p>Preview_UsesFilenames (<code>REGB_Preview_UsesFilenames</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Defines various capabilities of a [[Preview Class|preview class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Source_AspectCtrls/","title":"REGB_Source_AspectCtrls","text":"<p>Source_AspectCtrls (<code>REGB_Source_AspectCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this source tool class has image aspect controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Source_GlobalCtrls/","title":"REGB_Source_GlobalCtrls","text":"<p>Source_GlobalCtrls (<code>REGB_Source_GlobalCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this source tool class has global range controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Source_SizeCtrls/","title":"REGB_Source_SizeCtrls","text":"<p>Source_SizeCtrls (<code>REGB_Source_SizeCtrls</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this source tool class has image resolution controls.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGB_Unpredictable/","title":"REGB_Unpredictable","text":"<p>Unpredictable (<code>REGB_Unpredictable</code>) is a Registry Attribute of type Boolean ('<code>B</code>'). Indicates if this tool class is predictable or not.Predictable tools will generate the same result given the same set of input values, regardless of time.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_ClassType/","title":"REGI_ClassType","text":"<p>ClassType (<code>REGI_ClassType</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the type of this class, based on the classtype constants.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_ClassType2/","title":"REGI_ClassType2","text":"<p>ClassType2 (<code>REGI_ClassType2</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the type of this class, based on the classtype constants.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_DataType/","title":"REGI_DataType","text":"<p>DataType (<code>REGI_DataType</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies a data type RegID dealt with by this class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_HelpID/","title":"REGI_HelpID","text":"<p>HelpID (<code>REGI_HelpID</code>) is a Registry Attribute of type Integer ('<code>I</code>'). The help file and ID for the class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_InputDataType/","title":"REGI_InputDataType","text":"<p>InputDataType (<code>REGI_InputDataType</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies a data type RegID dealt with by the main inputs of this class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_Logo/","title":"REGI_Logo","text":"<p>Logo (<code>REGI_Logo</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies a resource ID of a company logo for this class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_MediaFormat_Priority/","title":"REGI_MediaFormat_Priority","text":"<p>MediaFormat_Priority (<code>REGI_MediaFormat_Priority</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the priority of a [[Media Format Class|media format class]].</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_MergeDataType/","title":"REGI_MergeDataType","text":"<p>MergeDataType (<code>REGI_MergeDataType</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies what type of data this merge tool class is capable of merging.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_OpIcon/","title":"REGI_OpIcon","text":"<p>OpIcon (<code>REGI_OpIcon</code>) is a Registry Attribute of type Integer ('<code>I</code>'). A resource ID for a bitmap to be used for toolbar images for this class.</p> <p>FKA \"REGI_OpIconID\"</p> <p>This attribute was named [[REGI_OpIconID]] in the Scripting Guide.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_PI_DataSize/","title":"REGI_PI_DataSize","text":"<p>PI_DataSize (<code>REGI_PI_DataSize</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Defines a custom data size for AEPlugin classes.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_Particle_DefaultRegion/","title":"REGI_Particle_DefaultRegion","text":"<p>Particle_DefaultRegion (<code>REGI_Particle_DefaultRegion</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the RegID of a default Region for this [[Particle Tool|particle tool]] class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_Particle_DefaultStyle/","title":"REGI_Particle_DefaultStyle","text":"<p>Particle_DefaultStyle (<code>REGI_Particle_DefaultStyle</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the RegID of a default Style for this [[Particle Tool|particle tool]] class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_Priority/","title":"REGI_Priority","text":"<p>Priority (<code>REGI_Priority</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies the priority of this class on the registry list.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_TileID/","title":"REGI_TileID","text":"<p>TileID (<code>REGI_TileID</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Specifies a resource ID used for the tile image by this class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGI_Version/","title":"REGI_Version","text":"<p>Version (<code>REGI_Version</code>) is a Registry Attribute of type Integer ('<code>I</code>'). Defines the version number of this class or plugin.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGST_MediaFormat_Extension/","title":"REGST_MediaFormat_Extension","text":"<p>MediaFormat_Extension (<code>REGST_MediaFormat_Extension</code>) is a Registry Attribute of type String Tabel ('<code>ST</code>'). Specifies the extensions supported by a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_Category/","title":"REGS_Category","text":"<p>Category (<code>REGS_Category</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies the category for the class, defining a position in the Tools menu for tool classes.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_HelpFile/","title":"REGS_HelpFile","text":"<p>HelpFile (<code>REGS_HelpFile</code>) is a Registry Attribute of type String ('<code>S</code>'). The help file and ID for the class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_HelpTopic/","title":"REGS_HelpTopic","text":"<p>HelpTopic (<code>REGS_HelpTopic</code>) is a Registry Attribute of type String ('<code>S</code>'). The help file and ID for the class.</p> <p>FKA \"REGI_HelpTopicID\"</p> <p>This attribute was named [[REGI_HelpTopicID]] in the Scripting Guide.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_ID/","title":"REGS_ID","text":"<p>ID (<code>REGS_ID</code>) is a Registry Attribute of type String ('<code>S</code>'). A unique ID for this class.</p> <p>FKA \"REGI_ID\"</p> <p>This attribute was named [[REGI_ID]] in the Scripting Guide.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_IconID/","title":"REGS_IconID","text":"<p>IconID (<code>REGS_IconID</code>) is a Registry Attribute of type String ('<code>S</code>'). A resource ID for a bitmap to be used for toolbar images for this class.</p> <p>FKA \"REGI_OpIconID\"</p> <p>This attribute was named [[REGI_OpIconID]] in the Scripting Guide.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_MediaFormat_FormatName/","title":"REGS_MediaFormat_FormatName","text":"<p>MediaFormat_FormatName (<code>REGS_MediaFormat_FormatName</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies the name of a [[Media Format Class|media format class]]</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_Name/","title":"REGS_Name","text":"<p>Name (<code>REGS_Name</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies the full name of the class represented by this registry entry.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_OpDescription/","title":"REGS_OpDescription","text":"<p>OpDescription (<code>REGS_OpDescription</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies a description of the class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_OpIconString/","title":"REGS_OpIconString","text":"<p>OpIconString (<code>REGS_OpIconString</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies the toolbar icon text used to represent the class.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_OpToolTip/","title":"REGS_OpToolTip","text":"<p>OpToolTip (<code>REGS_OpToolTip</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies a tooltip for the class to provide a longer name or description.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/REGS_ScriptName/","title":"REGS_ScriptName","text":"<p>ScriptName (<code>REGS_ScriptName</code>) is a Registry Attribute of type String ('<code>S</code>'). Specifies the scripting name of the class represented by this registry entry.If not specified, the full name defined by REGS_Name is used.</p>"},{"location":"Fusion/FusionScript/Registry%20Attributes/Registry%20Attributes/","title":"Registry Attributes","text":"<p>REGS_Category (String) Specifies the category for the class, defining a position in the Tools menu for tool classes.</p> <p>REGI_ClassType (Integer) Specifies the type of this class, based on the classtype constants.</p> <p>REGI_ClassType2 (Integer) Specifies the type of this class, based on the classtype constants.</p> <p>REGB_ControlView (Boolean) Indicates if this class is a control view class.</p> <p>REGB_CreateFramePreview (Boolean) Indicates that a preview object is to be created for each new frame window.</p> <p>REGB_CreateStaticPreview (Boolean) Indicates that a preview object is to be created at startup of this type.</p> <p>REGI_DataType (Integer) Specifies a data type RegID dealt with by this class.</p> <p>REGB_EightBitOnly (Boolean) Indicates if this tool class cannot deal with being given greater than 8 bit per channel images.</p> <p>REGB_ForceCommonCtrls (Boolean) Forces the tool to have common controls like motion blur, blend etc, even on modifiers.</p> <p>REGS_HelpFile (String) The help file and ID for the class.</p> <p>REGI_HelpID (Integer) The help file and ID for the class.</p> <p>REGS_HelpTopic (String) The help file and ID for the class. This attribute was named [[REGI_HelpTopicID]] in the Scripting Guide.</p> <p>REGS_ID (String) A unique ID for this class. This attribute was named [[REGI_ID]] in the Scripting Guide.</p> <p>REGS_IconID (String) A resource ID for a bitmap to be used for toolbar images for this class. This attribute was named [[REGI_OpIconID]] in the Scripting Guide.</p> <p>REGB_ImageFormat_CanLoadFields (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGB_ImageFormat_CanSave24bit (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGB_ImageFormat_CanSave32bit (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGB_ImageFormat_CanSave8bit (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGB_ImageFormat_CanSaveField (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGB_ImageFormat_CanScale (Boolean) Specify various capabilities of an [[Image Format Class|image format class]]</p> <p>REGI_InputDataType (Integer) Specifies a data type RegID dealt with by the main inputs of this class.</p> <p>REGI_Logo (Integer) Specifies a resource ID of a company logo for this class.</p> <p>REGB_MediaFormat_CanLoad (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanLoadAudio (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanLoadImages (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanLoadMIDI (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanLoadMulti (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanLoadText (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSave (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveAudio (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveCompressed (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveImages (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveMIDI (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveMulti (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_CanSaveText (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_ClipSpecificInputValues (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGST_MediaFormat_Extension (String Tabel) Specifies the extensions supported by a [[Media Format Class|media format class]]</p> <p>REGS_MediaFormat_FormatName (String) Specifies the name of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_LoadLinearOnly (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_OneShotLoad (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_OneShotSave (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGI_MediaFormat_Priority (Integer) Specifies the priority of a [[Media Format Class|media format class]].</p> <p>REGB_MediaFormat_SaveLinearOnly (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_WantsIOClass (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGB_MediaFormat_WantsUnbufferedIOClass (Boolean) Specify various capabilities of a [[Media Format Class|media format class]]</p> <p>REGI_MergeDataType (Integer) Specifies what type of data this merge tool class is capable of merging.</p> <p>REGS_Name (String) Specifies the full name of the class represented by this registry entry.</p> <p>REGB_NoAutoProxy (Boolean) Indicates if this tool class does not want things to be autoproxied when it is adjusted.</p> <p>REGB_NoAuxChannels (Boolean) Indicates if this tool class cannot deal with being given Auxiliary channels (such as Z, ObjID, etc)</p> <p>REGB_NoBlendCtrls (Boolean) Indicates if this tool class does not have blend controls.</p> <p>REGB_NoMotionBlurCtrls (Boolean) Indicates if this tool class does not have Motion Blur controls.</p> <p>REGB_NoObjMatCtrls (Boolean) Indicates if this tool class does not have Object/Material selection controls.</p> <p>REGB_NoSplineAnimation (Boolean) Specifies that this data type (parameter class) cannot be animated using a spline.</p> <p>REGS_OpDescription (String) Specifies a description of the class.</p> <p>REGI_OpIcon (Integer) A resource ID for a bitmap to be used for toolbar images for this class. This attribute was named [[REGI_OpIconID]] in the Scripting Guide.</p> <p>REGS_OpIconString (String) Specifies the toolbar icon text used to represent the class.</p> <p>REGB_OpNoMask (Boolean) Indicates if this Tool class cannot deal with being masked.</p> <p>REGS_OpToolTip (String) Specifies a tooltip for the class to provide a longer name or description.</p> <p>REGB_OperatorControl (Boolean) Indicates if this tool class provides custom overlay control handling.</p> <p>REGI_PI_DataSize (Integer) Defines a custom data size for AEPlugin classes.</p> <p>REGB_Particle_AgeRangeCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGI_Particle_DefaultRegion (Integer) Specifies the RegID of a default Region for this [[Particle Tool|particle tool]] class.</p> <p>REGI_Particle_DefaultStyle (Integer) Specifies the RegID of a default Style for this [[Particle Tool|particle tool]] class.</p> <p>REGB_Particle_EmitterCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_ProbabilityCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_RandomSeedCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_RegionCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_RegionModeCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_SetCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Particle_StyleCtrls (Boolean) Specifies that [[Particle Tool|particle tool]]s should have (or not have) various standard sets of controls.</p> <p>REGB_Preview_CanCopyAnim (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanCopyImage (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanCreateAnim (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanDisplayImage (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanNetRender (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanPlayAnim (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanRecord (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanSaveAnim (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_CanSaveImage (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGB_Preview_UsesFilenames (Boolean) Defines various capabilities of a [[Preview Class|preview class]].</p> <p>REGI_Priority (Integer) Specifies the priority of this class on the registry list.</p> <p>REGS_ScriptName (String) Specifies the scripting name of the class represented by this registry entry.If not specified, the full name defined by REGS_Name is used.</p> <p>REGB_Source_AspectCtrls (Boolean) Indicates if this source tool class has image aspect controls.</p> <p>REGB_Source_GlobalCtrls (Boolean) Indicates if this source tool class has global range controls.</p> <p>REGB_Source_SizeCtrls (Boolean) Indicates if this source tool class has image resolution controls.</p> <p>REGI_TileID (Integer) Specifies a resource ID used for the tile image by this class.</p> <p>REGB_Unpredictable (Boolean) Indicates if this tool class is predictable or not.Predictable tools will generate the same result given the same set of input values, regardless of time.</p> <p>REGI_Version (Integer) Defines the version number of this class or plugin.</p>","tags":["Reference"]},{"location":"Fusion/UI%20Controls/AddControlPage/","title":"AddControlPage","text":"<p>Synopsis AddControlPage(string NAME, table ATTR)</p> <p>Example <code>self:AddControlPage('Image', {CTID_DIB_ID = 'Icons.Tools.Tabs.Image'})</code></p> <p>For <code>Icons.Tools.Tabs.&lt;ID&gt;</code> use one of e.g. the following IDs: <code>Controls</code>, <code>Custom</code>, <code>Text</code>, <code>Layout</code>, <code>Transform</code>, <code>Style</code>, <code>Image</code>, <code>Common</code>, <code>Color</code>, <code>Blur</code>, <code>Merge</code>, <code>Channels</code>, <code>Noise</code>, <code>Tracker</code>, <code>Circles</code>, <code>Operation</code>, <code>Display</code>, <code>XYZ</code>, <code>Material</code>, <code>Shader</code>, <code>Background</code>, <code>Projection</code>, <code>Render</code>, <code>CameraTracker</code>, <code>PlanarTracker</code>, <code>Region</code>, <code>Calculation</code>, <code>Gradient</code>, <code>MIDI</code>, <code>MIDIChannel</code>, <code>Offset</code>, <code>PolyLine</code>, <code>NumberProbe</code>, <code>Shake</code>, <code>Time</code>, <code>XYPath</code>, <code>pRegion</code>, <code>pSets</code>, <code>ColorChannels</code>, <code>AuxChannels</code>, <code>Crop</code>, <code>AutoCrop</code>, <code>ColorGain</code>, <code>Saturation</code>, <code>HotSpot</code>, <code>ColorScale</code>, <code>Grain</code>, <code>HueCurves</code>, <code>ChromaKeyer</code>, <code>CleanPlate</code>, <code>Spill</code>, <code>Ranges</code>, <code>Mask</code>, <code>Key</code>, <code>Matte</code>, <code>Primatte</code>, <code>Replace</code>, <code>Degrain</code>, <code>Numbers</code>, <code>Points</code>, <code>LUTs</code>, <code>Vertex</code>, <code>Red</code>, <code>Green</code>, <code>Blue</code>, <code>Alpha</code>, <code>Solve</code>, <code>Camera</code>, <code>WhiteBalance</code>.</p> <p>These Icons can be found in the zipped fusion.fuskin file's \"Tools/Tabs\" sub-folder.</p> <p>Source: - EXRIO</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/","title":"Event Functions","text":"<p>Creating a Fuse is done by implementing different callback functions, which in this context are also known as event functions.</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#event-functions","title":"Event Functions","text":""},{"location":"Fusion/UI%20Controls/Event-Functions/#furegisterclass-string-name-ct_tool-table-attrs","title":"<code>FuRegisterClass( string &lt;NAME&gt;, CT_Tool, table &lt;ATTRS&gt;)</code>","text":"<p>...</p> <p>If you use a non-existing Icon ID for <code>REGS_IconID</code>, then the first three characters of the <code>REGS_OpIconString</code> are used as an Icon in the 'Effects' Pane and the 'Select Tool' window. But it's in green instead of the usual gray and the icon is not shown in the about dialog or if you enable 'Show Tile Picture' in the composition.</p> <p>Works: - Icons.Tools.Icons.Loader</p> <p>Does not work: - Icons.Tools.Icons.Layout</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#create","title":"<code>Create()</code>","text":"<p>...</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#processreq","title":"<code>Process(req)</code>","text":"<p>Can't access global variables created in OnAddToFlow(), OnConnected() or NotifyChanged().</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#onaddtoflow","title":"<code>OnAddToFlow()</code>","text":"<p>Called after the Fuse has been added. All Inputs have already been created and can be modified (e.g. by setting MinAllowed and MaxAllowed depending on the current composition's frame range).</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#onconnectedinput-old-new","title":"<code>OnConnected(input, old, new)</code>","text":"<p>Gets called whenever a connection is made to the inputs, either by connecting images to an image input or by animating a number input. Also called when this connection is removed or when this change in connections happens anywhere upstream of this Fuse.</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#checkrequestreq","title":"<code>CheckRequest(req)</code>","text":"<p>Called once or multiple times before Process(), depending on the input priority levels of this Fuse.</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#notifychangedinp-param-time","title":"<code>NotifyChanged(inp, param, time)</code>","text":"<p>Handle changes to an input.</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#precalcprocessreq","title":"<code>PreCalcProcess(req)</code>","text":"<p>Not called if REG_NoPreCalcProcess is true.</p>"},{"location":"Fusion/UI%20Controls/Event-Functions/#sources","title":"Sources","text":"<ul> <li>Creating Fuses articel on VFXPedia.</li> <li>Debug fuse by Stefan Ihringer, stefan@bildfehler.de</li> </ul>"},{"location":"Fusion/UI%20Controls/MultiButtonControl/","title":"MultiButtonControl","text":"<p>A multi button control (<code>INPID_InputControl='MultiButtonControl'</code>) displays one or more connected buttons. The actual buttons are added to the control by specifying a table with each entry containing <code>MBTNC_AddButton</code> items. Value of the control is the clicked button's number (starting at 0), or in case of multi-select, aka toggle buttons, the buttons' IDs are powers of two and the value when clicked is the bitwise or of the active buttons IDs.</p> <pre><code>  MyMultiButton = self:AddInput(\"A Multi Button\", \"mbtn\", {\n\n--   LINKID_DataType = \"FuID\",\n--   INPID_DefaultID = \"Sample\",\n\n    LINKID_DataType     = \"Number\",\n    INPID_InputControl  = \"MultiButtonControl\",\n    INP_Default         = 1,\n\n  -- INP_DoNotifyChanged = true,\n  -- INP_Integer = false,\n  -- IC_NoLabel = true,\n  -- IC_NoReset = true,\n  -- CC_LabelPosition = \"Horizontal\",\n  -- INP_MaxScale = 1,\n  -- INP_Default = 0,\n  -- INP_MinScale = 0,\n  -- INP_MaxAllowed = 1,\n  -- INP_MinAllowed = 0,\n  -- LINKS_Name = \"Foo\"\n\n    MBTNC_Type          = nil, -- nil|Normal|Toggle|TriState\n    MBTNC_ForceButtons  = true,\n    MBTNC_StretchToFit  = true,\n\n    { MBTNC_AddButton = \"Archibald\",  },\n    { MBTNC_AddButton = \"Lowry\",      },\n    { MBTNC_AddButton = \"Buttle\",     },\n\n    -- -- { CCS_AddString = \"Tuttle\" },\n    -- -- { CCS_AddString = \"Kurzmann\" },\n\n  })\n</code></pre>"},{"location":"Fusion/UI%20Controls/MultiButtonControl/#attributes","title":"Attributes","text":"<p>Besides of the general AddInput attributes, there are the following control specific properties:</p> <ul> <li>MBTNC_Align (string) Set to \"Center\", \"Left\" or \"Right\".</li> <li>MBTNC_AlphaSort</li> <li>MBTNC_ButtonHeight (int) Hight of the button in pixels (default is 26).</li> <li>MBTNCD_ButtonHeight</li> <li>MBTNC_ButtonWidth</li> <li>MBTNCD_ButtonWidth (float) Button widths from 0.0 (hidden) and 1.0 (full width; do not try to make it any wider). In contrast to the control's ICD_Width this is the width of the button within this outer control. If not set, then the buttons auto-size to their label width; but that does look bad because there is no left or right padding. Does nothing if <code>MBTNC_StretchToFit</code> is set to <code>true</code>.</li> <li>MBTNCD_ColdFromHot_H</li> <li>MBTNCD_ColdFromHot_L</li> <li>MBTNCD_ColdFromHot_S</li> <li>MBTNCD_ColdFromHot_Opacity</li> <li>MBTNC_ForceButtons=true can be used with and only with <code>MBTNC_Type=nil</code> to have the control actually rendered as buttons and not as a combo box.</li> <li>MBTNC_Height</li> <li>MBTNC_NoIconScaling (bool) Disable scaling of the icon to the full button size.</li> <li>MBTNC_Select</li> <li>MBTNCID_SelectID</li> <li>MBTNC_SetDisabled</li> <li>MBTNCS_SetName</li> <li>MBTNCS_SetToolTip</li> <li>MBTNC_ShowBasicButton (bool) is maybe just an old, today unused option? It's said to have no effect, or to depend on the skin, or to maybe have some effect by hiding the button but not its label. But with all my attempts so far I see no difference.</li> <li>MBTNC_ShowName (bool) Indicates if to show or hide the control's name as a label.</li> <li>MBTNC_StretchToFit (bool) Set to <code>true</code> to stretch the buttons equally across the full control's width. Does only work if MBTNCD_ButtonWidth has not been set.</li> <li>MBTNC_ShowIcon (bool) Enable/disable button's icon display.</li> <li>MBTNC_ShowLabel (bool) Enable/disable button's text display.</li> <li>MBTNC_ShowName</li> <li>MBTNC_ShowToolTip (bool) Seems to have no effect, neither on control nor on button level.</li> <li>MBTNC_Tab</li> <li>MBTNC_Type (string) Set to <code>\"Normal\"</code>, <code>\"Toggle\"</code>, <code>\"TriState\"</code>, or <code>nil</code>. Probably <code>nil</code> is some MBTNC_Type we don't know actual name for - and this type is the default.</li> <li><code>\"TriState\"</code> exist, but is not implemented. Looks as if it behaves like \"Normal\", but does i.e. not trigger events for NotifyChanged. So you should definitely not use it.</li> <li><code>\"Normal\"</code> buttons act like a simple button controls. Value is &gt;=1 (so numbering starts at 1) when button pressed, 0 when released. The events get triggered only when the button is release, so in this case you get an event with a value &gt;=1 immediately followed by a second event with the value being 0.</li> <li><code>\"Toggle\"</code> buttons behave like multi select toggle buttons (like a group of checkboxes would do). Activate a button with a click and deactivate it with a second click. Multiple buttons can be active at the same time (activation does not deactivate the others as it is the case with <code>MBTNC_Type=nil</code>). The buttons values are powers of two (1,2,4,8, etc). When multiple buttons are selected then the value is the bitwise combination of their values (3, if first and second button are enabled; 5 if the first and the third are enabled, etc). The toggle is broken in Fusion 17.0 - if behavior is not as expected then you may need to update</li> <li><code>nil</code> buttons behave like single select toggle buttons (like a group of radio buttons would do). A click activates the button and the previously activated button gets deactivated. With the event you get the number of the activated button (counting from 0). The event is triggered on button release only (not on click). There is no additional event triggered for the other button that gets disabled in that moment. Clicking a button that was already active does trigger the activation event as if it was inactive before (so it cannot be determined easily if it was already enabled). This is the exact behavior of a ComboBoxControl - and as long as you don't set <code>MBTNC_ForceButtons=true</code> this MultiButtonControl is actually rendered as a ComboBox.</li> <li>MBTNC_Width</li> </ul> <p>Button level attributes: - MBTNC_AddButton (string) Label of the button. - MBTNCS_ToolTip (string) Tooltip text. - MBTNCID_AddID (string) if <code>LINKID_DataType</code> has been set to <code>\"FuID\"</code> then set the ID for this particular button here.</p> <p>... whereby this list must be split into the control and the particular button related properties!</p> <p>Note: The attributes related to icons (MBTNC_NoIconScaling, MBTNC_ShowLabel and MBTNC_ShowIcon) are probably pretty useless, as a Fuse can't add icons for a button (in contrast to the internal C++ API). The TriState option for MBTNC_Type has never been implemented.</p> <p>Todo: MBTNC_ShowBasicButton is said to have no effect, or to depend on the skin, or to maybe have some effect by hiding the button but not its label ... have to try that out in a current Fusion version.</p>"},{"location":"Fusion/UI%20Controls/MultiButtonControl/#examples","title":"Examples","text":"<ul> <li>Docs/MultiButtonControl.fuse</li> </ul>"},{"location":"Fusion/UI%20Controls/MultiButtonControl/#notes","title":"Notes","text":"<p>The MultiButtonControl (see VFXPedia; usage example in OpenCL Fuses: Position and Time) does not work as expected since quite a while. This bug with adding a control to a Fusion tool when it comes to multi buttons has been reported on the BMD forum in 2018 already, as well as it had been put on the The most friendly feature request list for Fusion16. It's already been a pity that things like 'TriState' have never been implemented and adding icons is restricted to the C++ API, but with this bug the MultiButtonControl looks like just an ordinary ComboBoxControl. The solution to this is pretty simple but not easy to find: you add a <code>MBTNC_ForceButtons = true</code> and the options are shown as buttons again.</p>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/","title":"AddInput","text":"<p>The <code>AddInput()</code> function is used in the Fuse:Create() callback to add inputs (controls) to the Fuse. An input can be one of several control types that are shown in the tools inspector pane, or an image type input which appears on the Fuses node.</p> <pre><code>self::AddInput(label, identifier, attributes)\n</code></pre> <p>with  * label: a string that is typically shown on the left  (e.g. for sliders) or within (e.g. for buttons) of the control. * identifier: a string used for scripting, i.e. when saving the controls value to a lua file * attributes: a table with attributes determining the controls type and properties</p>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#attributes","title":"Attributes","text":""},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#mandatory-attribute","title":"Mandatory Attribute","text":"<ul> <li><code>INPID_InputControl</code> ist a string specifying the type of control to add and must be one of the following:</li> <li>ButtonControl</li> <li>CheckboxControl</li> <li>ColorControl</li> <li>ComboControl</li> <li>ComboIDControl</li> <li>FileControl</li> <li>FontFileControl</li> <li>GradientControl</li> <li>LabelControl</li> <li>MultiButtonControl</li> <li>MultiButtonIDControl</li> <li>OffsetControl</li> <li>RangeControl</li> <li>ScrewControl</li> <li>SliderControl</li> <li>TextEditControl</li> </ul>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#common-attributes","title":"Common Attributes","text":"<ul> <li><code>LINKID_DataType</code> as string that specifies the data type of the control. Set this according to the INPID_InputControl used; e.g., Number for a SliderControl, or Text for a FileControl. Use Image to specify an image input channel for the tool.</li> <li><code>FuID</code></li> <li><code>Gradient</code></li> <li><code>Image</code></li> <li><code>Number</code></li> <li><code>Particles</code></li> <li><code>Point</code></li> <li><code>Text</code></li> <li> <p>LINK_Main</p> </li> <li> <p><code>ICD_Width</code>(float): The width of the control; e.g. a 0.5 makes the control half of its normal size.</p> </li> </ul>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#input-control-types","title":"Input Control Types","text":"<p>When calling <code>AddInput()</code> use one of the following for <code>INPID_InputControl</code>:</p>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#combocontrol","title":"ComboControl","text":"<p>Creates a drop down menu. Selected entry is represented by a number (starting with 0 for the first entry).</p>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#attributes_1","title":"Attributes","text":"<ul> <li><code>CC_LabelPosition</code> (\"Vertical\"|\"Horizontal\"): Position of the label for this control (default is \"Horizontal\"). </li> <li><code>CCS_AddString</code></li> </ul>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#example","title":"Example","text":"<pre><code>InCombo = self:AddInput(\"Select one\", \"MySelectOneCombo\", {\n  INPID_InputControl = \"ComboControl\",\n  LINKID_DataType = \"Number\", \n  INP_Integer = true, -- 0..4 for the selected item\n  INP_Default = 2, -- third item preselected\n  { CCS_AddString = \"ONE\" },\n  { CCS_AddString = \"2\" },\n  { CCS_AddString = \"III\" },\n  { CCS_AddString = \"four\" },\n  { CCS_AddString = \"V\" },\n  CC_LabelPosition = \"Vertical\", -- put the label on top of the control\n  })\n</code></pre>"},{"location":"Fusion/UI%20Controls/Fuse/AddInput/#preview-control-types","title":"Preview Control Types","text":"<p>Values for <code>INPID_PreviewControl</code> are:</p> <ul> <li>AngleControl</li> <li>CrosshairControl</li> <li>ImgOverlayControl</li> <li>RectangleControl</li> <li>PointControl</li> <li>TransformControl</li> </ul>"},{"location":"Fusion/User%20Interface/Add%20Tool%20context%20menu/","title":"Add Tool context menu","text":"<p>On top of the context menu of your composition's [[Node panel]] you'll find the 'Add Tool' menu item to add a Tool to your composition. Alternatively you can add a Tool via the [[Effects panel]], the [[Tools menu]], or the [[Select Tool dialog]].</p>"},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/","title":"Conversion","text":"<p>This article is mainly based on @J-i-P-i's excellent WSL post \"Convert a Shadertoy WebGL Code to DCTL\".</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#show-stoppers","title":"Show Stoppers","text":"<p>Before converting a Shadertoy you should have a look if the code contains something yet not possible to convert: - dFdx / dFdy - texelfetch</p> <p>For other challenges there might be workarounds, but you should check the impact on the resulting image beforehand: - for <code>textureLod</code> omittimg the LOD by using <code>_tex2DVecN</code> might be sufficient - ...</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#floating-point-literals","title":"Floating Point Literals","text":"<p>Add the explicit type qualifier suffix <code>f</code> to every floating point literal to avoid its interpretation as a <code>double</code> precision value (which is the default if no suffix is present). Don't leave out the optional parts of the significant (though they are optional). That means don't use the shortcuts like <code>0.</code> or <code>.0</code>, but always write the complete <code>0.0</code> (or in our case even more precisely it must be a <code>0.0f</code>).</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#math-functions-for-scalars-types-floats","title":"Math Functions for Scalars Types (floats)","text":"<p>DCTL provides a lot of substitutes like <code>_sinf(float)</code>, <code>_cosf(float)</code> for the common math functions <code>sin(T)</code>, <code>cos(T)</code> to avoid ambiguities in particular with single precision, and double precision floating point types, and overloaded functions.</p> replace with sin, cos, pow _sinf, _cosf, _powf max, min _fmaxf, _fminf abs, mod _fabs, mod_f (Incompatibility) atan _atan2f (possibly on <code>_atan2f (var, 1.0f);</code> expand) clamp, dot, step no replacement needed mix _mix <p>See [[Mathematical Functions]] for further details.</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#porting-vector-types","title":"Porting Vector Types","text":"<p>Replace WebGL's <code>vec2</code>, <code>vec3</code>, <code>vec4</code> types by DCTL's <code>float2</code>, <code>float3</code>, <code>float4</code>. Note that for r-values you must use the corresponding <code>to_float</code>-functions.</p> <p>For example ... <pre><code>vec3 v = vec3(.2,.4,1.3);\n</code></pre> ... translates to ... <pre><code>float3 v = to_float3(0.2f,0.4f,1.3f);\n</code></pre></p> <p>One speciality with those vector types ist, that accessing multiple vector elements at ones (e.g. <code>float2 c=coords.xy</code>) must be resolved to single element access (the example could be converted to <code>float2 c = to_float2(coords.x,coords.y)</code>). See Swizzling for further details and more examples.</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#math-functions-for-vector-types","title":"Math Functions for Vector Types","text":"<p>The built-in math functions we usually need for shader programming only handle the scalar types (i.e. <code>float</code> and <code>double</code>). For vector types we have to implement these functions ourselves. But as this in most cases means to just perform the function on each of the vector's element, this is pretty easy to do. For example one could define the <code>floor</code> function for a <code>vec2</code> aka <code>floar2</code> as: <pre><code>__DEVICE__ inline floor_float2(float2 v) { return to_float2(_floor(v.x),_fllor(v.y)); }\n</code></pre></p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#matrices","title":"Matrices","text":"<p>In contrast to WebGL, where there is support for the matrix types 2x2, 3x3 and 4x4, this is missing in DCTL. An attempt to implement the different initializations with overloaded functions and the multiplication by overloading the operator could not be implemented in this way. Firstly, different procedures are necessary for overloading for OpenCL and Cuda, but unfortunately an operator cannot be overloaded in OpenCL, so that the following functions are added uniformly for all frameworks when using mat2.</p> <p>First the type definition: <pre><code> typedef struct\n  {\n     float2 r0, r1;\n  } mat2;\n ```\nThen the two initialization functions:\n```C\n __DEVICE__ inline mat2 make_mat2 (float2 A, float2 B)\n  {\n     mat2 C;\n     C.r0 = A;\n     C.r1 = B;\n     return C;\n  }\n\n __DEVICE__ inline mat2 make_mat2_2 (float A, float B, float C, float D)\n  {\n     mat2 E;\n     E.r0 = to_float2 (A, B);\n     E.r1 = to_float2 (C, D);\n     return E;\n  }\n</code></pre></p> <p>and the multiplication functions: <pre><code>  __DEVICE__ inline float2 mat2_multi_2f (mat2 B, float2 A)\n  {\n     float2 C;\n     C.x = A.x * B.r0.x + A.y * B.r0.y;\n     C.y = A.x * B.r1.x + A.y * B.r1.y;\n     return C;\n  }\n   __DEVICE__ inline float2 f2_multi_mat2 (float2 A, mat2 B)\n  {\n     float2 C;\n     C.x = A.x * B.r0.x + A.y * B.r0.y;\n     C.y = A.x * B.r1.x + A.y * B.r1.y;\n     return C;\n  }\n  __DEVICE__ inline mat2 mat2_multi_f (mat2 A, float B)\n  {\n    return make_mat2 (to_float2 (A.r0.x * B, A.r0.y * B), to_float2 (A.r1.x * B, A.r1.y * B));\n  }\n</code></pre></p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#shader-parameters","title":"Shader Parameters","text":"","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Conversion/#iresolution","title":"iResolution","text":"<p>Is a <code>vec3</code> with the width and height (in pixels) and the pixel aspect ration (usually 1.0) of the viewport.</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/","title":"Fuse Settings","text":"<p>This is specific to the Fuses in this repository!</p> <p>Trying to reorganize the settings to have ... - as many values as possible equipped with defaults so that a minimum of information must be given for the dev version - the variable names are more consistent</p> <p>All <code>FC_</code> variables are overwritten by the installer. That means they only take effect in development mode.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#example","title":"Example","text":"<pre><code>-- MANDATORY ----------------------------------------------\nlocal shadertoy_name       = \"Favela\"\nlocal shadertoy_author     = \"duvengar\"\nlocal shadertoy_id         = \"ldGcDh\"\nlocal shadertoy_license    = \"Favela by Julien Vergnaud @duvengar-2018 (CC BY-NC-SA 3.0)\"\nlocal dctlfuse_name        = shadertoy_name\nlocal dctlfuse_category    = \"AbstractShader\"\nlocal dctlfuse_author      = \"nmbr73\"\n-- OPTIONAL -----------------------------------------------\nlocal dctlfuse_authorurl   = \"https://www.youtube.com/c/nmbr73\"\nlocal dctlfuse_versionNo   = 42\nlocal dctlfuse_versionDate = \"March 2020\"\n-- local dctlfuse_infourl     = \"https://letmegooglethat.com/?q=Favela\"\n-- local dctlfuse_company     = \"nmbr73\"  -- defaults to dctlfuse_author\n-- local dctlfuse_shortcut    = \"FV\"      -- unused\n-- local dctlfuse_authorlogo = 'width=\"212\" height=\"41\" src=\"data:image/png;base64,...\"'\n</code></pre>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#mandatory-settings","title":"Mandatory Settings","text":"","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#shadertoy_name","title":"shadertoy_name","text":"<p>Name of the shadertoy. Should be the original name if possible.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#shadertoy_author","title":"shadertoy_author","text":"<p>The shadertoy author's login name on shadretoy.com.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#shadertoy_id","title":"shadertoy_id","text":"<p>ID (end of the URL on Shadertoy.com) of the shadertoy.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#shadertoy_license","title":"shadertoy_license","text":"<p>License text according to the license information found in the shadertoy's source code. Set to \"\" to excplicitely indicate that no such information was provided in the original code (in this case it is set to 'CC BY-NC-SA 3.0' as this is the shadertoy.com's default).</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_name","title":"dctlfuse_name","text":"<p>Advise is to set this to <code>shadertoy_name</code> if and only if the shadertoy name is suitable as a unique fuse identifier (such a fuse name may only contain alphanumeric characters and an underscore, must not start with a digit, and should not be all too long). Otherwise choose an appropriate fuse name here. Should correspont to the fuse's file name.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_category-overwritten-by-fc_category","title":"dctlfuse_category (overwritten by FC_CATEGORY)","text":"<p>Set this to the fuse's folder name. It's overwritten, but it's a must-have for the development version to work properly.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_author","title":"dctlfuse_author","text":"<p>Name of the developer who did the original port of this fuse.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#optional-settings","title":"Optional Settings","text":"<p>Recommendation is: - you should set <code>dctlfuse_authorurl</code> - you could set <code>dctlfuse_versionNo</code> and <code>dctlfuse_versionDate</code> - you must set <code>dctlfuse_infourl</code> if and only if needed</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_authorurl","title":"dctlfuse_authorurl","text":"<p>Some URL related to the author of he fuse. If not present, then this will just direct to the GitHub per default, but it is recommended that you set it to something more specific.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_versionno-overwritten-by-fc_versionno","title":"dctlfuse_versionNo (overwritten by FC_VERSIONNO)","text":"<p>The version number for this fuse. But it's maybe better to derive this automatically from the repository's commit log in future.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_versiondate-overwritten-by-fc_versiondate","title":"dctlfuse_versionDate (overwritten by FC_VERSIONDATE)","text":"<p>The date of the last major change on this fuse (corresponding to <code>dctlfuse_versionNo</code>). We may consider to incorporate it in future again. On the other hand, if it makes sense to mention the date, it could make more sense to just derive it from the commit log.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_infourl","title":"dctlfuse_infourl","text":"<p>If not present then the code combines the other (mandatory) information to build the GitHub Pages ULR for the fuse. It's recommended to set this variable if and only if this does not work - e.g. because the fuse name does not correspond to the filename. Or if you just want to see your very own page for this fuse instead of the GitHub.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_shortcut-unused","title":"dctlfuse_shortcut (unused)","text":"<p>This variable was previously defined, but is currently not used. It is kept in the code if present to not lose the information, but is are ignored for the time beeing. We may consider to incorporate it in future again.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_authorlogo-overwrites-fc_authorlogo","title":"dctlfuse_authorlogo (overwrites FC_AUTHORLOGO)","text":"<p>You can set <code>dctlfuse_authorlogo=\"width=\\\"212\\\" height=\\\"41\\\" src=\\\"data:image/png;base64,...\\\"\"</code> with <code>...</code> the base64 encoded image data and width and height set to the correct values to use a custom logo. Use <code>dctlfuse_authorlogo=\"\"</code> to avoid that the installer inserts a logo here automatically.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#dctlfuse_company","title":"dctlfuse_company","text":"<p>Only used in the fuse decription. Defaults to dctlfuse_author. But you can set a company name here if you want to have this instead of your name shown e.g. in Fusion's about dialog.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#installer-settings","title":"Installer Settings","text":"<p>Don't set these variables! They have defaults suitable for 'dev' (so everything should work as expected when DaFusion uses the fuses for development straight out of the repository). And for the other cases they are all overwritten by the installer anyways. They are documented here just in caes you want to try out different settings - bit don't forget to remove the definitions and assignments before you run an installer or commit your changes! Some of these can be overwritten by 'Optional Settings' (see above).</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_category","title":"FC_CATEGORY","text":"<p>Development: <code>dctlfuse_category</code> Installed: based on folder name Released: based on folder name Published: based on folder name</p> <p>Defaults to <code>dctlfuse_category</code>. This is the 'Add tools...' submenu name and should correspond to the Fuse's subdirectory (BlobShader, AbstractShader, MiscShader, ObjectShader). Set to <code>''</code> to make the Fuse appear on the menu's top level (that is directly beneath the FC_SUBMENU menu item).</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_submenu","title":"FC_SUBMENU","text":"<p>Development: \"Shadertoys (dev)\", Installed: \"Shadertoys (alpha)\",  Released: \"Shadertoys (beta)\",  Published: \"Fuses\\Shadertoys\"</p> <p>Defaults to \"Shadertoys (dev)\" and is set by the installer. Idea is to have all the Fuses beneath \"Shadertoy (dev)/\" for development (therefore the default), to have all Fuses copied by the installer beneath \"Shadertoys (beta)/\" and to have them finally in \"Fuses/Shadertoys/\" when they come with the Reactor. It's not allowed to be empty and therefore becomes \"Fuses\", if you set it to \"\". You can set it to some string, e.g. \"Fuses\\\\Shadertoys\", but this has effect only for the dev version.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_develop","title":"FC_DEVELOP","text":"<p>Development: true Installed: false Released: false Published: false</p> <p>Defaults to <code>true</code>. Set to <code>false</code> to hide the fuse's 'Edit' and 'Reload' buttons.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_versionno-overwrites-dctlfuse_versionno-not-implemented-yet","title":"FC_VERSIONNO (overwrites dctlfuse_versionNo; not implemented yet)","text":"<p>Defaults to <code>dctlfuse_versionNo</code>. Intention is to replace this some day with information comming from the git log.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_versiondate-overwrites-dctlfuse_versiondate-not-implemented-yet","title":"FC_VERSIONDATE (overwrites dctlfuse_versionDate; not implemented yet)","text":"<p>Development: <code>dctlfuse_versionDate</code> Installed: based on git log (resp. <code>dctlfuse_versionDate</code> unless implemented) Released: based on git log (resp. <code>dctlfuse_versionDate</code> unless implemented) Published: based on git log (resp. <code>dctlfuse_versionDate</code> unless implemented)</p> <p>Defaults to <code>dctlfuse_versionDate</code>. Intention is to replace this some day with information comming from the git log.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_tilepic","title":"FC_TILEPIC","text":"<p>Pfft.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_infobtnpos","title":"FC_INFOBTNPOS","text":"<p>Show button to open the project page -1 on top, 0 hide, 1 on bottom of the Control pane, or 2 on a separate Info pane.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_infotxtpos","title":"FC_INFOTXTPOS","text":"<p>Show fuse info text -1 on top, 0 hide, 1 on bottom of the Control pane, or 2 on a separate Info pane.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_authimgpos","title":"FC_AUTHIMGPOS","text":"<p>Show author logo -1 on top, 0 hide, 1 on bottom of the Control pane, or 2 on a separate Info pane.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Fuse-Settings/#fc_authimg-overtwritten-by-dctlfuse_authorlogo","title":"FC_AUTHIMG (overtwritten by dctlfuse_authorlogo)","text":"<p>Set <code>dctlfuse_authorlogo</code>to <code>\"\"</code> if you want to suppress any logo.</p>","tags":["webgl2dctl","rework"]},{"location":"Fusion/WebGL%20to%20DCTL/Links/","title":"Links","text":"<ul> <li>The Book of Shaders a comprehensive and highly recommended guide to Fragment Shaders.</li> <li>Shadertoy media files can be used as Media-In files for Fuses to mimic and test if it matches the original's behavior.</li> <li>ShaderToyFuses is a GitHub repository with some Shadertoys converted into Fuses using OpenCL.</li> <li>Tapered Bezier curve for Fusion by Bryan Ray</li> <li>Voronoi Fuse Developer's Diary by Bryan Ray</li> <li>cake23.de</li> <li>Cross-Compiling Shading Languages, a masterthesis by Likas Hermanns</li> <li>Shadertoy for absolute beginners, an entertaining introduction to the topic</li> <li>Chris Ridings, the trailblazer, created the fragmentshader.fuse</li> <li>desmos, the world's best functional plotter</li> </ul>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Links/#reference","title":"Reference","text":"<ul> <li>HLSL/ Cg (C for Graphics)</li> <li>Metal Shading Language Specification</li> <li>OpenGL ES 3.1 Spec</li> </ul>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Links/#wsl","title":"WSL","text":"<ul> <li>VFXPedia</li> </ul> <p>The We Suck Less forum is a huge source for information and inspiration when it comes to DaVinci Resolve and Fusion. Find here some links for posts dedicated to converting Shaders, programming Fuses, and all the things of interest in this context ...</p> <ul> <li>Convert a Shadertoy WebGL Code to DCTL by J-i-P-i is a step by step guide on how to convert an OpenGL ES shadertoy to a DCTL based Fuse</li> <li>DCTL Book of Shaders by David Kohen, aka Shem Namo, aka Learn Now FX ist a thread on writing DCTL shaders</li> <li>Building GUIs With Fusion's UI Manager by AndrewHazelden explains the different controls you can use in you Lua scropts called by DaFusion</li> </ul> <p>Reactor - The Atom Packages Documentation explains how to define a new installable item that is accessible in the Reactor package manager - Reactor on GitLab contains all the Rector sources</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Math%20Functions/","title":"Math Functions","text":"<p>Most shader languages are based on some kind of C and thereby seem to inherit a good bunch of the well known <code>math.h</code> functions. On the other hand does GLSL define additional functions which don't come with the C standard libraries, or it uses features like overloading, which leads to problems when a function like <code>sin()</code> is defined as <code>sin(float)</code> as well as for <code>sin(double)</code> - in these cases DCTL avoids the ambiguity by providing explicit functions to determine the required variant - in the example a <code>_sinf()</code> works for a float parameter and only a float parameter.</p> Function Remark [[cos()]] Replace with DCTL's <code>_cosf(float)</code> fract() Implementation needed for Cuda pow() Corrected version needed for some shaders max() Replace with <code>_fmaxf()</code> [[min()]] Replace with <code>_fmixf()</code> mod() Replace with <code>mod_f()</code> sign() Implementation needed for Cuda [[sin()]] Replace with DCTL's <code>_sinf(float)</code> <p>See also WebGL to DCTL for a differently formatted overview on how to convert which of these functions.</p> <p>Functions that do not come with <code>math.h</code> and must be implemented separately - if they don't come with the Graphics API or DCTL already.</p> Function Description clamp() Exists (at least <code>clamp(float,float,float)</code> dot() Exists (at least <code>dot(float,float)</code>; we'll have to check for Vector types radians() Implement as <code>radians(float)</code> (missing in Cuda - maybe better radians_f()) distance() Implement as <code>distance_f</code> and <code>distance_fx</code> (missing in Cuda) reflect() Missing in OpenCL (metal ? don't know exactly-please check)","tags":["reference","webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Math%20Functions/#external-links","title":"External links","text":"<ul> <li>C Mathematical Functions on Wikipedia</li> <li>Common Mathematical Functions on cppreference.co</li> <li>Cuda Math API on docs.nvidia.com</li> <li>OpenGL Reference at khronos.org</li> </ul>","tags":["reference","webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Swizzling/","title":"Swizzling","text":"","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Swizzling/#background","title":"Background","text":"<p>WebGL supports the so called swizzling. This is to generate a vector out of single and reordered elements of another vector.</p> <pre><code>vec3 a(1.,2.);\nvec4 b=a.xyxx; // b is (1.,2.,1.,1.)\nvec2 c=a.yy // c is (2.,2.)\n</code></pre>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Swizzling/#swizzling-for-r-values","title":"Swizzling for r-values","text":"<p>We can eliminate this by defines as follows: <pre><code>#define swixy(V) to_float2((V).x,(V).y)\n</code></pre></p> <p>A typical scenario is the <code>iResolution.xy</code> that you often see in shader code and which would then translate to <code>swixy(iResolution)</code>.</p> <p>As [[Metal]] has full support for swizzling we don't need this workaround here, which would make it: <pre><code>#if defined (DEVICE_IS_METAL)\n  #define swixy(V) (V).xy\n#else\n  #define swixy(V) to_float2((V).x,(V).y)\n#endif\n</code></pre></p> <p>It's simple to extend the list of these defines to whatever is needed in the respective shader: <pre><code>#ifdef DEVICE_IS_METAL\n  #define swixy(V) (V).xy\n  #define swiyx(V) (V).yx\n  #define swixz(V) (V).xz\n  #define swiyz(V) (V).yz\n  #define swixyz(V) (V).xyz\n  #define swixxy(V) (V).xxy\n  #define swixyx(V) (V).xyx\n  #define swiyxx(V) (V).yxx\n#else\n  #define swixy(V) to_float2((V).x,(V).y)\n  #define swiyx(V) to_float2((V).y,(V).x)\n  #define swixz(V) to_float2((V).x,(V).z)\n  #define swiyz(V) to_float2((V).y,(V).z)\n  #define swixyz(V) to_float3((V).x,(V).y,(V).z)\n  #define swixxy(V) to_float3((V).x,(V).x,(V).y)\n  #define swixyx(V) to_float3((V).x,(V).y,(V).x)\n  #define swiyxx(V) to_float3((V).y,(V).x,(V).x)\n#endif\n</code></pre></p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/Swizzling/#swizzling-for-l-values","title":"Swizzling for l-values","text":"<p>But furthermore swizzling is also possible for l-values. Here defines as follow can help, but are not that generic as the above definitions for r-values: <pre><code>#if defined (DEVICE_IS_METAL)\n  #define lswixy(L,R) (L).xy = (R)\n  #define lswiyx(L,R) (L).yx = (R)\n  #define lswiyz(L,R) (L).yz = (R)\n  #define lswixz(L,R) (L).xz = (R)\n  #define lswixyz(L,R) (L).xyz = (R)\n  // ...\n#else\n  #define lswixy(L,R) { float2 tmp = (R); (L).x=tmp.x; (L).y=tmp.y; }\n  #define lswiyx(L,R) { float2 tmp = (R); (L).y=tmp.x; (L).x=tmp.y; }\n  #define lswiyz(L,R) { float2 tmp = (R); (L).y=tmp.x; (L).z=tmp.y; }\n  #define lswixz(L,R) { float2 tmp = (R); (L).x=tmp.x; (L).z=tmp.y; }\n  #define lswixyz(L,R) { float3 tmp = (R); (L).x=tmp.x; (L).y=tmp.y; (L).z=tmp.z; }\n  // ...\n#endif\n</code></pre> With these ugly little helpers you can make for example a ... <pre><code>dir.yz=prod_float2_mat2(swiyz(dir),to_mat2(_cosf(an),_sinf(an),-_sinf(an),_cosf(an)));\n</code></pre> that would compile neither on OpenCL nor on CUDA, a <pre><code>lswiyz(dir,prod_float2_mat2(swiyz(dir),to_mat2(_cosf(an),_sinf(an),-_sinf(an),_cosf(an))));\n</code></pre> which should run on all platforms.</p>","tags":["webgl2dctl"]},{"location":"Fusion/WebGL%20to%20DCTL/WebGL%20to%20DCTL/","title":"WebGL to DCTL","text":"<p>Collecting here the information found on our journey converting GLSL shaders to DCTL. For example one could write an article on Swizzling, sign(), or Mathematical Functions ...</p> <p>Fusion/WebGL to DCTL/Conversion Mathematical Functions User Interface|Extending the Graphical User Interface Fuse Settings AddInput Script/Libraries</p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/clamp%28%29/","title":"Clamp()","text":"<p>No restrictions are known in Cuda and OpenCl so far. <code>clamp(variable, min, max)</code> can be accepted without changes</p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/distance%28%29/","title":"Distance()","text":"<p>Missing in Cuda, so it has to be impelmented. Unfortunately, there are two cases:</p> <pre><code>#if defined(DEVICE_IS_CUDA)\n   #define distance_f(pt1,pt2) (_fabs(pt1-pt2))\n   #define distance_fx(pt1,pt2) (_sqrtf(dot(pt2-pt1,pt2-pt1)))\n#else\n   #define distance_f(pt1,pt2) (distance(pt1,pt2))\n   #define distance_fx(pt1,pt2) (distance(pt1,pt2))\n#endif\n</code></pre>"},{"location":"Fusion/WebGL%20to%20DCTL/math/dot%28%29/","title":"Dot()","text":"<p>No restrictions are known in Cuda and OpenCl so far. <code>dot()</code> can be accepted without changes</p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/fract%28%29/","title":"Fract()","text":"<p>The fract function is absent in Cuda, but fortunately the _floor function works <pre><code>#ifdef DEVICE_IS_CUDA \n   #define fract(A) ((A)-_floor(A))\n#endif\n</code></pre></p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/max%28%29/","title":"Max()","text":"<p>Here it is important that both parameters are of the same type: <pre><code>float2 Par1 = 1.0f;\nfloat Par2 = 2.0f;\nfloat2 erg = _fmaxf(Par1, to_float2_s (Par2));\n</code></pre></p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/mod%28%29/","title":"Mod()","text":"<p>A stumbling block in the conversion arises with the modulo function. The <code>_fmod()</code> provided by DCTL unfortunately behaves a little differently than the one in WebGL. So it is sometimes absolutely necessary to use the replacement:</p> <pre><code>#define mod_f(a,b) (a-b*_floor(a/b))\n</code></pre> <p>OpenGL ES defines <code>mod(x,y)</code> to compute <code>x</code> modulo <code>y</code> as <code>x-y*floor(x/y)</code>. In <code>cmath.h</code> a <code>fmod(x,y)</code>is defined being the floating point remainder of <code>x/y</code> which is calculated as <code>x-n*y</code> with <code>n</code> being <code>x/y</code> with its fractional part truncated.  With <code>floor</code> truncating the fractional part this should be <code>floor(x/y)</code> and thereby this interpretation should match the OpenGL ES spec. And as <code>fmod</code> is overloaded to work with <code>float</code> as well as with <code>double</code> (the default), one would use <code>float fmodf(float,float)</code> to constrain it to <code>float</code> and only <code>float</code>. For Metal (don't know if it comes with Metal or is added by DCTL) <code>_modf</code> comes as the type generic macro <code>#define _modf(X, INTVAL) modf((X), (INTVAL))</code> - and here it even works for the vector types. Furthermore you should know that in the C standard library there also is a <code>T modf(T,T*)</code> function defined with <code>T</code> being <code>float</code>, <code>double</code>, or <code>long double</code> that does decompose a value in its integral and fractional part, and has its <code>modff</code> variant for single precision values.</p>"},{"location":"Fusion/WebGL%20to%20DCTL/math/pow%28%29/","title":"Pow()","text":"<p>There are shader translations in which unexpected results occur as a result of a pow calculation. This is due to the different handling of the result. The problem can be eliminated with the help of this substitute function:</p> <pre><code>// corrected pow-function by Chris Ridings\n__DEVICE__ float powcf(float x, float y) {\n  float ret = _powf(x,y);\n  if (isnan(ret))\n    return 0.0001f;\n  return ret;\n}\n</code></pre> <p>Alternative method</p> <pre><code>__DEVICE__ float lpowf(float a, float b) {\n  return _expf(b * _logf(a));\n}\n</code></pre>"},{"location":"Fusion/WebGL%20to%20DCTL/math/radians%28%29/","title":"Radians()","text":"<p>Exists in OpenGL ES, but not in Cuda, OpenCL, Metal, and it's not added by DCTL. So we have to define it ourselves ...</p> <pre><code>__DEVICE__ inline float radians(float degrees)\n{ \n  return M_PI * degrees / 180.0f;\n}\n</code></pre>"},{"location":"Fusion/WebGL%20to%20DCTL/math/reflect%28%29/","title":"Reflect()","text":"<p>Missing in OpenCL so it has to be added </p> <pre><code>#if defined(DEVICE_IS_OPENCL) || defined(DEVICE_IS_METAL)\n   #define _reflect(I,N) (I-2.0f*dot(N,I)*N) \n#endif\n</code></pre>"},{"location":"Fusion/WebGL%20to%20DCTL/math/sign%28%29/","title":"Sign()","text":"<p>The function sign() is defined in Metal as well as in OpenCL, but must be implemented for Cuda.</p> <pre><code>#ifdef DEVICE_IS_CUDA\n  __DEVICE__ inline float sign(float x) { return (x&lt;0.0f ? -1.0f : (x&gt;0.0f ? 1.0f : 0.0f)); }\n#endif\n</code></pre>"},{"location":"Kartaverse/KartaLink/","title":"KartaLink","text":""},{"location":"Kartaverse/KartaLink/#kartalink-learning-resources","title":"KartaLink Learning Resources","text":"<ul> <li>Render Fusion Comps in Houdini TOPs</li> <li>KartaLink MediaCommand Steakunderwater Forum Thread</li> </ul>"},{"location":"Kartaverse/KartaVR/","title":"KartaVR","text":"<p>KartaVR is ...</p>"},{"location":"Kartaverse/KartaVR/#adding-kartavr-via-reactor","title":"Adding KartaVR via Reactor","text":"<p>In order to install KartaVR you need to have Resolve/Fusion and the Reactor Package Manager installed beforehand. To add the KartaVR packages to a new workstation, first start by launching the Reactor Package Manager window (see Reactor#Open Reactor Package Manager).\u00a0</p> <p>In the Reactor window, double-click on the left side-bar category item labelled \"Kartaverse\" to expand this hierarchy.</p> <p></p> <p>Then select the \"Kartaverse &gt; KartaVR\" sub-category on the left sidebar to shorten the amount of content displayed in the part of the Reactor window where atom packages are listed.</p> <p></p> <p>Click on the package name \"KartaVR\" in the main part of the Reactor window, and then press the \"Install\" button.\u00a0</p> <p>A progress dialog is displayed that shows each of the files as they are downloaded from the Reactor GitLab repository via cURL and installed into the \"Reactor:/Deploy/\" PathMap location on your hard disk.</p> <p></p> <p>Several \"Install Script Confirmation\" dialogs will be displayed during the Reactor installation process. The dialog is asking for your input.\u00a0</p> <p>You can press the \"OK\" button if you would like to set up several preferences automatically during the install of the Reactor \"Bin\" category content like the FFmpeg utility. Alternatively, you can press the \"Cancel Installation\" button and that specific \"Install Script\" item will be skipped.</p> <p></p> <p>After the \"KartaVR\" content has been fully installed, we then need to click on the package name \"KartaVR 3<sup>rd</sup> Party Libraries\" to install it as well. This Reactor package adds the extra open-source utilities needed to efficiently use the KartaVR automation scripts.</p> <p>The \"KartaVR 3<sup>rd</sup> Party Libraries\" atom package description in the Reactor window lists all of the open-source tools you can optionally choose to install.</p> <p></p>"},{"location":"Kartaverse/KartaVision/","title":"KartaVision - Node Based Reverse Image Search","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/KartaVision/#overview","title":"Overview","text":"<p>1st1 Technologies, LLP, and authorized Photon workflow solutions developer, Andrew Hazelden of Dover Studios, Inc., are pleased to announce that \"KartaVision\", a D\u00e9j\u00e0VuAI Photon licensed integration plugin. The KartaVision for Blackmagic Design Resolve/Fusion plugin builds a new layer of intuitive artist-friendly node-based image processing technology on top of D\u00e9j\u00e0VuAI's best-in-class, industry-leading reverse image search algorithms.</p> <p></p> <p>Never before have visual effects artists, video editors, photographers, filmmakers, content creators, and game designers had this type of exciting technology wired into their DCC tools at such a low level via the power of \"data nodes\".</p> <p>KartaVision was designed from the ground up to meet the exacting needs of the Media and Entertainment sector. Whether you are an artist working with standard film &amp; TV media formats, 360VR immersive footage, volumetric 6DoF captured media, RGB LIDAR LASER scan point cloud datasets, multi-view lightfields, or ultra-high resolution game assets, KartaVision has your needs covered.</p> <p></p> <p>Fast, efficient, and customizable are the key attributes that make this new class of computer vision software a good fit for content creators of all types. KartaVision allows you to mix Photon's unrivaled power and versatility, with EXIF/IPTC metadata tag-based cascading search operators, LPeg expressions, and unified OpenCV and PyTorch image processing nodes for an unmatched set of tools that will take your media production efforts to new places.</p> <p>KartaVision is optimized for distributed computing workflows. It ships with ready-to-use presets for tools like Amazon AWS Thinkbox's Deadline render manager, PIXAR's Tractor render manager, and SideFX Houdini's TOPS (Task Operators)/PilotPDG technology. The KartaVision toolset can scale seamlessly from running on a single laptop system (via Photon Personal Server licensing), to running at scale with a roomful of workstations and rack-mounted render nodes that have super-powerful GPUs and CPUs.</p> <p>For even larger deployments, Photon Enterprise Server can be run in your favorite cloud or VM environment, with on-demand and burstable scaling. This is essential when you need to search through millions of high-resolution medium-format images, image sequences, and movie files on a tight deadline.</p> <p>Take your workflows to the next level with the combined power of D\u00e9j\u00e0VuAI Photon and KartaVision.</p> <p>A node/based RIS (Reverse Image Search) toolset that uses data nodes in Resolve/Fusion via an HTML 5 inspired CSS (Cascading Search Sheet) technology that allows concatenation of nodal operators, search variants, LuaJIT based search scriptlets, and overloaded search operators.</p> <p>With the ability to perform hybrid search using object classification operators, semantic segmentation operators, XMP/EXIF metadata operators, geographic metadata operators (including geo-fencing), and more.... You'll never walk past a CCTV camera in a public place and feel the same... \ud83e\udee0</p> <p>After 2 years of negotiation, a specially licensed version of DejaVuAI Photon RIS technology is available for order from Photon's webstore. Discount pricing for the Photon RIS engine is available to all KartaVision users. This addon gives you access to an unrivalled best-in-class RIS engine. The 3<sup>rd</sup> party Lua Module installs in mere moments and then becomes active in your next user session.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Kartaverse/","title":"Kartaverse","text":"<p>Kartaverse is an extensive open-source media production pipeline that integrates seamlessly with a broad range of post-production tools used in VFX, VP, XR, 360VR, fulldome, volumetric video, computer vision, and machine learning workflows.</p>"},{"location":"Kartaverse/Kartaverse/#the-kartaverse-packages","title":"The Kartaverse Packages","text":"<p>The core technologies that are part of the Kartaverse v5 suite are namely:</p> <ul> <li>KartaVR</li> <li>KartaVP</li> <li>KartaVision</li> <li>KartaSonic</li> <li>KartaLink</li> <li>CompX</li> <li>Vonk Ultra</li> </ul> <p>These modules are based upon the culmination of many years of research &amp; development.</p> <p>Kartaverse is delivered via the web as free open-source software. It costs you nothing to download and use the Kartaverse tools for both personal and commercial usage. It even works fine with Resolve (Free) running as the host program. The main tool, KartaVR, is Apache 2.0 licensed. Several tools like Vonk Ultra are GPL v3 licensed.</p>"},{"location":"Kartaverse/Kartaverse/#kartaverse-project-assistance","title":"Kartaverse Project Assistance","text":"<p>If you want to assist the Kartaverse effort, the best way to help is to provide access to camera original \"raw\" unprocessed footage from a wide range of digital cinema cameras, DSLR/mirrorless cameras, flagship multi-lens mobile phones, drones, 360VR camera rigs, structured light depth sensors, lightfield cameras, and LIDAR scanners with permissive licensing. Anything you can share helps greatly.</p> <p>Having new, modern, example footage to work with helps the whole Kartaverse community as it pushes forward the ongoing development of new tools, techniques and workflows.\u00a0</p> <p>It is important, if possible, that the sample footage is shared with permissive license terms that would allow the media to be used under a Creative Commons Attribution-ShareAlike 4.0 International license. This media usage policy allows new example project files to be created and shared broadly with the community for learning purposes.\u00a0</p> <p>If you have access to sample footage that you are willing to share and are the copyright holder, please email me. Thanks!</p> <p></p>"},{"location":"Kartaverse/Kartaverse/#the-karta-development-journey","title":"The Karta Development Journey","text":"<p>Many of the workflow ideas and features found in the Kartaverse suite started development in the following toolsets that I had the opportunity to collaborate on as either a developer, co-developer, software maintainer, or technical writer.</p> <p>Domemaster Photoshop Actions Pack, Domemaster3D, Domemaster Fusion Macros, RocketComp, PlayblastVR, Lightfielder Suite, OBQ Shaders, CompX, dome2rect, Panoramic Geometry Collection, CameraSnap, Z360 6DOF Stereo VR Tools, Dover Planar Grid Array Camera, KartaVR Volumetric Capture Utility, HDR Pano Camera Rig PIC32 Microcontroller Firmware, IRIXBASIC, Mission Control, WarpStitch TD, Spicy Acorn Vonk, Cryptomatte, KickAss ShaderZ, SilhouetteFX Python Scripts, along with the Steakunderwater Reactor Package Manager, the Dover Studios, Inc. in-house pipeline tools BucketTime/Popcorn, the CameraCommander volumetric video pipeline, the ongoing Kino TR2X virtual production project, and the Borikuaverse project.</p>"},{"location":"Kartaverse/Kartaverse/#choosing-your-installation-packages","title":"Choosing Your Installation Packages","text":"<p>The Kartaverse package installation approach is very flexible. Reactor makes it possible to do a minimal installation of only the KartaVR features you need. This is a good choice when getting started so you don't become overwhelmed by choice.</p> <p></p> <p>If you are are an entry-level 360VR content creator, who is new to using KartaVR in Resolve/Fusion, then you might choose to only install the \"Reframe360Ultra\" and \"WarpStitchUltra\" packages using Reactor. This is a good entry point during your first few weeks of using the toolset. These specific Reactor packages make it possible to work efficiently with fisheye, 360VR, and 180VR media.</p> <p>As you become more comfortable you could slowly add more Kartaverse tools as required.</p> <p>Alternatively, if you want to install every possible component in the full Kartaverse suite, it requires the dedication of several hours to set up the entire toolchain to a full production-usage level. This time estimate includes installing Resolve/Fusion/Fusion Render Node, configuring the settings in a render manager for each of the render nodes, and customizing the program execution paths for each of the 3<sup>rd</sup> party integration bindings available in the toolset.</p>"},{"location":"Kartaverse/Kartaverse/#kartaverse-development-reference-hardware","title":"Kartaverse Development Reference Hardware","text":"<p>The Kartaverse v5 release was developed using the following reference computer hardware:</p> <p>Windows 10 &amp; 11 / Rocky Linux 8.5: - [ASRock TRX 40 Creator Motherboard](https://www.asrock.com/mb/AMD/TRX40%20Creator/ - AMD Ryzen Threadripper 3990X Desktop CPU - NVIDIA GeForce RTX 3090 GPU 24 GB VRAM - 256 GB RAM - 10 GB Ethernet Networking</p> <p>macOS Monterey: - M1 MacBook AIR 16GB RAM, 2 TB HD - OWC Thunderbolt 3 Pro Dock with 10GB Ethernet</p> <p>Oculus Quest \"Santa Cruz\" HMD Dev Kit</p>"},{"location":"Kartaverse/Kartaverse/#kartaverse-learning-resources","title":"Kartaverse Learning Resources","text":"<ul> <li>Kartaverse Google Group</li> <li>KartaVR Documentation</li> <li>KartaVR Facebook Group (Paused)</li> <li>KartaVR Steakunderwater Forum Thread</li> <li>Reactor Package Manager Steakunderwater Forum Thread</li> <li>Vonk Ultra Learning Resources</li> </ul>"},{"location":"Kartaverse/Kartaverse/#workflow-guides","title":"Workflow Guides","text":"<p>See Kartaverse Workflows</p> <ul> <li>KartaVR Compositing Examples</li> <li>Creating ST Maps</li> <li>YouTube 360 to Equirectangular Conversions</li> <li>Creating Volumetric NeRFs</li> <li>Jupyter Notebook for Resolve/Fusion</li> <li>SketchFab in VR Via QuestLink</li> </ul>"},{"location":"Kartaverse/Kartaverse/#immersive-pipeline-integration-guide","title":"Immersive Pipeline Integration Guide","text":"<p>See Immersive Pipeline Integration Guide</p>"},{"location":"Kartaverse/Pipeline%20Guide%20-%20intentions/","title":"Pipeline Guide   intentions","text":"<p>Make this into an article?</p> <p>Maybe this post could be made an introduction/intention/explanation article for the Immersive Pipeline Integration Guide?!?</p> <p>Kartaverse Workflows | Immersive Pipeline Integration Guide 512 pages https://docs.google.com/document/d/1tewIaHZh8mWI8x5BzlpZBkF8eXhK2b_XhTWiU_93HBA/edit?usp=sharing</p> <p>A recent question on LinkedIn asked me to summarize what the Kartaverse Pipeline Guide was about: Q.</p> <p>So this giant document is an overview of the Kartaverse? And it is platform agnostic? More theoretical?</p> <p>My response on the effort: A.</p> <p>I try to take a wholistic view on pipelines that focuses on the task being achieved and what tools/resources are already on-site. My efforts are more on getting people to think about automation and efficiencies that can be had. Aka don't do media management on hundreds or thousands of assets by hand, automate backups, speed up slap-comp creation, etc... The process of selecting which tool to use these days seems to matter less and less compared to asking if the whole workflow is supporting the creative process or acting as a boat anchor. I spend so much time on automation and scripting to try and multiply the effective volume of work that a tiny self-funded team can achieve. If you skim the Google Docs sidebar category for the guide you will see it covers AWS deadline usage including using MistikaVR as a deadline job, how to install and use Resolve + Fusion + Fusion Render node. It has topics about Python and Lua scripting including a discussion of QT window UX creation. A bare metal Windows 11 step by step install guide including environment variables, and GPU performance tuning. A step by step coverage of bare metal install of Rocky Linux 8.5 including GPU driver config and all common VFX apps on Linux including Maya, Blender, V-Ray Benchmark, V-Ray Universal batch render, and Pixar's RenderMan + Tractor. Also s bare metal install guide for CentOS 7.9 + Cinnamon Window manager, GPU drivers and common tools. Also common RAW image processing, panoramic stitching workflows with PTGui Pro are discussed, along with a dissection of the PTGui Pro v11-12 json based .pts format and a listing of how to access all relevant controls via a programmatic fashion. A step-by-step explainer of ST Map based panoramic template generation for live 360VR and offline panoramic stitching is mentioned. Including notes about TouchDesigner based real-time stitching via STmaps with live capture from SDI/HDMI digitizers and network feeds like NDI. Also the same STMap approach is explored in Resolve/Fusion. A breakdown of common SfM based image based modelling tools is listed. Along with important notes about how to get Reality Capture able to be bent to the will of people trying to do 4D volumetric video mesh sequence generation through the use of image sequence based multi-view workflows. And tips like re-using exported Reality Capture XMP formatted 3D camera locators, XMP based bounding box region cropping effects, and the actual Reality Capture export options themself. The Agisoft metashape SfM image based modelling toolset is demonstrated with a command prompt/shell based code demo on how to set up a local volumetric video render cluster with client/server bindings for a small farm. RAW media processing and HDRI exposure brackt blending workflows are discussed including notes on how to Automate Photomatix to generate proper HDRI EXR files. A breakdown of the former Nikon camera RAW tools which are now sold as DxO Optics PhotoLab is given with a step-by-step explainer on how to access the 100% undocumented hidden RAW processing command-line interface. A listing of common open-source workflow tools used in media &amp; entertainment post-production is given. A breakdown of the core concepts for OpenColorIO based ACES color managed workflows is included along with a summary of ACEScg and ACES 2065-1 deliver options and a comparison against linear gamma 1.0 color managed workflows and common Rec.709/sRGB options of the past. A coverage of the rescuezilla open-source bare metal Win/Linux disaster recovery, and disk to disk full-drive imaging cloning/backup tool is included. Tips explain how to use the gParted and Disks drive utilties on Linux to shrink a Windows NTFS or Linux based complex filesystem drive partition. Notes explain ways to solve a drive layout problem that stops a drive to drive clone from working from a larger drive (with lots of empty space) onto a smaller drive that is big enough to hold the active data. Common LTO drive backup tools like Canister Hedge are discussed. The USB thumbdrive ISO/boot media cloning tool called Balena etcher is discussed to show how to prepare boot media in the case a low level OS reload is needed. Discussion of common network utilities is shown. Common web development practices like setting up a local content staging server to allow you to prototype a media heavy website creation task without needing to constantly re-upload footage via the open internet to an external website. A demonstration of how to get Meta Quest HMD drivers installed, including the use of AirLink/Quest Link to allow a connected PC workstation to use a self-standing Quest HMD as a review tool. EXIFtool and other tools are shown for how to work with movie and image metadata. A discussion of nodal workflows including \"data node\" concepts for automation are displayed. A step by step guide on how to get Houdini and Houdini's bundled license-free render manager tool HQueue is presented. Houdini's node based \"render manager\" like system called PilotPDG/TOPs (task operators) is demoed and a side presetation shows how to make custom nodes in TOPs to arbitrary tasks like controlling the creation of a full composite in an external VFX tool, and using TOPs to also manage the distributed rendering operations. Houdini centric Pixar OpenUSD approaches are examined including way to streamline TOPs (task operators) to perform Alembic and USD ROPs (render operations). There is a side topic on how to set up a full Windows build environment including Git, Visual Studio, NVIDIA OPTIX, CUDA Toolkit, CMAKE, and other libraries like NVIDIA InstantNGP so neural graphics primitives based NeRF scene reconstructions can be created and explored interactively. A step by step workflow for applying \"Ai\" based image generator techniques that use the OpenAI \"Dall-E\" prompt based image generator toolset by hand from the command prompt is demoed, including setting up an OpenAI free account from scratch. Then a data-node presentation shows how arbitrary comp-specific tasks (like doing Dall-E AI image generation) can be done in a code-less fashion to allow any comp to synthesize new novel ML based visuals with 4D timeline based variations shown. A coverage of OpenEXR Multi-channel and multi-part media I/O is given, along with a comparison of encoding said multi-view EXR media between flat image sequences, tiled texture atlas and EXR multi-part/multi-channel representations. A discussion of truly parallel I/O based multi-view data processing techniques is given. Houdini Tokens work based upon environment variables. The tokens can be used in filenames for loading/saving content in a Houdini node graph are explored. Environment variables on macOS and windows are explored, including notes about macOS Launch Agents vs Terminal window defined environment variable scopes. A side-companion guide shows how to \"reverse\" the YouTube360 cubic format media you rip from their site back into spherical mono 2D or Stereo 3D formats. Plus a full breakdown of Resolve Studio, Resolve (Free), Fusion Studio, and Fusion Render Node is given. An introduction to Resolve Fusion page/Fusion Studio centric nodal workflows and a UI overview is given for first timers who have never used the toolset. A detailed coverage of all ways Resolve and Fusion can be customized via custom scripts/macros/templates/hotkey bindings/menus/OFX Plugins/Fusion native plugins/a fuses is given. And extensive coverage of common 360VR footage transformation operations is shown. And a novel Mobius transform tool that allows XYZ translation effects to be carried out on a classical 2D mono or stereo 3D pano. And coverage of 360VR and normal camera extraction workflows to be able to apply camera native recorded IMU accelerometer/gyro data in a node based fashion to do smoothing of hand-held motion. This is done with a thing called data nodes and an open source tool called Gyroflow. Did I mention I love workflows. LOL Now I'm more focused on making a viable alternative to Unreal Engine 5.1 + nDisplay + Disguise that is a performant interactive ML (machine learning) driven multi-view display generator for fulldome, projection mapping, 360VR, passive stereo displays, and virtual production usage. What IMHO sets my humble dev effort that is a WIP apart from conventional VP techniques by Disguise is my effort to apply true volumetric photoreal NeRF rendering to the task of making large scale volumetric representations of live-action captured locations. I call this concept nVP (Neural Volumetric Production) and it relies on building a feature rich tech stack ontop of NVIDIA's latest and greatest InstantNGP NeRF library that was just released this year. And I'm working to make the nVP workflows Pixar OpenUSD based so camera 3D locators and image planes can migrate from conventional DCC packages, into SfM image based modelling tools, over to common NeRF tools. That's most of what the pipeline integration guide content is about.</p>"},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/","title":"360VR Stitching Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#google-vr180-creator","title":"Google VR180 Creator","text":"<p>Google VR180 Creator</p> <p>If you are exploring VR180 workflows with BMD Resolve/Fusion, it is handy to have a copy of the \"Google VR180 Creator\" program to be able to easily inject the SBS 180 metadata tags into your final MP4 video file.</p> <p>Step 1. Google in their infinite wisdom removed the VR180 Creator tool from their website recently but a copy of the program for macOS/Windows/Linux is available for download from the Internet Archive \"Wayback Machine\" snapshot of the site.</p> <p></p> <p>Step 2. Drag the \"VR180 Creator.app\" file from the disk image into your macOS Applications folder.</p> <p></p> <p>Step 4. If you are on a macOS Monterey system you will likely have to edit the \"System Preferences &gt; Security &amp; Privacy &gt; Full Disk Access\" settings to allow the application to run.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#using-the-vr180-creator-app-with-180x180-fov-center-cropped-latlong-image-projection-based-media","title":"Using the VR180 Creator App With 180\u00b0x180\u00b0 FOV Center-Cropped LatLong Image Projection Based Media","text":"<p>Using the VR180 Creator App With 180\u00b0x180\u00b0 FOV Center-Cropped LatLong Image Projection Based Media</p> <p>After launching the VR180 Creator app you have several options to choose from. We want to add VR180 metadata to an existing MP4 video that was exported from Resolve/Fusion already.</p> <p>Select the \"Prepare for Publishing\" option.</p> <p></p> <p>Drag an MP4 video into the window, or select the file manually from your hard disk by clicking on the blue \"Select\" button in the center of the view.</p> <p></p> <p>Customize the \"Prepare for publishing\" settings before exporting your video:</p> <p></p> <p>Viewing the Finished VR180 Metadata Injected Movie in YouTube's VR media player allows you to pan-and-tilt the view to navigate around the scene:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#kartalink-media-command","title":"KartaLink Media Command","text":"<p>KartaLink Media Command</p> <p>Media Command is a scriptable interface for batch processing content that resides in your Resolve Media Pool. This streamlines the process of selecting footage, and running automation scripts on those specific items.</p> <p>When Media Command is launched it automatically scans for Lua and Python scripts that are located on your hard disk inside the \"Reactor:/Deploy/Scripts/MediaCommand/\" folder. These items are added to the \"Command Script\" ComboMenu in the interface.</p> <p>If you are a long time Fusion user, you will find the Media Command script was designed to give your Media page content management operations the same power and flexibility as you have with a Fusion page \"tool\" script in the Fusion nodes view context.</p> <p></p> <p>Media Command Resources:</p> <ul> <li>Media Command | Reactor Repo Markdown Docs</li> <li>WSL | [RELEASED] KartaLink | Media Command</li> <li>WSL | Resolve Media Pool \"Script\" Menu Entry</li> <li>BMD Forums | DaVinci Resolve Feature Requests | Media Pool \"Script\" Menu Entry</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#media-command-docs","title":"Media Command Docs","text":"<p>Media Command Docs</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#search-controls","title":"Search Controls","text":"<p>Search Controls</p> <p>The \"Type:\" ComboMenu allows you to limit the tree view to show only media of a certain format. The menu options are: \"All\", \"Still\", \"Video\", \"Video + Audio\", \"Audio\", \"Compound\", \"Fusion\", \"Generator\", \"Geometry\", \"Stereo\", \"Subtitle\", and \"Timeline\".</p> <p></p> <p>The \"Search:\" text field allows you to narrow down the results in the tree view with plain text search of the \"Clip Name\" and \"File Name\" records.</p> <p></p> <p>The \"Select: (All) (None) (Invert)\" buttons can be used to quickly modify the footage that is selected in the tree view. It is worth noting that the select buttons work on the content that is visible in the tree view at the current moment so you can apply the select buttons to the filtered search results, then flip back to the full unfiltered list of content in the tree view.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#script-controls","title":"Script Controls","text":"<p>Script Controls</p> <p>The \"Command Script:\" ComboMenu allows you to select a Lua or Python script you would like to run.</p> <p></p> <p>The (Edit) button will open the active command script using the script editor defined in the Fusion preferences.</p> <p>The (Go!) button will run the active command script and use it to process the media that is selected in the tree view.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#view-controls","title":"View Controls","text":"<p>View Controls</p> <p>If the \"Keep Open\" button is active, the Media Command window will remain open after a script is launched. This is handy if you need to batch process multiple clips in rapid succession. If this button is inactive the Media Command window will close each time a script is run.</p> <p>The \"Console\" button toggles the visibility of the Console window. If you need to troubleshoot a script there is likely useful diagnostic information already visible in the Console.</p> <p>The \"Refresh\" button allows you to reload the tree view listing. This is something you might want to do after modifying the content in the Media Pool/Media page, or if you have changed the currently active bin.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#script-usage","title":"Script Usage","text":"<p>Script Usage</p> <p>Step 1. Place your custom .lua or .py scripts into the \"Reactor:/Deploy/Scripts/MediaCommand/\" folder.</p> <p>Step 2. Launch the Media Command script from the Resolve \"Workspaces &gt; Scripts &gt; Edit &gt; Kartaverse &gt; KartaLink &gt; Media Command\" menu entry.</p> <p>Step 3. Select the footage you would like to batch process by clicking on the tree view row entries in the Media Command window. At the moment you need to click on the actual \"text\" words on the row to toggle the \"selected\" checkbox state.</p> <p>Step 4. Choose a script you would like to run on the selected media using the \"Command Script\" ComboMenu, then press the \"Go\" button.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#creating-a-media-command-script","title":"Creating a Media Command Script","text":"<p>Creating a Media Command Script</p> <p>When a script is launched it has an \"args\" global variable that holds a plain text formatted Lua table structure.</p> <p>Note: If you are using Python scripting in Resolve v18, you might have to set Resolve to use Python 2.7 if the built-in API command \"bmd.readstring()\" is unable to convert a plain text formatted table into a Python dict. This is done in the \"Fusion &gt; Fusion Settings...\" menu item. Switch to the \"Script\" section on the left side of the view and then enable the \"Default Python Version &gt; Python 2.7\" option in the window.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#bundled-scripts","title":"Bundled Scripts","text":"<p>Bundled Scripts</p> <p>Copy File Name.lua</p> <p>Copies the file names from the selected footage into the clipboard buffer.</p> <p>Copy File Path.lua</p> <p>Copies the absolute file path from the selected footage into the clipboard buffer.</p> <p>Copy JSON.lua</p> <p>Copies the clip properties as JSON formatted data into the clipboard buffer.</p> <p>Copy Lua Table.lua</p> <p>Copies the clip properties as Lua table formatted data into the clipboard buffer. This format of data can be reimported with the Fusion based Vonk data nodes directly into a ScriptVal.</p> <p>List Args</p> <p>Outputs a Lua table/Python dict with the active clip properties to the Console window.</p> <p>List Clips</p> <p>Outputs the clip name from the selected footage to the Console window.</p> <p>XR/Add MediaIn to Comp.lua</p> <p>Adds the selected images to the currently open Fusion compositing session. The clip properties are automatically added to each of the MediaIn node \"Comments\" fields. This allows you to create Text+ node based burn-ins from any of the Clip properties with the help of a Text+ node StyledText field expression.</p> <p>XR/Send to DeoVR.lua</p> <p>Opens a new DeoVR Player on Windows session where the currently selected images are auto-loaded into the media playback tool.</p> <p>XR/Send to PTGui.lua</p> <p>Opens a new PTGui session where the currently selected images are auto-loaded into the project.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#example-comps","title":"Example Comps","text":"<p>Example Comps</p> <p>Clip Lua Table to ScriptVal.comp</p> <p>This example shows how \"Copy Lua Table\" script exports can be used with the Vonk data nodes.</p> <p></p> <p>The file available on-disk at the following PathMap location:</p> <pre><code>Reactor:/Deploy/Comps/Kartaverse/KartaLink/Media Command/Clip Lua Table to ScriptVal.comp\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#touchdesigner-real-time-immersive-workflows","title":"TouchDesigner Real-Time Immersive Workflows","text":"<p>TouchDesigner Real-Time Immersive Workflows</p> <p>TouchDesigner is a node-based real-time visual creation environment.</p> <p>TD's initial development roadmap branched off from its parent app, SideFX Prims/Houdini, in the early days of things but the program still shares many of the same paradigms, crazy acronyms, and ideas.</p> <p>The commercial version of TD can be licensed using several methods including a CodeMeters based cloud-floating license, or a hardware USB dongle.</p> <p>There is a free non-commercial edition of TD that you can get started with that is limited to 720p output but otherwise has all the other main features enabled for learning.</p> <p>TD Links:</p> <ul> <li>https://derivative.ca/download</li> <li>https://derivative.ca/learn</li> <li>https://derivative.ca/UserGuide/TouchDesigner</li> </ul> <p>TouchDesigner is a good choice for building a custom node-based panoramic 360VR video stitching environment with support for multiple video input streams from capture hardware or IP network video streams. It supports depth sensors, a wide range of HID input devices, and VR HMDs.</p> <p>TD 360VR Stitching Resources:</p> <ul> <li>YouTube | Hugh Hou | Edit Canon R5C &amp; R5 VR180 w/ DaVinci Resolve 18 FREE - 3D 8K 60fps RAW LT Clog3 Workflow</li> <li>WarpStitch + STMap + Canon R5C + RF 5.2mm Dual Fisheye VR180 Example Project (720 MB)</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#real-time-video-stitching-with-touchdesigner-kartavr-stmaps","title":"Real-Time Video Stitching with TouchDesigner + KartaVR + STMaps","text":"<p>Real-Time Video Stitching with TouchDesigner + KartaVR + STMaps</p> <p>Building the STMap Warping Node-Graph in TD</p> <p></p> <p>This video stitching approach works live and real-time in TouchDesigner. It uses a pre-made STmap template image to warp Canon R5C + RF 5.2mm dual fisheye imagery into a 180VR Side-by-Side layout.</p> <p>This example requires you to have a custom STMap template image created beforehand which is a task KartaVR can help with. \ud83d\ude03</p> <p>For more information about ST Maps check out the article:</p> <p>https://docs.google.com/document/d/1lQ-wc9ucLJqj-HL7iKMNWA71klV5O1fk2-JicRB6gDY/edit?usp=sharing</p> <p>Step 1. Create a new TouchDesigner project. Set the End/REnd frame range to the duration of the video footage you want to export. Customize the FPS parameter to 60 fps.</p> <p>Step 2. Use a MovieFileIn node to load an STMap template image named \"Media/EOS_R5C_RF52_STMap.0001.exr\".</p> <p>Step 3. Use a node to bring in the Canon R5C video footage.</p> <p>You can import a pre-existing movie file from disk using a \"MovieFileIn\" node.</p> <p>Or</p> <p>You can import a live video feed into TouchDesigner with the help of either an NDI video stream, or a video capture card.</p> <p>Step 4. Add a \"Remap\" node. Connect the Canon R5C footage and the STMap footage to the input connection on the Remap node.</p> <p>Step 5. Add a MovieFileOut node and connect it to the Remap node. This is how the finished footage is exported from TouchDesigner.</p> <p>Choose if you want to save out an image sequence or a movie file.</p> <p>Then customize the File attribute to define the filename for rendered footage.</p> <p>When you toggle on the \"Record\" button\", the MovieFileOut footage will be written to disk. You can turn on the \"Pause\" button if you want to pause the export process.</p> <p>It is a good idea to turn off the \"[x] Realtime\" checkbox at the top toolbar area in TouchDesigner if you are offline rendering a Movie file to disk and don't want to have any skipped frames.</p> <p>Step 6. If you want you could enable pushing footage out to an HMD in real-time, or to an HDMI video output connection, or to a real-time internet video streaming platform with the \"videostreamout\" node.</p> <p>Fusion Studio Based STMap Template Creation</p> <p>STmap Creation.comp</p> <p></p> <p>This example processes Canon EOS 180VR footage filmed with a Canon EOS R5C Camera Body and a Canon RF 5.2mm Dual Stereo Fisheye 190\u00b0 Lens.</p> <p>A CustomTool node was used to create the source ST Map default gradient pattern of a red and green gradient color.</p> <p>Fusion's right-click in the node view &gt; Copy/Paste Instance contextual menu items were used to duplicate the RGB color warping nodes and make an instanced version of the nodes that automatically mirror those settings. This allowed us to swap out the RGB imagery and run an ST map warping template through in their place.</p> <p>Then a Combiner node merged the left and right eye views' STMap warping templates into a side-by-side format.</p> <p>The STMap warping template was then saved to disk as a single frame duration still image.</p> <p>An STMap template needs to be saved in a high dynamic range format like a 16 bit or 32 bit per channel image format. The EXR image format makes a good output choice and you can use any 100% lossless image codec such as ZIP or None.</p> <p>A ChangeDepth node was added just before the CustomTool to push the frame buffer to a floating-point high dynamic range format (32-bit float). This ensures we aren't working with a gradient image that is low-dynamic range for the rest of the comp.</p> <p>For more information about ST Maps check out the article:</p> <ul> <li>KartaVR Workflows | Creating ST Maps</li> </ul> <p>STmap Rendering.comp</p> <p></p> <p>This composite uses a pre-made STmap template image to warp Canon R5C + RF 5.2mm dual fisheye imagery into a 180VR Side-by-Side layout. The template was created with the help of the KartaVR WarpStitch fuse.</p> <p>This example uses the STMapper fuse for warping the STmap template which is available in the Reactor Package Manager.</p> <p>A stereo 3D preview of the scene is viewed with an anaglyph node and the kvrReframe360Ultra fuse which is available in the Reactor Package Manager.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolve-vr180-warping-via-stmapperinline","title":"Resolve VR180 Warping via STMapperInline","text":"<p>Resolve VR180 Warping via STMapperInline</p> <p>This approach works in the Resolve Studio Edit page. It uses a pre-made STmap template image to warp Canon R5C + RF 5.2mm dual fisheye imagery into a 180VR Side-by-Side layout.</p> <p>This example requires you to have installed the STMapper fuse and the STMapperInline \"Effects Template\" macro which are available in the Reactor Package Manager.</p> <p>For more information about ST Maps check out the article:</p> <ul> <li>KartaVR Workflows | Creating ST Maps</li> </ul> <p>Step 1. Create a new Resolve Studio project.</p> <p></p> <p>Step 2. Edit the project settings.</p> <p></p> <p>Set the Master Settings to use a Timeline format &gt; Timeline Resolution of 8192x4096 px processing.</p> <p>Set the Timeline Format &gt; Playback frame rate to 59.94 frames per second.</p> <p>Set the Image Scaling to use an Input Scaling &gt; Mismatched resolution files &gt; Stretch frame to all corners.</p> <p>Set the Output Scaling to Mismatched resolution files &gt; Stretch frame to all corners.</p> <p></p> <p></p> <p>Step 3. Add the movie file to the Resolve Media Pool. Create a new timeline based upon the clip.</p> <p>In the \"Create New Timeline\" dialog uncheck \"[x] Use Project Settings\".</p> <p>Switch to the Format tab and enable Timeline Resolution 8192 x 4096 processing.</p> <p>Timeline Frame Rate 59.94 fps. Mismatched Resolution Stretch frame to all corners.</p> <p>Step 4. In the Edit page, open the \"Effects\" tab at the top left of the user interface. Expand the \"Toolbox &gt; Effects &gt; Stitching\" section. Select the \"STMapperInline\" item and drag it onto the video clip in the Edit page timeline.</p> <p></p> <p>Step 5. Expand the Edit page \"Inspector\" tab. Switch to the Effects section in the Inspector window. Select the STMapperInline item.</p> <p>Click the \"Browse\" button and navigate on your hard disk to where this example project file is stored to select the STMap warping template image named: \"STMap Canon R5C RF 5.2mm/Resolve Project/Media/EOS_R5C_RF52_STMap.0001.exr\".</p> <p>After a moment the Edit page preview window should show the results of the STMap warping the dual fisheye imagery into a side-by-side 180VR cropped 180x180\u00b0 LatLong view layout.</p> <p>Step 6. You can now edit the footage.</p> <p>Step 7. The footage is then rendered via the Delivery page. If you are on a macOS system a good output format might be to use:</p> <pre><code>Render Settings &gt; Custom\n\n[x] Export Video\n\nFormat: QuickTime\nCodec: Apple ProRes\nType: Apple ProRes 422 HQ\n\nResolution: Custom\n8192 x 4096 px\n\nFrame Rate: 59.94 fps\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#ptgui-pro-batch-automated-workflows","title":"PTGui Pro Batch Automated Workflows","text":"<p>PTGui Pro Batch Automated Workflows</p> <p>PTGui Pro is the golden standard of panoramic 360VR stitching programs. For pipeline automation needs it has a powerful feature called batch-builder that lets you automate repetitive tasks like bulk stitching of HDRIs, or automatically stitch multi-view image sequences.</p> <p>https://ptgui.com/</p> <p>The Batch-Builder mode needs image sequences to be broken down into numbered folders for each timeline frame. Each folder holds all of the camera views for one specific frame number from the image sequences. Then a PTGui .pts file is copied into that folder.</p> <p></p> <p>You can then use the Batch-Builder user interface in PTGui Pro to process this media.</p> <p>Alternatively, you can control the PTGui command line task from a render manager like Deadline, or a toolset like Houdini TOPs, or a Fusion composite running Vonk Data Nodes.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#ptgui-uses-a-json-based-project-file-format","title":"PTGui Uses a JSON Based Project File Format","text":"<p>PTGui Uses a JSON Based Project File Format</p> <p>A big change for PTGui v11-12+ project files is that they are stored in a JSON format. This means both the Notepad++ for Fusion atom package in the Reactor, and the Vonk JSON data nodes in Fusion can be used to interactively read every single attribute on the fly.</p> <p></p> <p>A Summary of the PTGui Pro .pts JSON Hierarchy</p> <p>PTGui .pts Image Name</p> <pre><code>project.imagegroups.[#].images.[1].filename\n</code></pre> <p>Camera View Data</p> <pre><code>project.imagegroups.[#].maskbitmap = 2be950115163281b1954bd0cf1951d00\nproject.imagegroups.[#].images.filename =  \"Media/CameraA.0001.jpg\"\nproject.imagegroups.[#].images.include = true / false\n\nproject.imagegroups.[#].size = [2700,2700]\nproject.imagegroups.[#].position.params.yaw\nproject.imagegroups.[#].position.params.pitch\nproject.imagegroups.[#].position.params.roll\n\nproject.controlpoints.[#] = {\"t\":0,\"0\":[1,0,580,1306],\"1\":[2,0,2388,1305]},\n\nproject.panoramaparams.hfov\nproject.panoramaparams.vfov\nproject.panoramaparams.projection = equirectangular\nproject.panoramaparams.outputcrop = [0,0,1,1]\n\nproject.globallenses.[#].lens.params.focallength\nproject.globallenses.[#].lens.params.cropcircleradius\nproject.globallenses.[#].lens.params.cropcenteroffset\nproject.globallenses.[#].lens.params.a\nproject.globallenses.[#].lens.params.b\nproject.globallenses.[#].lens.params.c\nproject.globallenses.[#].shift.params.longside\nproject.globallenses.[#].shift.params.shortside\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#ptgui-pts-mask-base64-encoded-png","title":"PTGui .pts Mask Base64 Encoded PNG","text":"<p>PTGui .pts Mask Base64 Encoded PNG</p> <pre><code>assets.[#].data\n</code></pre> <p>Each of the hand-painted masks created in PTGui for an individual camera view is saved into the .pts file as a JSON record that holds an inline Base64 encoded PNG image.</p> <p>The image framebuffer uses an indexed color palette with support for 3 un-anti-aliased colors; black (unpainted), red (exclude zone), and green (include zone).</p> <p>Individual Mask Base64 Data Record</p> <pre><code>assets.data\nassets.id = 2be950115163281b1954bd0cf1951d00\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#using-ptgui-batch-builder-with-kartavr","title":"Using PTGui Batch Builder with KartaVR","text":"<p>Using PTGui Batch Builder with KartaVR</p> <p>The KartaVR toolset includes two Lua-based automation scripts called \"PTGui BatchBuilder Creator\" and \"PTGui BatchBuilder Extractor\" which can be used to bring multi-view media into and out of a numbered-folder hierarchy.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#using-ptgui-with-vonk-ultra","title":"Using PTGui with Vonk Ultra","text":"<p>Using PTGui with Vonk Ultra</p> <p>The Vonk Data Nodes also provide several example .comp files that show approaches for automating a PTGui workflow.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#virtual-production-cylinder-stitching-example","title":"Virtual Production Cylinder Stitching Example","text":"<p>Virtual Production Cylinder Stitching Example</p> <p>This KartaVP stitching example shows an interesting workflow that interactively stitches a PTGui Pro v12 .pts file inside of Fusion's node graph via a RunCommand node.</p> <p></p> <p>Then Vonk JSON and Vonk Text data nodes work together to parse the JSON formatted .pts file to extract the relative file path location of the PTGui Pro v12 Batch rendered HDRI panoramic image.</p> <p></p> <p>Finally, a simulated virtual production LED video stage wall is created using Fusion's 3D workspace. The latest PTGui Pro stitched imagery is automatically placed onto this LED video wall surface. A Camera3D node can then be flown around inside the virtual production stage filming volume to create reframed shots with the wrap-around live-action background plate visible.</p> <p></p> <p>This sample footage was captured using a Nikon D750 Camera with an AF DX Fisheye-Nikkor 10.5mm F/2.8 ED lens. A Nodal Ninja panoramic head was adjusted to an indexed rotation value of 15 degrees per view rotation increment, and 12 view angles were captured in the Nikon RAW NEF image format starting at 1:30 AM, local time on 2021-12-08.</p> <p>Each photo was HDR exposure blended from a set of three RAW images taken at +3EV, 0EV, and -3EV. The pictures had an average of a 30 second exposure time, ISO 1600, aperture F/8, and the content was captured using a manual exposure mode.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#sgo-mistikavr-stitching-workflows","title":"SGO MistikaVR Stitching Workflows","text":"<p>SGO MistikaVR Stitching Workflows</p> <p>SGO MistikaVR is a popular program for stitching 360VR videos with optical flow seaming. It supports the import of PTGui .pts project files for new camera rig template creation, and is capable of exporting STMaps that bake out the lens template setting used.</p> <p>Mistika Boutique offers a wide range of online finishing features to expand on the 360VR stitching capabilities users get with MistikaVR. SGO also has a node-based video encoding and workflow automation tool that is appropriately called Mistika Workflows.</p> <p>SGO Mistika is available on a subscription plan.</p> <p>https://www.sgo.es/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#distributed-mvr-stitching-via-a-render-farm","title":"Distributed MVR Stitching Via a Render Farm","text":"<p>Distributed MVR Stitching Via a Render Farm</p> <p>MistikaVR has command-line support which allows for external render manager based control and job distribution using programs like Amazon AWS Deadline.</p> <p>This allows you to build a mini-render-cluster on a LAN network or in the cloud to speed up your immersive workflows when taking on ultra-high resolution stitching tasks of footage over 8K-16K+ resolution.</p> <p>A MVR distributed rendering process becomes relevant if you start to create live-action captured backgrounds for virtual production LED video stage productions that need extreme image quality and lightning-fast turnaround times.</p> <p></p> <p>You can use a combination of the \"Submit MistikaVR Job to Deadline\" controls for the \"Pool\", \"Concurrent Tasks\", \"Machine Limit\", and \"Machine List\" settings to hone the exact job distribution parameters to meet your GPU-powered render farm's precise hardware capabilities and scale.</p> <p>The \"Frames Per Task\" control specifies how many frames are sent to an individual render node in a single job task. Setting a lower value might protect against memory leaks and GPU glitches from accumulating. Setting a higher value reduces the startup time overhead for launching a new MVR task.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#stitchem-videostitch-studio-vahanavr","title":"StitchEm VideoStitch Studio + VahanaVR","text":"<p>StitchEm VideoStitch Studio + VahanaVR</p> <p>VideoStitch Studio and VahanaVR played an important role in the development of the 360VR stitching market. Eventually Orah and other products came to market from the same company.</p> <p>https://github.com/stitchEm/StitchEm</p> <p>https://github.com/stitchEm/camorah</p> <p>VideoStitch Studio User Interface:</p> <p></p> <p>VahanaVR User Interface:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#license","title":"License","text":"<p>License</p> <p>VideoStitch Studio is an MIT-licensed open-source project. A license key is not required to run the software. The software was originally developed by VideoStitch SAS. After the company folded in 2018, the source code was acquired by the newly founded non-profit organization stitchEm, to publish it under a free software license.</p> <p>StitchEm Resources:</p> <ul> <li>StitchEm Facebook Group</li> <li>Getting Started YouTube Video by Veroma</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#stitchem-github-release-page","title":"StitchEm GitHub Release Page","text":"<p>StitchEm GitHub Release Page</p> <p>You can download the various StitchEm builds for macOS and Windows from the project's GitHub Releases page. Take note of the GPU support requirements for each of the software releases to line that information up with your system's actual hardware.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#stitchem-reactor-package-manager-based-install","title":"StitchEm Reactor Package Manager Based Install","text":"<p>StitchEm Reactor Package Manager Based Install</p> <p>Both the StitchEm VideoStitch Studio and VahanaVR programs are available in the Reactor package manager's \"Bin\" category for Windows users.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolvefusion-hmd-connectivity","title":"Resolve/Fusion HMD Connectivity","text":"<p>Resolve/Fusion HMD Connectivity</p> <p>When you are running Resolve Studio (the Paid edition of Resolve) you can connect to an HMD inside the Fusion page compositing session environment. This is done by opening up the \"Fusion &gt; Settings...\" menu.</p> <p>In Fusion Studio Standalone this settings change is done by opening the \"Fusion Preferences\" menu item.</p> <p></p> <p>Then in the Fusion page settings window select the category on the left side of the window labelled \"VR Headset\". In this \"VR Headset\" section you can adjust the HMD settings to match your personal needs. With the HMD Support in the Resolve Fusion page, you can use Oculus SDK, and OpenVR based HMDs. The same approach works inside of Fusion Studio Standalone, too.</p> <p>If you have an Oculus Quest HMD you can tether this HMD to Resolve's Fusion page as an output device by installing the Windows 10 based \"Quest Link\" drivers found on the Oculus website (https://www.meta.com/help/quest/articles/headsets-and-accessories/oculus-link/meta-quest-link-compatibility/). Then you connect a USB 3 class cable with a USB-C connector from your PC's USB 3 or 3.1 class USB port to the Quest HMD.</p> <p>Personally speaking, I'm using a fairly long \"Amazon Basics\" USB-C cable and it works for my needs, although I wish it had a right angle connector on it like the Oculus Quest default charging cable has since I'm sometimes worried I might put stress on the Quest end of the cable when using room-scale 6DoF approaches with the HMD.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#kartavr-warpstitch-ultra-fuse","title":"KartaVR WarpStitch Ultra Fuse","text":"<p>KartaVR WarpStitch Ultra Fuse</p> <p>WarpStitch is a hardware-accelerated DCTL fuse for Resolve/Fusion that allows you to warp and stitch fisheye imagery into an equirectangular/spherical/LatLong image projection panoramic video. Floating-point 16-bit per channel, and 32-bit per channel image processing is supported so you can work with bracket merged high dynamic range data and stitch the media into a spherical HDRI.</p> <p>The DCTL support in WarpStitch allows the same fuse code to run equally well in a cross-platform fashion on Windows/Linux/macOS systems running across CUDA, OpenCL, and Metal GPU hardware.</p> <p>WarpStitch Ultra was created by David Kohen (Learn Now FX), and Andrew Hazelden (KartaVR for Fusion). Development was made possible based upon code contributions from Chad Capeland's CustomShader3D project, and DCTL code examples by BaldAvenger.</p> <p>WarpStitch Ultra Resources:</p> <ul> <li>YouTube | Hugh Hou | Edit Canon R5C &amp; R5 VR180 w/ DaVinci Resolve 18 FREE - 3D 8K 60fps RAW LT Clog3 Workflow</li> <li>WarpStitch + STMap + Canon R5C + RF 5.2mm Dual Fisheye VR180 Example Project (720 MB)</li> </ul> <p></p> <p>Open-Source Software License Terms:</p> <p>The WarpStitch fuse is Apache 2.0 licensed.</p> <p>DCTL Fuse Support Requirements:</p> <ul> <li>An OpenCL, CUDA, or Metal based GPU</li> <li>Fusion Studio 17-18+ or Resolve 17-18+</li> </ul> <p>Known Issues:</p> <ul> <li>IMU Control page code not active yet</li> <li>Stereo3D Control page code not active yet</li> <li>Panotools A/B/C lens distortion code not present yet in lens distortion controls</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#the-warpstitch-ultra-user-interface","title":"The WarpStitch Ultra User Interface","text":"<p>The WarpStitch Ultra User Interface</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#an-introduction-to-warpstitch-ultra","title":"An Introduction to WarpStitch Ultra","text":"<p>An Introduction to WarpStitch Ultra</p> <p>1. Use a Loader or MediaIn node in Fusion to import footage that was filmed with a circular fisheye lens. Select this node.</p> <p>2. With the Nodes view active, press the \"Shift + Space\" hotkey to display the Select Tool dialog.</p> <p>Type in \"WarpStitch\" and then press the \"Add\" button to insert a new KartaVR WarpStitch node into your composite. WarpStitch should now be connected to your Loader or MediaIn node.</p> <p>3. It is a good idea to insert an \"AutoDomain\" node into the composite immediately after a WarpStitch node, so Fusion will effortlessly handle the frame size and aspect ratio changes performed by WarpStitch. An AutoDomain node can be added using the \"Shift + Space\" hotkey to display the Select Tool dialog. Type in \"AutoDomain\" and then press the \"Add\" button.</p> <p>4. Select the WarpStitch node in your comp. In the Inspector window there is a \"View Mode\" ComboMenu control, which is at the top of the list of controls for the node.</p> <p>The \"View Mode\" ComboMenu lets you switch between seeing the \"Final Result\", the \"Original Image\", or a variety of diagnostic modes like \"Initial Crop\", \"Rotated Image\", \"Vector Mask\", \"Masked Image\", \"Warped Image\", and \"Color Corrected Image\" which are useful for inspecting the intermediate stages of internal data processing performed by the WarpStitch node.</p> <p>There are four tabs present that we need to interact with labeled \"Lens\", \"Color\", \"Image\", and \"Settings\".</p> <p>The \"Lens\" tab provides the controls needed to adjust the warping process including: - Defining the lens center with the \"Optical Frame Center\" control - Modifying the original image's rotation is possible with the \"Image Orientation &gt; Angle\" control.</p> <p>It allows you to choose between 0, 90, 180, and 270 degree rotations. - Applying vector masking to your imagery is done with the \"Circular Fisheye Masking\" / \"Rectangular Masking\" / \"Split View Masking\" controls - Adjusting the FOV for the circular fisheye lens is done with the \"Diagonal Field of View\" control.</p> <p>A typical circular fisheye lens might have a 180 degree FOV. - Rotation of the spherical image projection output is done via the Rotate Sphere controls which provide access to rotating the warped image via a set of \"Tilt\", \"Pan\" and \"Roll\" controls. If you wanted to rotate a panoramic image horizontally by 180 degrees you would set the Pan control to 180.</p> <p>The \"Color\" tab provides the controls needed to perform basic per-camera view color corrections to help your footage better match up when blended.</p> <p>The Exposure, Gamma, Levels, and Output Levels controls allow you to adjust the overall brightness and contrast in the image along with the shadows and highlights.</p> <p>The Saturation and Vibrance controls allow you to make the colors \"pop\" and appear more vivid. The White Balance section provides Color Temperature and Tint controls which allow you to compensate for per-camera differences in the color of the lighting.</p> <p>The \"Image\" tab allows you to adjust the image aspect ratio settings for the final warped image. Additionally, the \"Output ST Map\" checkbox tells the WarpStitch node to output a \"UV Pass\" warping template image called an \"ST Map\" which can be used to store a pre-computed image projection transform into an image's red and green color channels. The \"Edge Settings &gt; Edge\" control can help fix seam artifacts.</p> <p>The \"Settings\" tab allows you to assign your own intool scripting based \"Frame Render Scripts\", along with providing access to a pair of Edit Code buttons labeled \"Edit Fuse\" and \"Reload Fuse\" that can be used to manually tweak the default range of WarpStitch's user interface controls or to adjust any other aspect of the fuse's code.</p> <p>5. Switch back to the \"Lens\" tab.</p> <p>Adjust the \"Initial Crop &gt; Optical Frame Center\" control to place the onscreen \"X\" shaped on-screen viewer control in the center of the circular fisheye image.</p> <p>If you click in the Fusion viewer window so it has the user input focus, you can tap the TAB key several times to quickly toggle the active onscreen control widget so the \"X\" shaped on-screen viewer control is highlighted in red and can be dragged around visually with your cursor.</p> <p>Note: If you are working with footage from a 1-piece panoramic camera that places both the front and back fisheye images inside the same image frame in a \"SBS\" side-by-side layout, you can typically start out by changing the \"Optical Frame Center\" value from \"0.5\" over to either \"0.25\" or \"0.75\" as an initial starting point before you would then refine the value further.</p> <p>Change the \"View Mode\" to \"Initial Crop\".</p> <p>The \"Initial Crop &gt; Frame Border Padding\" slider can be used to help \"uncrop\" a circular fisheye image that has been captured on a 16:9 video sensor that would cut off part of the circular fisheye image frame area.</p> <p>If your camera body was rotated when mounted on the panoramic camera rig, you can adjust the \"Image Orientation &gt; Angle\" setting to correct for this view rotation. The \"View Mode\" control labeled \"Rotated Image\" lets you verify the image orientation adjustment is set as you'd expect so you can be sure you have the correct \"upright\" axis defined for the image before it is warped into a spherical image projection.</p> <p>6. Change the \"View Mode\" to \"Masked Image\" to see the circular masking applied to the imagery.</p> <p>To adjust the circular fisheye masking setting, you can use the Inspector and drag the slider for the \"Vector Masking &gt; Circular Fisheye Masking &gt; Mask Diameter\" control to line up with the border of your fisheye lens image data, or the circular shaped onscreen control handle can be used to resize the mask visually.</p> <p>The \"Vector Masking &gt; Circular Fisheye Masking &gt; Mask Softness\" slider allows you to adjust how hard or soft you want the mask edge to appear. Additionally, you could set the \"View Mode\" to \"Vector Mask\" to see just the black/white masking output if you want to see the precise size of the mask used and its overall softness.</p> <p>7. The \"Warped Image &gt; Diagonal Field of View\" control can be adjusted to change the FOV of the circular fisheye image. Typical wide angle fisheye lenses are somewhere in the range of 180 - 220 degree FOV.</p> <p>You need to change the \"View Mode\" control to \"Warped Image\" or \"Final Result\" to see the effects of the FOV modifications. The Rotate Sphere controls for Tilt, Pan, and Roll are used to adjust the placement of the fisheye image inside the final spherical image projection.</p> <p>8. Switch to the Color tab. This tab allows you to perform \"Quick 'n Dirty\" modifications to each of the camera views you are processing. This is a time saver if you need to apply small color tweaks.</p> <p>The \"View Mode\" control has a \"Color Corrected Image\" option that allows you to see the result of these changes. If you need to perform more complex color corrections you could always add a separate ColorCorrector node to the comp per-camera view.</p> <p>Change the \"View Mode\" over to \"Final Result\" to see the effects of all the settings applied at once. This \"Final Result\" option is the setting WarpStitch should be left at when you are done with all your adjustments and want to look at the footage downstream in your composite.</p> <p>9. Repeat the main steps shown in sections 1-8 to set up each of the per-camera views you want to warp into a spherical image projection. For speed of adjustment consider using the copy/paste instance approach alongside the Deinstance controls tip to rapidly deploy many near identical camera views.</p> <p>10. Connect each of the WarpStitch per-camera view processed composite branches together using either a series of Merge nodes chained together, or with a kvrMergeLayers node that supports blending multiple image input connections that are fed into the same node simultaneously.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#kartavr-reframe360-ultra-fuse","title":"KartaVR Reframe360 Ultra Fuse","text":"<p>KartaVR Reframe360 Ultra Fuse</p> <p>A DCTL fuse that allows you to reframe your equirectangular/spherical/LatLong panoramic videos to create unique camera angles.</p> <p>The code was ported by David Kohen (Learn Now FX), and Andrew Hazelden (KartaVR for Fusion) from the original open-source Reframe360 Resolve OpenFX plugin by Stefan Sietzen. Development was made possible based upon code contributions from the DCTL code examples by BaldAvenger.</p> <p>kvrReframe360Ultra Resources:</p> <ul> <li>WSL | Reframe 360 Ultra Thread</li> <li>YouTube | Hugh Hou | How to ReFrame ANY 360 Video in DaVinci Resolve FREE in Real Time (Insta360, GoPro MAX, Qoocam 8K)</li> </ul> <p></p> <p>Open-Source Software License Terms:</p> <p>The WarpStitch fuse is Apache 2.0 licensed.</p> <p>DCTL Fuse Support Requirements:</p> <ul> <li>An OpenCL, CUDA, or Metal based GPU</li> <li>Fusion Studio 17-18+ or Resolve 17-18+</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#the-reframe360-ultra-user-interface","title":"The Reframe360 Ultra User Interface","text":"<p>The Reframe360 Ultra User Interface</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusion-comp-examples","title":"Fusion Comp Examples","text":"<p>Fusion Comp Examples</p> <p>When the \"Reframe360 Ultra\" Reactor atom package is installed you can explore the example Fusion composites in this folder:</p> <pre><code>Reactor:/Deploy/Comps/KartaVR/Reframe360/\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#how-to-solve-a-black-hole-issue-in-resolve","title":"How to Solve a \"Black Hole\" Issue in Resolve","text":"<p>How to Solve a \"Black Hole\" Issue in Resolve</p> <p>kvrReframe360 Ultra users have occasionally reported having a black circle region appear in the zenith and nadir zones of their panoramic video when reframing footage in the Resolve Edit/Fusion page. After working through the reports with the users, the following solution was found to be effective:</p> <p>The issue is related to the source MP4 video file having a 2:1 aspect ratio, and their editing timeline was set to use a 16:9 aspect ratio or 1:1 aspect ratio for the output.</p> <p>Resolve's default Timeline Settings will typically fit the panoramic footage to the frame size on one axis, and crop the footage on the other axis which creates the black hole artifact.</p> <p>To fix the black region at the bottom of the frame issue, you should edit the Resolve Timeline settings.</p> <p>In the Timeline Settings window, uncheck the \"[x] Use Project Settings\" checkbox. Then edit the \"Mismatched Resolution\" preference so it is set to \"Stretch frame to all corners\".</p> <p>This will fit the source MP4 video so the width and height are scaled to precisely match the frame size of the rendered video.</p> <p>The \"Mismatched resolution files\" setting can also be defined in the \"Project Settings &gt; Image Scaling &gt; Input Scaling\" preferences window, too.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolvefusion-360vr-point-tracking","title":"Resolve/Fusion 360VR Point Tracking","text":"<p>Resolve/Fusion 360VR Point Tracking</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#applying-2d-tracking-to-latlong-360vr-based-3d-transforms","title":"Applying 2D Tracking to LatLong 360VR based 3D Transforms","text":"<p>Applying 2D Tracking to LatLong 360VR based 3D Transforms</p> <p>This post explains how to link a Tracker node to a Transform3D node. This allows you to track a 2D element in 360VR monoscopic footage with a stock Fusion Tracker node.</p> <p>Step 1. Add a Tracker node to the comp, connect the Tracker node to your Loader/MediaIn based footage, and perform a 1-point track of an object in the frame. Refine the point tracking output using traditional Fusion tracking techniques, which can be found in other tutorials.</p> <p>Step 2. Add your 3D element to the scene using either an FBX Mesh, ABC Mesh, or Fusion's geometry tools like a Shape3D node.</p> <p>Step 3. Add a Transform3D node. Connect the geometry to the Transform3D node. Then select the Transform3D node.</p> <p></p> <p>Step 4. Y-Axis Rotation Linking:</p> <p>On the Y Rotation channel right-click and select the Connect To &gt; Tracker1 &gt; Offset X Position (3D Space).</p> <p></p> <p>Then on the Y Rotation channel, right-click again and select \"Insert &gt; Calculation: First Operand -&gt; Calculation\".</p> <p></p> <p>This will add a \"Calculation on Transform3D\" modifier to the node.</p> <p>Click on the \"Modifiers\" tab on the Transform3D node to see the new modifier. The First Operand is linked to the tracker's X offset animation curve. Set the \"Operator\" to \"Multiply\". Then set the \"Second Operand\" to \"-360\".</p> <p></p> <p>Tip: Alternatively, if you are working with 180VR footage you can set the \"Second Operand\" value to \"-180\".</p> <p>Step 5. X-Axis Rotation Linking:</p> <p>On the X Rotation channel right-click and select the Connect To &gt; Tracker1 &gt; Offset Y Position (3D Space).</p> <p>Then on the X Rotation channel, right-click again and select \"Insert &gt; Calculation: First Operand -&gt; Calculation\".</p> <p>This will add a \"Calculation on Transform3D\" modifier to the node.</p> <p>Click on the \"Modifiers\" tab on the Transform3D node to see the new modifier. The First Operand is linked to the tracker's Y offset animation curve. Set the \"Operator\" to \"Multiply\". Then set the \"Second Operand\" to \"180\".</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#applying-2d-tracking-to-the-panomap-node","title":"Applying 2D Tracking to the PanoMap Node","text":"<p>Applying 2D Tracking to the PanoMap Node</p> <p>It is also possible to apply this same type of approach to a PanoMap node's rotation controls.</p> <p></p> <p>The PanoMap node's Rotation X and Rotation Y channels are what you would bind to the Tracker node in a similar fashion as a Transform3D node's rotation controls.</p> <p></p> <p>The same modifier approach is then used to adapt the screen space 0-1 normalized coordinate system into a 360VR centric 360x180\u00b0 coordinate system value range.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusionkartaverse-exr-multi-part-vs-multi-channel-workflows","title":"Fusion/Kartaverse EXR Multi-Part vs Multi-Channel Workflows","text":"<p>Fusion/Kartaverse EXR Multi-Part vs Multi-Channel Workflows</p> <p>This example shows two EXR image files that both contain 45 camera views along with an ST Map template. This is intended to be a demo of EXR Multi-Channel and Multi-Part usage.</p> <p>The footage shows a green storm hurricane lantern that was rendered from V-Ray for Maya in a custom stereo camera rig that created 45 views in a linear camera array configuration. The camera filmback was altered so it created a uniform and consistent multi-view output that is \"stereo converged\" at the same zero parallax distance in the 3D scene.</p> <p>For the purpose of this demo I grabbed pre-existing media from an existing GitHub project called Lightfielder Suite.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#exr-sample-media-download-link","title":"EXR Sample Media Download Link","text":"<p>EXR Sample Media Download Link</p> <p>To follow along on your local system, you can download the sample media here:</p> <p>https://www.andrewhazelden.com/projects/kartaverse/downloads/exr_multipart_vs_multichannel.zip</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#what-is-the-difference","title":"What is the Difference?","text":"<p>What is the Difference?</p> <p>A \"Part\" in EXR image container terms can be thought of as a Photoshop layer. Each part in an EXR image can hold an arbitrary amount of image channels.</p> <p>A \"Channel\" in EXR image container terms would be one greyscale channel of data like \"Red\", \"Green\", \"Blue\", \"Alpha\", or \"Z-Depth\" data.</p> <p>It is possible to hold multi-view data in an EXR container as either:</p> <p>1 set of RGBA channels per EXR image like you are doing now.</p> <p>Or multiple camera views (per-timeline-frame) can be packaged into a single EXR image for easier data portability with systems that can support multi-view or multi-part data I/O like the Resolve Fusion page, or NukeX, etc...</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#exr-multi-channel-data","title":"EXR Multi-Channel Data","text":"<p>EXR Multi-Channel Data</p> <p></p> <p>The file \"Media/Multi-Channel.0000.exr\" stores each image from \"Cam 01\" to \"Cam 45\" as separate RGBA channels inside the same EXR image. This results in each camera view being accessed with the image data elements named like:</p> <pre><code>Cam 01.A  \nCam 01.R  \nCam 01.G  \nCam 01.B  \n...  \nCam 02.A  \nCam 02.R  \nCam 02.G  \nCam 02.B  \n...  \nUndistort STMap.A  \nUndistort STMap.R  \nUndistort STMap.G  \nUndistort STMap.B\n</code></pre> <p>This is an example of a Fusion Loader node accessing the multi-channel components in the image:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#exr-multi-part-data","title":"EXR Multi-Part Data","text":"<p>EXR Multi-Part Data</p> <p></p> <p>The file \"Media/Multi-Part.0000.exr\" stores each image from \"Cam 01\" to \"Cam 45\" in separate image parts.</p> <p>This results in each camera view being accessed by name. The individual RGB channels inside the EXR part are all consistently named \"RGBA\" with no prefix added.</p> <pre><code>Part Name: Cam 01   \nChannels: RGBA  \n...  \nPart Name: Cam 02  \nChannels: RGBA  \n...  \nPart Name:  Undistort STMap  \nChannels: RGBA\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#quilted-frame","title":"Quilted Frame","text":"<p>Quilted Frame</p> <p></p> <p>The image \"Media/JPEGS/9x5_quilted_green_lantern.jpg\" holds 45 views of imagery in a 5 horizontal x 9 vertical image grid layout.</p> <p>This would sometimes be called a texture atlas, a quilted image, or a grid/tiled image layout. This media was originally prepared for playback on a Looking Glass Display.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#multi-view-image-sequences","title":"Multi-View Image Sequences","text":"<p>Multi-View Image Sequences</p> <p></p> <p>This approach is the plain-vanilla way to work with multi-view imagery, like you are already doing now. Each image stream from an individual camera on the multi-view camera rig is exported to a separate image sequence.</p> <p>In this case a single timeline frame from the sample media was named like:</p> <pre><code>\"Media/JPEGs/Lantern.[0000-0044].0000.png\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusionkartaverse-lightfield-workflows","title":"Fusion/Kartaverse Lightfield Workflows","text":"<p>Fusion/Kartaverse Lightfield Workflows</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#k-lens-multiview","title":"K Lens MultiView","text":"<p>K Lens MultiView</p> <p>With the help of sample footage from a DPREVIEW article covering the German-made DSLR compatible \"K Lens\" light-field lens, several proof-of-concept light-field workflows were created in Resolve/Fusion/KartaVR.</p> <p>The processing steps involved a \"K Lens\" light-field 3x3 camera view image extraction.</p> <p>Then each of the 9 camera view positions were precisely aligned and registered against a common image feature. Finally, the output was repackaged back into a tiled grid layout. I used an expression on a Fusion \"Text+\" node to automatically label and number each camera view which allowed me to visually check and verify that the 3x3 grid layout based frame-packing order was correct.</p> <p></p> <p>The imagery used for the proof-of-concept test was pulled from a December 8<sup>th</sup>, 2021 article by Damien Demolder on the DPREVIEW website titled:</p> <p>Hands-on with the K-Lens, a light field lens that captures 3D data for post-capture refocusing</p> <p>Using this web-sourced image sample for an R&amp;D test meant the footage was available at something like 1/10<sup>th</sup> of the original DSLR camera body's native photo resolution.</p> <p>The native resolution for light-field media photographed with a DSLR + K Lens is calculated by breaking apart the 3x3 multi-view layout imagery. This is done as \"Image Width \u00f7 3\", and \"Image Height \u00f7 3\" for the final view size that is visible on a multi-view compatible playback device.</p> <p>I don't think the lens resolution is an unworkable issue with the availability of image resizing options like PyTorch driven ML super-resolution techniques, or Topaz Labs software.</p> <p>When a VFX artist carries out XR post-production, computational imaging techniques in Resolve/Fusion/KartaVR v5 allow \"disparity mapping\" and \"Z-depth\" to occur.</p> <p>These approaches make it feasible to perform novel view synthesis tasks which generate interpolated views for playback on lenticular based light-field monitors like a \"Looking Glass Display\". In this case you can have up to 45 unique view angles rendered on screen at the same time using a method called \"lenticular slicing\".</p> <p>Interestingly, it is worth noting that a \"Lightfield Labs\" display (https://www.youtube.com/watch?v=7oGtgbsmmg8) can play 6DoF footage in glasses-free stereo 3D so the viewer experiences comfortable vertical and horizontal stereo parallax effects when changing the viewing position.</p> <p>The elegance of having a single light-field lens mounted on a DSLR camera body is the type of innovation needed to support the production requirements of 6DoF live action filmmaking. Wider adoption of these 6DoF concepts will happen once end-to-end solutions exist for multi-view capture, along with affordable displays for multi-view glasses free media playback.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#looking-glass-multi-view","title":"Looking Glass Multi-View","text":"<p>Looking Glass Multi-View</p> <p>KartaVR includes several Looking Glass Display optimized macro nodes and example comps that support light-field image editing, Stereo 3D left/right eye image generation, and Fusion 3D workspace based multi-view rendering.</p> <p>Check out theLookingGlassRenderer3D macro docs for information about the node:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#vonk-vimagecreatetiles-node","title":"Vonk vImageCreateTiles Node","text":"<p>Vonk vImageCreateTiles Node</p> <p>The Vonk Data Node project provides a \"vImageCreateTiles\" fuse node that makes the creation of image grid layouts a node-based task.</p> <p></p> <p>This node makes it easy to create tiled \"texture atlas\" like grid layouts. If you need the imagery to be scaled down to a specific size, attach a resize or scale node to the image stream before you connect it to the vImageCreateTiles node.</p> <p>The \"Tiles X\" control specifies how many images are stacked horizontally.</p> <p>The \"Tiles Y\" control specifies how many images are stacked vertically.</p> <p>The \"Reverse X Order\" and \"Reverse Y Order\" checkboxes are used to provide control over the image placement ordering when the grid layout is built. This allows you to start frame 1 at either of the 4 corners of the frame border.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#multiview-tiled-image-samples","title":"MultiView Tiled Image Samples","text":"<p>MultiView Tiled Image Samples</p> <p>Pikachu</p> <p>A 13x10 multi-view stereo based tiled image grid dataset of a Pikachu character is included in the KartaVR images folder:</p> <pre><code>Reactor:/Deploy/Macros/KartaVR/Images/pikachu_13x10_image_grid.jpg\n</code></pre> <p></p> <p>A YouTube video is available that shows the Pikachu multi-view footage playing back as a navigable 6 DoF real-time lightfield experience inside of Unreal Engine:</p> <p>https://www.youtube.com/shorts/lWMF5g1MR_o</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#silver-mask","title":"Silver Mask","text":"<p>Silver Mask</p> <p>A 4x4 multi-view image of a photogrammetry-based silver mask is included in the KartaVR images folder:</p> <pre><code>Reactor:/Deploy/Macros/KartaVR/Images/lg_silver_mask_4x4_quilted.0001.jpg\n</code></pre> <p></p> <p>A YouTube video is available that shows the silver mask multi-view footage playing back inside of Photoshop as an anaglyph stereo 3D formatted output using the Lightfielder Suite provided set of actions:</p> <p>https://www.youtube.com/shorts/YDEcVpiCbZg</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#green-lantern","title":"Green Lantern","text":"<p>Green Lantern</p> <p>A 5x9 multi-view image of a V-Ray for Maya rendered green hurricane lantern is included in the KartaVR images folder:</p> <pre><code>Reactor:/Deploy/Macros/KartaVR/Images/lg_green_lantern_5x9_quilted.0001.jpg\n</code></pre> <p></p> <p>A YouTube video is available that shows the green hurricane lantern multi-view footage playing back on a Looking Glass Display:</p> <p>https://youtube.com/shorts/qMnJIbk4lrY</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#example-fusion-based-lightfield-compositing-projects","title":"Example Fusion-Based Lightfield Compositing Projects","text":"<p>Example Fusion-Based Lightfield Compositing Projects</p> <p>The following Fusion .comp files are provided in the \"KartaVR Examples | Comps\" atom package in Reactor:</p> <p>\u2022 LookingGlassRenderer3D.comp</p> <p>\u2022 Looking Glass 4x4 Quilted Anaglyph Stereo 3D Viewer.comp</p> <p>\u2022 Looking Glass 4x4 Quilted to Image Sequence.comp</p> <p>\u2022 Looking Glass 5x9 Quilted Anaglyph Stereo 3D Viewer.comp</p> <p>\u2022 Looking Glass 5x9 Quilted to Image Sequence.comp</p> <p>These examples can be installed using the Reactor package manager by navigating on the left side of the window to the \"Kartaverse &gt; KartaVR &gt; Comps\" category.</p> <p>Click on the \"KartaVR Examples | Comps\" entry in the main atoms list area. Then press the \"Install\" button.</p> <p></p> <p>The example Fusion comps are installed on-disk to the following PathMap location:</p> <pre><code>Reactor:/Deploy/Comps/KartaVR/\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusionkartaverse-multi-view-parallel-io-concepts","title":"Fusion/Kartaverse Multi-View Parallel I/O Concepts","text":"<p>Fusion/Kartaverse Multi-View Parallel I/O Concepts</p> <p>Pio (Parallel I/O) techniques in Fusion allow for more image channels/image streams to run through a Resolve/Fusion node graph than is normally possible in a controlled fashion.</p> <p>Parallel I/O node graph construction approaches are different from most conventional stock workflows you would see for comp-based media management in a typical YouTube video, or in BMD's own user guides and manuals.</p> <p></p> <p>An exciting aspect of Fusion-based multi-view comp creation is that data driven approaches can be used to automate and streamline media access through the use of open-source tools like the Vonk Data Nodes, and the ReadEXRUltra fuse.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#parallel-io-example-comp-download","title":"Parallel I/O Example Comp Download","text":"<p>Parallel I/O Example Comp Download</p> <p>This example shows a simplistic representation of multi-input and multi-output approaches applied in a Fusion composite.</p> <p>Parallel_IO_Workflow_Demo_1.zip</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#parallel-io-workflow-summary","title":"Parallel I/O Workflow Summary","text":"<p>Parallel I/O Workflow Summary</p> <p>Parallel I/O provides a series of modular building blocks that will help accelerate the construction of densely packed multi-view node graphs. The primary use for this type of node assembly is for multi-view panoramic video stitching, for videogrammetry image based modeling, and for UDIM tile-based 3D texture map creation workflows.</p> <p>This toolset was designed to assist artists who find themselves frequently assembling highly symmetrical layouts.</p> <p>You can tell this is happening in your composite if you have a few \"stacks\" of very well-defined comp branches that travel the full length of the comp tree. These types of stacked multi-view branches in a comp will frequently use many synchronized settings that are mirrored across each view with the help of expression-linked attributes or instanced nodes.</p> <p>Parallel I/O tools work by containerizing each of the individual processes that run concurrently across each of your individual multi-view data processing steps. This containerization process makes things easier to manage, and very consistent.</p> <p>From the initial design stage, the Parallel I/O nodes encourage the use of super-nodal modifier nodes like the Vonk data node fuses. This allows for an \"every datatype is a node connection away\" philosophy.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#what-is-this-idea-all-about","title":"What is this idea all about?","text":"<p>What is this idea all about?</p> <p>My current multi-view data processing technique is done using an approach I call \"Parallel I/O\", \"pI/O\", or simply \"pio\" for short.</p> <p>When working with all the normal nodes that come with Fusion, pI/O node graphs use multi-input and multi-output connections applied to your own \"GroupOperator\" based macro nodes. If you want you can place PipeRouters at the bottom of a pI/O node to provide a quick way to view image streams in a Fusion viewer window.</p> <p>This grouped macro version of pI/O operates as a wrapper-like \"container\" for any type of node that could be found in Fusion Standalone or Resolve's Fusion page, including 3<sup>rd</sup> party OFX plugins, too.</p> <p>This \"pI/O\" technique can be taken even further in custom DIY-created DCTL fuses, and it can be achieved with compiled FusionSDK based plugins, too. In these situations, you also get the benefit of new connection ports being added only as needed since you can go a bit deeper with the customization.</p> <p>The Parallel I/O concept is effective for multi-view workflows as it allows you to take many, many, image streams and \"trunk\" them in parallel as the image data flows through the comp.</p> <p>(Note: With this approach to parallel data trunking, it is very helpful to change the \"Fusion Preferences &gt; Global and Default Settings &gt; Flow &gt; Build direction &gt;\" setting to Vertical.)</p> <p>My goal with this development effort was to allow Fusion to better compete with the near-unlimited EXR channel handling system present in other popular (and far less affordable) node-based compositing packages and to closer match the functional capabilities of the ubiquitous \"Shuffle\" node to be able to remap these extra image channels however you want to.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#a-detailed-summary-of-the-parallel-io-idea","title":"A Detailed Summary of the Parallel I/O Idea","text":"<p>A Detailed Summary of the Parallel I/O Idea</p> <p>I see the Parallel I/O concept as an excellent way to be able to assign the same image processing settings in bulk, and to have those values transparently kept in sync across each of the individual image streams passing through the node.</p> <p>This all happens via the magical wonder of Fusion's Right-Click contextual menu-based \"Copy\" (Command + C) entry, and the matching \"Paste Instance\" (Shift + Command + V) menu entry being used on most of the nodes that are packaged inside a \"pI/O\" wrapper based GroupOperator (aka Group node) shell.</p> <p>This technique can be done even better when applied to your own fuse-based tools that use the dynamic input connection creation code that originated in the classic Eyeon Software era \"Switch.fuse\" example that was created by Stefan Ihringer (aka CompFu) all the way back in 2010. This fuse node-based approach makes it so the extra \"pI/O\" connection ports are created as needed, on the fly, as you connect and disconnect imagery from the Parallel I/O nodes in the Nodes view. Very cool stuff and a nice quality of life improvement.</p> <p>With these Parallel I/O based multi-view techniques applied in Resolve/Fusion, you can quickly add your own synchronized LUT nodes, cropping, transforming, image projection changes, stabilization, 2D filters, or any other thing you might want to do individually to each image stream that is coming from a multi-view camera array and passing through your composite.</p> <p>IMHO, this concept perfectly lines up with the needs of immersive artists who regularly work on multi-view, stereo 3D, 3603D VR, lightfield, or video/photogrammetry workflows.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#streamlining-the-footage-loading-and-saving-process","title":"Streamlining the Footage Loading and Saving Process","text":"<p>Streamlining the Footage Loading and Saving Process</p> <p>I am currently working on a simpler approach for media management in Fusion by allowing the use of filename tokens in the \"Filename\" field of Multi-view based Loader/Saver node remakes. These node remakes are being created as fuse nodes (which work in Resolve (free), Resolve Studio, and Fusion Studio Standalone).</p> <p>The use of multi-input/multi-output fuses for media access works by leveraging the Fusion native Fuse API PutFrame/GetFrame/EXRIO functions which are accessible from the Vonk \"vImage\" fuses, the \"pioSaver\" fuse, and the \"LifeSaver\" fuse.</p> <p>The end result of all this deeply technical discussion is that these new KartaVR v5 centric approaches allow an artist, in only a few clicks, to bulk-load a \"metric ton\" of multi-view footage into a Fusion composite on the fly, which makes it possible to do just about anything to the content in post-production.</p> <p>You can then render this multi-view media out via a Fusion GUI session, the Delivery Page, or distribute the task on a render farm or a cloud compute cluster via the unlimited render node license capability of the Fusion Render Node app. Very sweet stuff indeed.</p> <p>Getting creative as a compositor, and combining pI/O techniques for node building, along with the magical Vonk Fuses, would allow you to dramatically re-define how all of your multi-view imagery is loaded into each image stream in the comp session. Additionally, the media I/O tasks could all be made to happen in a fashion that can be controlled 100% by external data sources that live outside a .comp file such as JSON, XML, YAML, CSV (comma-separated value), TSV (tab-separated value), or IFL files (image file lists).</p> <p>With pI/O (and the Vonk fuse) at play, you'd even have the option to pull data into the composite that is stored externally on your local LAN network or the full open interweb via Fusion's LuaJIT FFI scripting bindings that offer built-in cURL based internet socket connections. Adding nodes constructed with live network connectivity to a flow is achieved with a small adaptation of the existing Vonk \"vImageFromNet\", \"vJSONFromNet\", or \"vTextFromNet\" nodes.</p> <p>To make this Parallel I/O process faster to use in real-world immersive compositing workflows, I am looking into ways to script and automate the pI/O tools so an artist could select any two compatible nodes in the Nodes views, and do automatic multi-input and multi-output connection wiring in an instant via .fu based hotkey bindings, or with a right-click in the flow \"tool\" script contextual menu item entry.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#multichannel-exr-exporting-piosaver-node","title":"MultiChannel EXR Exporting pioSaver Node","text":"<p>MultiChannel EXR Exporting pioSaver Node</p> <p>pioSaver is a fuse based replacement for the traditional Saver node. It is available in the Reactor Package Manager.</p> <p>This fuse uses EXRIO for the file output and supports multi-channel EXR data export. This node is special in that you can use it in comps that are created inside of Resolve's Fusion page and inside of Fusion Standalone.</p> <p>In this example comp, the Vonk \"vTextCreate\" fuse node is used to externally supply the base \"filename prefix\" text string record used for the pioSaver powered EXRIO image saving node. This filename-prefix is added using the token value of \"<code>${COMP}/${NODE}/${NODE}</code>\".</p> <p>The Vonk \"vTextSubFormat\" fuse node is used to add the relative PathMap for the current comp's Render folder, along with the frame padding information, and the image extension using the string \"<code>Comp:/Render/{1}.0000.exr</code>\"</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusion-native-lens-distortion-correction","title":"Fusion Native Lens Distortion Correction","text":"<p>Fusion Native Lens Distortion Correction</p> <p>Although it is preferable to be able to exclusively use Panotools/Hugin/PTGui style A/B/C lens distortion parameters in your 360VR workflows...</p> <p>The built-into Fusion LensDistort node has existed for ages and it allows you to access the lens distortion/undistortion math that is used in the 3D Equalizer camera match-moving/tracking software which is a tool that comes from the feature film VFX industry. The Fusion LensDistort node's \"3DE Radial - Fisheye, Degree 8, Release 1\" lens distortion model can be used to linearize the f-theta distortion that is present in your 360VR camera rig's original unstitched circular fisheye lens shot media.</p> <p></p> <p>This corrective lens warping action will give your footage a lens distortion effect that more closely resembles an \"angular fisheye\" lens model, which is often called a \"Domemaster\" style of image in the 180 degree diagonal FOV (Field of View) planetarium show production space.</p> <p>The Lens Distortion correction process results in footage that is very consistent and uniform. The resulting media is much easier to apply DIY, artist-driven, 100% manual, node-based stitching techniques to.</p> <p>Most people don't realize they can use the Fusion LensDistort node in their composites, with no external tool requirement, as long as you don't mind taking some time with test footage to eye-ball the warping effect to taste, for each of the lenses you work with in your 360VR content creation process. With a little practice, this approach will often work well enough for a quick-n-dirty lens correction that is done 100% inside of a stock copy of Fusion or Resolve's Fusion page.</p> <p>Alternatively, you could explore ST Map (UV pass) warping to apply pre-computed lens correction values sourced from an ST Map template image that you would create externally. Yes, in the long term, solutions for applying Panotools style A/B/C corrections are preferred... but if you want to get work done today, this post should get you going in a positive direction.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusion-stereo-3d-360vr-view-rotation-effects","title":"Fusion Stereo 3D 360VR View Rotation Effects","text":"<p>Fusion Stereo 3D 360VR View Rotation Effects</p> <p>An important distinction in 360VR post-production is the difference between the idea of levelling a panorama with XYZ rotations (pan/tilt/roll) vs what a reframed video output offers.</p> <p>If your goal is to level a 360VR video clip, and you want your final output to still be a 360\u00b0x180\u00b0 spherical clip that you can view on an HMD, you should explore the use of the Fusion built-in PanoMap node to apply the view rotation effect.</p> <p>After you do the view rotation via the PanoMap node, you can render out the footage to a 2:1 aspect ratio movie file, and then use a tool like the Spatial Media Metadata Injector to make this footage play back correctly on YouTube 360 or in a VR movie player like VLC or GoProPlayer.</p> <p>If you need to level/rotate a Top/Bottom 360VR stereo video, you can use a combination of the Splitter node (Split: Vert), two PanoMap nodes (with the 2<sup>nd</sup> node added via Copy/Paste Instance (Ctrl + Shift + V hotkey), and then finally a Combiner node (Combine: Vert) at the end.</p> <p></p> <p>The Splitter node lets you separate the left and right eyes apart from the TopBottom original footage. The two PanoMap nodes apply your view rotations. Finally, the Combiner node allows you to merge the two separate left and right eye image streams back together into a single TopBottom formatted 360VR output.</p> <p>A reframing effect, by comparison, acts as its own version of an offline-rendered panoramic movie viewer. The reframing process that the Reframe360 Ultra node does converts a 360VR movie into a \"flat\" output, which is also called a rectilinear image projection in tools like PTGui. The reframing process takes a spherical 360\u00b0 panorama and makes it suitable for viewing on a conventional monitor without any VR gear, or for posting on platforms like Instagram, TikTok, or Twitter where there is no native VR playback support.</p> <p>A reframed video conversion is also great if you are looking to get a \"Tiny Planet\" like output from your spherically shot 360\u00b0x180\u00b0 source footage.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolve-edit-page-panomap-effects-templates","title":"Resolve Edit Page PanoMap Effects Templates","text":"<p>Resolve Edit Page PanoMap Effects Templates</p> <p>Here are two Resolve Studio Edit page compatible \"Effects Template\" versions of the built-in Fusion PanoMap node that might be of use for 360VR video editors.</p> <p>One macro node is named \"PanoMapMono\" for monoscopic 360\u00b0 video usage.</p> <p>The other macro node is named \"PanoMapStereo\". The node allows you to work in the Edit page and apply view rotations to stereoscopic 3D Top/Bottom and Side-by-Side formatted 360\u00b0 video content. This macro has integrated Splitter/Combiner nodes that are expression linked.</p> <p></p> <p>To use the two effects template files:</p> <p>Step 1. Download the attached \"PanoMapMono.setting.txt\" and \"PanoMapStereo.setting.txt\" files and remove the .txt extension from the end of the filenames.</p> <p>Macro Download Links:</p> <p>PanoMapMono.setting.txt</p> <p>PanoMapStereo.setting.txt</p> <p>Step 2. Create a new \"VR'' subfolder inside your Resolve Edit page based Templates folder. You will have to manually create the multiple intermediate subfolders to do this:</p> <p>Windows:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Support\\Fusion\\Templates\\Edit\\Effects\\VR\\\n</code></pre> <p>macOS:</p> <pre><code>/Library/Application Support/Blackmagic Design/DaVinci Resolve/Fusion/Templates/Edit/Effects/VR/\n</code></pre> <p>Linux:</p> <pre><code>/var/BlackmagicDesign/DaVinci Resolve/Support/Fusion/Fusion/Templates/Edit/Effects/VR/\n</code></pre> <p>Step 3. Copy the Effects Template files into the new \"VR\" folder created in Step 2.</p> <p>Step 4. Restart Resolve. Switch to an Edit page timeline with VR footage in it. In the Effects Library Tab navigate to the \"Toolbox &gt; Effects\" view.</p> <p>Step 5. Drag a \"PanoMap\" or \"PanoMapStereo\" macro onto a clip in the timeline.</p> <p>Step 6. Select the 360VR video clip in your timeline, then open the Inspector view and select the \"Effects\" control page/tab. The PanoMap node's controls will be accessible and editable.</p> <p>For the PanoMapStereo macro node, the \"Split: Vert\" control is used for \"Top/Bottom Stereo\" footage. The \"Split: Horiz\" control is used for \"Side-by-Side Stereo\" footage.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#mobius-transformations","title":"Mobius Transformations","text":"<p>Mobius Transformations</p> <p>M\u00f6bius transformations make it possible to apply zoom, rotation, and translation effects to immersive 360VR footage. With M\u00f6bius operations, the input and output media will maintain their original 360\u00b0x180\u00b0 degree spherical image projection. This allows you to transform the footage and still be able to view the media on a VR HMD afterwards.</p> <p>https://github.com/AndrewHazelden/mobius</p> <p>This is a spherical image before a mobius zoom is applied:</p> <p></p> <p>The next image shows the same scene with a mobius zoom effect used to pull the camera upwards, away from the nadir zone at the bottom of the panorama:</p> <p></p> <p>When the mobius transformed media is displayed in a panoramic image viewer you will see what looks vaguely like a tiny planet result but the media input is still 360\u00b0x180\u00b0 content which allows you to freely look around the scene with a VR HMD on.</p> <p>Note: A mobius transform approach is distinctly different from the results you get with traditional \"overcapture\" 360VR reframing processes that will translate a source 360\u00b0x180\u00b0 degree spherical image projection into either a traditional rectilinear \"flat\" image projection with a ~90\u00b0 FOV (Field of View) output, or a stereographic \"tiny planet\" flattened image projection.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#credits","title":"Credits","text":"<p>Credits</p> <p>The Kartaverse Mobius fuse development project is a fork of Henry Segerman's original Spherical Image Editing GitHub repository.</p> <p>The Kartaverse goal is to port the underlying math formulas from Henry's original code to run as a hardware-accelerated fragment shader inside of DCC packages like Blackmagic Design's Resolve/Fusion post-production software.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#python-installation","title":"Python Installation","text":"<p>Python Installation</p> <p>The following resources are required to use the Python based source code in this repository:</p> <ul> <li>Python x64 v3.6 - v3.10</li> <li>3<sup>rd</sup> Party Python Library Install:</li> <li>pip3 install --upgrade pip</li> <li>pip3 install Pillow</li> <li>pip3 install numpy</li> <li>pip3 install scipy</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#mobius-screenshots","title":"Mobius Screenshots","text":"<p>Mobius Screenshots</p> <p>Mobius Spherical Zooming</p> <p></p> <p>Mobius Spherical Rotations</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#python-cli-usage-instructions","title":"Python CLI Usage Instructions","text":"<p>Python CLI Usage Instructions</p> <pre><code>python3 mobius.py --input \"source.0000.png\" --output \"output.0000.png\" --x 180 --y 135 --zoom 10\n\npython3 mobius.py --input \"source.0000.png\" --output \"output.0000.png\" --x 0.5 --y 0.75 --zoom 10 --normalized\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#python-script-syntax","title":"Python Script Syntax","text":"<p>Python Script Syntax</p> <pre><code>usage: mobius.py [-h] -i INPUT -o OUTPUT -x X -y Y -z ZOOM [-n]\n\nApply Mobius transformations to spherical 360x180 degree footage.\n\noptions:\n  -h, --help            show this help message and exit\n  -i INPUT, --input INPUT\n                        The filepath to your source image\n  -o OUTPUT, --output OUTPUT\n                        The filepath to your output image\n  -x X, --x X           Center X (in degrees)\n  -y Y, --y Y           Center Y (in degrees)\n  -z ZOOM, --zoom ZOOM  Zoom level\n  -n, --normalized      Use normalized (0-1) range screen space coordinates for the CenterX/Y input values\n                        instead of degrees.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolvefusion-latlong-patcher-node","title":"Resolve/Fusion LatLong Patcher Node","text":"<p>Resolve/Fusion LatLong Patcher Node</p> <p>The Resolve Studio/Fusion Studio native \"LatLong Patcher\" tool, when operating in the \"Apply\" mode, takes a 90\u00b0 FOV CubeMap face image as the input. The cubic view is connected to the \"yellow\" input triangle on the node.</p> <p>That 90\u00b0 FOV cubic view image is then warped into a LatLong image projection.</p> <p></p> <p>The source image fed into a \"LatLong Patcher\" node, (when this patcher tool is set to the \"Apply\" Mode), is typically a \"MediaIn\" or \"Loader\" node that has a 1:1 aspect ratio. This imagery should be as close as possible to an idealized 90\u00b0 FOV (Field of View) that corresponds to the \"front\" face of a cubic panoramic frame format. You can use a crop node to reformat a larger, or wider aspect ratio down to the correct 1:1 ratio that is required.</p> <p>The \"LatLong Patcher\" node's \"XYZ Rotation\" controls allow you to adjust the placement of the converted image by shifting the Yaw/Pitch/Roll.</p> <p>Tech Note: The animated rotation effect generated by this node, (even when the Motion blur setting is active in the composite), will not typically have motion-blur applied if you keyframe animate the XYZ rotation channels.</p> <p>For motion-blurred 360VR output, look at a true Fusion 3D workspace based image projection conversion, that is then rendered to disk using a \"Renderer3D\" node.</p> <p>This is typically generated using a \"Spherical Camera\" node that is connected upstream of the \"Renderer3D\" node, inside the Fusion 3D scene graph you build.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#resolvefusion-360vr-inertial-stabilization-workflows-with-gyroflow","title":"Resolve/Fusion 360VR Inertial Stabilization Workflows With Gyroflow","text":"<p>Resolve/Fusion 360VR Inertial Stabilization Workflows With Gyroflow</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#command-line-based-shell-script","title":"Command-Line Based Shell Script","text":"<p>Command-Line Based Shell Script</p> <p>\"Gyroflow to CSV\" is a Python script that converts your Gyroflow stabilization to a CSV file.</p> <p>When using the CLI based Gyroflow to CSV script, make sure to choose \"including processed gyro data\" when exporting from Gyroflow. By default, Gyroflow saves out the rotation data using a Euler rotation (ZYX) based notation format. It also saves out the data in your footages' native frame rate.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#fusion-based-comp-script","title":"Fusion Based Comp Script","text":"<p>Fusion Based Comp Script</p> <p>Gyroflow Fusion is a Python-based comp script with a custom UI Manager based GUI that runs inside of the Fusion page, and in Fusion Studio.</p> <p>Script Requirements:</p> <ul> <li>Resolve (free) or Resolve Studio or Fusion Studio</li> <li>Python 3.6+ is required to use this script.</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#dragdrop-support","title":"DragDrop Support","text":"<p>DragDrop Support</p> <p>The Gyroflow Fusion toolset supports drag and drop handling of .gyroflow files. This works by dragging the file from an Explorer/Finder/Nautilus desktop folder browsing location and dropping the file into the Fusion nodes view area.</p> <p>In this situation, the Gyro Fusion script is automatically launched and the \"Gyroflow Filename\" textfield is pre-filled in advance in the GUI.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#using-the-script","title":"Using the Script","text":"<p>Using the Script</p> <p>To run the script, open the Fusion Studio based \"Script &gt; Gyroflow Fusion &gt; Gyroflow to CSV\" Menu item.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#splash-screen","title":"Splash Screen","text":"<p>Splash Screen</p> <p>A splash screen is shown that provides usage information about the required Gyroflow export settings.</p> <p>\"The script converts your Gyroflow stabilization to a CSV file. Make sure to choose\"including processed gyro data\" when exporting from Gyroflow. As default it saves out the rotations as Euler rotation (ZYX). It also saves out the data in your footages' native frame rate.\"</p> <p>Click the \"Continue\" button to proceed.</p> <p>Note: If you want to go to the Gyroflow website you can click on the logo image at the top of the dialog.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#file-dialog","title":"File Dialog","text":"<p>File Dialog</p> <p>This dialog is used to define the parameters used when the Gyroflow document is exported to a CSV file. In the \"Gyroflow Filename\" field select a file with the \".gyroflow\" file extension.</p> <p>Click the \"Go\" button to proceed.</p> <p></p> <p>If you enabled the '[x] Add \"Gyroflow CSV\" Nodes to Comp' checkbox in the dialog, a Vonk node graph is inserted into your Fusion composite that has the path to the Gyroflow generated CSV file pre-entered into the \"vTextFromFile\" node's \"Input\" textfield.</p> <p>The nodes named \"xGyro1\", \"yGyro1\", and \"zGyro1\" provide the Number data-type based outputs for the Rotate X/Y/Z channels of IMU (inertial) stabilization data from Gyroflow.</p> <p></p> <p>If you have a large Gyroflow file that takes a while to process, you can watch the progress status in the Console window. Clicking the Console button on the top left of the Fusion interface, or pressing the \"Shift + 0\" hotkey is a quick way to open the Console window.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#macro","title":"Macro","text":"<p>Macro</p> <p>A \"Gyroflow CSV\" macro is available in the \"Select Tool\" dialog. This macro makes it quick and painless to quickly add the supporting Vonk nodes to the node-graph.</p> <p></p> <p>The nodes named \"xGyro1\", \"yGyro1\", and \"zGyro1\" provide the Number data-type based outputs for the Rotate X/Y/Z channels of IMU (inertial) stabilization data from Gyroflow.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#example-fusion-comp","title":"Example Fusion Comp","text":"<p>Example Fusion Comp</p> <p>A Gyroflow example compositing project is provided that includes a short video clip, a .gyroflow file, and a CSV export. This project shows an applied use of the \"Gyroflow to CSV\" script and Vonk data nodes inside of Fusion.</p> <p>In order to use this example comp you need to have Vonk installed (from the Reactor Package Manager) to read a Gyroflow CSV file and drive a 3D camera with it.</p> <p>Open the example project if you want to see how it's done:</p> <pre><code>Reactor:/Deploy/Comp/Gyroflow Fusion/Gyroflow.comp\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#gyroflow-node-connections","title":"Gyroflow Node Connections","text":"<p>Gyroflow Node Connections</p> <p>You can connect these nodes to your Fusion 3D workspace based Camera3D or Transform3D node's Rotation channels.</p> <p></p> <p>Right-clicking on either of the X/Y/Z channel keyframe \"diamond shapes\" in the Inspector view provides access to the \"Connect To\" contextual menu entry.</p> <p></p> <p>The mapping of Gyroflow channels is:</p> <pre><code>xGyro1.Output -&gt; Transform3DOp.Rotate.X\nyGyro1.Output -&gt; Transform3DOp.Rotate.Y\nzGyro1.Output -&gt; Transform3DOp.Rotate.Z\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#timeline-render-start-frame","title":"Timeline Render Start Frame","text":"<p>Timeline Render Start Frame</p> <p>The \"vNumberAdd\" node is used to shift the starting frame number when accessing the CSV (comma separated value) text file's \"Index\" based line number. By default the offset of adding 1 to the current timeline frame number is entered so things work out of the box with a timeline that has frame 0 as the \"Render Start\" frame value.</p> <p>You can easily modify the vNumberAdd node's \"Term 2\" setting to line up with your VFX workflow needs such as a shot with a frame 1, frame 1000, or frame 1001 \"Render Start\" frame.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#imu-motion-corrections","title":"IMU Motion Corrections","text":"<p>IMU Motion Corrections</p> <p>If you need to adjust the direction axis for the IMU corrections, there are two preset values stored in the \"Versions\" controls for the \"xGyro1\", \"yGyro1\", and \"zGyro1\" nodes.</p> <p>This applies a \"1\" or \"-1\" multiplication operation to the rotation channel data using a Vonk \"vNumberMultiply\" node's built-in \"Factor2\" control.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#360vr-rotation-correction","title":"360VR Rotation Correction","text":"<p>360VR Rotation Correction</p> <p>If your footage was filmed on a 360VR spherical camera that records internal IMU data, it is possible to apply the Gyroflow corrections to a Resolve/Fusion built-in \"PanoMap\" node instead of using a Camera3D or Transform node.</p> <p>In this case the mapping of Gyroflow channels is:</p> <pre><code>xGyro1.Output -&gt; Rotate.X\nyGyro1.Output -&gt; Rotate.Y\nzGyro1.Output -&gt; Rotate.Z\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#monoscopic-360vr","title":"Monoscopic 360VR","text":"<p>Monoscopic 360VR</p> <p>You would connect your source 360VR footage to a Loader/MediaIn node. Then connect the image output to the PanoMap node:</p> <pre><code>Loader -&gt; PanoMap\n</code></pre> <p>or</p> <pre><code>MediaIn -&gt; PanoMap\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#stereoscopic-3d-360vr","title":"Stereoscopic 3D 360VR","text":"<p>Stereoscopic 3D 360VR</p> <p>If you are working with Side-by-Side or Over/Under formatted stereo 3D footage, you would need to split apart the left and right eye views with Fusion's built-in \"Splitter\" node.</p> <p>The PanoMap node is used to apply the view rotation corrections. When adding PanoMap nodes to the comp, the use of the \"Copy\" and \"Paste Instance\" commands can be a timesaver as it will keep the left and right eye view node attributes synced up in the Inspector tab.</p> <p>Finally, the Fusion built-in Combiner node is used to merge the left and right eye views back together again into a single stereoscopic 3D image.</p> <p>The node connections are:</p> <pre><code>Loader/MediaIn -&gt; Splitter\n\nSplitter.Image1 (Left) -&gt; PanoMap (Left)\nSplitter.Image2 (Right) -&gt; PanoMap (Right)\n\nPanoMap (Left) -&gt; Combiner.Image1\nPanoMap (Right) -&gt; Combiner.Image2\n\nCombiner -&gt; Saver/MediaOut\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/360VR%20Stitching%20Tools/#360vr-overcapture-reframing","title":"360VR Overcapture / Reframing","text":"<p>360VR Overcapture / Reframing</p> <p>You could also use Gyroflow X/Y/Z view rotation data to help drive the KartaVR Reframe360 node's output. The Gyroflow data would be connected to the kvrReframe360Ultra node's View Transforms &gt; \"Pitch\", \"Yaw\", \"Roll\" attributes.</p> <p>This allows the IMU data to be used for the primary view leveling (or motion dampening) effect. This would be followed by a Vonk vNumberMultiply / vNumberAdd node approach to blend in artist controlled keyframable view offset adjustments that are animated across the timeline frame range.</p> <p>Averaging / motion dampening can be applied using Vonk based temporal effects on Number datatypes. This makes it possible to read frame values ahead/behind the current playhead/timeline frame number (vNumberCompReqTime).</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/ACES%20Color%20Management/","title":"ACES Color Management","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The ACES color management system is an adopted industry-wide standard for the entertainment sector. All footage and textures used in film, animation, visual effects, and games are created, edited, and displayed with ACES color profiles enabled.</p> <p>https://acescentral.com</p> <p>\"ACEScg\" is the color profile used for computer generated imagery.</p> <p>All digital cinema camera systems have custom vendor specific ACES color profiles.</p> <p>Finished film and TV projects are delivered as DCPs (digital cinema packages) and DCDM (digital cinema distribution masters). These delivery formats are based around a specific \"ACES 2065-1\" color encoding standard. This is used for the long-term archiving of all media in the motion picture industry.</p> <p>Library of Congress DCDM Guide:</p> <p>Digital Cinema Initiative Distribution Master (DCDM)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/ACES%20Color%20Management/#opencolorio","title":"OpenColorIO","text":"<p>OpenColorIO</p> <p>As you start to work with media from a wide range of sources, including digital cinema cameras, RAW high-bit-depth footage from 360VR camera rigs, and CG renderings, the need for an end-to-end color managed workflow becomes essential and unavoidable.</p> <p>Currently, your best option is to consider using an ACES OpenColorIO v1.0.3 based color managed workflow in Fusion Studio v18.1 and Fusion Render Node 18.1.</p> <p>https://opencolorio.org/</p> <p>OCIO Resources:</p> <ul> <li>ACES Central</li> <li>OpenColorIO Documentation</li> <li>OpenColorIO GitHub Repo</li> <li>YouTube | StatixVFX | Fusion Pipeline - Getting started with OCIO and ACES</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/ACES%20Color%20Management/#installing-opencolorio","title":"Installing OpenColorIO","text":"<p>Installing OpenColorIO</p> <p></p> <p>Installing OpenColorIO v1.0.3 is done by downloading the resources directly from an OCIO repository, or to install the OCIO config files with the Reactor Package Manager.</p> <p>Unzip the OCIO files and either store the \"aces\" folder locally on your laptop/workstation's internal hard disk, or if you are working in a studio environment move the OCIO config folder to a shared mount point on a file server that is accessible to the machines on your local LAN subnet so the Fusion Render Node systems and other computers can access the content.</p> <p>Next, you need to define a custom environment variable that tells all of the OCIO compatible graphics tools on your system where to find your aces config folder. The environment variable is named \"OCIO\", and the value you define for that environment variable is the full absolute filepath on your hard disk to the \"config.ocio\" file.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/ACES%20Color%20Management/#using-opencolorio-in-fusion","title":"Using OpenColorIO in Fusion","text":"<p>Using OpenColorIO in Fusion</p> <p>With OCIO installed on your system, in Fusion Studio v18.1 you can then add a viewer LUT that allows you to preview footage correctly on your monitor. A viewer LUT allows you to maintain the original working color space and gamut for the footage loaded into your composite, while previewing the content in a correct fashion on your monitor so you will be able to make informed decisions as a compositor.</p> <p></p> <p>The \"OCIOColorspace\" node is then used by Fusion's node graph to convert your footage into the right space for your needs.</p> <p></p> <p>With the OCIOColorspace node selected in the Nodes view you can then access the controls in Fusion's Inspector view. The primary controls you are concerned with in this node are the \"Source Space\" and \"Output Space\" settings.</p> <p></p> <p>When you are working on a large-scale professional media project you will typically receive and deliver footage as ACES 2065-1 formatted content when interfacing with external vendors.</p> <p>All your in-house compositing, and node-based 360VR/180VR/Fulldome based stitching, paint, and roto operations should be done using ACEScg.</p> <p>ACEScg usage at your studio also covers all of the imagery that your 3D department renders when they deliver EXR format media to a compositor that contains beauty and denoised RGBA render passes coming from production renderers like RenderMan, V-Ray, Arnold, Redshift, Houdini Karma, or Blender Cycles X.</p> <p>An important detail for your 3D department to keep in mind, when generating OpenEXR based image sequences from a 3D rendering package, is that you can opt to use a 16-bit half-float framebuffer, with the ZIPS or DWAA codec for your RGBA based beauty pass and denoised content.</p> <p>The technical passes stored in an EXR file, like Z-depth, cryptomatte, world position, UV, and motion vectors should however be kept as 32-bit float image data for numerical precision reasons. Do not use a lossy compression codec on technical passes as it will create visual artifacts when you go to apply those channels in your compositing workflows.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/ACES%20Color%20Management/#openimageio","title":"OpenImageIO","text":"<p>OpenImageIO</p> <p>OIIO Resources:</p> <ul> <li>OIIO Docs</li> <li>OIIO GitHub Repository</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/","title":"AWS Deadline Deployment","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p></p> <p>Deadline is a render manager and job scheduling tool that is distributed by Amazon AWS Thinkbox. Deadline has Win/Linux/macOS cross platform support and can run on-premise or in the cloud via Amazon AWS EC2.</p> <p>Amazon AWS Thinkbox provides a very accessible 50,000 render nodes for free licensing option which allows companies to get comfortable with the toolset before committing to it as their core tool.</p> <p>https://www.awsthinkbox.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#deadline-monitor","title":"Deadline Monitor","text":"<p>Deadline Monitor</p> <p>Rendering jobs in Deadline are managed using the \"Monitor\" program which can be run on artist workstations, and on render node systems, too.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#deadline-configuration","title":"Deadline Configuration","text":"<p>Deadline Configuration</p> <p>Configure Monitor Options</p> <pre><code>    Monitor Options\n        Task List\n            Rendering Task Double-Click Behaviour - Connect to Worker log\n</code></pre> <p>Tools &gt; Super User Mode</p> <pre><code>    Monitor Options\n        Misc\n            [x] Start in Super user mode\n</code></pre> <p>Tools</p> <pre><code>    Configure Repository Options\n    - Client Setup\n        - Remote Control\n        [x] Remote Administration\n        (x) Disable the allow list\n</code></pre> <p>Performance Settings</p> <pre><code>    - (Auto Adjust) button\n        5 workers\n</code></pre> <p>Mapped Paths</p> <pre><code>    (might be required later)\n</code></pre> <p>Usage Based Licensing</p> <pre><code>[ ] Use Cloud License Server\n[ ] Use dynamic licensing mode\n[ ] Autodetect 3rd party Usage based license consumption\n</code></pre> <p>Tools</p> <p>- Manage Pools</p> <p>The Manage Pools window is where you configure the individual groups of render nodes that have certain collections of software installed and licensed, or that are running a similar operating system, or hardware configuration.</p> <p>This interface allows you to segment job tasks you want to run based upon the best fit for the available hardware, GPU, OS, or software needs.</p> <p></p> <p>Pools:</p> <p><code>maya</code></p> <p><code>vray</code></p> <p><code>fusion</code></p> <p><code>houdini</code></p> <p><code>ptgui</code></p> <p>Assigned Pools</p> <pre><code>    R1 - vray, fusion, houdini, ptgui\n    R2 - maya, vray, fusion, houdini, ptgui\n    R3 - vray, fusion, houdini, ptgui\n    R4 - vray, fusion, houdini, ptgui\n    R5 - maya, vray, fusion, houdini, ptgui\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#configure-script-menus","title":"Configure Script Menus","text":"<p>Configure Script Menus</p> <p>Use shift-select to highlight the tools you aren't using. The \"Edit Selection\" button has an \"[x] Enable\" checkbox you can turn off to hide a tool from the Submit menus.</p> <p></p> <p>2D Comp</p> <p>Fusion</p> <p>3D</p> <p>Houdini</p> <p>Maya</p> <p>V-Ray</p> <p>Misc</p> <p>Command Line</p> <p>Command Script</p> <p>Python</p> <p>Processing</p> <p>DJV</p> <p>FFmpeg</p> <p>Mistika VR</p> <p>VDenoise</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#submitters","title":"Submitters","text":"<p>Submitters</p> <p>Deadline uses a \"submitter\" tool to define how a new job task is created. This is the interface where you specify all the parameters for the program you want to launch and the type of data you want to process.</p> <p>Fusion</p> <p>The highest \"Version\" is currently \"16\". We need to add \"18\".</p> <p>Houdini</p> <p>The highest \"Version\" is currently \"19\". We need to add \"19.5\".</p> <p>Maya</p> <p>Supports \"Version\" 2023 by default.</p> <p>Editing Worker \"Render Node\" Attributes.</p> <p>If you would like to edit a Deadline worker system's attributes you can right-click on a worker. In the contextual menu select \"Worker Properties\".</p> <p>Then navigate in the dialog to \"General &gt; Worker Description\". Enter a value that clearly defines what type of computer system is used for the current render node like:</p> <p><code>Threadripper 3990X</code></p> <p>Deadline Submitter Installers</p> <pre><code>    F:\\Deadline\\DeadlineRepository10\\submission\\Maya\\Installers\n    F:\\Deadline\\DeadlineRepository10\\submission\\Houdini\\Installers\n    F:\\Deadline\\DeadlineRepository10\\submission\\Fusion\\Installers\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#configure-plugins","title":"Configure Plugins","text":"<p>Configure Plugins</p> <p>The \"Configure Plugins\" window is where you set up the individual programs you want Deadline to control, and specify the installation location for each version of the apps you</p> <p>want to launch on render nodes.</p> <p></p> <p>Configure Plugins &gt; MayaBatch - Done by default</p> <p>Configure Plugins &gt; MayaCmd - Done by default</p> <p>Configure Plugins &gt; Fusion</p> <pre><code>C:\\Program Files\\Blackmagic Design\\Fusion Render Node 18\\FusionRenderNode.exe\nC:\\Program Files\\Blackmagic Design\\Fusion 18\\Fusion.exe\n/opt/BlackmagicDesign/FusionRenderNode18/FusionRenderNode\n/opt/BlackmagicDesign/Fusion18/Fusion\n/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node\n/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/Fusion\n</code></pre> <p>Configure Plugins &gt; FusionCmd</p> <pre><code>C:\\Program Files\\Blackmagic Design\\Fusion Render Node 18\\FusionRenderNode.exe\nC:\\Program Files\\Blackmagic Design\\Fusion 18\\Fusion.exe\n/opt/BlackmagicDesign/FusionRenderNode18/FusionRenderNode\n/opt/BlackmagicDesign/Fusion18/Fusion\n/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node\n/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/Fusion\n</code></pre> <p>Configure Plugins &gt; Vray</p> <pre><code>C:\\Program Files\\Chaos Group\\V-Ray\\Maya 2023 for x64\\maya_vray\\bin\\vray.exe\n</code></pre> <p>Configure Plugins &gt; vdenoise</p> <pre><code>C:\\Program Files\\Chaos Group\\V-Ray\\Maya 2023 for x64\\vray\\bin\\vdenoise.exe\n</code></pre> <p>Configure Plugins &gt; Houdini</p> <p>Houdini has its own bundled version of the Python scripting utilities called \"Hython\" aka. \"Houdini Python\".</p> <p>Houdini 19.5 Hython Executable</p> <pre><code>C:\\Program Files\\Side Effects Software\\Houdini 19.5.368\\bin\\hython.exe\n/Applications/Houdini/Houdini19.5.368/Frameworks/Houdini.framework/Versions/19.5/Resources/bin/hython\n/opt/hfs19.5.368/bin/hython\n</code></pre> <p>Houdini 19.5 Sim Tracker File</p> <pre><code>C:\\Program Files\\Side Effects Software\\Houdini 19.5.368\\houdini\\python3.7libs\\simtracker.py\n/Applications/Houdini/Houdini19.5.368/Frameworks/Houdini.framework/Versions/19.0/Resources/houdini/python3.7libs/simtracker.py\n/opt/hfs19.5.368/houdini/python3.7libs/simtracker.py\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#deadline-plugins-patching","title":"Deadline Plugins Patching","text":"<p>Deadline Plugins Patching</p> <p>In order to get the most out of Amazon AWS Deadline software, you will likely need to edit a few of the submitters and configuration files by hand in a programmer's text editor like \"Notepad++\", \"BBEdit\", or \"gedit\". This step is relevant in cases where you are using the Deadline toolset in the license-free mode, and are working without a paid AWS Thinkbox support contract.</p> <p>The \"Submit Fusion Job To Deadline\" scripted GUI looks like this image below. It has been modified to add newer Fusion Render Node version support than currently comes in a stock release of Deadline. Instructions below cover this process.</p> <p></p> <p>We need to start by adding a revised set of \"Fusion.ico\" / \"FusionCmd.ico\" image resources to match our use of BMD Fusion Studio v18.</p> <p>The following items listed below are listings of the individual text files you need to manually open up in your text editor. Also included are the sections of the text file you need to find in the document and then edit by hand.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#fusion-plugin","title":"Fusion plugin","text":"<p>Fusion plugin</p> <p>Edit File</p> <pre><code>plugins\\Fusion\\Fusion.options\n</code></pre> <p>Changes</p> <pre><code>Default=18\n</code></pre> <p>Content to Edit</p> <pre><code>[Version]\nType=string\nLabel=Version\nCategory=Fusion Version\nDescription=The Fusion version to render with\nRequired=true\nDisableIfBlank=false\nDefault=18\n</code></pre> <p>Edit File</p> <pre><code>plugins\\Fusion\\Fusion.param\n</code></pre> <p>Content to Add</p> <pre><code>[Fusion17RenderExecutable]\nType=multilinemultifilename\nLabel=Fusion 17 Render Executable\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=0\nDefault=C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\FusionRenderNode.exe;C:\\Program Files\\Blackmagic Design\\Fusion 17\\Fusion.exe;/opt/BlackmagicDesign/FusionRenderNode17/FusionRenderNode;/opt/BlackmagicDesign/Fusion17/Fusion;/Applications/Blackmagic Fusion 17 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node;/Applications/Blackmagic Fusion 17/Fusion.app/Contents/MacOS/Fusion\nDescription=The path to the Fusion 17 Render Node executable used for rendering. Enter alternative paths on separate lines.\n\n[Fusion17WaitForExecutable]\nType=string\nLabel=Fusion 17 Wait For Executable\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=1\nDefault=\nDescription=If you use a proxy FusionRenderNode.exe, set this to the name of the renamed original.  For example, it might be set to FusionRenderNode_original.exe.\n\n[Fusion17VersionToEnforce]\nType=string\nLabel=Fusion 17 Version To Enforce\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=2\nDefault=\nDescription=Deadline will only render Fusion 17 jobs on Workers running this version of Fusion 17. Use a ; to separate alternative versions. Leave blank to disable this feature.\n\n[Fusion17SlavePreferenceFile]\nType=filename\nLabel=Fusion 17 Node Preference File\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=3\nDefault=\nDescription=The path to a global RenderSlave.prefs preference file that is copied over before starting the Render. Leave blank to disable this feature.\n\n[Fusion18RenderExecutable]\nType=multilinemultifilename\nLabel=Fusion 18 Render Executable\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=0\nDefault=C:\\Program Files\\Blackmagic Design\\Fusion Render Node 18\\FusionRenderNode.exe;C:\\Program Files\\Blackmagic Design\\Fusion 18\\Fusion.exe;/opt/BlackmagicDesign/FusionRenderNode18/FusionRenderNode;/opt/BlackmagicDesign/Fusion18/Fusion;/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node;/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/Fusion\nDescription=The path to the Fusion 18 Render Node executable used for rendering. Enter alternative paths on separate lines.\n\n[Fusion18WaitForExecutable]\nType=string\nLabel=Fusion 18 Wait For Executable\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=1\nDefault=\nDescription=If you use a proxy FusionRenderNode.exe, set this to the name of the renamed original.  For example, it might be set to FusionRenderNode_original.exe.\n\n[Fusion18VersionToEnforce]\nType=string\nLabel=Fusion 18 Version To Enforce\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=2\nDefault=\nDescription=Deadline will only render Fusion 18 jobs on Workers running this version of Fusion 18. Use a ; to separate alternative versions. Leave blank to disable this feature.\n\n[Fusion18SlavePreferenceFile]\nType=filename\nLabel=Fusion 18 Node Preference File\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=3\nDefault=\nDescription=The path to a global RenderSlave.prefs preference file that is copied over before starting the Render. Leave blank to disable this feature.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#fusioncmd-plugin","title":"FusionCmd plugin","text":"<p>FusionCmd plugin</p> <pre><code>Added a revised FusionCmd.ico for Fusion v18.\n</code></pre> <p>Edit File</p> <pre><code>plugins\\FusionCmd\\FusionCmd.options\n</code></pre> <p>Content Edit</p> <pre><code>[Version]\nType=string\nLabel=Version\nCategory=Fusion Version\nDescription=The Fusion version to render with\nRequired=true\nDisableIfBlank=false\nDefault=18\n</code></pre> <p>Edit File</p> <pre><code>FusionCmd.param\n</code></pre> <p>Content to Add</p> <pre><code>[Fusion17RenderExecutable]\nType=multilinemultifilename\nLabel=Fusion 17 Render Executable\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=0\nDefault=C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\FusionRenderNode.exe;/opt/BlackmagicDesign/FusionRenderNode17/FusionRenderNode;/opt/BlackmagicDesign/Fusion17/Fusion;/Applications/Blackmagic Fusion 17 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node;/Applications/Blackmagic Fusion 17/Fusion.app/Contents/MacOS/Fusion\nDescription=The path to the Fusion 17 Console Node executable used for rendering. Enter alternative paths on separate lines.\n\n[Fusion17SlavePreferenceFile]\nType=filename\nLabel=Fusion 17 Render Node Preference File\nCategory=Fusion 17 Options\nCategoryOrder=6\nCategoryIndex=1\nDefault=\nDescription=The path to a global RenderSlave.prefs preference file that is copied over before starting the Render Node. Leave blank to disable this feature.\n\n[Fusion18RenderExecutable]\nType=multilinemultifilename\nLabel=Fusion 18 Render Executable\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=0\nDefault=C:\\Program Files\\Blackmagic Design\\Fusion Render Node 18\\FusionRenderNode.exe;/opt/BlackmagicDesign/FusionRenderNode18/FusionRenderNode;/opt/BlackmagicDesign/Fusion18/Fusion;/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node;/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/Fusion\nDescription=The path to the Fusion 18 Console Node executable used for rendering. Enter alternative paths on separate lines.\n\n[Fusion18SlavePreferenceFile]\nType=filename\nLabel=Fusion 18 Render Node Preference File\nCategory=Fusion 18 Options\nCategoryOrder=7\nCategoryIndex=1\nDefault=\nDescription=The path to a global RenderSlave.prefs preference file that is copied over before starting the Render Node. Leave blank to disable this feature.\n</code></pre> <p>Edit File</p> <pre><code>F:\\Deadline\\DeadlineRepository10\\scripts\\Submission\\FusionSubmission.py\n</code></pre> <p>Content to Edit</p> <pre><code>    scriptDialog.AddControlToGrid( \"VersionLabel\", \"LabelControl\", \"Version\", 5, 0, \"The version of Fusion to render with.\", False )\n    scriptDialog.AddComboControlToGrid( \"VersionBox\", \"ComboControl\", \"18\", [\"5\",\"6\",\"7\",\"8\", \"9\", \"16\", \"17\", \"18\"], 5, 1 )\n    commandLineModeBox = scriptDialog.AddSelectionControlToGrid( \"CommandLineModeBox\", \"CheckBoxControl\", False, \"Command Line Mode\", 5, 2, \"Enable to render in command line mode using the FusionCmd plugin (this disables some features).\" )\n    commandLineModeBox.ValueModified.connect(CommandLineModeChanged)\n\n    scriptDialog.AddControlToGrid( \"BuildLabel\", \"LabelControl\", \"Build\", 6, 0, \"\", False )\n    scriptDialog.AddComboControlToGrid( \"BuildBox\", \"ComboControl\", \"None\", (\"None\",\"32bit\",\"64bit\"), 6, 1 )\n    scriptDialog.AddSelectionControlToGrid(\"SubmitSceneBox\", \"CheckBoxControl\", True, \"Submit Comp File\", 6, 2, \"If this option is enabled, the flow/comp file will be submitted with the job, and then copied locally to the Worker machine during rendering.\")\n    scriptDialog.EndGrid()\n</code></pre> <p>Edit File</p> <pre><code>F:\\Deadline\\DeadlineRepository10\\scripts\\Submission\\HoudiniSubmission.py\n</code></pre> <p>Content to Edit</p> <pre><code>HOU_VERSIONS = (\"9.0\", \"10.0\", \"11.0\", \"12.0\", \"13.0\", \"14.0\", \"15.0\", \"15.5\", \"16.0\", \"16.5\", \"17.0\", \"17.5\", \"18.0\", \"18.5\", \"19.0\", \"19.5\")\n</code></pre> <p>Edit File</p> <pre><code>F:\\Deadline\\DeadlineRepository10\\plugins\\Houdini\\Houdini.param\n</code></pre> <p>Content to Edit</p> <pre><code>[Houdini19_5_Hython_Executable]\nLabel=Houdini 19.5 Hython Executable\nCategory=Render Executables\nCategoryOrder=0\nType=multilinemultifilename\nIndex=14\nDefault=C:\\Program Files\\Side Effects Software\\Houdini 19.5.368\\bin\\hython.exe;/Applications/Houdini/Houdini19.5.368/Frameworks/Houdini.framework/Versions/19.5/Resources/bin/hython;/opt/hfs19.5/bin/hython\nDescription=The path to the hython executable. It can be found in the Houdini bin folder.\n\n[Houdini19_5_SimTracker]\nLabel=Houdini 19.5 Sim Tracker File\nCategory=HQueue Simulation Job Options\nCategoryOrder=1\nType=multilinemultifilename\nIndex=10\nDefault=C:\\Program Files\\Side Effects Software\\Houdini 19.5.368\\houdini\\python3.7libs\\simtracker.py;/Applications/Houdini/Houdini19.5.368/Frameworks/Houdini.framework/Versions/19.5/Resources/houdini/python3.7libs/simtracker.py;/opt/hfs19.5/houdini/python3.7libs/simtracker.py\nDescription=The path to the simtracker.py file that is used when distributing HQueue sim jobs. This file can be found in the Houdini install.\n</code></pre> <p>Edit File</p> <pre><code>F:\\Deadline\\DeadlineRepository10\\plugins\\Houdini\\Houdini.options\n</code></pre> <p>Content to Edit</p> <pre><code>[Version]\nType=label\nLabel=Version\nCategory=Houdini Version\nCategoryOrder=1\nDescription=The version of Houdini to use for rendering.\nRequired=false\nDisableIfBlank=true\nDefault=14\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#deadline-worker","title":"Deadline Worker","text":"<p>Deadline Worker</p> <pre><code>Options Menu\n    [x] Hide When Minimized\n    [x] Minimize on Startup\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/AWS%20Deadline%20Deployment/#deadline-todos","title":"Deadline Todos","text":"<p>Deadline Todos</p> <p>Document how to solve the issue with the Deadline sanity check function when submitting Fusion comps that lack a Saver node, when the \"Command-Line Mode\" checkbox is disabled.</p> <p>This default sanity checking feature of Deadline's for pre-flight inspecting the contents of a .comp file can interfere with the rendering of composites that use fuses like ExternalMatteSaver, LiveSaver, pioSaver, or Vonk data nodes to save media directly to disk.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/About/","title":"About","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Welcome to the Kartaverse</p> <p>Contributed by Andrew Hazelden</p> <p>About</p> <p>As a technical writer and pipeline TD in the visual effects sector, I am pleased to be able to share a new workflow guide. In time, I hope the learning content might be deemed an essential read for those interested in accelerating immersive media post-production workflows using Blackmagic Design's Resolve Studio and Fusion Studio software as the central hub-like toolset.</p> <p>The free guide has over 512 pages of content that covers the primary steps required to get a working content creation pipeline established from scratch for artists working at a freelancer, or small boutique studio scale of operation.</p> <p>I'll be the first to admit that the document is a long read but you will be rewarded with a wide range of insights into topics you've likely not explored in-depth before. Enjoy!</p> <p>Special Thanks</p> <p>Special thanks go out to BMD staff including Peter Chamberlain, Steve Roberts, Kerry de Boer, Stephanie Hueter, Daniel Koch, and Peter Loveday for their assistance over the many years I've worked on Resolve/Fusion based community projects. Without their kind and thoughtful help many projects including this guide would not have been possible for me to create.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Adding%20KartaVR%20via%20Reactor/","title":"Adding KartaVR via Reactor","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>In order to install KartaVR you need to have Resolve/Fusion and the Reactor Package Manager installed beforehand. To add the KartaVR packages to a new workstation, first start by launching the Reactor Package Manager window.</p> <p>In Fusion Studio you can do this by opening the root-level \"Reactor\" menu, then select the \"Open Reactor\" menu item.</p> <p></p> <p>In Resolve Studio you can do this by opening the root-level \"Workspaces\" menu, then navigating to the \"Scripts &gt; Comp &gt; Reactor &gt; Open Reactor...\" menu item.</p> <p></p> <p>When the Reactor Package Manager window loads initially you will see a list of all the atom packages that are able to be installed using this user interface.</p> <p>Note: The content that is listed in the Reactor window comes from the Reactor GitLab repository. If you have an outgoing firewall, or your country/company/ISP (internet service provider) has network filtering rules that block access to GitLab you will have to use another approach to install the Reactor content on your system.</p> <p>In the Reactor window, double-click on the left side-bar category item labelled \"Kartaverse\" to expand this hierarchy.</p> <p></p> <p>Then select the \"Kartaverse &gt; KartaVR\" sub-category on the left sidebar to shorten the amount of content displayed in the part of the Reactor window where atom packages are listed.</p> <p></p> <p>Click on the package name \"KartaVR\" in the main part of the Reactor window, and then press the \"Install\" button.</p> <p>A progress dialog is displayed that shows each of the files as they are downloaded from the Reactor GitLab repository via cURL and installed into the \"Reactor:/Deploy/\" PathMap location on your hard disk.</p> <p></p> <p>Several \"Install Script Confirmation\" dialogs will be displayed during the Reactor installation process. The dialog is asking for your input.</p> <p>You can press the \"OK\" button if you would like to set up several preferences automatically during the install of the Reactor \"Bin\" category content like the FFmpeg utility. Alternatively, you can press the \"Cancel Installation\" button and that specific \"Install Script\" item will be skipped.</p> <p></p> <p>After the \"KartaVR\" content has been fully installed, we then need to click on the package name \"KartaVR 3<sup>rd</sup> Party Libraries\" to install it as well. This Reactor package adds the extra open-source utilities needed to efficiently use the KartaVR automation scripts.</p> <p>The \"KartaVR 3<sup>rd</sup> Party Libraries\" atom package description in the Reactor window lists all of the open-source tools you can optionally choose to install.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Adding%20Vonk%20Ultra%20via%20Reactor/","title":"Adding Vonk Ultra via Reactor","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Vonk Ultra provides a wide range of \"data node\" fuses that allow you to create efficient node graphs in Fusion that directly work with text, numbers, CSV spreadsheets, JSON, XML, YAML, and many other types of data using modifier nodes. More information about Vonk Ultra can be read in the documentation.</p> <p>After you have the Reactor Package Manager window open again, you have the option to select the \"Kartaverse &gt; Vonk Ultra\" category on the left sidebar.</p> <p>To install Vonk Ultra, click on the package named \"Vonk Ultra\", and then press the \"Install\" button. This will automatically install each of the required Vonk sub-packages in a single step.</p> <p></p> <p>Once the Reactor installation process is complete, please relaunch Resolve or Fusion standalone. This will cause Fusion to scan for and then load the new fuses we just installed. Scanning for new fuses is a process only done when Fusion first starts up.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Apple%20Compressor%20Command-Line%20Syntax/","title":"Apple Compressor Command Line Syntax","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Apple's Compressor program supports command line job submission. This allows for high-quality ProRes 4444XQ video encodes to be done in an automated fashion on a tiny video encoding system like a macMini that could be placed in the corner of a machine room.</p> <p>Compressor Learning Resources:</p> <ul> <li>Apple | Compressor</li> <li>Apple | Compressor 4 | Shell Commands for Submitting Compressor Jobs</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Apple%20Compressor%20Command-Line%20Syntax/#image-sequence-to-movie-encoding","title":"Image Sequence to Movie Encoding","text":"<p>Image Sequence to Movie Encoding</p> <p>Almost every macOS based visual effects artist has a copy of Apple Final Cut Pro on their system, along with the Apple Compressor program, regardless of how often they use it.</p> <p>What you might not have noticed is that Apple Compressor can be used as a standalone tool for batch converting image sequences, like OpenEXR RGBA footage, into a standards compliant ProRes movie output.</p> <p>When doing the encoding task a key detail is that you need to place one image sequence per folder on your hard disk. Additionally, just to state this one more time since it is important, only have a single image sequence \"clip\" in that folder so Compressor doesn't get distracted!</p> <p>Also it is a good idea to start the image sequence at frame 0000.</p> <p>To encode an image sequence into a movie, start up the Compressor program. Then select the \"File &gt; Add Image Sequence...\" menu item.</p> <p></p> <p>You can then adjust the encoding parameters for the current batch job.</p> <p>If you are doing this operation very often it makes sense to carry along to the next part of this process and automate the task fully with the help of Compressor's command-line interface.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Apple%20Compressor%20Command-Line%20Syntax/#compressor-command-line-usage","title":"Compressor Command-Line Usage","text":"<p>Compressor Command-Line Usage</p> <p>macOS ZSH Shell Syntax:</p> <pre><code>\"/Applications/Compressor.app/Contents/MacOS/Compressor\" -batchname \"ProRes Encode\" -jobpath \"$Home/Desktop/ImageSequence/\" -settingpath \"Reactor:/Deploy/Bin/compressor/settings/ProRes.cmprstng\" -locationpath \"$Home/Desktop/ProRes_Encode.mov\"\n</code></pre> <p>Note: The \"<code>.cmprsrng</code>\" file format is a Compressor exported encoding preset settings file.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Apple%20Compressor%20Command-Line%20Syntax/#compressor-python-command-line-usage","title":"Compressor Python + Command-Line Usage","text":"<p>Compressor Python + Command-Line Usage</p> <p>Here is an example that shows how a SilhouetteFX program based Apple Compressor command-line job submission operation can be carried out. The details can be found in the SilhouetteFX-Python-Scripts GitHub repository here.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automated%20Reactor%20PathMaps%20in%20Resolve%20Studio%20and%20Fusion%20Studio/","title":"Automated Reactor PathMaps in Resolve Studio and Fusion Studio","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>If you need to install Reactor on an entire render farm, the following guide explains how to configure the preferences using command-prompt based shell scripting:</p> <p>https://www.steakunderwater.com/wesuckless/viewtopic.php?p=42846#p42846</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/","title":"Automation Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#keyboard-maestro-on-macos","title":"Keyboard Maestro on macOS","text":"<p>Keyboard Maestro on macOS</p> <p>Keyboard Maestro is a GUI automation tool that allows you to script and control macOS based programs through the use of scripting direct user interface based interactions like mouse cursor moves, mouse clicks, keyboard key presses, menu selections, button pressing, text field typing, and Apple Script code execution.</p> <p>From a practical perspective, for any process that a human user can do on a macOS system, Keyboard Maestro can be used to automate the same task in a visual fashion.</p> <p>https://www.keyboardmaestro.com/main/</p> <p>For more information:</p> <ul> <li>Keyboard Maestro Wiki</li> <li>Keyboard Maestro Forum</li> <li>KartaLink kvrKeyboardMaestro Fuse</li> </ul> <p>Keyboard Maestro offers a free trial version on their website you can use to evaluate the toolset.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#kartalink-keyboard-maestro-node","title":"KartaLink | Keyboard Maestro Node","text":"<p>KartaLink | Keyboard Maestro Node</p> <p>KartaLink is an effort to provide node-based pipeline automation features to help XR artists tame complex multi-application based post-production workflows.</p> <p>The new Keyboard Maestro fuses make it possible to run macOS based Keyboard Maestro macros from inside Fusion's node graph. This unlocks node-based GUI automation techniques such as controlling external applications via simulating keyboard and mouse actions.</p> <p>This fuse requires the installation of \"Keyboard Maestro\" for macOS:</p> <p>https://www.keyboardmaestro.com/main/</p> <p>The Reactor Package Manager is used to install the KartaLink collection of tools.</p> <p></p> <p>There are two versions of the Keyboard Maestro macros: A version that can be connected to image based input/output connections, and a version that works with text based input/output connections such as the Vonk Ultra \"vText\" nodes.</p> <p></p> <p>The\"kvrKeyboardMaestro\" fuses have an \"Open Keyboard Maestro\" button that is found in the Inspector window. This feature makes revising the automation macros a single-click task.</p> <p></p> <p>The Keyboard Maestro Editor is very flexible in how you build your automation macros. You can either run a recorder to track your visual on-screen actions, or you can incrementally build the actions one at a time by hand for more precision and control.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#usage","title":"Usage:","text":"<p>Usage:</p> <p>1. Create a new comp.</p> <p>2. Add a \"kvrKeyboardMaestro\" image or text based fuse to the comp.</p> <p>3. In the Inspector window, enter the name of the Keyboard Maestro macro you want launched into the text field labelled \"Macro Name\".</p> <p>4. The first time the macro is run, you need to approve a macOS security message that says:</p> <pre><code>\"Fusion.app\" wants access to control \"Keyboard Maestro.app\". Allowing control will provide access to documents and data in \"Keyboard Maestro.app\" and to perform actions within that app.\n</code></pre> <p>You need to click the \"OK\" button to continue.</p> <p>5. In Keyboard Maestro's Editor program create a corresponding macro that will perform the actual GUI automation tasks. Click the \"New Action\" button in the Editor window to add each step you'd like the macro to carry out. You could also use the \"Record\" button to save a series of mouse interactions or keyboard button presses.</p> <p>6. When your macro is complete, switch out of the \"Edit\" state and then try out the macro.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#tips","title":"Tips:","text":"<p>Tips:</p> <p>If you only want Keyboard Maestro launched when a Fusion batch render is occurring, uncheck the \"Interactive Render\" checkbox.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#using-applescript-osax-scripting-from-the-terminal","title":"Using AppleScript OSAX Scripting from the Terminal","text":"<p>Using AppleScript OSAX Scripting from the Terminal</p> <p>AppleScript is the native macOS scripting architecture that allows for inter-application control via the Apple Scripting Dictionary and Apple Events. AppleScripts are typically created in the macOS Script Editor program. You can also run inline AppleScript code as a block of text from a command-prompt session using the OSAX scripting utility.</p> <p>For more information:</p> <ul> <li>Apple Mac Automation Scripting Guide</li> <li>KartaLink kvrAppleScript Fuse Docs</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#kartalink-apple-script-node","title":"KartaLink | Apple Script Node","text":"<p>KartaLink | Apple Script Node</p> <p>Kartaverse's KartaLink tool collection includes a package named \"KartaLink | Apple Script\". This is available in the Reactor Package Manager for Resolve/Fusion.</p> <p></p> <p>Run macOS based Apple Script code snippets from inside a Fusion Studio node-graph. This unlocks node-based automation techniques such as controlling external applications via Apple Events and OSAX (Open Scripting Architecture Extension) scripting.</p> <p>In only a few moments you can start exploring Apple Script automation techniques inside of Resolve/Fusion. The simplest command to begin with if this is 100% new territory for you is \"beep\" which plays a chime sound as each frame is rendered. The double dashes on the first line of code is used to add a comment entry that is ignored when the code is run.</p> <p></p> <p>Apple Script allows you to automate tasks that can include sending SMS messages via the Apple Messages app.</p> <p></p> <p>It's now possible to have progress messages or other info passed from Resolve/Fusion to your cell phone via SMS when you need to find out what's happening on a rendering task.</p> <p></p> <p>The Apple Script Editor dictionary allows you to learn more about the 3<sup>rd</sup> party scripting capabilities you can tap into on your mac.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#apple-script-editor","title":"Apple Script Editor","text":"<p>Apple Script Editor</p> <p>If you want to learn more about Apple scriptable programs, open the Apple Script Editor and then select the \"File &gt; Open Dictionary...\" menu item.</p> <p></p> <p>The \"Open Dictionary\" window allows you to select Apple Scriptable programs and learn more about their capability.</p> <p></p> <p>This is the Apple Script Dictionary output from the Panic Transmit file transfer program.</p> <p></p> <p>You could also use the \"Record\" button to save a series of interactions into the Apple Script Editor window.</p> <p>After you record a task in the Script Editor window, you can then copy/paste this code back into the \"kvrAppleScript\" fuse's interface in the Resolve/Fusion Inspector view.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#auto-it-on-windows","title":"Auto-IT on Windows","text":"<p>Auto-IT on Windows</p> <p>AutoIT is a GUI automation program for Windows. It is the Windows equivalent to Keyboard Maestro.</p> <p>https://www.autoitscript.com/site/autoit/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#microsoft-power-automate-for-windows","title":"Microsoft Power Automate for Windows","text":"<p>Microsoft Power Automate for Windows</p> <p>https://powerautomate.microsoft.com/en-us/</p> <p>https://learn.microsoft.com/en-us/power-automate/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#pyautogui","title":"PyAutoGui","text":"<p>PyAutoGui</p> <p>https://pypi.org/project/PyAutoGUI/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#homebrew-package-manager-for-macos","title":"Homebrew Package Manager for macOS","text":"<p>Homebrew Package Manager for macOS</p> <p>If you need to regularly compile and run common open-source software on your macOS system, the odds are good that a brew package already exists for the tool.</p> <p>https://brew.sh</p> <p>Homebrew can be installed on a fresh macOS system by running the following shell script in the terminal:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#luajit","title":"LuaJIT","text":"<p>LuaJIT</p> <p>LuaJIT is a cross-platform scripting environment that runs Lua scripts from a terminal session. As far as interpreted scripting languages go, Lua is fast, efficient, and simple to use.</p> <p>https://luajit.org/luajit.html</p> <p>For more information:</p> <ul> <li>LuaJIT FFI Library</li> <li>LuaJIT FFI Tutorial</li> <li>LuaJIT FFI API Functions</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#luajit-in-resolvefusion","title":"LuaJIT in Resolve/Fusion","text":"<p>LuaJIT in Resolve/Fusion</p> <p>Blackmagic Design's Resolve Studio, and Fusion Studio software, both include a scripting API known as \"FuScript\". This scripting system has a built-in copy of the LuaJIT interpreter which allows users to run .lua script files. You can also use your own install of Python with the FuScript API.</p> <p>LuaJIT has advanced features like \"FFI library\" access which allows .lua scripts and fuses to access ANSI C API functions provided by external shared libraries like .dll (Windows), .dylib (macOS), and .so (Linux and macOS).</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#lua-rocks-package-manager","title":"Lua Rocks Package Manager","text":"<p>Lua Rocks Package Manager</p> <p>Lua Rocks provides a web-based cross-platform compatible package manager that runs from a Terminal session. This approach is the most common way to be able to find and use compiled Lua modules.</p> <p>https://luarocks.org/</p> <p>Lua Rock compiled Lua Modules can be used with the LuaJIT FFI interface from Resolve Studio and Fusion Studio.</p> <p>You may have to customize your macOS Terminal shell session's \"LUA_PATH\" and \"LUA_CPATH\" environment variables if you want Fusion to be able to use the Lua Rocks compiled libraries.</p> <p>Doing this step means you don't have to copy your Lua Rocks compiled .dll/.so files and .lua files into the Fusion managed LuaModules: PathMap folder.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Automation%20Tools/#lua-love-real-time-2d-engine","title":"Lua Love Real-Time 2D Engine","text":"<p>Lua Love Real-Time 2D Engine</p> <p>Lua Love is an lean and efficient open-source real-time 2D engine that uses Lua scripts to create 2D games and immediate mode GUI based graphical tools and utilities.</p> <p>https://love2d.org/</p> <p>For more information:</p> <ul> <li>Love Wiki</li> <li>L\u00d6VE-Nuklear Immediate Mode GUI</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Choosing%20Your%20Installation%20Packages/","title":"Choosing Your Installation Packages","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The Kartaverse package installation approach is very flexible. Reactor makes it possible to do a minimal installation of only the KartaVR features you need. This is a good choice when getting started so you don't become overwhelmed by choice.</p> <p></p> <p>If you are are an entry-level 360VR content creator, who is new to using KartaVR in Resolve/Fusion, then you might choose to only install the \"Reframe360Ultra\" and \"WarpStitchUltra\" packages using Reactor. This is a good entry point during your first few weeks of using the toolset. These specific Reactor packages make it possible to work efficiently with fisheye, 360VR, and 180VR media.</p> <p>As you become more comfortable you could slowly add more Kartaverse tools as required.</p> <p>Alternatively, if you want to install every possible component in the full Kartaverse suite, it requires the dedication of several hours to set up the entire toolchain to a full production-usage level. This time estimate includes installing Resolve/Fusion/Fusion Render Node, configuring the settings in a render manager for each of the render nodes, and customizing the program execution paths for each of the 3<sup>rd</sup> party integration bindings available in the toolset.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Closing%20Thoughts/","title":"Closing Thoughts","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>By the time you reach this point in the pipeline integration guide, you should have a better understanding of the many tools, technologies, and customization options available to freelancers and small studios working in the media creation and post-production space.</p> <p>If you set up an efficient workflow for your projects from the beginning, you will be able to maintain your team's productivity and get the most out of the hardware and software resources available to you.</p> <ol> <li> <p>Connecting simulation to audio DSP with parameters\", Microsoft Project Acoustics, Web, January, 2022.\u00a0\u21a9</p> </li> </ol>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/","title":"Computer Vision and Machine Learning Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#python-virtual-environment-basics","title":"Python Virtual Environment Basics","text":"<p>Python Virtual Environment Basics</p> <p>Python venv Docs</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#pytorch","title":"PyTorch","text":"<p>PyTorch</p> <p>https://pytorch.org/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#accessing-the-dall-e-api","title":"Accessing the Dall-E API","text":"<p>Accessing the Dall-E API</p> <p>The OpenAI Dall-E machine learning based image generation toolset is now available to the public using a web-based API. This makes it possible to quickly create concept images from a simple text-based prompt input syntax.</p> <p>Dall-E Resources</p> <ul> <li>Dall-E Website</li> <li>WSL - Dalle-E API Now Available in Public (Fusion Community Forum Thread)</li> <li>LinkedIn | Using OpenAI DALL\u00b7E With the Vonk Data Nodes in Fusion</li> </ul> <p>A DALL-E demo of the \"Girl with a Pearl Earring\" painting shows the power of out-painting to extend the canvas larger on an image. In visual effects workflows, this approach would be a big help for digital matte painters who need to extend the border of a frame to provide padding for 2.5D centric pan and tile workflows.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#using-openai-dalle-with-the-vonk-data-nodes-in-fusion","title":"Using OpenAI DALL\u00b7E With the Vonk Data Nodes in Fusion","text":"<p>Using OpenAI DALL\u00b7E With the Vonk Data Nodes in Fusion</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#step-1-account-registry","title":"Step 1. Account Registry","text":"<p>Step 1. Account Registry</p> <p>Start by registering for an OpenAI account to get an API Key. This allows you to access Dall-E as a web service. You get $18 in credits with a new OpenAI account registry.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#step-2-api-key","title":"Step 2. API Key","text":"<p>Step 2. API Key</p> <p>Click at the top right corner of the OpenAI webpage on your account name. Then select the menu entry labelled \"View API Keys\". On the API keys page select the \"Create new secret key\" option. This will generate a new API key.</p> <p></p> <p>After you see the \"API key generated\" dialog, you will have to save a copy of this code somewhere for later use. This is important as the information is only displayed once in this dialog.</p> <p></p> <p>On the API Keys view you will see a reduced detail summary of each API key that is active for your account. You can delete old keys by clicking on the trash can icon.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#step-3-environment-variable","title":"Step 3. Environment Variable","text":"<p>Step 3. Environment Variable</p> <p>Create a new environment variable to hold the API key. Our environment variable will be named \"<code>OPENAI_API_KEY</code>\" and the variable will hold the contents of the API Key you created in step 2.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#step-4-install-vonk","title":"Step 4. Install Vonk","text":"<p>Step 4. Install Vonk</p> <p>Install the \"Vonk Ultra\" atom package for Resolve/Fusion using the WSL Reactor Package Manager. Re-launch Resolve/Fusion once after installing Vonk to activate the new fuses.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#step-5-explore-the-vonk-dall-e-example-comp","title":"Step 5. Explore the \"Vonk Dall-E\" Example Comp","text":"<p>Step 5. Explore the \"Vonk Dall-E\" Example Comp</p> <p>Open the provided \"<code>Demo Vonk Dall-E.comp</code>\" example project in Fusion Studio.</p> <p></p> <p>This example comp uses the sample image generation prompt text of \"Blackmagic Design Control Panel, Fusion Reactor, Cooling Tank, Blue Glow Water\".</p> <p>Note: Performance optimizations for this example comp can be implemented in the future that will reduce unneeded Fusion pre-process requests. These are what cause re-downloads of the cURL JSON file to occur on the same frame. As usual, down the road all of this can be wrapped into a single neat-and-tidy fuse node that does all of the processing steps internally. :)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#common-json-errors","title":"Common JSON Errors","text":"<p>Common JSON Errors</p> <p>If an error occurs while generating the image, the technical information about the issue will be written into the JSON file. This allows you to troubleshoot problems and track down the source of the problem.</p> <p>If you have a valid OpenAI API Key the most common JSON error for a free usage account will be:</p> <pre><code>{\n  \"error\": {\n    \"code\": null,\n    \"message\": \"Rate limit reached for images per minute. Limit: 25/5min. Current: 27/5min. Please visit https://help.openai.com/en/articles/6696591 to learn how to increase your rate limit.\",\n    \"param\": null,\n    \"type\": \"requests\"\n  }\n}\n</code></pre> <p>If you do not have a valid API key then you will see a JSON error of:</p> <pre><code>{\n    \"error\": {\n        \"message\": \"Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://beta.openai.com.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"invalid_api_key\"\n    }\n}\n</code></pre> <p>If you don't have anything typed into the prompt text-field (meaning the text field content is completely empty) you will see a JSON error of:</p> <pre><code>{\n    \"error\": {\n    \"code\": null,\n    \"message\": \"You must provide a prompt.\",\n    \"param\": null,\n    \"type\": \"invalid_request_error\"\n  }\n}\n</code></pre> <p>If Dall-E could not understand the meaning of your prompt you will see a JSON error of:</p> <pre><code>{  \"error\": {\n    \"code\": null,\n    \"message\": \"Something went wrong with your generation. You may try again or ask for a different prompt\",\n    \"param\": null,\n    \"type\": \"server_error\"\n  }\n}\n</code></pre> <p>If you hit into the Dall-E safety-rule limitations it means your prompt words are being censored. In those cases you will see an error like this message which was generated by having the words \"COVID mask\" as part of a prompt:</p> <pre><code>{\n  \"error\": {\n    \"code\": null,\n    \"message\": \"Your request was rejected as a result of our safety system. Your prompt may contain text that is not allowed by our safety system.\",\n    \"param\": null,\n    \"type\": \"invalid_request_error\"\n  }\n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#windows-command-prompt-test","title":"Windows Command Prompt Test","text":"<p>Windows Command Prompt Test</p> <p>If you want to do a test run of the cURL + OpenAI Key environment variable you can try running this cURL code directly in a command-prompt window:</p> <pre><code>\"curl.exe\" -v -H \"Content-Type: application/json\" -H \"Authorization: Bearer %OPENAI_API_KEY%\" -d \"{\\\"prompt\\\": \\\"Blackmagic Design Control Panel, Fusion Reactor, Cooling Tank, Blue Glow Water\\\", \\\"n\\\": 1, \\\"size\\\": \\\"256x256\\\"}\"  https://api.openai.com/v1/images/generations\n</code></pre> <p>The JSON based request result you will get back looks like this:</p> <pre><code>{\n  \"created\": 1667534341,\n  \"data\": [\n    {\n      \"url\": \"https://oaidalleapiprodscus.blob.core.windows.net/private/&lt;snip&gt;.png?st=2022-11-04T02%3A59%3A01Z&amp;se=2022-11-04T04%3A59%3A01Z&amp;sp=r&amp;sv=2021-08-06&amp;sr=b&amp;rscd=inline&amp;rsct=image/png&amp;skoid=&lt;snip&gt;&amp;skt=2022-11-04T00%3A59%3A13Z&amp;ske=2022-11-05T00%3A59%3A13Z&amp;sks=b&amp;skv=2021-08-06&amp;sig=&lt;snip&gt;\"\n    }\n  ]\n}\n</code></pre> <p>When you copy the URL part of the text output from the command prompt window session into your Web browser's address bar, you will then see a new randomly created PNG image. With any luck it will look like something out of a futuristic SciFi movie with moody blue lighting in the results:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#comp-description-download-from-the-wsl-dall-e-thread","title":"Comp Description (Download from the WSL Dall-E Thread)","text":"<p>Comp Description (Download from the WSL Dall-E Thread)</p> <p>The command line version of cURL is used to perform a JSON request with an authorization token. You need to have an OpenAI API Key stored in an environment variable named \"<code>OPENAI_API_KEY</code>\".</p> <p>The ML image generator prompt is defined in the \"ImagePrompt\" node. The number of images generated each time is defined in the \"ImageCount\" node. The image size for the generated imagery is a square image sized to either 256px, 512px, or 1024px. This value is defined in the \"ImageSizePx\" node.</p> <p>The \"vTextSubFormatMultiline\" node is used to combine the command-line launching string elements together using several text based input connections. Each input on the node matches a token value like input #1 = {1}, input #2 = {2}, Input #3 = [3}, etc...</p> <p>The vTextProcessOpen node runs a shell command via popen(). This is how we launch the command line version of cURL to request that OpenAI generates a new image. BTW Windows 10 &amp; 11 include cURL with the OS by default. The vTextViewer node makes it easier to read the shell commands that will be run in the Inspector view.</p> <p>A temporary .bat/.sh/.command file is written to disk. This holds the current cURL CLI command needed. Doing this avoids one whole level of headaches for the handling of nested quotation symbols in blocks of text used by \"<code>popen()</code>\".</p> <p>The vTextSubFormat2 node named \"LinkOrder\" uses the 1<sup>st</sup> input connection to replace the data stream from the vTextProcessOpen node with the original filename of the JSON file. This keeps the order of processing inline when rendering the comp.</p> <p>The \"vJSONFromFile1\" node reads in the JSON data using the supplied filename. The JSON data downloaded by cURL is then loaded into a ScriptVal based Lua table. The \"data.#.url\" table element is accessed nodally to extract a URL that points to a specific element index number's PNG image resource.</p> <p>The PNG image is then displayed in Fusion using a \"vImageFromNet\" node.</p> <p>Finally, a grid of image views are combined into a single horizontal frame layout using the \"vImageCreateTiles\" node.</p> <p>The \"Tiles X\" parameter on this node is driven based upon the number of elements in the ScriptVal Lua table. This allows the \"ImageCount\" node to automatically adjust the number of images loaded into the grid view.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#rescuing-your-vimagefromnet-temp-files","title":"Rescuing Your vImageFromNet Temp Files","text":"<p>Rescuing Your vImageFromNet Temp Files</p> <p>The \"vImageFromNet\" node caches a temporary file to disk for each download request that is processed. The cache location is the \"Temp:/Vonk/\" PathMap folder which is a directory that is automatically cleared by your operating system on restart.</p> <p>This is a relevant tip if your latest interactive prompt creation and rendering session resulted in an amazing image being generated... that you are then having a hard time recreating later on. In this type of circumstance you may need to \"fish out\" that specific asset from the Dall-E processed temporary PNG image files in the cache directory.</p> <p>If this is the case, you can quickly access this content using the \"Script &gt; Vonk Ultra &gt; Open &gt; Show Temp Folder\" menu item.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#dall-e-for-fusion","title":"Dall-E for Fusion","text":"<p>Dall-E for Fusion</p> <p>There is now a macro packaged version of the \"Dall-E for Fusion\" workflow. It bundles all of the Vonk nodes into a single GroupOperator that is streamlined with a minimalistic UI for artists to interact with.</p> <p>Under the hood this macro uses the Base64 request format option to communicate with the Dall-E API's web service. This requires you to have the most recent version of Vonk Ultra (with the Base64 atom package) installed. :)</p> <p></p> <p>The \"Image Resolution\" control defines how large of an image is created. You can choose between \"256px\", \"512px\", or \"1024px\". This will generate either a \"256x256 px\", \"512x512 px\", or \"1024x1024 px\" sized image.</p> <p>The \"Number of Images\" control specifies how many images are generated at a single time. These images are then accessible by advancing the Fusion timeline play head frame-by-frame.</p> <p>The \"Prompt\" text field is where you enter your text to define what type of image content you want to have generated by Dall-E. Do not use quote symbols in this text-field. When entering text into the prompt, keep the content as a \"single line\" block of text without adding any newline characters, slashes or quote characters.</p> <p>The \"Show Temp Folder\" button allows you to open the \"<code>Temp:/Vonk/Dall-E/</code>\" PathMap location on-disk. You can browse the cached images saved here if you need to recover a previously generated image.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#example-comp-and-macro-download-from-the-wsl-dall-e-thread","title":"Example Comp and Macro (Download from the WSL Dall-E Thread)","text":"<p>Example Comp and Macro (Download from the WSL Dall-E Thread)</p> <p></p> <p>Description</p> <p>This comp allows you to use the OpenAI \"Dall-E\" image generator.</p> <p>In order to use the \"<code>kdrDallE</code>\" macro you need to have the \"Vonk Ultra\" package installed from Reactor. You also need to register for an OpenAI API key to access the Dall-E API via the web. This API key should be added to an environment variable on your computer named \"<code>OPENAI_API_KEY</code>\".</p> <p>Note</p> <p>I'm still refining the image caching functionality in the macro, especially when the Number of Images control is above 1.</p> <p>For the next update I need to learn more from Dall-E's API docs on what their equivalent to a seed value is to see how stable of an output you can get within a short window of time with the exact same prompt request.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#accessing-the-hugging-face-api","title":"Accessing the Hugging Face API","text":"<p>Accessing the Hugging Face API</p> <p>https://huggingface.co/inference-api</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#stable-diffusion","title":"Stable Diffusion","text":"<p>Stable Diffusion</p> <p>Stable Diffusion is an open-source machine learning based \"AI\" image generator created by StabilityAI. There is a web-based \"DreamStudio\" interface that can be explored. It is quite similar to MidjourneyAI and OpenAI's Dall-E technology.</p> <p>For getting started quickly, Stable Diffusion's \"DreamStudio\" is an easy-to-use interface for creating images using the recently released Stable Diffusion image generation model. Stable Diffusion is a fast, efficient model for creating images from text which understands the relationships between words and images. It can create high quality images of anything you can imagine in seconds--just type in a text prompt and hit Dream. A safety filter is activated by default.</p> <p>Already there is a Photoshop plugin, several Blender plugins, a Figma plugin, and a Krita plugin.</p> <p>https://github.com/CompVis/stable-diffusion</p> <ul> <li>Wikipedia | Stable Diffusion</li> <li>WSL | [DEV] Kartaverse Stable Diffusion ML Fuse</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#stable-diffusion-for-fusion","title":"Stable Diffusion for Fusion","text":"<p>Stable Diffusion for Fusion</p> <p>A Fuse-based implementation of Stable Diffusion bindings are under development for Fusion. Currently this SD for Fusion effort is working on how best to package and deliver the required library dependencies to create a straightforward, easy to use experience for the end user.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#opencv","title":"OpenCV","text":"<p>OpenCV</p> <p>OpenCV is a popular open-source cross-platform compatible computer vision framework.</p> <p>https://opencv.org/</p> <p>The OpenCV library makes it possible to carry out advanced image analysis with only a few lines of Python code.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#gluoncv","title":"GluonCV","text":"<p>GluonCV</p> <p>Gluon makes it easy to perform common computer vision tasks like image classification, object segmentation and more. It is worth trying out even if you have never explored CV workflows beforehand.</p> <p>https://cv.gluon.ai/</p> <p>GluonCV Resources:</p> <ul> <li>GluonCV Docs</li> <li>GluonCV Image Clasifier</li> </ul> <p>Installing GluonCV for Windows</p> <p>Step 1. Perform a base install of GluonCV via Python PIP Package Manager</p> <pre><code>REM Update Python pip package manager\npython.exe -m pip install --upgrade pip\n\nREM Nvidia driver 512.96\nREM Cuda 11.7 is written below as \"cu117\" when adding mxnet\n\nREM Add mxnet\npip install --upgrade mxnet-cu117\n\nREM Add PyTorch\npip install torch==1.12.1 torchvision==0.7.0\n\nREM Update GluonCV\npip install --upgrade gluoncv\n</code></pre> <p>Step 2. Start working your way through the GluonCV models and tutorials materials to get comfortable with the library.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#openmmlab","title":"OpenMMLab","text":"<p>OpenMMLab</p> <p>https://github.com/open-mmlab</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#mediapipe","title":"MediaPipe","text":"<p>MediaPipe</p> <p>https://mediapipe.dev/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#ffmpeg","title":"FFMpeg","text":"<p>FFMpeg</p> <p>FFMpeg is the ultimate command-line utility for working with video files. It is cross-platform compatible and open-source.</p> <p>https://ffmpeg.org/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#imagemagick","title":"Imagemagick","text":"<p>Imagemagick</p> <p>Imagemagick is a popular command-line image editing and conversion utility that is available for macOS, Linux, and Windows. In addition to the command-line based tools, there are versions of Imagemagick that can be used from inside scripting languages, or as a dynamic library that can be accessed from compiled programming languages.</p> <p>https://imagemagick.org/</p> <p>Using Imagemagick to Burn in Text Overlays</p> <p>Here is an Imagemagick shell scripting example that creates a desktop wallpaper image that has a text caption rendered from a text file named \"desktop_caption.txt\". The output is saved to an image named \"Desktop.png\":</p> <pre><code>#!/usr/bin/env bash\n# Desktop Pattern Generator\n\necho \"Desktop Pattern Generator\"\n\nHOST='R01'\nIPADDRESS='10.20.30.1'\nMACADDRESS='00:25:90:59:5b:16'\nNETSPEED='1000T'\nHARDDISK='70 GB HD / 34 GB Free'\nOSVERSION='Ubuntu 14.04.05 LTS'\n\n# Generate a text string and write it to disk\nprintf \"${HOST} / ${IPADDRESS}\\n${MACADDRESS} ${NETSPEED}\\n${HARDDISK}\\n${OSVERSION}\"&gt; $TMPDIR/desktop_caption.txt\n\n# Create the rendered image from the text file\nconvert -size 320x100 -density 72 -pointsize 18 -interline-spacing 0 -background black -fill white -font Arial caption:@$TMPDIR/desktop_caption.txt \"$HOME/Pictures/Desktop.png\"\n</code></pre> <p>Using ImageMagick in 360VR workflows</p> <p>The Dome2Rect GitHub repository includes a range of .bat shell scripts that use ImageMagick to edit and re-layout cubic panoramic images into different cubic image projections.</p> <p>https://github.com/AndrewHazelden/dome2rect</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#exiftool","title":"EXIFTOOL","text":"<p>EXIFTOOL</p> <p>The exiftool command-line utility is used to modify EXIF metadata tags in images. This tool allows a terminal (Linux/macOS) or command-prompt (Windows) based shell script to carry out batch operations of reading/writing/editing image metadata on a folder of images.</p> <p>https://exiftool.org/</p> <p>When you start writing your own pipeline tools for automating volumetric video or ML workflows, it can be useful to take the time to embed meaningful EXIF metadata into each of the images used in a project folder.</p> <p>This is especially relevant if you are working with multi-view content, or need to convert dozens of movies into image sequences and want to add information into each file. The thing to remember with metadata is that when you do things correctly, those records will be passed down-stream to all the other tools in the pipeline, in a seamless manner.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#hugin-nona","title":"Hugin Nona","text":"<p>Hugin Nona</p> <p>The Hugin panoramic warping toolset includes the \"nona\" command-line utility. Nona uses the PanoTools \"PTStitcher\" scripting syntax to apply image projection and lens distortion correction operations.</p> <p>https://hugin.sourceforge.io/</p> <p>For more information:</p> <ul> <li>Nona Docs</li> <li>Nona Script Example</li> <li>PTStitcher Syntax Docs</li> <li>Scripting PTStitcher</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Computer%20Vision%20and%20Machine%20Learning%20Tools/#enblend-and-enfuse","title":"Enblend and Enfuse","text":"<p>Enblend and Enfuse</p> <p>The Enblend command-line utility allows for seamless blending of multi-view images. A companion tool Enfuse allows for command-line based HDRI image bracket merging.</p> <p>https://enblend.sourceforge.net/</p> <p>For more information:</p> <ul> <li>Enfuse Docs</li> <li>Hugin PTX Users Google Group</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Configuring%20Fusion%20Centric%20Environment%20Variables/","title":"Configuring Fusion Centric Environment Variables","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Common Environment variables in a fully configured Fusion Studio deployment typically include:</p> <ul> <li><code>PATH</code></li> <li><code>LD_LIBRARY_PATH</code></li> <li><code>FUSION16_PROFILE</code></li> <li><code>FUSION16_PROFILE_DIR</code></li> <li><code>FUSION16_MasterPrefs</code></li> <li><code>FUSION_LICENSE_SERVER</code></li> <li><code>FUSION_PLUGIN_PATH</code></li> <li><code>FUSION_OFX_PLUGIN_PATH</code></li> <li><code>OCIO</code></li> <li><code>LUA_PATH</code></li> <li><code>LUA_CPATH</code></li> <li><code>REACTOR_DEBUG</code></li> </ul> <p>Essential reading on this topic includes:</p> <ul> <li>VFXPedia | Fusion Environment Variables</li> <li>VFXPedia | Per-User Preferences and Paths</li> <li>VFXPedia | Administrators FAQ</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Configuring%20Fusion%20Centric%20Environment%20Variables/#blocking-incompatible-ofx-plugins-from-loading-in-fusion","title":"Blocking Incompatible OFX Plugins From Loading in Fusion","text":"<p>Blocking Incompatible OFX Plugins From Loading in Fusion</p> <p>After you install a wider range of compositing tools on your visual workstations and render nodes, you will likely need to set up a \"Fusion OFX Blocklist File\". This will stop a wide range of Fusion startup error messages from being spawned regularly by the broken OFX plugins, that would otherwise spam the Console window and halt Fusion with nagging error dialogs.</p> <p>The standard OFX Plugin folder location is:</p> <p>Windows:</p> <pre><code>C:\\Program Files\\Common Files\\OFX\\Plugins\n</code></pre> <p>Mac:</p> <pre><code>/Library/OFX/Plugins/\n</code></pre> <p>Linux:</p> <pre><code>/usr/OFX/Plugins/\n</code></pre> <p>An interesting thing about using an OFX blocklist file approach, is that it allows incompatible OFX plugins to be skipped transparently when Fusion Studio/Fusion Render Nodes are launched. This is achieved by specifically defining the exact name of the OFX plugins you want excluded, one-item-per-line in the file.</p> <p>This document is created at the PathMap location of:</p> <pre><code>Profile:\\FusionOFX.blocklist\n</code></pre> <p>The \"UI Manager\" atom package includes a handy script called the \"OFX Blocklist Generator\" that streamlines the effort needed to prepare a Fusion Studio v18 compatible blocklist resource. The script scans inside your OFX Plugins folder path and then lists those items in a new text-based configuration file.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Configuring%20Fusion%20Centric%20Environment%20Variables/#fusion-profile-customizations","title":"Fusion Profile Customizations","text":"<p>Fusion Profile Customizations</p> <p>A customized Fusion Profile Path can be configured to pre-define the Fusion preferences for an artist through the use of environment variables, along with a Fusion Master Prefs.</p> <p>Make sure to define a Master Prefs locking setting when generating the Lua table based document.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Configuring%20Fusion%20Centric%20Environment%20Variables/#fusion-diagnostic-tool","title":"Fusion Diagnostic Tool","text":"<p>Fusion Diagnostic Tool</p> <p>The \"UI Manager\" atom package includes a handy script called the \"Fusion Diagnostics Tool\" that allows you to troubleshoot your most common Fusion-based environment variables in a low-effort fashion.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Configuring%20Fusion%20Render%20Node%20PathMaps/","title":"Configuring Fusion Render Node PathMaps","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>1. Open the Fusion Render Node program and select the \"Preferences...\" menu item.</p> <p></p> <p>2. Click on the \"Global Settings &gt; Path Map\" category on the left side of the Preferences window.</p> <p></p> <p>3. At the bottom of the window click on the \"New\" button to add a new entry to the \"User\" section of the \"Path Map\" view.</p> <p>4. Enter the following settings <code>From: LuaModules:</code> and <code>To: UserPaths:Modules/Lua</code>. Click the \"Save\" button to retain these settings.</p> <p>5. If you don't have Reactor Path Map entries added to Fusion Render Node already, then you might have to further customize the preferences to add values like:</p> <p>Windows:</p> <p><code>From: Reactor:</code> and <code>To: C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\</code></p> <p>macOS:</p> <p><code>From: Reactor:</code> and T<code>o: /Library/Application Support/Blackmagic Design/Fusion/Reactor/</code></p> <p>Linux:</p> <p><code>From: Reactor:</code> and <code>To: /var/BlackmagicDesign/Fusion/Reactor/</code></p> <p>Also you would need to edit the pre-existing UserPaths PathMap entry:</p> <p><code>From: UserPaths:</code> and <code>To: UserData:;AllData:;Fusion:;Reactor:Deploy</code></p> <p>6. Restart Fusion Render Manager to lock in these values.</p> <p>Note: If the LuaModules PathMap entries were not added to Fusion Render Node's preferences, a typical error message in Fusion Render Node would look a bit like this:</p> <pre><code>14/Apr/22 16:12:50: .../Fusion/Fuses/Vonk Ultra/Text/Create/vTextFromArray.fuse:5: module 'vjsonutils' not found:\nno field package.preload['vjsonutils']\nno file 'LuaModules:vjsonutils.lua'\nno file 'LuaModules:vjsonutils/init.lua'\nno file 'LuaModules:vjsonutils.so'\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/","title":"Display Solutions, GPUs, Video Cables, Converters/Adapters","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#pcoip-thin-clients","title":"PCoIP Thin Clients","text":"<p>PCoIP Thin Clients</p> <p>Remote workers in the enterprise end of the media sector often use thin client systems driven by \"PCoIP\" hardware like HP branded Teradici remote access terminals.</p> <p>https://www.teradici.com</p> <p>This thin client gear passes USB (keyboard, mouse, graphics tablet), sound, and monitor signals in an encrypted fashion over a conventional high-speed internet connection. The remote employee never has access to raw files over this thin client connection and only sees the visual image on the monitor which makes studios happy for security reasons.</p> <p>On the data center side of things, the host server system for the thin client session provides hardware accelerated graphics using NVIDIA GRID GPU drivers. Often the system provides more than 4 concurrent user sessions per rack-mounted server case.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#workstation-reference-hardware","title":"Workstation Reference Hardware","text":"<p>Workstation Reference Hardware</p> <p>The average visual workstation in the enterprise end of the Film &amp; TV / immersive sector has a NVIDIA CUDA graphics card with an RTX 2000/3000 series GPU hardware for freelancers, and NVIDIA A6000 or newer series GPUs for 3D animators, and game artists inside of large corporate studio settings.</p> <p>Most workstations have a small dedicated SSD/NVME drive for the OS boot volume.</p> <p>Then the artists' programs are run from a shared file server. It is worth mentioning that temp files generated by programs are not commonly written to the boot volume. All user data is read/written from a 10 Gig Ethernet connected network file path that is specific to the current show they are working on.</p> <p>A separate dedicated computer (that is not the file server) is used as a license server for all of the workstations on a local area network. This license server system will have all the required hardware license dongles attached to it, and floating software licenses are bound to that system's unique hardware IDs as well.</p> <p>These days some studios require/expect to have the ability to run a license server on a VMWARE vSphere based virtual machine, or on an Amazon AWS EC2 cloud hosted instance. For companies that are going for fully cloud-based workstations, \"login based\" licensing is common.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#dummy-hdmi-plugs-for-headless-gpu-render-nodes","title":"Dummy HDMI Plugs for Headless GPU Render Nodes","text":"<p>Dummy HDMI Plugs for Headless GPU Render Nodes</p> <p>When setting up headless render nodes that need to run 24x7 with hardware accelerated GPU rendering tasks it is important to plug a \"dummy HDMI plug\" dongle-like device into the GPU. These are readily available from marketplaces like OWC, Amazon, eBay.</p> <p>This allows the graphics card to correctly auto-sense the EDID resolution parameters so macOS, Windows, and Linux window managers operate correctly. It also allows screen sharing programs to work more reliably.</p> <p>Some remote access programs, like Parsec, also benefit from having a spare mouse plugged into the USB port if you want to have a hardware cursor that works on Windows.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#pcie-riser-ribbon-cables","title":"PCIe Riser Ribbon Cables","text":"<p>PCIe Riser Ribbon Cables</p> <p>If you need to get creative with how you build your workstation to be able to fit in multiple GPUs a less common option is to use LinkUP brand PCIe flex cables. Amazon is a good source for them when they are available.</p> <p>https://linkup.one/ultra-4-0-pcie-riser-cables/</p> <p>The flex cables come in up to 30 cm long lengths while still being able to function on a PCIe Gen 4 bus at 16 lanes of bandwidth. It is possible to \"fan out\" several large GPUs like NVIDIA RTX 3090s in a wider fashion than the mechanical limits of PCIe motherboard slot spacing with LinkUP cables.</p> <p></p> <p></p> <p>Note: The \"LinkUP flex cables\" shown above are not bandwidth-throttled like the commonly available discount cables on Amazon or eBay that come from the more common \"cryptocurrency mining\" style of single-lane PCIe cables and risers. Discount cables must be avoided at all costs as this format of hardware is not effective for GPU rendering use.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#msi-afterburner-on-windows-gpu-performance-tuning","title":"MSI Afterburner on Windows GPU Performance Tuning","text":"<p>MSI Afterburner on Windows GPU Performance Tuning</p> <p>MSI Afterburner allows you to optimize the thermal cooling and performance of your GPU.</p> <p>You can improve the stability of GPU rendering workflows by making small changes to the core clock, memory clock, power limit, and fan speed settings.</p> <p>https://www.msi.com/Landing/afterburner/graphics-cards</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#green-with-envy-on-linux-single-gpu-performance-tuning","title":"Green With Envy on Linux Single GPU Performance Tuning","text":"<p>Green With Envy on Linux Single GPU Performance Tuning</p> <p>https://gitlab.com/leinardi/gwe</p> <p>It is possible to persistently enable fan speed control in nvidia-settings using:</p> <pre><code>Option \"Coolbits\" \"28\"\n\n# Toggle the prefs for all GPUs connected:\nsudo nvidia-xconfig --enable-all-gpus\n\n# Edit xorg\ncp /etc/X11/xorg.conf $HOME/xorg.conf.bak\nsudo gedit /etc/X11/xorg.conf\n\n# For a Dual GPU setup paste the following into the xorg.conf file:\n# nvidia-xconfig: X configuration file generated by nvidia-xconfig\n# nvidia-xconfig:  version 460.73.01\n\nSection \"ServerLayout\"\n    Identifier     \"Layout0\"\n    Screen      0  \"Screen0\"\n    Screen      1  \"Screen1\" RightOf \"Screen0\"\n    InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n    InputDevice    \"Mouse0\" \"CorePointer\"\nEndSection\n\nSection \"Files\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Mouse0\"\n    Driver         \"mouse\"\n    Option         \"Protocol\" \"auto\"\n    Option         \"Device\" \"/dev/input/mice\"\n    Option         \"Emulate3Buttons\" \"no\"\n    Option         \"ZAxisMapping\" \"4 5\"\nEndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Keyboard0\"\n    Driver         \"kbd\"\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"Monitor0\"\n    VendorName     \"Unknown\"\n    ModelName      \"Unknown\"\n    Option         \"DPMS\"\nEndSection\n\nSection \"Monitor\"\n    Identifier     \"Monitor1\"\n    VendorName     \"Unknown\"\n    ModelName      \"Unknown\"\n    Option         \"DPMS\"\nEndSection\n\nSection \"Device\"\n    Identifier     \"Device0\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce RTX 3090\"\n    BusID          \"PCI:1:0:0\"\n    Option         \"Coolbits\" \"28\"\n    Option         \"AllowEmptyInitialConfiguration\"\nEndSection\n\nSection \"Device\"\n    Identifier     \"Device1\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce RTX 3090\"\n    BusID          \"PCI:33:0:0\"\n    Option         \"Coolbits\" \"28\"\n    Option         \"AllowEmptyInitialConfiguration\"\nEndSection\n\nSection \"Screen\"\n    Identifier     \"Screen0\"\n    Device         \"Device0\"\n    Monitor        \"Monitor0\"\n    DefaultDepth    24\n    SubSection     \"Display\"\n        Depth       24\n    EndSubSection\nEndSection\n\nSection \"Screen\"\n    Identifier     \"Screen1\"\n    Device         \"Device1\"\n    Monitor        \"Monitor1\"\n    DefaultDepth    24\n    SubSection     \"Display\"\n        Depth       24\n    EndSubSection\nEndSection\n</code></pre> <p>Finally you can check the NVIDIA prefs to see if the preference was defined correctly:</p> <p>sudo nvidia-settings</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#ipmi-remote-management-interface","title":"IPMI Remote Management Interface","text":"<p>IPMI Remote Management Interface</p> <p>If you are building a render farm with second-hand \"surplus\" business and industrial server gear purchased from eBay, you might notice the presence on server systems from vendors like Super-Micro of a low-level device management interface that was known as an IPMI interface.</p> <p>This interface allows you to modify BIOS settings remotely via a dedicated ethernet IP network connection that is separate from the server's network interface used by the running operating system.</p> <p>If the server is an older generation like a quad AMD G34 CPU powered system, you may have to run the IPMI management utility in a virtual machine that runs an older release of Windows ranging from Windows XP, Vista, or 7. This was due to using the common requirement of Internet Explorer 6 and ActiveX controls.</p> <p>https://www.supermicro.com/en/solutions/management-software/ipmi-utilities</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#nvme-storage-raid-controller-cards","title":"NVME Storage Raid Controller Cards","text":"<p>NVME Storage Raid Controller Cards</p> <p>KartaVR v5's volumetric workflows were developed using a file server that had a High-Point SSD7540 8x NVME raid array controller card. The card is compatible with Windows, Linux, and macOS systems which is excellent.</p> <p>The disk throughput is quite phenomenal and it reduces the pain of working with large media assets like tons of image sequences and per-frame photogrammetry reconstructed mesh sequences.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Display%20Solutions%2C%20GPUs%2C%20Video%20Cables%2C%20Converters_Adapters/#networking-gear","title":"Networking Gear","text":"<p>Networking Gear</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Essential%20Reactor%20Atom%20Packages/","title":"Essential Reactor Atom Packages","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>There are currently (as of 2022-11-08) a total of 356 atom packages in the Reactor Package Manager. This means there is likely something interesting for just about any type of Resolve/Fusion user's tastes.</p> <p>If you are regularly creating visual effects in Fusion Studio then the following Reactor atom packages are likely something you would deem essential to maintain your productivity and sanity:</p> <ul> <li>Attribute Spreadsheet (Batch node editing)</li> <li>Append (Modify clip timings in a node-based fashion)</li> <li>AudioWaveform (Visualize .wav audio files)</li> <li>Batch Change Parameters (Batch node editing)</li> <li>ClassBrowser (Undocumented Scripting API browser)</li> <li>Cryptomatte</li> <li>DeleteFileRequesterHistory (Speed up file dialog load time by pruning the recent files list)</li> <li>Eyeon Legacy (Archive Composition Script)</li> <li>Glitch Tools (Create intentional defects / video artifacts in your footage)</li> <li>hos_SplitEXR_Ultra (Helps split apart multi-channel EXR footage)</li> <li>KAK (A powerful node-based keyer)</li> <li>Krokodove (The ultimate Fusion motion-graphics toolset)</li> <li>MultiMerge (Merge imagery with a multi-input like layer stack)</li> <li>ml_LFTools (Lens Flares)</li> <li>nuke2fusion (Helps Nuke Users migrate to Fusion with modified hotkey bindings and node names)</li> <li>ReadEXR Ultra (Multi-Part EXR reader with filename token support)</li> <li>SlashFor (Batch node editing with expressions in the Console)</li> <li>SuckLessAudio (A modifier to import .wav audio files)</li> <li>stx_tools (Custom macros including an optical flow based warp tracker)</li> <li>STMapper (An amazing UV Pass/ST Map warping DCTL Fuse. It's SO FAST!!!)</li> <li>Shadertoys (A wild visual trip with DCTL ports of popular ShaderToy fragment shaders)</li> <li>TimeMachine (Retime nodes)</li> <li>Tintensity (Color Correction)</li> <li>UI Manager Lua &amp; Python Examples (Code examples for creating custom Qt based GUIs in scripts)</li> <li>LifeSaver (Multi-Part EXR writer with filename token support)</li> <li>ParallelIO pioSaver (Multi-Channel EXR writer with filename token support)</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/FFMpeg%20Command-Line%20Syntax/","title":"FFMpeg Command Line Syntax","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>https://ffmpeg.org/</p> <p>For more information</p> <ul> <li>FFMpeg Syntax</li> <li>KartaVR Scripts | Convert Movies to Image Sequences</li> <li>KartaVR Scripts | Combine Stereo Movies</li> <li>KartaVR Scripts | Video Snapshot</li> <li>Dome2Rect | Image Sequence To Movie</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/","title":"Fulldome","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Fulldome is the term often associated with video-based planetarium style hemispherical \"dome\" theaters.</p> <p></p> <p>A fulldome theater typically plays 180\u00b0\u00a0angular fisheye content that is stored in a media file called a \"domemaster\" image projection. It is also possible to use cubic or LatLong/Spherical/Equirectangular image projection footage in a dome theatre.</p> <p>Rectilinear image projection content can be warped and stretched to fill a fulldome screen as well.</p> <p>Affordable portable domes can be inflated on-site, or built with module geodesic construction approaches. Portable domes often use a half-spherical mirror based projection approach that can be played back with a warp-mesh control file.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#fulldome-playback-software","title":"Fulldome Playback Software","text":"<p>Fulldome Playback Software</p> <p>Common fulldome playback tools include the following products:</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#amateras-dome-player","title":"Amateras Dome Player","text":"<p>Amateras Dome Player</p> <p>https://www.orihalcon.co.jp/amateras/domeplayer/en/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#blendy-dome-vj","title":"Blendy Dome VJ","text":"<p>Blendy Dome VJ</p> <p>https://blendydomevj.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#paul-bourke-warp-mesh","title":"Paul Bourke Warp Mesh","text":"<p>Paul Bourke Warp Mesh</p> <p>http://paulbourke.net/dataformats/meshwarp/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#whirligig","title":"Whirligig","text":"<p>Whirligig</p> <p>http://www.whirligig.xyz/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#festoon-player","title":"Festoon Player","text":"<p>Festoon Player</p> <p>https://www.festoonsoftware.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#fulldome-real-time-2d3d-rendering-and-slicing-software","title":"Fulldome Real-time 2D/3D Rendering and Slicing Software","text":"<p>Fulldome Real-time 2D/3D Rendering and Slicing Software</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#amateras","title":"Amateras","text":"<p>Amateras</p> <p>https://www.orihalcon.co.jp/amateras/index_en.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#ref5","title":"Blendy Dome VJ","text":"<p>Blendy Dome VJ</p> <p>https://blendydomevj.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#nest","title":"NEST","text":"<p>NEST</p> <p>http://www.nestimmersion.ca</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#vuo","title":"VUO","text":"<p>VUO</p> <p>https://vuo.org/</p> <p>For more information:</p> <ul> <li>http://www.paulbourke.net/dome/vuo/</li> <li>http://www.paulbourke.net/dome/vuo/index1.html</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#unreal-domemaster-camera","title":"Unreal Domemaster Camera","text":"<p>Unreal Domemaster Camera</p> <p>https://www.unrealengine.com/marketplace/en-US/product/dx12-360-livestream-camera</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#fulldome-angular-fisheye-post-production-software","title":"Fulldome / Angular Fisheye Post Production Software","text":"<p>Fulldome / Angular Fisheye Post Production Software</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#immersive-compositing","title":"Immersive Compositing","text":"<p>Immersive Compositing</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#adobe-aftereffects-vr-effects","title":"Adobe AfterEffects | VR Effects","text":"<p>Adobe AfterEffects | VR Effects</p> <p>https://helpx.adobe.com/after-effects/how-to/vr-converter-effect.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#foundry-nukex-spherical-transform","title":"Foundry NukeX | Spherical Transform","text":"<p>Foundry NukeX | Spherical Transform</p> <p>https://learn.foundry.com/nuke/content/reference_guide/transform_nodes/sphericaltransform.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#blackmagic-design-resolve-studiofusion-studio-kartavr","title":"Blackmagic Design Resolve Studio/Fusion Studio | KartaVR","text":"<p>Blackmagic Design Resolve Studio/Fusion Studio | KartaVR</p> <p>https://andrewhazelden.com/projects/kartavr/docs/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#skyskan-domexf-for-after-effects","title":"SkySkan DomeXF for After Effects","text":"<p>SkySkan DomeXF for After Effects</p> <p>https://skyskan.com/domexf/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#es-evans-sutherland-virtual-projector-for-after-effects","title":"E&amp;S (Evans &amp; Sutherland) Virtual Projector for After Effects","text":"<p>E&amp;S (Evans &amp; Sutherland) Virtual Projector for After Effects</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#3d-animationrenderingpreviz","title":"3D Animation/Rendering/Previz","text":"<p>3D Animation/Rendering/Previz</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#blender","title":"Blender","text":"<p>Blender</p> <p>https://docs.blender.org/manual/es/2.79/game_engine/camera/dome.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#domemaster3d-for-mayamax","title":"Domemaster3D for Maya/Max","text":"<p>Domemaster3D for Maya/Max</p> <p>https://github.com/zicher3d-org/domemaster-stereo-shader</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#playblastvr-for-maya","title":"PlayblastVR for Maya","text":"<p>PlayblastVR for Maya</p> <p>https://www.awn.com/news/playblastvr-maya-v20-now-available</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#fulldome-hardware","title":"Fulldome Hardware","text":"<p>Fulldome Hardware</p> <p>Fulldome hardware vendors, system integrators, and content producers include:</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#front-pictures","title":"Front Pictures","text":"<p>Front Pictures</p> <p>https://frontpictures.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#cosm","title":"COSM","text":"<p>COSM</p> <p>https://www.cosm.com/experience-center/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#es-evans-sutherland-digistar","title":"E&amp;S (Evans &amp; Sutherland) DigiStar","text":"<p>E&amp;S (Evans &amp; Sutherland) DigiStar</p> <p>https://www.es.com/digistar/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#spitz-inc-cosm","title":"Spitz, Inc.\u00a0(COSM)","text":"<p>Spitz, Inc.\u00a0(COSM)</p> <p>https://www.spitzinc.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#skyskan-digisky","title":"SkySkan DigiSky","text":"<p>SkySkan DigiSky</p> <p>https://skyskan.com/digitalsky-darkmatter/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#konica-minolta-rsa-cosmos","title":"Konica Minolta | RSA Cosmos","text":"<p>Konica Minolta | RSA Cosmos</p> <p>https://www.konicaminolta.com/planetarium/index.html</p> <p>https://www.rsacosmos.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#orihalcon-japan","title":"Orihalcon Japan","text":"<p>Orihalcon Japan</p> <p>https://www.orihalcon.co.jp/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#zeiss-planetariums","title":"Zeiss Planetariums","text":"<p>Zeiss Planetariums</p> <p>https://www.zeiss.com/planetariums/int/home.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#portable-fulldome-hardware","title":"Portable Fulldome Hardware","text":"<p>Portable Fulldome Hardware</p> <p>Portable fulldome hardware vendors, system integrators, and content producers include:</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#loch-ness-productions","title":"Loch Ness Productions","text":"<p>Loch Ness Productions</p> <p>http://www.lochnessproductions.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#nsc-creative-uk","title":"NSC Creative UK","text":"<p>NSC Creative UK</p> <p>https://www.linkedin.com/company/nsc-creative/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#eplanetarium","title":"ePlanetarium","text":"<p>ePlanetarium</p> <p>https://www.eplanetarium.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#dome3d","title":"Dome3D","text":"<p>Dome3D</p> <p>http://www.dome3d.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fulldome/#the-elumenati","title":"The Elumenati","text":"<p>The Elumenati</p> <p>https://www.elumenati.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Fusion%20Render%20Node%20Customization/","title":"Fusion Render Node Customization","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>It is important to customize the Fusion Render node program's PathMap settings if you would like your render farm to be able to access the same Reactor content that you have installed in Resolve/Fusion on your laptop/desktop/workstation. This is especially true after fuses are installed using the Reactor Package Manager.</p> <p>If you rely on fuses, OFX plugins, or FusionSDK C++ compiled plugins, you need to pre-install the 3<sup>rd</sup> party addons on each render node in your render farm. If you send a Fusion composite to a render farm node that lacks a required plugin it will generate an error during the batch rendering process.</p> <p>Something that can help reduce the pain of setting up and syncing Reactor content across a render farm is sharing the exact same Reactor content across a mapped SMB drive mount, or on a NFS shared mount point.</p> <p>An extra step that can often be overlooked is the requirement to configure a custom \"<code>LuaModules:</code>\" PathMap entry in the Fusion Render Node app preferences to avoid Fusion Render Manager errors when batch rendering comps that use fuses like the Vonk data nodes or Cryptomatte.</p> <p>Note: The example below shows the PathMaps used for locally installed Reactor content that was added to a Reactor default \"AllData:\" folder based install.</p> <p>You can point the \"<code>Reactor:</code>\" PathMap at any folder path you need to as long as it is not a UNC path, and it doesn't have high-ASCII or Unicode multi-byte extended characters in the filepath.</p> <p>Make sure to have a trailing slash on the final absolute filepath used to define the PathMap entry for your version of the \"<code>From: Reactor:</code>'' and\"<code>To: /Volumes/Some/Random/Pipeline/Folder/Path/Reactor/</code>\" install location.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/","title":"Hardware Control Surfaces and HID Devices","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/#bmd-control-surfaces-for-resolvefairlight","title":"BMD Control Surfaces for Resolve/Fairlight","text":"<p>BMD Control Surfaces for Resolve/Fairlight</p> <p>Blackmagic Design has a wide range of control surfaces to meet the needs of video editors, audio professionals, and colorists.</p> <p></p> <p>For more information:</p> <ul> <li>Resolve/Fairlight Panels</li> <li>Resolve/Fairlight Consoles</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/#graphics-tablets","title":"Graphics Tablets","text":"<p>Graphics Tablets</p> <p>Fusion's user interface, including the hotkeys used to navigate the viewport inside the Fusion 3D workspace are optimized for use by artists working with a graphics tablet.</p> <p>For more information:</p> <ul> <li>Wacom Products</li> <li>Cintiq Products</li> <li>Huion Products</li> </ul> <p>In addition to controlling the mapping of the buttons on the side of a stylus, artists have the option to customize what the extra buttons and control strips on their tablet are used for on a per-application basis.</p> <p>This makes it possible to use FuScript based command-line scripting with Resolve/Fusion to allow the extra buttons on your graphics tablet to carry out just about any operation you can imagine including: running scripts, loading media in the viewer windows, adding nodes, bypassing nodes, rendering footage, opening the Fusion Render Manager/Console/Bin windows, or toggling the visibility of views like the Nodes view or Inspector controls.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/#logitech-mx-master-options-mice-driver","title":"Logitech MX-Master Options Mice Driver","text":"<p>Logitech MX-Master Options Mice Driver</p> <p>For more information:</p> <ul> <li>MX-Master3 Mouse</li> <li>Logitech Unifying Dongle</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/#3dconnexion-spacemouse","title":"3dconnexion SpaceMouse","text":"<p>3dconnexion SpaceMouse Enterprise</p> <p>https://3dconnexion.com/uk/</p> <p></p> <p>SpaceMouse Dev Resources:</p> <ul> <li>WSL | [DEV] 3dconnexion SpaceMouse Integration Plugin</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Hardware%20Control%20Surfaces%20and%20HID%20Devices/#vrhmd-based-haptic-interfaces","title":"VR/HMD Based Haptic Interfaces","text":"<p>VR/HMD Based Haptic Interfaces</p> <p>An interesting consideration when re-creating virtual environments, is the existing Meta Quest HMD supports optical hand-tracking. Hand tracking brings accurate real-time \"hand gesture\" capture into a virtual world.</p> <p>Hand-tracking works without the need for any 3<sup>rd</sup> party plastic VR hand-controller gadgets/nunchucks. One simply reaches out and uses one's own fingers to interact directly with objects existing inside the digital-twin location.</p> <p>You can touch, pick up, carry and interact with the props, tools, and natural objects in the virtual environment. Forces like gravity act upon the objects so dropping or setting down a prop will kick-off a rigid body dynamics simulation of the settling motion as the object's motion comes to a resting state.</p> <p>These images show the Meta Quest HMD's hand gesture training content:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/","title":"IP Based Video Workflows","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/#newtek-ndi-network-device-interface","title":"Newtek NDI (Network Device Interface)","text":"<p>Newtek NDI (Network Device Interface)</p> <p>Newtek's NDI video protocol is revolutionizing connected immersive content creation, and fulldome content playback approaches.</p> <p>https://www.newtek.com/ndi/applications/</p> <p>For more information:</p> <ul> <li>Wikipedia Network Device Interface</li> <li>NDI Connect</li> <li>NDI SDK</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/#nobe-display","title":"Nobe Display","text":"<p>Nobe Display</p> <p>https://timeinpixels.com/nobe-display/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/#lightsailvr-vr-ndi","title":"LightSailVR VR NDI","text":"<p>LightSailVR VR NDI</p> <p>https://lightsailvr.com/tools.php</p> <p>For more information:</p> <ul> <li>VR NDI Documentation</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/#syphon-for-macos","title":"Syphon for macOS","text":"<p>Syphon for macOS</p> <p>http://syphon.v002.info/</p> <p>For more information:</p> <ul> <li>Syphon | GitHub</li> <li>Syphon Python Bindings</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/IP%20Based%20Video%20Workflows/#spout-for-windows","title":"Spout for Windows","text":"<p>Spout for Windows</p> <p>https://spout.zeal.co/</p> <p>For more information:</p> <ul> <li>Spout | Forum</li> <li>Spout To NDI</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Immersive%20Pipeline%20Integration%20Guide/","title":"Immersive Pipeline Integration Guide","text":"<p>Dissolve content into independent articles!</p> <p>In this folder you will find an export generated from a Scrivener source. Scrivener being an authoring software for writing book type content, the different files will come originally meant to be read in some linear order. Please help to put re-organize and re-write them into separate articles, each working kind of independently from the others. Remove finished files from the <code>.pages</code> file.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Immersive%20Pipeline%20Integration%20Guide/#original-table-of-contents","title":"Original Table of Contents","text":"<ul> <li>Immersive Pipeline Integration Guide</li> <li>About</li> <li>Overview</li> <li>Install Reactor Package Manager</li> <li>Essential Reactor Atom Packages</li> <li>Adding KartaVR via Reactor</li> <li>Adding Vonk Ultra via Reactor</li> <li>The Kartaverse Packages</li> <li>Kartaverse Project Assistance</li> <li>The Karta Development Journey</li> <li>Choosing Your Installation Packages</li> <li>Kartaverse Development Reference Hardware</li> <li>Kartaverse Learning Resources</li> <li>Fusion Render Node Customization</li> <li>Configuring Fusion Render Node PathMaps</li> <li>Automated Reactor PathMaps in Resolve Studio and Fusion Studio</li> <li>Installing the BMD Resolve / Fusion Software</li> <li>Working With Environment Variables</li> <li>Configuring Fusion Centric Environment Variables</li> <li>AWS Deadline Deployment</li> <li>Pixar Tractor Deployment</li> <li>Installing Common Utilities</li> <li>Installing Digital Content Creation Apps</li> <li>Photogrammetry Tools</li> <li>Spatial Audio Tools</li> <li>RAW and HDRI Image Processing Tools</li> <li>ACES Color Management</li> <li>[[360VR Stitching Tools|360VR Stitching Tools]]</li> <li>FFMpeg Command-Line Syntax</li> <li>Apple Compressor Command-Line Syntax</li> <li>IP Based Video Workflows</li> <li>Virtual Production</li> <li>Fulldome</li> <li>Software Packaging and Deployment Tools</li> <li>Installing a Local Content Staging Web Server</li> <li>Using Notepad++ for Fusion on Windows</li> <li>Using BBEdit on macOS</li> <li>Automation Tools</li> <li>Computer Vision and Machine Learning Tools</li> <li>Display Solutions, GPUs, Video Cables, Converters/Adapters</li> <li>Hardware Control Surfaces and HID Devices</li> <li>Installing Hardware Virtualization Tools</li> <li>Installing Operating Systems From Scratch</li> <li>Installing Data Backup and Disaster Recovery Tools</li> <li>System Admin Resources</li> <li>Closing Thoughts</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Install%20Reactor%20Package%20Manager/","title":"Install Reactor Package Manager","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>If you already use Blackmagic Design's Resolve, Resolve Studio, or Fusion Studio software then the singular most important tool you can choose to install is likely the free Reactor Package Manager.</p> <p>The Fusion community developed the Reactor software as a group effort to create a single-stop resource that hosts the largest collection of curated content for extending the capabilities of Resolve/Fusion. Reactor also includes a lot of content that was previously available only on the VFXPedia resource.</p> <p>YouTube | Reactor is released - GET IT NOW!</p> <p>https://www.youtube.com/watch?v=mklCsf8yOUk</p> <p></p> <p>YouTube | Fusion Reactor now available for BMD DaVinci Resolve</p> <p>https://www.youtube.com/watch?v=iEIFl6gp58Q</p> <p></p> <p>So far the Reactor Package Manager has been installed over 190,000 times since 2018! Wow. \ud83c\udf89</p> <p></p> <p>To start using Reactor, first you need to download the Reactor-Installer.lua script to your computer.</p> <p></p> <p>Start up a new Resolve (Free), Resolve Studio, or Fusion Studio session. Open the Console window. Then simply drag the installer script from your desktop into the Fusion Console tab to run it.</p> <p>Note: If you are in the Fusion page or using Fusion Studio you can press the \"Shift + 0\" shortcut to display the Console window.</p> <p>If for some reason the drag-and-drop approach to launching the Reactor installer fails to work... Alternatively, you can also copy/paste the text contents of the script into the Console text entry area.</p> <p></p> <p>In the DaVinci Resolve Fusion page and in Fusion Studio you can also drag the script from your desktop into the Nodes view to run it.</p> <p>When the Reactor Installer starts you are presented with the following dialog. If you want to go with the default settings you simply have to press the \"Install and Launch\" button.</p> <p></p> <p>Custom Install Path Button</p> <p>When installing Reactor you also have the option to choose a \"Custom Install Path\". This button allows you to select a custom location you would like to have the Reactor content installed to. This could be a location like your user account's home folder, or another hard drive on your system, or a mapped network drive mount point for shared usage of Reactor content.</p> <p>You can change the installed Reactor location later on by modifying the Fusion \"PathMap\" preferences and pointing the \"Reactor:\" PathMap at a new folder path.</p> <p>Reactor Installation Status</p> <p>Reactor shows a progress bar while the installation process is underway.</p> <p></p> <p>When the Reactor installation is complete an Explorer (Win), Finder (macOS), or Nautilus (Linux) folder browsing window is displayed. This shows you the location on-disk where new Reactor content is downloaded to. This folder in Fusion terms is called the \"Reactor:\" PathMap location.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/","title":"Installing Common Utilities","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-anydesk-screen-sharing-on-linux","title":"Install AnyDesk Screen Sharing on Linux","text":"<p>Install AnyDesk Screen Sharing on Linux</p> <p>AnyDesk is a remote access tool which allows for system administration tasks to be done via screen sharing. It can tunnel a remote connection through a firewall if required.</p> <p>https://www.anydesk.com/</p> <pre><code># Add a new AnyDesk repo entry\ncat &gt; /etc/yum.repos.d/AnyDesk-RHEL.repo &lt;&lt; \"EOF\"\n[anydesk]\nname=AnyDesk RHEL - stable\nbaseurl=http://rpm.anydesk.com/rhel/$releasever/$basearch/\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://keys.anydesk.com/repos/RPM-GPG-KEY\nEOF\n\n# Add Anydesk using the DNF package manager\nsudo dnf install anydesk\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-teamviewer-screen-sharing-on-windowsmacos","title":"Install TeamViewer Screen Sharing on Windows/macOS","text":"<p>Install TeamViewer Screen Sharing on Windows/macOS</p> <p>https://www.teamviewer.com/en/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-parsec-screen-sharing-on-windows","title":"Install Parsec Screen Sharing on Windows","text":"<p>Install Parsec Screen Sharing on Windows</p> <p>https://parsec.app/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-realvnc-screen-sharing-on-windows","title":"Install RealVNC Screen Sharing on Windows","text":"<p>Install RealVNC Screen Sharing on Windows</p> <p>https://www.realvnc.com/en/</p> <p>For more information:</p> <ul> <li>https://www.realvnc.com/en/connect/download/vnc/</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-steam-on-linux","title":"Install Steam on Linux","text":"<p>Install Steam on Linux</p> <p>https://www.dedoimedo.com/computers/rocky-linux-8-steam.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#remote-keyboard-and-mouse-sharing-with-synergy","title":"Remote Keyboard and Mouse Sharing with Synergy","text":"<p>Remote Keyboard and Mouse Sharing with Synergy</p> <p>Through the magic of Synergy keyboard/mouse sharing it is possible to track the mouse pointer seamlessly across the two or more systems, regardless of the host OS platform.</p> <p>This can remove the need to juggle multiple keyboards on the same desk if you need to manage Windows, Linux, and macOS systems as part of your daily activities.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#sharing-a-microsoft-windows-keyboard-with-a-macos-system-using-windows-key-vs-command-key-remapping","title":"Sharing a Microsoft Windows Keyboard with a macOS System Using Windows Key vs Command Key Remapping","text":"<p>Sharing a Microsoft Windows Keyboard with a macOS System Using Windows Key vs Command Key Remapping</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#virtualhere-network-based-usb-device-sharing","title":"VirtualHere Network-Based USB Device Sharing","text":"<p>VirtualHere Network-Based USB Device Sharing</p> <p>If you have several fixed USB licensing dongles that you need to be able to float between several different computers, then the VirtualHere software is a miracle for your problems.</p> <p>https://www.virtualhere.com/</p> <p>One thing to keep in mind when buying a VirtualHere license is that the host server program is a perpetual licensed program but it is tied to one fixed host system ID and no license migrations are provided. Ever.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#sharp-keys-based-keyboard-remapping-for-windows","title":"Sharp Keys Based Keyboard Remapping for Windows","text":"<p>Sharp Keys Based Keyboard Remapping for Windows</p> <p>The Sharp Keys utility for Windows is excellent if you need to modify the default key bindings of a specific key on your keyboard. This is typically required when using a macOS keyboard with Control/Option/Command keys connected to a remote access session hosted on a Windows PC.</p> <p>Microsoft App Store | SharpKeys</p> <p>You have a useful option with the Sharp Keys utility of being able modify both the left and right side \"Windows\" keys on your keyboard to an alternative kep mapping.</p> <p></p> <p>Or you could choose to bind only a single Windows key (like the left Windows key) to an alternative key mapping. This allows you the flexibility to occasionally access the original unmodified right Windows key.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#install-meta-questlink-airlink-drivers-on-windows","title":"Install Meta QuestLink / AirLink Drivers on Windows","text":"<p>Install Meta QuestLink / AirLink Drivers on Windows</p> <p>Please see guide \"Kartaverse Workflows | SketchFab in VR Via QuestLink\"</p> <p>https://docs.google.com/document/d/1sWkv5H7ZAM1SnqrEXYRL3kBKnvjqmDjKTA9v9ObN490/edit</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Common%20Utilities/#windows-system-internals-utilities","title":"Windows System Internals Utilities","text":"<p>Windows System Internals Utilities</p> <p>https://learn.microsoft.com/en-us/sysinternals/downloads/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Data%20Backup%20and%20Disaster%20Recovery%20Tools/","title":"Installing Data Backup and Disaster Recovery Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Data%20Backup%20and%20Disaster%20Recovery%20Tools/#balena-etcher","title":"Balena Etcher","text":"<p>Balena Etcher</p> <p>A cross-platform compatible bootable Linux OS disk image cloning tool.</p> <p>https://etcherofficial.com/</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Data%20Backup%20and%20Disaster%20Recovery%20Tools/#rescuezilla-bare-metal-disk-imaging-backups-and-restores","title":"Rescuezilla Bare Metal Disk Imaging, Backups and Restores","text":"<p>Rescuezilla Bare Metal Disk Imaging, Backups and Restores</p> <p>Install Rescuezilla</p> <p>Step 1. Go to the Rescuezilla download page, and download the \"<code>rescuezilla-2.3.1-64bit.impish.iso</code>\" file to disk.</p> <p>Step 2. Download and Install Balena Etcher, or a similar disk image recording tool.</p> <p>Step 3. Use Balena Etcher to record the \"<code>rescuezilla-2.3.1-64bit.impish.iso</code>\" to an external USB thumbstick or memory card.</p> <p>Disk to Disk Clone</p> <p>A 500gb NVME can be copied disk to disk in 5 minutes with Rescuezilla. This tool is a GUI and mouse driven version of the earlier text console based Clonezilla bootable disk management and backup utility.</p> <p>Boot windows once and then choose restart to switch over to rescuezilla. This removes the windows hibernation file.</p> <p>In gparted, if a small partition is spaced out at the far end of the disk you need to use the \"move partition\" function to bring the selected disk partition inwards, towards the left of the active disk partitions, to be able to fully shrink down a large ext4 or NTFS formatted NVME's storage space usage. This allows you to clone the data onto a smaller hard disk.</p> <p>You can't resize a partition larger if the \"free space\" zone is sandwiched on the opposite side of another partition block. In that case, you can slide/move the partition you don't need to make larger, out of the way, to the far right end of a disk.</p> <p>Rescuezilla Workflow Essentials</p> <ul> <li>Move the server to a workbench.</li> <li>Insert the Rescuezilla USB thumbdrive media.</li> <li>Turn on the render node.</li> <li>Press F11 to switch the OS selection over to boot Windows. Restart immediately to Linux Rescuezilla so there is no hibernation image</li> <li>Press F11 at boot to switch the boot OS to Rescuezilla.</li> <li>Select \"English\" language</li> <li>Select \"Graphical Fallback Mode\"</li> <li>Using gparted, move the blocking partitions out of the way, then resize the data partitions smaller to fit on a smaller drive.</li> <li>Rescuezilla - clone big disk to smaller disk</li> <li>Using gparted, expand the data partition on cloned drive</li> <li>Shutdown the render node and remove the large NVME, and the Rescuezilla USB thumbdrive media.</li> <li>Turn on the render node</li> <li>Press delete at BIOS and set the boot volume to the 500 GB NVME system.</li> <li>Wait 1 minute from power on for the 10G ethernet to power up and for the OS to finish booting.</li> <li>Restart Windows once to check everything is working as expected.</li> <li>Power off the server and insert the HDMI dummy video adapter dongle.</li> <li>Redeploy the server back to regular operations in the rack.</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Data%20Backup%20and%20Disaster%20Recovery%20Tools/#linux-bootrepair-utility","title":"Linux BootRepair Utility","text":"<p>Linux BootRepair Utility</p> <p>If you have issues after installing, upgrading, or cloning a BIOS or UEFI based Linux GRUB bootloader setup you might need to use the BootRepair utility to help fix broken Linux boot configurations. It is available in most Linux Software Manager utilities.</p> <p>Yes, it is also possible to carry out the same commands fully from a terminal session, but sometimes late in the night between midnight to 2 AM when GRUB most often fails on you, it might be nice to have a Live Image of a Linux distro on a USB thumbdrive along with a Boot-Repair GUI available to try and fix things.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Data%20Backup%20and%20Disaster%20Recovery%20Tools/#installing-the-canister-lto-backup-tool","title":"Installing the Canister LTO Backup Tool","text":"<p>Installing the Canister LTO Backup Tool</p> <p>Hedge Canister is a macOS based LTO tape backup program that makes creating long-term offline backups easy and reliable. It works with SAS + Thunderbolt connected tape drives on macOS Intel and ARM64 compatible systems.</p> <p>https://hedge.video/canister</p> <p></p> <p>This is what a typical LTO SAS tape drive looks like. This unit is an HP Enterprise Ultrium drive in an external enclosure. It has SAS connectors on the back that are used to connect to a file server.</p> <p></p> <p>When choosing hardware, it is handy to know that Apple macMini systems make a very affordable macOS based host for an LTO drive. You will want to add 10Gb Ethernet to the macMini via a Thunderbolt solution if the computer doesn't natively have 10Gb Ethernet onboard.</p> <p>If you need to connect a SAS based LTO tape drive to a macOS based host system you can use an OWC Mercury Helios 3 Thunderbolt 3 PCIe enclosure to host an ATTO SAS based PCIe card. It takes a bit of research to gather all the required cabling and SAS adapters if you haven't used gear with the SAS protocol before.</p> <p></p> <p>LTO Tapes have a long archival shelf-life if stored according to manufacturer's instructions in the proper environmental conditions. LTO tapes are typically ordered in box sizes of 5-tape cartridges at a time.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/","title":"Installing Digital Content Creation Apps","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>An effective content creation pipeline is able to support a wide range of tools to allow artists to work effectively. Below is an ever-expanding list of popular design tools with detailed installation, software configuration, and automation/scripting notes being added over time.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#install-blender-3-on-linux","title":"Install Blender 3 on Linux","text":"<p>Install Blender 3 on Linux</p> <p>Blender is a free open-source GPL licensed 3D package that features integrated modeling, texturing, animation, simulation, rendering, video editing, and compositing tools.</p> <p>http://blender.org/</p> <pre><code># Add Blender v3\nsudo dnf install blender -y\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#autodesk-maya-on-linux","title":"Autodesk Maya on Linux","text":"<p>Autodesk Maya on Linux</p> <p>Maya Installation</p> <p></p> <pre><code># GUI Install of Maya\n./Setup\n\n# CLI Maya Install\ncd Packages\nsudo rpm -ivh Maya2020*.rpm adlmapps*.rpm adsklicensing*.rpm adlmflex*.rpm\n\n# Force the install with -f\nsudo rpm -ivhf --force  *.rpm\n\n# Add the extra stuff\nsudo dnf install libpng15 compat-openssl10 -y\n\nsudo dnf install mesa-libGLw libXp gamin audiofile audiofile-devel compat-openssl10 libpng15 libnsl python2 xorg-x11-fonts-ISO8859-1-100dpi xorg-x11-fonts-ISO8859-1-75dpi -y\n\n# Run Maya\n/usr/autodesk/maya2022/bin/maya\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#common-maya-preferences","title":"Common Maya Preferences","text":"<p>Common Maya Preferences</p> <ul> <li>\u2022 Interface &gt; Devices &gt; Mouse scroll wheel &gt; [x] Enable</li> <li>Display &gt; Performance &gt; Max res. for swatches \"4k x 4k\"</li> <li>Display &gt; View &gt; (x) Background Gradient</li> <li>Settings &gt; Rendering &gt; Preferred Renderer &gt; V-Ray</li> <li>Settings &gt; Rendering &gt; Preferred Render Setup System &gt; Legacy Render Layers</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#mayaenv-file-settings","title":"Maya.env File Settings","text":"<p>Maya.env File Settings</p> <p>A Maya.env file is used to hold environment variable settings for a specific Maya release version.</p> <p>The initial Maya.env file can be created on Linux using:</p> <pre><code>sudo mkdir -p $HOME/maya/2023/\nsudo chmod -R 777 $HOME/maya/\nnano $HOME/maya/2023/Maya.env\n</code></pre> <p>When editing this file you can paste in:</p> <pre><code># Suppress Arnold not found error message:\nMAYA_NO_WARNING_FOR_MISSING_DEFAULT_RENDERER=1\n\n# Set the CIP disable flag:\nMAYA_DISABLE_CIP=1\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#running-maya-batch-from-the-linux-command-line","title":"Running Maya Batch from the Linux Command-Line","text":"<p>Running Maya Batch from the Linux Command-Line</p> <p>The batch version of Maya can be run on render node systems using:</p> <pre><code>maya -batch --help\n\nRender -help\nUsage: Render [options] filename\n       where \"filename\" is a Maya ASCII or a Maya binary file.\n\nCommon options:\n  -help              Print help\n  -test              Print Mel commands but do not execute them\n  -verb              Print Mel commands before they are executed\n  -keepMel           Keep the temporary Mel file\n  -listRenderers     List all available renderers\n  -renderer string   Use this specific renderer\n  -r string          Same as -renderer\n  -proj string       Use this Maya project to load the file\n  -log string        Save output into the given file\n  -rendersetuptemplate string Apply a render setup template to your scene before command line rendering.  Only templates exported via File &gt; Export All in the Render Setup editor are supported.  Render setting presets and AOVs are imported from the template.  Render settings and AOVs are reloaded after the template if the -rsp and -rsa flags are used in conjunction with this flag.\n  -rst string        Same as -rendersetuptemplate\n  -rendersettingspreset string Apply the scene Render Settings from this template file before command line rendering.  This is equivalent to performing File &gt; Import Scene Render Settings in the Render Setup editor, then batch rendering.\n  -rsp string        Same as -rendersettingspreset\n  -rendersettingsaov string Import the AOVs from this json file before command line rendering.\n  -rsa string        Same as -rendersettingsaov\n\nSpecify a valid -r option to get a more detailed help about a renderer.\nFor example: Render -help -r sw\n</code></pre> <p>To check the current Maya version you can run:</p> <pre><code>maya -batch -v\n# Maya 2020, Cut Number 202011110415\n</code></pre> <p>You can verify that Maya has been registered and activated by a network or log-in license using the following command-line licensing utility:</p> <pre><code>/opt/Autodesk/AdskLicensing/9.2.1.2399/helper/AdskLicensingInstHelper list\n</code></pre> <p>If successful, Maya should appear in the list of products returned by the Adsk Licensing Inst Helper utility. A sample output from running the executable looks like this:</p> <pre><code>[\n  {\n    \"feature_id\": \"MAYA\",\n    \"def_prod_key\": \"657L1\",\n    \"def_prod_ver\": \"2020.0.0.F\",\n    \"sel_prod_key\": \"657L1\",\n    \"sel_prod_ver\": \"2020.0.0.F\",\n    \"supported_lic_methods\": [\n      2,\n      1,\n      4\n    ],\n    \"lic_servers\": [\n      \"\"\n    ],\n    \"serial_number_sa\": \"...\",\n    \"serial_number_nw\": \"...\",\n    \"def_prod_code\": \"MAYA\",\n    \"sel_prod_code\": \"MAYA\"\n  }\n]\n</code></pre> <p>Manually creating a License.env file</p> <pre><code>sudo nano /usr/autodesk/maya2020/bin/License.env\n</code></pre> <p>Used a text editor to add your network licensing details to the License.env file</p> <pre><code>MAYA_LICENSE=657L1\nMAYA_LICENSE_METHOD=network\n</code></pre> <p>Manually creating a maya.lic license file</p> <pre><code>sudo nano /var/flexlm/maya.lic\n</code></pre> <p>Add your floating license server details to the maya.lic text file:</p> <pre><code>SERVER R1 0\n USE_SERVER\n</code></pre> <p>At this point you should add \"<code>/opt/Autodesk/Adlm/R17/lib64/</code>\" directory temporarily to the \"<code>LD_LIBRARY_PATH</code>\" environment variables to set your shared libraries for this session.</p> <p>For example, you can run the following command in a BASH shell:</p> <pre><code>export LD_LIBRARY_PATH=/opt/Autodesk/Adlm/R17/lib64/\n</code></pre> <p>It is a good idea to backup the old Maya licensing .pit file:</p> <pre><code>sudo mv /var/opt/Autodesk/Adlm/Maya2020/MayaConfig.pit /var/opt/Autodesk/Adlm/Maya2020/MayaConfig.pit.bak\nsudo rm -rf /var/opt/Autodesk/Adlm/Maya2020/MayaConfig.pit\n</code></pre> <p>Now you can run the following commands to register Maya with the Autodesk licensing app:</p> <p>In the following example the serial number is represented as <code>&lt;...&gt;</code> for a snipped out value to be replaced with your own code.</p> <p>An example Maya product key is 657L1 (which is used for Maya 2020).</p> <pre><code>{\ncd /usr/autodesk/maya2020/bin\n\n/usr/autodesk/maya2020/bin/adlmreg -i N 657L1 657L1 2020.0.0.F &lt;...&gt; /var/opt/Autodesk/Adlm/Maya2020/MayaConfig.pit\n}\n</code></pre> <p>When deploying a new Linux based render node, if a Maya network license was not listed by the Adsk Licensing Inst Helper utility, you can manually register a license using a command line syntax that looks roughly like this:</p> <pre><code>sudo /opt/Autodesk/AdskLicensing/9.2.1.2399/helper/AdskLicensingInstHelper register -pk 657L1 -pv 2020.0.0.F -el EN_US -cf /var/opt/Autodesk/Adlm/Maya2020/MayaConfig.pit\n</code></pre> <p>If the licensing service is not running, you can start it using the following command.</p> <p>Note: When running a program with a service based approach, the executable will continue to run in the session.</p> <pre><code>sudo /opt/Autodesk/AdskLicensing/9.2.1.2399/AdskLicensingService/AdskLicensingService --run\n</code></pre> <p>Verify the licensing service is running using:</p> <pre><code>sudo systemctl status adsklicensing\n\n# \u25cf adsklicensing.service - Autodesk Licensing Service\n#    Loaded: loaded (/usr/lib/systemd/system/adsklicensing.service; enabled; vendor preset: disabled)\n#    Active: active (running) since Fri 2021-04-23 14:40:20 ADT; 1min 5s ago\n#  Main PID: 26769 (AdskLicensingSe)\n#     Tasks: 33\n#    CGroup: /system.slice/adsklicensing.service\n#            \u2514\u250026769 /usr/bin/AdskLicensingService --run\n#  Apr 23 14:40:20 Moonraker systemd[1]: Started Autodesk Licensing Service.\n</code></pre> <p>You should verify again if the service is running. If it is still not running, set up the licensing service manually:</p> <pre><code>{\nsudo getent group adsklic &amp;&gt;/dev/null || sudo groupadd adsklic\nsudo id -u adsklic &amp;&gt;/dev/null || sudo useradd -M -r -g adsklic adsklic -d / -s /usr/sbin/nologin\nsudo ln -sf /opt/Autodesk/AdskLicensing/9.2.1.2399/AdskLicensingService/AdskLicensingService /usr/bin/AdskLicensingService\nsudo mkdir /usr/lib/systemd/system\nsudo cp -f /opt/Autodesk/AdskLicensing/9.2.1.2399/AdskLicensingService/adsklicensing.el7.service /usr/lib/systemd/system/adsklicensing.service\nsudo chmod 644 /usr/lib/systemd/system/adsklicensing.service\nsudo systemctl daemon-reload\nsudo systemctl enable adsklicensing\nsudo systemctl start adsklicensing\n}\n</code></pre> <p>Take a look at the Autodesk knowledge base for more information about installing configuring Maya on Linux:</p> <ul> <li>\\&lt;$ScrKeepWithNext&gt;Autodesk | Install Maya on Linux using the rpm package</li> <li>Autodesk | Additional information for Linux</li> <li>Autodesk | Additional required Linux libraries for Maya</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#andersson-technologies-syntheyes-pro","title":"Andersson Technologies SynthEyes Pro","text":"<p>Andersson Technologies SynthEyes Pro</p> <p>SynthEyes Pro is high-quality, feature rich, cross-platform compatible MatchMoving software for the film &amp; TV sector. It supports 360VR footage tracking, and stereo 3D camera rigs.</p> <p>https://www.ssontech.com</p> <p>For more information:</p> <ul> <li>YouTube | SynthEyes | Universal Scene Description (USD) Export, with Tricks</li> <li>YouTube | Using SynthEyes with Resolve</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#chaos-group-v-ray-renderer","title":"Chaos Group V-Ray Renderer","text":"<p>Chaos Group V-Ray Renderer</p> <p>Chaos Group makes a cross-platform compatible production renderer that runs efficiently on a CPU or a GPU.</p> <p>V-Ray's render engine has very strong indirect illumination lighting features that make rendering artifact-free interior scenes of architecture easier and faster than ever.</p> <p>https://www.chaos.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-benchmark","title":"V-Ray Benchmark","text":"<p>V-Ray Benchmark</p> <p>Installing V-Ray Benchmark on Linux</p> <pre><code># Add the extra libraries to support Electron GUI and GTK based apps\nsudo dnf install libpng15 compat-openssl10 -y\n\n# Fix a Vray Benchmark GUI error in the terminal window caused by a missing canberra GTK2 library module\nsudo dnf install libcanberra-gtk2 -y\n</code></pre> <p>V-Ray Benchmark Download</p> <p>Go to the Chaos Group \"Benchmark\" webpage to download the most recent version.</p> <p>https://www.chaos.com/vray/benchmark</p> <p>Copy the downloaded V-Ray benchmark app to the opt folder</p> <pre><code>sudo cp $HOME/Desktop/vray-benchmark-5.02.00 /opt/vray-benchmark-5.02.00\n</code></pre> <p>Run the benchmark utility</p> <pre><code>cd /opt/\n/opt/vray-benchmark-5.02.00\n</code></pre> <p>Render Node Benchmarks</p> <p>The reference system for Kartaverse v5 is an AMD TRX 40 based Threadripper 3990X based server that has high-performance CPU and GPU compute capabilities.</p> <p>V-Ray CPU Test</p> <p>68,232</p> <p>V-Ray CUDA Test</p> <p>7988</p> <p>V-Ray RTX Test</p> <p>11344</p> <p>It's worth mentioning that the V-Ray benchmark program is Multi-GPU and Multi-CPU aware which is excellent when fine-tuning a new workstation build.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#installing-v-ray-universal-render-node","title":"Installing V-Ray Universal Render Node","text":"<p>Installing V-Ray Universal Render Node</p> <p>Chaos Group sells monthly or annual V-Ray license subscriptions that provide access to a dedicated cross-platform \"Universal\" render node program.</p> <p>This executable supports the creation of render farms that can process content coming from a wide range of host DCC (digital-content creation) packages. All that is needed is for the DCC program to use a V-Ray plugin to export standalone .vrscene files.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-installer-xml-based-config-files","title":"V-Ray Installer XML-Based Config Files","text":"<p>V-Ray Installer XML-Based Config Files</p> <p>After you run the V-Ray installer program, you have the option of saving a config file to disk that holds all of your choices. This config file is exported using the XML file format.</p> <p>The config file is particularly helpful when carrying out numerous V-Ray Universal Render Node deployment tasks on a render farm since the installer program allows you to run the executable from a text-based SSH shell session:</p> <pre><code>sudo ./vray_adv_52003_maya2023_centos7 -configFile=\"/home/vfx/config_vray.xml\" -ignoreErrors=1\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-licensing-preference-file","title":"V-Ray Licensing Preference File","text":"<p>V-Ray Licensing Preference File</p> <p>When V-Ray is used with a network license checkout option, a file is created on-disk named:</p> <pre><code>$HOME/.ChaosGroup/vrlclient.xml\n</code></pre> <p>Since the \".ChaosGroup\" folder starts with a period character it is typically hidden on macOS and Linux filesystems by default.</p> <p>A vrlclient.xml file that does a network license checkout will typically look like this document:</p> <pre><code>&lt;VRLClient&gt;\n    &lt;LicServer&gt;\n        &lt;Host&gt;R1&lt;/Host&gt;\n        &lt;Port&gt;30304&lt;/Port&gt;\n        &lt;Host1&gt;&lt;/Host1&gt;\n        &lt;Port1&gt;30304&lt;/Port1&gt;\n        &lt;Host2&gt;&lt;/Host2&gt;\n        &lt;Port2&gt;30304&lt;/Port2&gt;\n        &lt;User&gt;&lt;/User&gt;\n        &lt;Pass&gt;&lt;/Pass&gt;\n    &lt;/LicServer&gt;\n&lt;/VRLClient&gt;\n</code></pre> <p>The Host field can hold either a hostname or IP address. This value can be customized visually by the V-Ray installer program to point to your LAN's V-Ray license server system.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-environment-variables","title":"V-Ray Environment Variables","text":"<p>V-Ray Environment Variables</p> <p>Linux Standalone</p> <pre><code>export VRAY_FOR_MAYA2023_MAIN=/usr/autodesk/maya2023/vray\nexport VRAY_FOR_MAYA2023_PLUGINS=/usr/autodesk/maya2023/vray/vrayplugins\nexport VRAY_OSL_PATH_MAYA2023=/usr/autodesk/Maya2023/opensl\nexport VRAY_PATH=/usr/autodesk/maya2023/vray/bin\nexport VRAY_SEND_FEEDBACK=1\nexport VRAY_TOOLS_MAYA2023=/usr/autodesk/Maya2023/bin\n</code></pre> <p>Windows Standalone</p> <pre><code>VRAY_FOR_MAYA2023_MAIN=C:\\Program Files\\Chaos Group\\V-Ray\\Standalone for x64\\vray\nVRAY_FOR_MAYA2023_PLUGINS=C:\\Program Files\\Chaos Group\\V-Ray\\Standalone for x64\\vray\\vrayplugins\nVRAY_OSL_PATH_MAYA2023=C:\\Program Files\\Chaos Group\\V-Ray\\Maya 2023 for x64/opensl\nVRAY_SEND_FEEDBACK=1\nVRAY_TOOLS_MAYA2023=C:\\Program Files\\Chaos Group\\V-Ray\\Maya 2023 for x64/bin\n</code></pre> <p>macOS Standalone</p> <pre><code>VRAY_FOR_MAYA2023_MAIN=/Applications/Autodesk/maya2023/vray\nVRAY_FOR_MAYA2023_PLUGINS=/Applications/ChaosGroup/V-Ray/Maya2023/VRay.app/Contents/MacOS/plugins\nVRAY_OSL_PATH_MAYA2023=/Applications/ChaosGroup/V-Ray/Maya2023/opensl\nVRAY_PATH=/Applications/Autodesk/maya2023/vray/bin\nVRAY_SEND_FEEDBACK=0\nVRAY_TOOLS_MAYA2023=/Applications/ChaosGroup/V-Ray/Maya2023/bin\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#manually-starting-v-ray-server","title":"Manually Starting V-Ray Server","text":"<p>Manually Starting V-Ray Server</p> <p>If you need direct control over a V-Ray DR process you can manually start the vrayserver executable from a command-prompt/terminal session.</p> <p>Here is a Linux based example:</p> <pre><code>sudo /usr/ChaosGroup/V-Ray/Maya2023-x64/bin/vrayserver\n</code></pre> <p>Here is a Windows based example:</p> <pre><code>cd /usr/ChaosGroup/V-Ray/Maya2023-x64/bin\nsudo ./registerVRayServerDaemon\nsudo ./startVRayServerDaemon\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-dr-check","title":"V-Ray DR Check","text":"<p>V-Ray DR Check</p> <p>The V-Ray DR Check utility is available on all supported host operating systems. The tool lets you see the specifics for a running V-Ray Universal Render Node session. You need to specify the exact hostname or IP address for a render node system along with a port number. The default V-Ray DR port number is 20207.</p> <pre><code>/usr/ChaosGroup/V-Ray/Maya2023-x64/bin/vraydr_check -host=10.20.30.2 -port=20207\n</code></pre> <p>On macOS and Linux systems it is possible to check if multiple concurrent V-Ray rendering processes are active, or stalled, on a render node using the terminal-based ps utility with the output piped into grep:</p> <pre><code>echo \"[List V-Ray Processes]\"\nps -edf | grep \"vray\\.bin\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-distributed-rendering","title":"V-Ray Distributed Rendering","text":"<p>V-Ray Distributed Rendering</p> <p>When project deadlines are fast approaching, having a render farm with the V-Ray Universal Render Node program installed on multiple nodes is an excellent resource to use for V-Ray DR (Distributed Rendering). This V-Ray DR technique will dramatically accelerate the final-frame and interactive rendering performance of an artist's interactive GUI session.</p> <p>With DR active in your V-Ray render sessions, artists have the option to access multiple render nodes concurrently, and will be able to use that hardware to perform faster interactive lighting and \"look development\" in programs that have a full-featured V-Ray integration plugin like Maya, Houdini, and 3DS Max.</p> <p>This V-Ray distributed rendering approach is discussed in the following article:</p> <p>Master V-Ray Next for Maya with this 4-part practical guide</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#v-ray-scene-render-for-fusion-fuse","title":"V-Ray Scene Render for Fusion Fuse","text":"<p>V-Ray Scene Render for Fusion Fuse</p> <p>WSL [BETA] kvrVraySceneRender Fuse Thread Post</p> <p>Render V-Ray based .vrscene file assets interactively from the V-Ray VFB window, from within the comfort of a Resolve/Fusion GUI or Fusion Render Node session, via V-Ray Universal Render Node command-line interface bindings.</p> <p></p> <p>GUI Controls</p> <p></p> <p>The VRScene Filename control supports the use of PathMaps and %04d style frame padding characters.</p> <p>The EXR Filename control supports the use of PathMaps and %04d style frame padding characters.</p> <p>The \"Static Frame\" control allows you to load either a (static) single image, or an image sequence.</p> <p>The \"Interactive\" control allows you to have the rendering launched during a Fusion Studio GUI artist session. When this control is unchecked, renderings are only carried out during batch renders.</p> <p>The \"Skip Rendering if image exists\" checkbox allows you to make sure you aren't re-rendering the same frame again. This control will look for the expected image name on-disk and only launch a rendering of a new image if no image file is found.</p> <p>Workflow Notes</p> <p>This fuse works with Cryptomatte since a \"Metadata.Filename\" record is added automatically to the image output stream that is generated by the V-Ray Batch Render fuse. This metadata information allows Cryptomatte masking operations to work in Fusion if the VRScene file being rendered has the Cryptomatte render element enabled.</p> <p>Dev Todo Sooner List</p> <ul> <li>Error handling - missing V-Ray host program error is mis-identified as a missing scene</li> <li>Drag and drop import .vrscene file into Fusion comp view</li> <li>Parse the vrscene file on drag/drop import to look for scene filename token</li> <li>\"Open VRScene in Script Editor\" Button - Open the file with the Script editor defined in the Fusion preferences</li> <li>V-Ray Bin hosts on macOS/Win/Linux selector</li> </ul> <p>Dev Todo Later List</p> <ul> <li>Customize EXR Filename</li> <li>Render Element Override controls</li> <li>Figure out multi-rendering of same frame issue</li> <li>Check-point auto-save image every N minutes</li> <li>Get EXR image name from popen() result</li> <li>Batch vs interactive rendering</li> <li>VFB project workspace - save history tab path</li> <li>Cryptomatte depth is not 32-bit - look at V-Ray frame buffer settings in Maya</li> <li>EffectsMask input on VrayBatchRender sets bucket priority masking</li> </ul> <p>Image Saved File Info</p> <pre><code>[2021/Jul/8|06:41:39] [2117 MB] Successfully written image file \"/Volumes/Projects/Yeti_Vray_Project/images/tmp/blue_fur.exr\"\n</code></pre> <p>When drag/drop importing a vrsene file grab the name from the fields:</p> <pre><code>img_file=\"sphere.exr\";\nimg_dir=\"/Users/vfx/Documents/maya/projects/default/images/tmp/\";\n</code></pre> <p>A sample .vrscene code block:</p> <pre><code>SettingsOutput vraySettingsOutput {\n  img_width=1920;\n  img_height=1080;\n  img_pixelAspect=1;\n  img_file=\"sphere.exr\";\n  img_dir=\"/Users/vfx/Documents/maya/projects/default/images/tmp/\";\n  img_file_needFrameNumber=0;\n  img_separateAlpha=0;\n  img_noAlpha=0;\n  img_dontSaveRgbChannel=0;\n  img_deepFile=0;\n  img_rawFile=0;\n  img_rawFileVFB=1;\n  img_rawFileSaveColorCorrections=0;\n  img_clearMode=0;\n  anim_start=1;\n  anim_end=1;\n  anim_frame_padding=4;\n  anim_renumber_on=0;\n  anim_renumber_start=0;\n  anim_renumber_step=1;\n  anim_ren_frame_start=0;\n  frame_start=1;\n  frames_per_second=1;\n  frames=ListInt(    1);\n  rgn_left=0;\n  rgn_width=1920;\n  rgn_top=0;\n  rgn_height=1080;\n  bmp_width=1920;\n  bmp_height=1080;\n  r_left=0;\n  r_width=1920;\n  r_top=0;\n  r_height=1080;\n  relements_separateFolders=0;\n  relements_separate_rgba=0;\n  relements_divider=\".\";\n  film_offset_x=0;\n  film_offset_y=-0;\n }\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#pixar-renderman","title":"Pixar RenderMan","text":"<p>Pixar RenderMan</p> <p>Pixar's RenderMan is the original production renderer used in the film industry for feature animation and visual effects. The native RenderMan scene description format is called a RenderMan Interface Bytestream (.rib) file.</p> <p>https://renderman.pixar.com/</p> <p>RenderMan Resources</p> <ul> <li>Download RenderMan Non-Commercial Edition (free)</li> <li>Learn RenderMan (free)</li> <li>Art of RenderMan Volume 1 Training Video (free)</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#renderman-for-fusion-tf31-plugin","title":"RenderMan for Fusion (TF31 Plugin)","text":"<p>RenderMan for Fusion (TF31 Plugin)</p> <p>Marcel Gandriau (Tolosa Films) has a new RenderMan v24 for Fusion plugin that is under development for Resolve Studio and Fusion Studio. The plugin is able to work with RenderMan's paid and NC (Non-Commercial) editions.</p> <p>This image shows the Eisko Louise character asset from the RenderMan learning page being used with the TF31 RenderMan for Fusion plugin:</p> <p></p> <p>This image shows a plush dragon model with alembic hair curves. The asset is from the RenderMan learning page and it is shown in a Fusion composite that uses the TF31 RenderMan for Fusion plugin:</p> <p></p> <p>This image shows the Cookies and Milk assets from the RenderMan learning page in a Fusion composite that uses the TF31 RenderMan for Fusion plugin:</p> <p></p> <p>The TF31 integration plugin provides Fusion-based artists with access to Pixar's RenderMan software which is a high-quality film-level production renderer that can be used to raytrace a detailed 2D scene with reflections, refractions, subsurface shading, advanced lighting including light-filters, and render-time procedural features like Xgen Hair.</p> <p>This makes it possible to use Fusion's 3D workspace and node-graph to author native RenderMan .rib formatted scene description files. This RIB formatted content is exported to disk by a Renderer3D node, and rendered using RenderMan Pro Server.</p> <p>There is a handy \"RigExtractor\" command-line utility included with the TF31 plugin. It is used to translate RenderMan for Maya, and RenderMan for Blender exported .rib files into Fusion node-graph based comps with underlays:</p> <pre><code>RibExtractor &lt;YourRenderManScene.rib&gt; &lt;directory&gt;\n</code></pre> <p>An early-access version of the TF31 plugin runs today with Fusion Studio v18 on macOS (Intel x64) and Windows 10/11 systems. It is available in limited release as a beta version hosted on the Steakunderwater forum's FusionSDK zone (A WSL forum login with FusionSDK access permissions added is required to view this link).</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#renderman-nc-non-commercial-installer-download","title":"RenderMan NC (Non-Commercial) Installer Download","text":"<p>RenderMan NC (Non-Commercial) Installer Download</p> <p>The Pixar RenderMan learning website provides access to a downloadable copy of RenderMan v24 NC (Non-Commercial).</p> <p>Click the \"Free to Try\" button to register for a free RenderMan account that allows you to download the RenderMan DCC plugin, RenderMan Pro Server, and LocalQueue.</p> <p></p> <p>The current (as of 2022-11-25) RenderMan NC v24.4 release for macOS has the filename of:</p> <pre><code>RenderMan-InstallerNCR-24.4.0_2226589-osxMojave_clang10.x86_64.dmg\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#fixing-a-prman-installer-disk-permissions-issue","title":"Fixing a PRMan Installer Disk Permissions Issue","text":"<p>Fixing a PRMan Installer Disk Permissions Issue</p> <p>In order for the macOS based RenderMan NC installer to be able to write the files to disk it is a good idea to add the \"RenderMan Installer.app\" file to the \"System Preferences &gt; Security &amp; Privacy &gt; Privacy &gt; Full Disk Access\" section. Make sure to enable the checkbox by that entry's name in the dialog.</p> <p>Additionally, you can temporarily change the folder permissions on the Pixar folder to make installing files easier:</p> <pre><code>sudo chmod -R 777 /Applications/Pixar/\n</code></pre> <p>Once these changes have been made you can run the \"RenderMan Installer.app\" program and the RPS (RenderMan Pro Server) and RFM (RenderMan for Maya) installs will complete successfully.</p> <p></p> <p>If you don't make the macOS disk permission changes, the first time the RenderMan installer is run it will generate and save the \"pixar.license\" license file to disk. Unfortunately the RenderMan installer will then report a disk permission write access issue on macOS Monterey which causes the installer to fail at the stage of creating the \"RenderManProServer-24.4\" and \"RenderManForMaya-24.4\" sub-folders in the Pixar directory. This error stage cancels the reset of the install process.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#configuring-renderman-environment-variables","title":"Configuring RenderMan Environment Variables","text":"<p>Configuring RenderMan Environment Variables</p> <p>If you want to use the RenderMan for Fusion (TF31) plugin, or RenderMan Pro Server, it helps to add several environment variables to your system.</p> <p>macOS Environment Variables</p> <p>Since macOS Monterey uses ZSH for the default terminal, I created a \"$HOME/.zshenv\" file and added the following content to the text file:</p> <pre><code>export RMSTREE=/Applications/Pixar/RenderManForMaya-24.4\nexport RMANTREE=/Applications/Pixar/RenderManProServer-24.4\nexport RFMTREE=/Applications/Pixar/RenderManForMaya-24.4\nexport RFM_VERSION=24.4\nexport RFM_MAYA_VERSION=2023\nexport PIXAR_LICENSE_FILE=/Applications/Pixar/pixar.license\n</code></pre> <p>Windows Environment Variables</p> <p>On Windows 10/11 you can use the System Control Panel to add the following environment variable entries. Some of these entries will be automatically added for you by the RenderMan installer.</p> <pre><code>RMANTREE=C:\\Program Files\\Pixar\\RenderManProServer-24.4\\\nRFMTREE=C:\\Program Files\\Pixar\\RenderManForMaya-24.4\\\nRFM_VERSION=24.4\nRFM_MAYA_VERSION=2023\nPIXAR_LICENSE_FILE=C:\\Program Files\\Pixar\\pixar.license\nPATH=C:\\Program Files\\Pixar\\RenderManProServer-24.4\\bin;C:\\Program Files\\Pixar\\RenderManProServer-24.4\\lib\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#using-the-renderman-for-fusion-tf31-plugin","title":"Using the RenderMan for Fusion (TF31) Plugin","text":"<p>Using the RenderMan for Fusion (TF31) Plugin</p> <p>Install The TF31 Plugin</p> <p>Copy the TF31 plugin files into one of the Fusion \"Plugins:/\" PathMap supported folder locations on-disk.</p> <p>On Windows you need to add the following RenderMan Pro Server library files to the Plugins folder:</p> <ul> <li>libprman.dll (from Pixar/RenderManProServer-xx.x/lib/)</li> <li>libpxrcore.dll (from Pixar/RenderManProServer-xx.x/bin/)</li> <li>libstats.dll (from Pixar/RenderManProServer-xx.x/bin/)</li> </ul> <p>The TF31 plugin bundled files include:</p> <ul> <li>RibRendererMac.plugin or RibRendererWin.plugin</li> <li>aovs.json</li> <li>tf31.tif</li> </ul> <p>The \"tf31.tif\" image is the default placeholder texture map that is applied to 3D models when they are viewed in the Fusion 3D workspace's viewer window context. The image shows a RenderMan \"R\" shaped logo:</p> <p></p> <p>Launch Fusion Studio</p> <p>On macOS, if you defined your RenderMan environment variables using a $HOME/.zshenv file you can start Fusion Studio v18 from a terminal session using:</p> <pre><code>\"/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/Fusion\" -verbose -clean -log \"$HOME/Desktop/Fusion_log.txt\"\n</code></pre> <p>On Windows, you can start Fusion Studio v18 from a command-prompt session using:</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\Fusion 18\\Fusion.exe\" /verbose /clean /log \"%USERPROFILE%\\Desktop\\Fusion_log.txt\"\n</code></pre> <p>Launching Fusion Studio from a terminal/command-prompt window is useful for troubleshooting purposes as it lists detailed diagnostic logging information, and saves error messages to a log file on-disk as well, if there are any issues.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#check-the-tf31-plugin-version","title":"Check the TF31 Plugin Version","text":"<p>Check the TF31 Plugin Version</p> <p>If you want to see what version of the TF31 plugin you have installed, select the \"Fusion Studio &gt; About Fusion Studio\" menu entry. This will open the \"About Fusion Window\".</p> <p>Then click on one of the TF31 plugin's nodes, in the list on the lower left part of the window, to see the exact build date.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#the-tools-menu","title":"The Tools Menu","text":"<p>The Tools Menu</p> <p>The RenderMan for Fusion nodes are accessible in Fusion Studio using the \"Tools &gt; TF31 &gt; pxr &gt;\" menus.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#fusion-preferences","title":"Fusion Preferences","text":"<p>Fusion Preferences</p> <p>The plugin has its own Fusion preference page found at:</p> <p>Global and Default Settings &gt; Rib</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#creating-renderman-node-graphs-in-fusion","title":"Creating RenderMan Node Graphs in Fusion","text":"<p>Creating RenderMan Node Graphs in Fusion</p> <p></p> <p>If you are building a new RenderMan scene in Fusion, the typical node-connections used with the TF31 plugin are:</p> <pre><code>TF31PxrSurface -&gt; TF31PxrSG\nTF31PxrSG -&gt; Shape3D\nShape3D -&gt; Merge3D\nTF31PxrCamera -&gt; Merge3D\nTF31PxrRectLight -&gt; Merge3D\nMerge3D -&gt; Renderer3D\n</code></pre> <p>The \"TF31PxrSurface\" node is the Pixar surface material node.</p> <p>The \"TF31PxrSG\" node represents a typical Autodesk Maya style shading group.</p> <p>The \"TF31PxrCamera\" node is used to add a Pixar camera to the scene.</p> <p>The \"TF31PxrRectLight\" node is a rectangular area light.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#renderer3d-node","title":"Renderer3D Node","text":"<p>Renderer3D Node</p> <p>The \"Renderer3D\" node is used to define the render-time output settings for a Fusion 3D scene graph.</p> <p>When creating a new Fusion 3D comp, you need to change the Renderer3D node's \"Render Type\" setting from outputting the scene using a typical OpenGL or software rendering setting over to using the \"Rib Renderer''. This allows a RenderMan .rib file to be generated.</p> <p></p> <p>The Renderer3D node has a \"Preview\" button that can be used to export a .rib file that holds the 3D scene graph information. When the Preview button is pressed an additional RenderMan Tractor Render Manager/LocalQueue based \"Alfred\" .alf job description file is created at the same time.</p> <p>This \"Alfred\" .alf file streamlines the process of using RenderMan Pro Server to create renderings in the background without blocking a Fusion Studio GUI based artist session.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#tf31pxralembic-node","title":"TF31PxrAlembic Node","text":"<p>TF31PxrAlembic Node</p> <p>It is possible to bypass Fusion's AlembicMesh3D node and import Alembic data natively using a \"TF31PxrAlembic\" node. This native mesh loading node allows attributes like subdivision surface creases to be retained.</p> <p>Surface Material Previews</p> <p>Note: When RenderMan surface materials are displayed in the real-time Fusion 3D viewer window contexts you will see a place-holder texture map on the 3D models that features a repeating pattern of a small RenderMan \"R\" shaped logo on all of the surfaces.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#rendering-exported-rib-files-using-renderman-pro-server","title":"Rendering Exported RIB Files Using RenderMan Pro Server","text":"<p>Rendering Exported RIB Files Using RenderMan Pro Server</p> <p>After you export a .rib file to disk, you are able to render it directly from a terminal window on a macOS system using a shell command like:</p> <pre><code>/Applications/Pixar/RenderManProServer-24.4/bin/prman \"$HOME/Documents/Blackmagic Design/Fusion/test/ribs/test_000.rib\"\n</code></pre> <p>The rib file will typically render an OpenEXR formatted image to disk with the .openexr file extension. You can view the image in the \"IT.app\" utility.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#renderman-lacks-arm64-native-support","title":"RenderMan Lacks ARM64 Native Support","text":"<p>RenderMan Lacks ARM64 Native Support</p> <p>Note: At the current moment you cannot use the TF31 plugin on a macOS system with an Apple ARM64 architecture based CPU. You need to run the TF31 plugin on a native Intel x64 based macOS system or a Hackintosh.</p> <p>This is due to the Pixar RenderMan SDK's lack of ARM64 compatible include/header/libraries in the currently shipping version of RenderMan Pro Server. Hopefully this ARM64 support issue will be fixed when Autodesk Maya ships with ARM64 native support, and the RenderMan for Maya plugin also ships with ARM64 support as well.</p> <p>In the meantime you will see this error message on a macOS ARM64 system if you run the TF31 plugin inside of Fusion Studio.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#what-the-heck-is-a-fusion-plugins-blocklist-file","title":"What the heck is a Fusion Plugins Blocklist File?","text":"<p>What the heck is a Fusion Plugins Blocklist File?</p> <p>If you have a Fusion 3<sup>rd</sup> party plugin loading issue during Fusion Studio's startup process you will typically see an error message that starts with the words \"Unable to load plugin\".</p> <p></p> <p>After the plugin fails to load an entry is added automatically to the file:</p> <pre><code>%appdata%\\Blackmagic Design\\Fusion\\Profiles\\Default\\Plugins17.blocklist\n</code></pre> <p>This blocklist file is used to stop recurring Fusion Studio startup error messages from being displayed in the future.</p> <p>The blocklist file contents will typically look like this:</p> <pre><code>{\n    { \"C:/ProgramData/Blackmagic Design/Fusion/Reactor/Deploy/Plugins/RibRenderer.plugin\", 1666459470000 }\n}\n</code></pre> <p>After you correct the issue that caused the 3<sup>rd</sup> party plugin's error state to occur, you can remove the entry that was added in the Plugins17.blocklist file. This allows the plugin to be used in the future.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ftrack-ftrack-connect-deployment","title":"ftrack / ftrack Connect Deployment","text":"<p>ftrack / ftrack Connect Deployment</p> <p>https://www.ftrack.com/en/connect</p> <p>ftrack Studio is a shot management, production tracking, and media review platform. ftrack Connect integrates the toolset with your creative apps. It allows you to optimize your pipeline, publish assets, launch tools, run integrations, and streamline daily workflows with custom processes unique to your studio.</p> <p>This process allows the assignment of tasks to individual staff on a project, and streamlines version control which tracks revisions on individual shots, along with managing the media created.</p> <p>The \"ftrack connect\" software is used to help interconnect the core ftrack program with the rest of your production pipeline.</p> <ul> <li>ftrack Connect Product Page</li> <li>ftrack Connect Docs</li> <li>ftrack Developer Hub</li> <li>ftrack Integrations</li> <li>ftrack Python API</li> <li>ftrack Help | Getting Started With the API</li> <li>ftrack Help | Developing with ftrack</li> <li>ftrack Help | Query Syntax</li> <li>ftrack Help | Publishing</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ftrack-fusion-a-resolvefusion-integration-for-ftrack-connect","title":"ftrack-fusion | A Resolve/Fusion Integration for ftrack Connect","text":"<p>ftrack-fusion | A Resolve/Fusion Integration for ftrack Connect</p> <p>Development on a new community created ftrack integration for BMD Fusion Studio and Resolve Studio is underway. Please bookmark the following webpages to stay up-to-date on progress information:</p> <p>https://gitlab.com/AndrewHazelden/ftrack-fusion</p> <p>For more information:</p> <ul> <li>WSL | [DEV] ftrack-fusion | A Resolve/Fusion Integration for ftrack Connect</li> <li>GitHub | Movalex ftrack Saver Node Python Script</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#revision-effects","title":"Re:Vision Effects","text":"<p>Re:Vision Effects</p> <p>Re:Vision Effects creates a wide range of VFX plugins that help with tasks like image uprezzing, lens distortion correction, motion vector warping, multi-view stereo color matching, and ST Map based warping. The plugins work with just about every single editing and compositing package out there, including Resolve/Fusion.</p> <p>https://revisionfx.com/</p> <p>The Re:Vision Effects company is a USA based collaborator that is working with the Left Angle Autograph software's development team to help re-design and re-imagine what is possible in artist-friendly next-generation motion graphics and compositing workflows. The future is literally being made right now. \ud83d\ude80</p> <p>https://www.left-angle.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#cinesyncplay-deployment","title":"CineSyncPlay Deployment","text":"<p>CineSyncPlay Deployment</p> <p>Ftrack has a new CineSyncPlay program that makes image sequence, movie, and 360VR media playback fast and easy. It is cross-platform compatible and runs on Windows, Linux, and macOS.</p> <p>CineSyncPlay supports command line flags which allows it to be added to the Amazon AWS Thinkbox \"Deadline\" render manager's Monitor program as the default media viewer. Double-clicking on a completed job task in the Deadline Monitor window will then display the final rendered footage instantly for review and playback. This works really smoothly in an immersive pipeline.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#backlight-ikonic-deployment","title":"Backlight Ikonic Deployment","text":"<p>Backlight Ikonic Deployment</p> <p>Ikonic is a cloud based media management solution. Ikonic is released by the same parent company that creates the ftrack software.</p> <p>https://www.iconik.io</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#jupyter-notebook-deployment","title":"Jupyter Notebook Deployment","text":"<p>Jupyter Notebook Deployment</p> <p></p> <p>Jupyter is used for interactive scripting with programming languages like Python. It is popular with machine learning, data science, and computer vision researchers.</p> <p>More information about how to use Jupyter Notebook with Resolve/Fusion can be read here:</p> <p>Kartaverse Workflows | Jupyter Notebook for Resolve/Fusion</p> <p>https://docs.google.com/document/d/1Jza91fL7csYVOSgYCMsa17r3DMmaJdwXevieTh-tqWg/edit</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#sidefx-houdini-195-install-for-windows","title":"SideFX Houdini 19.5 Install for Windows","text":"<p>SideFX Houdini 19.5 Install for Windows</p> <p>Change Windows Env vars for HFS</p> <p>- Name = <code>HFS:</code></p> <p>- Value = <code>C:\\Program Files\\Side Effects Software\\Houdini 19.5.357</code></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#install-options","title":"Install Options","text":"<p>Install Options</p> <pre><code>    - Houdini\n        Main Application\n        File Associations\n        Industry File Types\n        SideFX Labs\n        Desktop icon\n        HQueue Client\n        - C:\\HQueueClient\n        - Host = 10.20.30.1\n        - Port = 5000\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#houdini-hkey","title":"Houdini HKey","text":"<p>Houdini HKey</p> <pre><code>Licensing Program\n\n    C:\\Program Files\\Side Effects Software\\Houdini 19.5.357\\bin\\hkey.exe\n\nLicensing Settings\n    - \"File &gt; Change License Server\" Menu\n    - Add Custom Server if required, or use web based licensing for Houdini Indie.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#houdini-195-install-for-linux","title":"Houdini 19.5 Install for Linux","text":"<p>Houdini 19.5 Install for Linux</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#linux-dependencies","title":"Linux Dependencies","text":"<p>Linux Dependencies</p> <p>Required for libXss.so.1</p> <pre><code>    sudo dnf install -y libXScrnSaver\n</code></pre> <p>Required for ibnsl.so.1</p> <pre><code>    sudo dnf install -y libnsl\n</code></pre> <p>Note: Houdini 19.5 will not run on a Linux distro that has glibc 2.34 installed. This includes new Ubuntu Linux releases shipped after Jan 2021.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#license-houdini-on-linux","title":"License Houdini on Linux","text":"<p>License Houdini on Linux</p> <p>If you need to license Houdini on on a computer without a monitor connected (aka a headless Linux compute node), the licensing stage can be done by creating a text file on-disk at:</p> <pre><code>$HOME/.sesi_licenses.pref\n</code></pre> <p>The text file contents should list the hostname that is acting as a Houdini floating license server:</p> <pre><code>serverhost=10.20.30.1\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#linux-network-shares","title":"Linux Network shares","text":"<p>Linux Network shares</p> <p>You can connect a Houdini based Linux render node to an NFS based shared file server drive mount using BASH shell commands like:</p> <pre><code>    sudo mkdir -p  /Volumes/Farm\n    sudo chmod -R 777 /Volumes/Farm\n\n    sudo nano /etc/fstab\n\n    R1:/Volumes/Farm /Volumes/Farm   nfs      auto,rw,async,noatime,nolock,bg,nfsvers=3,intr,tcp,actimeo=1800 0 0\n\n    sudo mount -a\n    df -h\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#install-houdini-hqueue-on-linux","title":"Install Houdini + HQueue on Linux","text":"<p>Install Houdini + HQueue on Linux</p> <p>It is possible to install Houdini from a terminal window or via a remote SSH session using the following BASH shell commands:</p> <pre><code>cd $HOME/Downloads/Houdini/houdini-19.5.303-linux_x86_64_gcc9.3\n\n#  To fix an error \"python3.9.tar.gz: Cannot open: Permission denied\"\nsudo chmod -R 777 .\n\nsudo ./houdini.install\n\nWhere do you want to install the HQueue Server? [/opt/hqueue] ==&gt; \n/opt/hqueue\n\n# Set the user account as \"vfx\" not \"hqueue\" in the installer dialog:\nWhere do you want to install the HQueue Client? [/home/hquser/hqclient] ==&gt; \n/home/vfx/hqclient\n\ncd /opt/hfs19.5\n./houdini_setup_bash\n\nsudo chmod -R 777 /opt/hfs19.5\n\nnano $HOME/.bash_profile\n\n# User specific environment and startup programs\ncd /opt/hfs19.5\nsource /opt/hfs19.5/houdini_setup\ncd $HOME\n\n# Create the dummy HQ Shared root folder\nsudo mkdir -p /mnt/hq/\n\n# Start hqueue server\ncd /opt/hqueue/scripts\nsudo chmod -R 777 /opt/hqueue/\n./hqserverd start\n\n# Start hqueue client\ncd $HOME/hqclient\n./hqclientd start\n./hqclientd restart\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#uninstall-houdini-on-linux","title":"Uninstall Houdini on Linux","text":"<p>Uninstall Houdini on Linux</p> <pre><code>cd /opt/hfs19.5\nsudo ./houdini.uninstall\nsudo rm -rf /opt/sidefx_packages/\n\n# Remove HQServer\nsudo rm -rf /opt/hqueue/\n\n# Remove HQclient in the hquser folder\nssh hquser:hqpass@localhost\nor\nsu - hquser\n# enter password \"hqpass\"\n\nrm -rf /home/hquser/hqclient\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#houdini-viewport-customizations","title":"Houdini Viewport Customizations","text":"<p>Houdini Viewport Customizations</p> <pre><code>d hotkey = display options\nBackground = Dark (Applied to both the Obj and Stage contexts)\nDefault desktop: Technical\nGlobal UI scale: 1.25\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#hq-scheduler-notes","title":"HQ Scheduler Notes","text":"<p>HQ Scheduler Notes</p> <pre><code>Linux based Houdini TOPs - hqueuescheduler:  \nHFS &gt; Python Executable: $HFS/bin/hython\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#houdini-environment-variables","title":"Houdini Environment Variables","text":"<p>Houdini Environment Variables</p> <p>If you need to keep a Houdini project file organized and make sure the asset filepaths are up-to-date, you can use the following tokens as placeholders in filename fields. The tokens will be evaluated automatically when the node graph is cooked at render time:</p> <pre><code>$F4 = 4 digits of frame padding on the current frame number\n$HQHOSTS = The name of the current render node that is processing this frame chunk\n$HFS = The path to the Houdini program files folder where the houdini setup shell script is stored inside of\n$HIP = The path to the folder where the current Houdini .hip file is stored\n$HIPNAME = The name of the current Houdini .hip file\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#sidefx-hqueue-render-manager","title":"SideFX HQueue Render Manager","text":"<p>SideFX HQueue Render Manager</p> <p>HQueue is a cross-platform compatible network render manager program with a Web-based user interface that comes from SideFX software. It is a license-free toolset that can be installed on an unlimited number of render nodes without requiring a Houdini license.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#step-1","title":"Step 1.","text":"<p>Step 1.</p> <p>Modify the HQROOT entries from your HQServer \"network_folders.ini\" file's settings to a local dummy folder like:</p> <pre><code>HQROOT\nC:\\HQShared\n</code></pre> <p>Also create a Windows based system environment variable for:</p> <pre><code>HQROOT = C:\\HQShared\n</code></pre> <p>Edit the \"<code>C:\\HQClient\\hqnode.ini</code>\" file so the server is set to:</p> <pre><code>[main]\nserver = 10.20.30.4\nport = 5000\n\n[job_environment]\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#step-2","title":"Step 2.","text":"<p>Step 2.</p> <p>In TOPs, clear out the pre-existing \"PDG Path Map\" fields.</p> <p>Set the \"topnet1\" node to use a \"Default Scheduler\" entry like:</p> <pre><code>localscheduler (local only jobs)\n</code></pre> <p>or</p> <pre><code>hqueuescheduler1 (network jobs)\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#step-3","title":"Step 3.","text":"<p>Step 3.</p> <p>Inside the current task area set the \"hqueuescheduler\" node to use:</p> <pre><code>HQueue Server:\nhttp://localhost:5000\nor\nhttp://10.20.30.4:5000\n\nHFS:\n    [ ] Universal HFS (Clear out)\n    Linux HFS Path: (Clear out)\n    macOS HFS Path: (Clear out)\n    Windows HFS Path: $HFS\n</code></pre> <p>Paths:</p> <p>Load Item Data From: Temporary JSON File</p> <p>Uncheck \"[ ] Compress work item data\".</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#step-4","title":"Step 4.","text":"<p>Step 4.</p> <p>Press the \"U\" key in the nodes view area to navigate back to the top-level tasks view.</p> <p>Select \"topnet1\" in the nodes view.</p> <p>To launch a new batch network render, click on the \"Dirty All\" button to clear out any render progress information. Then click on \"Cook Output Node\".</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#popular-hqueue-errors","title":"Popular HQueue Errors","text":"<p>Popular HQueue Errors</p> <pre><code>Error: localsharedroot path not found.\n</code></pre> <p>This happens if a dummy <code>$HQROOT</code> value is not entered.</p> <p>Note: With \"RPC Message Passing\" the render job fails, so use JSON temp files instead.</p> <p>Note: Don't use a fully expanded absolute filepath for the Windows SideFX Houdini folder in place of <code>$HFS</code>, or it will error the job.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#alembic-rop-hqueue-in-tops","title":"Alembic ROP + HQueue in TOPs","text":"<p>Alembic ROP + HQueue in TOPs</p> <p>Alembic files can be written to disk inside task-based node graph using an Alembic ROP node.</p> <p>hqscheduler Node</p> <p>Add an \"hqscheduler\" node in the TOPs context.</p> <pre><code>HFS: $HFS\nPython: From HFS\n</code></pre> <p>ropalembic Node</p> <p>Add a \"ropalembic\" node to the tasks context.</p> <pre><code>ROP Alembic Tab\n\nEvaluate Using:\n    Frame Range\n\nAlembic File:\n\n    $HIP/geo/$HIPNAME/$OS.$F4.abc\n    or\n    $HIP/geo/$HIPNAME/$OS/$OS.$F4.abc\n\nRoot Object:\n    /obj/&lt;Select the geo node to export&gt;\n\n\nROP Fetch Tab:\n    Frames per Batch: 1\n\n\nOP Cook path:\n    /tasks/topnet1/ropalembic1/ropnet1/alembic1\n</code></pre> <p>Waitforall Node</p> <p>If you want to merge the execution branching in TOPS for multiple parallel tasks, add a \"waitforall\" node at the end of the node tree.</p> <p>USD Render in TOPS</p> <p>It is possible to export OpenUSD files from a task context. This is done with a ROP node approach.</p> <pre><code>In tasks context\n\nROP USD Output  \n    - [x] use External LOP\n\nLOP Path: (need to define in new projects)\n    /stage/output0\n\nOutput file:\n    $HIP/geo/$HIPNAME.$OS.usd\n\nConnected to:\n\nUSD Render\n\nSource: \n    USD File - Upstream Output File\n\nOutput:\n    $HIP/render/$HIPNAME.$OS.&lt;F4&gt;.exr\nStage\n    Geometry\n        &gt; Camera\n        &gt; Render Settings (or RenderProduct if old school v18)\n        &gt; Output0\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#render-fusion-comps-in-houdini-tops","title":"Render Fusion Comps in Houdini TOPs","text":"<p>Render Fusion Comps in Houdini TOPs</p> <p>A Houdini TOPs based node graph can be used to create workflow automation projects in a visual interface. It is another way to control a task that would otherwise need to be run as a Deadline Render Manager based job using a custom submitter.</p> <p>It is possible to use Houdini TOPs to control image processing workflows:</p> <p>https://docs.google.com/document/d/1l9L-LhCxTobZmRlinu3oKUM61EuqtZJmcf_Tv1VG-8Q/edit</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#distributing-a-houdini-tops-job-with-hqueue","title":"Distributing a Houdini TOPs Job With HQueue","text":"<p>Distributing a Houdini TOPs Job With HQueue</p> <p></p> <p>Shortly after you create your first TOPs job in Houdini, you will feel the need to speed up your render time and output volume through another layer of automation. This is where distributed compute techniques come into play.</p> <p>Houdini includes the (free) HQueue render farm controller program that should likely be your first port-of-call in distributing a TOPs based task to render nodes.</p> <p>If you eventually out-grow the features provided by the bundled HQueue render manager, you also have the option of distributing a TOPs job using Pixar's Tractor render manager, or the Amazon AWS Thinkbox Deadline render manager.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#configuring-hqueue-on-windows","title":"Configuring HQueue on Windows","text":"<p>Configuring HQueue on Windows</p> <p>Here are a few tips to help you configure a fresh install of HQueue.</p> <p>As a small observation, when working in a small render farm, the act of pointing the HQROOT path at your storage server's primary volume, tends to just cause headaches when you only have one shared hard disk for the whole file server.</p> <p>Also, it helps to segment your HQueue Pools into separate groups per operating system. Don't mix and match them unless you have taken the time to set up and fully customize environment variables for use on any OS specific value you need to rely on in a TOPs job.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ref1","title":"Step 1.","text":"<p>Step 1.</p> <p>Modify the HQROOT entries from your HQServer \"network_folders.ini\" file's settings to a local dummy folder like:</p> <pre><code>HQROOT\nC:\\HQShared\n</code></pre> <p>Also create a Windows based system environment variable for:</p> <pre><code>HQROOT = C:\\HQShared\n</code></pre> <p>Edit the \"<code>C:\\HQClient\\hqnode.ini</code>\" file so the server is set to:</p> <pre><code>[main]\nserver = 10.20.30.2\nport = 5000\n\n[job_environment]\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ref2","title":"Step 2.","text":"<p>Step 2.</p> <p>In TOPs, clear out the pre-existing \"PDG Path Map\" fields.</p> <p>Set the \"topnet1\" node to use:</p> <pre><code>Default Scheduler:\nlocalscheduler (local only jobs) \nor\nhqueuescheduler1 (network jobs)\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ref3","title":"Step 3.","text":"<p>Step 3.</p> <p>Then inside the current task area:</p> <p>Set the \"hqueuescheduler\" node to use:</p> <p>HQueue Server:</p> <p>You can connect as localhost if HQueue is running on the same system as Houdini:</p> <p>http://localhost:5000</p> <p>Or you can enter the server's fixed IP v4 address like:</p> <p>http://10.20.30.4:5000</p> <pre><code>HFS:\n[ ] Universal HFS (Clear out)\nLinux HFS Path: (Clear out)\nmacOS HFS Path: (Clear out)\nWindows HFS Path: $HFS\n\nPaths:\nLoad Item Data From: Temporary JSON File\nUncheck \"[ ] Compress work item data\".\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#ref4","title":"Step 4.","text":"<p>Step 4.</p> <p>Press the \"U\" key in the node view context to navigate back to the top level Tasks view.</p> <p>Select \"topnet1\" in the nodes view.</p> <p>To launch a new batch network render, click on the \"Dirty All\" button to clear out any render progress information. Then click on \"Cook Output Node\".</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#popular-hqueue-error-messages","title":"Popular HQueue Error Messages","text":"<p>Popular HQueue Error Messages</p> <p><code>Error: localsharedroot path not found.</code></p> <p>This happens if a dummy <code>$HQROOT</code> value is not entered.</p> <p>Note: If you enabled the TOPs based parameter for \"RPC Message Passing\", and the render job fails each time it is run, a workaround is to switch over to using JSON temp files instead. JSON temp files on the small scale can be more reliable and easier to manage on a small farm.</p> <p>Note: Don't try to manually enter a fully expanded absolute filepath that points to the Windows SideFX Houdini folder, in place of the $HFS environment variable. Doing this will likely result in rendering errors when you cook a TOPs job.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Digital%20Content%20Creation%20Apps/#hqueue-links","title":"HQueue Links","text":"<p>HQueue Links</p> <p>mqserver</p> <p>https://www.sidefx.com/docs/houdini/ref/utils/mqserver.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/","title":"Installing Hardware Virtualization Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>If you need to run multiple operating systems on the same hardware you have multiple approaches that can be taken to solve this task. Virtualization is the creation of a \"canister\" like container that represents something that could be best described as a unique imaginary computer device that is simulated inside your active computer session. Each processor instruction call done inside the virtual machine is injected back into the real CPU processor using an approach called a hypervisor.</p> <p>This approach allows you to use disk images to store the operating system and files. The virtual machine can support input devices, USB, audio, monitor connections, remote screen sharing, networking with controllable data routing options. A unique ethernet MAC ID address is assigned for each virtual machine network interface.</p> <p>The virtual machine is able to be snapshotted, paused, resumed, reset, and shutdown as needed. The virtual machine session can be hosted locally or in the cloud, and it is even possible to transfer the location of a running virtual machine session between different data centers while it is still running.</p> <p>One essential feature when working with graphics programs on a virtual machine instance is the support for native graphics rendering calls to the underlying hardware. This is called PCIe hardware passthrough support. It allows a virtualization environment to access native OpenGL, DirectX, OpenCL, CUDA, and Metal features that are able to work at peak performance often with less than 1-3% of a non-virtualized process running on the same hardware.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#docker-containers","title":"Docker Containers","text":"<p>Docker Containers</p> <p>https://www.docker.com/</p> <p>For more information:</p> <ul> <li>Containers and Virtual Machines</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#install-virsh-qemu-on-linux","title":"Install VIRSH + QEMU on Linux","text":"<p>Install VIRSH + QEMU on Linux</p> <p>Linux distros have an amazing virtualization environment called libVirt that can access PCIE hardware like GPUs, audio interfaces, and NVME storage via direct hardware passthrough of low-level devices.</p> <p>It is possible to virtualize operating systems including Linux, Windows, and even macOS using VIRSH.</p> <p>For more information:</p> <ul> <li>VIRSH</li> <li>Red Hat | KVM Migration</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#install-virtualbox-on-linux","title":"Install VirtualBox on Linux","text":"<p>Install VirtualBox on Linux</p> <p>VirtualBox is open-source virtual machine software developed by Oracle. It allows you to run Windows, Linux, and other operating systems from a disk image.</p> <p>https://www.virtualbox.org</p> <pre><code># Download Virtual Box\nsudo dnf install wget\ncd $HOME/Downloads/\nwget &lt;https://download.virtualbox.org/virtualbox/6.1.32/VirtualBox-6.1-6.1.32_149290_el8-1.x86_64.rpm&gt;\n\n# Install the RPM package\nsudo rpm -Uvh $HOME/Downloads/VirtualBox-6.1-6.1.32_149290_el8-1.x86_64.rpm\n\n# Check for a possible EFI secure boot issue with modprobe and vboxdrv.\n# Restart the system. Hold down the delete key to enter BIOS.\n# Change the BIOS settings to:\n# BIOS &gt; Security &gt; Attempt Secure Boot &gt; Disabled.\n\n# Alternative approach - DNF Package Manager Based VirtualBox install\n# install\nsudo dnf install VirtualBox-6.1 -y\n\n# Add yourself to the VirtualBox USB port sharing group\nsudo usermod -a -G vboxusers Au\n# sudo usermod -a -G vboxusers vfx\n\n# Note: Look at adding `whoami` to the usermod string.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#start-virtualbox","title":"Start VirtualBox","text":"<p>Start VirtualBox</p> <p>In a terminal window type in:</p> <pre><code>virtualbox\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#create-a-new-virtual-machine","title":"Create a new Virtual Machine","text":"<p>Create a new Virtual Machine</p> <p>Click the \"New\" button in the VirtualBox toolbar.</p> <p>Name: \"Win10\"</p> <p>Type: \"Microsoft Windows\"</p> <p>Version: \"Windows 10 (64-bit)\"</p> <p>Click the \"Next\" button to continue.</p> <p>Memory Size: 16384 MB</p> <p>Click the \"Next\" button to continue.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#create-virtual-machine-dialog","title":"Create Virtual Machine Dialog","text":"<p>Create Virtual Machine Dialog</p> <p>Hard Disk</p> <p>Click the \"(x) Create a virtual hard disk now\" option.</p> <p>Then click on the \"Create\" button to continue.</p> <p>Hard disk file type Dialog</p> <p>Select the \"(x) VMDK (Virtual Machine Disk)\" option.</p> <p>Click the \"Next\" button to continue.</p> <p>Storage on physical hard disk</p> <p>Select the \"(x) Dynamically allocated\" option.</p> <p>Click the \"Next\" button to continue.</p> <p>File size location</p> <p>Type in \"256 GB\".</p> <p>Click the \"Create\" button to continue.</p> <p>At this point, a new \"Win10\" disk image will be listed in the \"Oracle VM VirtualBox Manager\" window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#edit-the-virtualbox-vm-settings","title":"Edit the VirtualBox VM Settings","text":"<p>Edit the VirtualBox VM Settings</p> <p>Click the \"Settings\" button in the VirtualBox toolbar.</p> <p>In the Win10 Settings dialog, click on the \"Storage\" icon on the left side of the dialog.</p> <p>Select the item named \"Empty\". On the right side of the Storage tab, is an \"Optical Drive\" input field.</p> <p>Click the small optical disc icon, then in the popup dialog select \"Choose a disk file...\".</p> <p>Then select the Windows 10 ISO image named \"<code>Win10_21H2_English_International_x64.iso</code>\".</p> <p>Click the \"OK\" button to continue. This will close the settings dialog.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#start-the-new-virtual-machine","title":"Start the New Virtual Machine","text":"<p>Start the New Virtual Machine</p> <p>Back in the main \"Oracle VM VirtualBox Manager\" window, press the \"Start\" button in the toolbar.</p> <p>This will launch the new virtual machine with the Windows 10 installation media ISO connected to a virtual optical drive.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#eject-the-windows-installation-media-iso","title":"Eject the Windows Installation Media ISO","text":"<p>Eject the Windows Installation Media ISO</p> <p>From the VirtualBox Menu at the top of the Win10 VM window, uncheck the \"Devices &gt; Optical Drives &gt; Win10_21H2_EnglishInternational_x64.iso\" menu item.</p> <p>This will remove the installation media so the disk image is no longer accessible inside the Virtual Machine.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#lets-create-a-virtualbox-disk-snapshot","title":"Let's Create a VirtualBox Disk Snapshot","text":"<p>Let's Create a VirtualBox Disk Snapshot</p> <p>Let's take a new snapshot of the current state of the virtual machine and it's virtual hard disk.</p> <p>From the VirtualBox Menu at the top of the Win10 VM window, select the \"Machine &gt; Take Snapshot...\" menu item.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#take-snapshot-of-virtual-machine-dialog","title":"Take Snapshot of Virtual Machine Dialog","text":"<p>Take Snapshot of Virtual Machine Dialog</p> <p>In the \"Take Snapshot of Virtual Machine\" dialog enter the following parameters:</p> <p>Snapshot Name: \"Win10\"</p> <p>Snapshot Description: \"Fresh Install\"</p> <p>Then click the \"OK\" button to close this window and save the snapshot to disk.</p> <p></p> <p>A new disk snapshot will be saved to the .vmdk file. This can be thought of as something vaguely similar to a Windows \"Restore Point\" on a conventional PC.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#backup-a-vmdk-disk-image-to-an-external-disk-or-lto-tape","title":"Backup a VMDK Disk Image to an External Disk or LTO Tape","text":"<p>Backup a VMDK Disk Image to an External Disk or LTO Tape</p> <p>By default, your VirtualBox disk images are stored in disk at the default folder location of:</p> <pre><code>/home/vfx/VirtualBox VMs/\n</code></pre> <p>The newly created \"Win10\" disk image can be accessed using the $HOME environment variable as:</p> <pre><code>$HOME/VirtualBox VMs/Win10/\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#connect-the-virtualbox-network-adapter","title":"Connect the VirtualBox Network Adapter","text":"<p>Connect the VirtualBox Network Adapter</p> <p>Enable the \"Devices &gt; Network &gt; [x] Connect Network Adapter\" option. This will allow Windows to connect to the internet and start downloading drivers and updates.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#enable-the-virtualbox-seamless-desktop-mode","title":"Enable the VirtualBox Seamless Desktop Mode","text":"<p>Enable the VirtualBox Seamless Desktop Mode</p> <p>The VirtualBox \"View &gt; Seamless Mode\" menu item allows you to use Windows and Linux together in a more transparent and user friendly fashion.</p> <p>The \"Host +L\" hotkey for toggling On/OFF the \"Seamless Mode\" is typically configured as the \"Right Control + L\" hotkey combination when running with a default keyboard layout in Virtual Box.</p> <p></p> <p>At the same time as the \"Seamless Mode\" is enabled in VirtualBox, it also helps to have a \"Shared Folder\" enabled in the VirtualBox preferences, too.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-snapshots-allow-incremental-disk-backups","title":"VirtualBox Snapshots Allow Incremental Disk Backups","text":"<p>VirtualBox Snapshots Allow Incremental Disk Backups</p> <p>Use the VirtualBox \"Machine &gt; Take Snapshot...\" menu item to save a disk snapshot of the current .vmdk file.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-shared-clipboard-copypaste-buffer","title":"VirtualBox Shared Clipboard Copy/Paste Buffer","text":"<p>VirtualBox Shared Clipboard Copy/Paste Buffer</p> <p>VirtualBox has a shared clipboard copy/paste feature that helps make the process of using Windows applications like web browsers and text editors seamless inside a Linux host OS based environment.</p> <p>At the top of the VirtualBox window, select the \"Devices &gt; Shared Clipboard &gt; Bidirectional\" menu item. This turns on two way copying between Linux and Windows.</p> <p></p> <p>You can also access this bidirectional clipboard option using the \"Win10 Settings &gt; General &gt; Advanced\" tab. In this view, you can set the \"Shared Clipboard:\" to \"Bidirectional\". Set the \"Drag 'n Drop:\" control to \"Bidirectional\" as well.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-shared-folders","title":"VirtualBox Shared Folders","text":"<p>VirtualBox Shared Folders</p> <p>When you are working with Linux and Windows filesystems on the same host computer, it can be a big help to be able to pass files transparently between the two operating systems.</p> <p>VirtualBox offers a \"Shared Folder\" option inside each virtual machine environment. You are able to choose the source folder on the host OS side, and the mount location inside the virtual machine where that content shows up.</p> <p>It is also possible to decide if you want that shared folder location to be read-only which is useful in some cases if you don't want to have security risks like data being modified inside a Windows virtual machine used for software testing.</p> <p>Step 1. Turn off the Windows session using the Windows 10 start menu \"Shutdown\" feature.</p> <p>Step 2. In the VirtualBox software, where a \"VirtualBox Manager\" dialog shows all of the virtual machines, click on the left sidebar entry for \"Win10\". Then click in the toolbar on the orange colored \"Settings\" gearwheel icon.</p> <p></p> <p>Step 3. This will open up the VirtualBox Settings dialog for that specific virtual machine session. On the left sidebar of this \"Win10 - Settings\" dialog, select the \"Shared Folder\" entry. Then click on the far top right corner of the Shared Folder's view on a small icon that shows a \"folder with + sign\" icon. This is the button used to add a new Linux to Windows shared folder location.</p> <p></p> <p>Step 4. An \"Add Share\" dialog will appear. This is where you set up the folder sharing settings.</p> <p>Click on the \"Folder Path\" pop-up menu, and choose the \"Other...\" option. Navigate to select your Linux home folder path which equates to \"$HOME\".</p> <p></p> <p>In the \"Add Share\" dialog, set the values to something roughly like this:</p> <p>Folder Path: <code>\\home\\vfx</code></p> <p>Folder Name: <code>vfx</code></p> <p>[x] Auto-mount (enable the checkbox)</p> <p>Mount Point: <code>F:\\</code></p> <p>Step 5. Then click the \"OK\" button to close this dialog. Back in the \"Win10 - Settings\" dialog, also click the \"OK\" button to close this dialog.</p> <p>Step 6. Now you should be back in the \"VirtualBox Manager\" Window. Click on the Win10 virtual machine. Then press down in the center of the green \"Start\" button. This will re-launch the Windows 10 session.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-display-settings","title":"VirtualBox Display Settings","text":"<p>VirtualBox Display Settings</p> <p>VirtualBox supports a wide range of GPU customizations that will increase the performance of the virtualized graphics. In the default compatibility mode we will use the \"Graphics Controller\" option of \"VBoxSVGA\".</p> <p>In the \"Acceleration:\" section turn on the \"[x] Enable 3D Acceleration\" checkbox.</p> <p>Drag the \"Video Memory:\" slider all the way to the right to select all the video memory we can allocate. This is typically \"256 MB\".</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-audio-settings","title":"VirtualBox Audio Settings","text":"<p>VirtualBox Audio Settings</p> <p>The \"Host Audio Driver\" pop-up menu is set to \"PulseAudio\".</p> <p>Turn on the \"[x] Enable Audio Input\" and \"[x] Enable Audio Output\" checkboxes.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Hardware%20Virtualization%20Tools/#virtualbox-usb-settings","title":"VirtualBox USB Settings","text":"<p>VirtualBox USB Settings</p> <p>Change the VirtualBox settings to enable the \"(x) USB 3.0 (xHCI) Controller\".</p> <p>We can also add any USB hardware we want to have permanently connected to the virtual machine in this window using the \"USB Device Filters\" list. The \"Blue Colored USB plug\" Icon on the far right of this window can be used to select each device that should be automatically connected to the VirtualBox instance at boot.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/","title":"Installing Operating Systems From Scratch","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#installing-windows-10-build-21h2","title":"Installing Windows 10 Build 21H2","text":"<p>Installing Windows 10 Build 21H2</p> <p>This part of the guide is here to help if you have an emergency on one of your computer systems and fixing the issue requires you to fully reload the operating system. This process can be scary the first few times you do it, especially if one has never performed a fresh install of Windows 10 on a visual workstation or render node system.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-setup","title":"Windows Setup","text":"<p>Windows Setup</p> <p>Language to install: \"English (United Kingdom)\"</p> <p>Change the Keyboard from \"United Kingdom\" over to \"US\".</p> <p>Then click the \"Next\" button to continue.</p> <p></p> <p>Windows Setup</p> <p>Click on the \"Install Now\" button to continue.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#activate-windows","title":"Activate Windows","text":"<p>Activate Windows</p> <p>Click on the \"[x] I don't have a product key\" checkbox.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#select-the-operating-system-you-want-to-install","title":"Select the operating system you want to install","text":"<p>Select the operating system you want to install</p> <p>Choose \"Windows 10 Home\" from the list.</p> <p>Click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#applicable-notices-and-license-terms","title":"Applicable notices and license terms","text":"<p>Applicable notices and license terms</p> <p>Enable the \"[x] I accept the license terms\" checkbox. Then click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#what-type-of-installation-do-you-want","title":"What type of installation do you want?","text":"<p>What type of installation do you want?</p> <p>Choose the \"Custom install\" option to continue.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#where-do-you-want-to-install-windows","title":"Where do you want to install Windows?","text":"<p>Where do you want to install Windows?</p> <p>Click on the \"*New\" button that has the orange star icon next to it.</p> <p></p> <p>A numerical entry field will appear with an auto- sized value pre-filled in MB (megabytes). Press the \"Apply\" button to accept this value.</p> <p>Then click the \"Next\" button to continue.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref6","title":"Windows Setup","text":"<p>Windows Setup</p> <p>A dialog with the message text \"To ensure that all Windows features work correctly, Windows might create additional partitions for system files.\" will appear.</p> <p>Click the \"OK\" button to continue.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref7","title":"Where do you want to install Windows?","text":"<p>Where do you want to install Windows?</p> <p>Click the \"Next\" button to continue.</p> <p></p> <p>Installing Windows</p> <p>An installation progress window will appear. At a certain point the installer will restart the computer and transition from running off the Windows installation media ISO image, onto the new Windows install on the local hard disk.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#access-the-virtualbox-menus-for-the-win10-vm","title":"Access the VirtualBox Menus for the \"Win10\" VM","text":"<p>Access the VirtualBox Menus for the \"Win10\" VM</p> <p>Uncheck the \"Devices &gt; Network &gt; [ ] Connect Network Adapter\" option.</p> <p>By unchecking the checkbox control, VirtualBox will disable the network connection during the Windows install.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#lets-start-with-region-is-this-correct","title":"Let's start with region. Is this correct?","text":"<p>Let's start with region. Is this correct?</p> <p>Select the \"United Kingdom\" option.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#is-this-the-right-keyboard-layout","title":"Is this the right keyboard layout?","text":"<p>Is this the right keyboard layout?</p> <p>Select the \"US\" entry from the list.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#do-you-want-to-add-a-second-keyboard-layout","title":"Do you want to add a second keyboard layout?","text":"<p>Do you want to add a second keyboard layout?</p> <p>Click the \"Add layout\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#which-keyboard-layout-would-you-like-to-use","title":"Which keyboard layout would you like to use?","text":"<p>Which keyboard layout would you like to use?</p> <p>Select the \"US\" entry from the list.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#lets-connect-you-to-a-network","title":"Let's connect you to a network","text":"<p>Let's connect you to a network</p> <p>Click on the text \"I don't have internet\" to continue the Win10 install with no internet access connected.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#there-is-more-to-discover-when-you-connect-to-the-internet","title":"There is more to discover when you connect to the Internet","text":"<p>There is more to discover when you connect to the Internet</p> <p>Click on the text \"Continue with limited setup\"</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#whos-going-to-use-this-pc","title":"Who's going to use this PC?","text":"<p>Who's going to use this PC?</p> <p>Name: \"vfx\"</p> <p>Click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#create-a-really-memorable-password","title":"Create a really memorable password","text":"<p>Create a really memorable password</p> <p>Password: \"\\&lt;Write In Something&gt;\"</p> <p>Click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#confirm-your-password","title":"Confirm your password","text":"<p>Confirm your password</p> <p>A textual message will appear: \"Type your password one last time\".</p> <p>Password: \"\\&lt;Write In Something&gt;\"</p> <p>Click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#create-security-questions-for-this-account","title":"Create security questions for this account","text":"<p>Create security questions for this account</p> <p>A textual message will appear of \"Just in case you forget your password, choose 3 security questions and make sure your answers are unforgettable\".</p> <p>Your answer: \"\\&lt;Write In Something&gt;\"</p> <p>Click the \"Next\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#let-microsoft-and-apps-use-your-location","title":"Let Microsoft and apps use your location","text":"<p>Let Microsoft and apps use your location</p> <p>Select the \"No\" option.</p> <p>Click the \"Accept\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#find-my-device","title":"Find my device","text":"<p>Find my device</p> <p>Select the \"No\" option.</p> <p>Then click the \"Accept\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#send-diagnostic-data-to-microsoft","title":"Send diagnostic data to Microsoft","text":"<p>Send diagnostic data to Microsoft</p> <p>Select the \"Send Required diagnostic data\" entry.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#improve-inking-typing","title":"Improve inking &amp; typing","text":"<p>Improve inking &amp; typing</p> <p>Select the \"No\" option.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#get-tailored-experiences-with-diagnostic-data","title":"Get tailored experiences with diagnostic data","text":"<p>Get tailored experiences with diagnostic data</p> <p>Select the \"No\" option.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#let-apps-use-advertising-id","title":"Let apps use advertising ID","text":"<p>Let apps use advertising ID</p> <p>Select the \"No\" option.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#let-cortana-help-you-get-things-done","title":"Let Cortana help you get things done","text":"<p>Let Cortana help you get things done</p> <p>Click the \"Not now\" button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-setup-progress-messages","title":"Windows Setup Progress Messages","text":"<p>Windows Setup Progress Messages</p> <p>Several Windows progress dialog messages will appear over the next few minutes. No user input is required at this point for the installation to complete.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-setup-complete","title":"Windows Setup Complete","text":"<p>Windows Setup Complete</p> <p>When the Windows desktop pattern shows up, with the \"Microsoft Edge\" and \"Recycle Bin\" icons present, you have completed the Windows 10 installation process.</p> <p></p> <p>Quite a few background tasks will run at this point, such as the Windows Update mechanism which will download quite a few GBs of extra files. Over the course of the next few system reboots you do, a range of hardware drivers will get added for the accessories built-into your current laptop, workstation, or server.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-desktop-settings","title":"Windows Desktop Settings","text":"<p>Windows Desktop Settings</p> <p>In the Windows explorer folder browsing view, expand the ribbon toolbar using the fold-down disclosure triangle at the top right corner of the window.</p> <p>Switch the ribbon over to the \"View\" Tab. Then enable the \"[x] File name extensions\" checkbox. Also enable the \"[x] Hidden Items\" checkbox, too.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-group-policy-editor","title":"Windows Group Policy Editor","text":"<p>Windows Group Policy Editor</p> <p>If you are running a copy of Windows 10 Pro or Enterprise you have the option to control the Windows OS update cycle. This does not appear to be a feature available in Windows 10 Home.</p> <p>Option A: Click on the Start menu icon. In the search field type in \"Group Policy\". Click on the search result entry for the \"Edit Group Policy\" entry to launch the utility.</p> <p></p> <p>Option B: Alternatively, open a command prompt with the \"Run as administrator\" mode. Type in \"<code>gpedit.msc</code>\" to launch the Edit Group Policy utility.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#group-policy-reduce-notification-area-message-verbosity","title":"Group Policy | Reduce Notification Area Message Verbosity","text":"<p>Group Policy | Reduce Notification Area Message Verbosity</p> <p>To reduce the frequency of the firewall notification messages, it is possible to edit the group policy setting for \"Disable Security and Maintenance Notifications\".</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#group-policy-control-windows-update-scheduling","title":"Group Policy | Control Windows Update Scheduling","text":"<p>Group Policy | Control Windows Update Scheduling</p> <p>Using the panel on the left side of the \"Local Group Policy Editor\" window, navigate to the Windows Update folder using the path:</p> <p>Computer Configuration &gt; Administrative Templates &gt; Windows Components &gt; Windows Update</p> <p>Read through the list of settings you can edit until you find a \"Configure Automatic Updates\" policy. Double-click on the \"Configure Automatic Updates\" entry. In the dialog that appears, change the setting to \"(x) Disabled\" to turn off the automatic update feature permanently. To close the window, click on the \"Apply\" button, followed by the \"OK\" button to save changes.</p> <p>Once these changes are saved to disk, your system will no longer download and apply Windows updates automatically, and you are then able to manually check for updates from the Settings. If you want to check the updates manually, then open the Settings app and go in the Update &amp; Security option, then Windows Update.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-office-365-on-windows","title":"Install Office 365 on Windows","text":"<p>Install Office 365 on Windows</p> <p>When setting up a new workstation using an air gapped process, it works well to install \"Microsoft Office 365 Home Personal Edition\" using an offline installer file that is downloaded in advance.</p> <p>Microsoft Office Offline Installer docs:</p> <ul> <li>How to download Office 365 for offline install</li> <li>Use the Office offline installer</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#windows-start-menu-based-startup-folders","title":"Windows Start Menu Based Startup Folders","text":"<p>Windows Start Menu Based Startup Folders</p> <p>A startup folder based approach is handy if you need to launch a program or command-line script when Windows starts. This is a viable option you might consider using in cases where a system service is not possible such as for tasks that require GPU based hardware acceleration.</p> <p>The two most often used Windows startup folder locations are:</p> <pre><code>C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\\n\n\nC:\\Users\\vfx\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-rocky-linux-85-on-a-bare-metal-system","title":"Install Rocky Linux 8.5 on a Bare Metal System","text":"<p>Install Rocky Linux 8.5 on a Bare Metal System</p> <p>This part of the guide is here to help if you have an emergency on one of your computer systems and fixing the issue requires you to fully reload the operating system. This process can be scary the first few times you do it, especially if one has never performed a fresh install of Rocky Linux on a visual workstation or render node system.</p> <p>In your BIOS settings, make sure USB based media is bootable. The USB boot media needs to be listed at the top of the \"Boot Priority\" dialog, in advance of the internal hard disk in the list. This allows the computer to start up using the external USB boot media as the primary operating system during the install process.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#rocky-linux-8-boot-menu","title":"Rocky Linux 8 Boot Menu","text":"<p>Rocky Linux 8 Boot Menu</p> <p>Select the \"Install Rocky Linux 8\" menu item. Then press the \"Enter\" key on the keyboard to continue.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#welcome-to-rocky-linux-8","title":"Welcome to Rocky Linux 8","text":"<p>Welcome to Rocky Linux 8</p> <p>What language would you like to use during the installation process?</p> <p>Select the \"English &gt; English (United States)\" language option.</p> <p>Click the \"Continue\" button to proceed to the next screen.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#installation-summary","title":"Installation Summary","text":"<p>Installation Summary</p> <p>The installation summary dialog lets you fully customize the Rocky Linux 8 OS installation parameters.</p> <p>Note: There is a certain order-of-operations logic needed, where you have to define the network properties in advance, if you want to use any internet connected features in the other parts of the installer.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#system","title":"System","text":"<p>System</p> <p>KDUMP</p> <p>Rocky Linux has a diagnostics mode called \"KDUMP\" that can save diagnostic logging information when a crash occurs. For most normal use cases in the VFX and animation sector, like setting up a new render node or a workstation, this KDUMP feature is not required.</p> <p>Let's disable KDUMP and get 160 MB of extra RAM back in the process. Uncheck the \"[ ] Enable kdump\" checkbox near the top left of this dialog window. Then press the \"Done\" button to return to the primary \"Installation Summary\" installer screen.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#network-host-name","title":"Network &amp; Host Name","text":"<p>Network &amp; Host Name</p> <p>The \"Network &amp; Host Name\" dialog allows you to bring network interfaces like WiFi connections or Ethernet connections online. This means you can use Rocky Linux Minimal installation media to get the install going, and pull in the remaining packages you might need over the internet from a repository to complete the set up of a visual workstation.</p> <p>Select your network interface at the top left part of the dialog. In my case I am using an Etherent connection called \"Ethernet (enp0s3)\". On the far right side of the dialog is an ON/OFF control. To bring the network interface online, toggle the control to the ON state.</p> <p>The computer's name is defined with the \"Host Name:\" field at the bottom left corner of a dialog. I will give this system a host name of \"R1\" to represent render node 1 in my mini on-premise render cluster. Click the \"Apply\" button after entering a custom host name.</p> <p></p> <p>Let's further customize the remaining network settings. Click the \"Configure\" button.</p> <p>Network &amp; Host Name &gt; Configure &gt; Ethernet &gt; MTU &gt; 9000 (This setting will turn on Jumbo packets)</p> <p>Network &amp; Host Name &gt; Configure &gt; General &gt; [x] Connect automatically with priority &gt; 0</p> <p>Security Policy &gt; Apply Security Policy &gt; OFF</p> <p>Installation Destination &gt; (Skip customizing it until later on in this guide.)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#software","title":"Software","text":"<p>Software</p> <p>Software Selection</p> <p>Base Environment</p> <p>(x) Server</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#additional-software-for-selected-environment","title":"Additional Software for Selected Environment","text":"<p>Additional Software for Selected Environment</p> <ul> <li>File and Storage Server</li> <li>GNOME</li> <li>Hardware Monitoring Utilities</li> <li>Network File System Client</li> <li>Network Servers</li> <li>Performance Tools</li> <li>Windows File Server</li> <li>Development Tools</li> <li>Graphical Administration Tools</li> <li>Headless Management</li> <li>Legacy UNIX Compatibility</li> <li>Scientific Support</li> <li>System Tools</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#localization","title":"Localization","text":"<p>Localization</p> <p>Keyboard</p> <p>\"English US\"</p> <p>Language Support</p> <p>English (United States)</p> <p>Date &amp; Time</p> <p>Americas/Halifax Timezone</p> <p>24-Hour Clock</p> <p>Network Time</p> <p>Set the control to \"ON\"</p> <p>Note: You have to enable the network settings FIRST in order for the \"Date &amp; Time &gt; Network Time\" option to be available to be turned on at all.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#user-settings","title":"User Settings","text":"<p>User Settings</p> <p>Root Password</p> <p>Type in a secure password, that is possible to be remembered, and possible to be typed in correctly without error, by hand, many times over via an SSH network session.</p> <p>If the password is deemed too short by the Root Password page, it is possible to click the \"Done\" button twice to force that shorter password to be retained and used.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#user-creation","title":"User Creation","text":"<p>User Creation</p> <p>Enable the \"[x] Make this user administrator\" checkbox.</p> <p>Enable the [x] Require a password to use this account\" checkbox.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#full-name","title":"Full name:","text":"<p>Full name:</p> <p>vfx</p> <p>User name:</p> <p>vfx</p> <p>For better pipeline and shell scripting compatibility, choose a user name with less than 8 characters, no accented characters, no unicode characters, and pure ASCII alphanumeric digits, and no spaces. Going with lower case letters here isn't a bad thing if you are manually deploying a lot of tools and want faster, easier typing.</p> <p>The user name you select here becomes your home folder location of:</p> <p>/home/vfx/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#installation-destination","title":"Installation Destination","text":"<p>Installation Destination</p> <p>Local Standard Disks</p> <p>Click on a drive to add a checkmark to indicate the install disk you would like to overwrite.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#storage-configuration","title":"Storage Configuration","text":"<p>Storage Configuration</p> <p>Select the \"(x) Custom\" option</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#installation-options-warning-dialog","title":"Installation Options Warning Dialog","text":"<p>Installation Options Warning Dialog</p> <p>Your current Rocky Linux software selection requires (GiB) of available space, including (GiB) for software and (GiB) for swap space.</p> <p>Click the (Reclaim Space) Button.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#reclaim-disk-space","title":"Reclaim Disk Space","text":"<p>Reclaim Disk Space</p> <p>One has to be very careful when you go to remove pre-existing disk partitions on your destination drive where you are installing Rocky Linux. If you have several additional disks in the system, you need to check the drive make/model and disk capacity to ensure you are targeting the correct drive on the install.</p> <p>The \"sdb\" like values hop around a bit when you plug in more internal and external drives so stay very vigilant not to destroy important disks like backup drives at this time.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#hard-drive-layout","title":"Hard Drive Layout","text":"<p>Hard Drive Layout</p> <p>EFI System Partition (EFI System Partition)</p> <p>/boot/efi (EFI System Partition) 512 MiB</p> <p>/ (ext4)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#manual-partitioning","title":"Manual Partitioning","text":"<p>Manual Partitioning</p> <p>New mount points will use the following partitioning scheme:</p> <p>Standard Partitioning</p> <p>Note: When you look through the hard drives shown in the \"Unknown\" section of the dialog, keep an eye out for any volumes that have an \"ISO 9660\" file system.</p> <p>Seeing a USB drive listed as \"ISO 9660\" at this stage typically indicates this volume is the installation media you booted from that was created from an original ISO disk image. Don't delete this drive, as you are likely running the current Rocky Linux OS installer off that disk/memory card/USB thumbdrive right now!!!</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#create-a-disk-partition-one","title":"Create a Disk Partition \"One\"","text":"<p>Create a Disk Partition \"One\"</p> <p>Tip: Look at the top right of the manual partitioning window at the entry labelled \"Device(s)\" to see the hardware brand and drive model information for the partition you are interacting with.</p> <p>This will be a value like \"ATA OWC Mercury Extr...\" for a render node with an SSD drive. Other drives will be listed here for laptops, desktops, or server systems.</p> <p>To add a new partition to the boot volume click the bottom left of the manual portioning window's little \"+\" shaped button icon.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#add-a-new-mount-point-dialog","title":"Add a new mount point dialog","text":"<p>Add a new mount point dialog</p> <p>Desired Capacity:</p> <p>512 MiB</p> <p>Mount Point:</p> <p>/boot/efi</p> <p>Click the \"Add a mount point\" button to close the window and apply the settings. This will create a drive partition with an \"EFI System Partition\" file system.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#create-a-disk-partition-two","title":"Create a Disk Partition \"Two\"","text":"<p>Create a Disk Partition \"Two\"</p> <p>Click the bottom left of the manual portioning window's little \"+\" shaped button icon, to add a new partition to the boot volume.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref8","title":"Add a new mount point dialog","text":"<p>Add a new mount point dialog</p> <p>Mount Point:</p> <p>/</p> <p>Device Type:</p> <p>Standard Partition</p> <p>Desired Capacity:</p> <p>Leave this input field blank to use all of the remaining space on the hard drive for file storage.</p> <p>Click the \"Add a mount point\" button to close the window and apply the settings.</p> <p>Once the \"Add a new mount point\" dialog closes and you are back at the \"Manual Partitioning\" window, you need to click on the \"/\" based drive partition at the top left part of the window.</p> <p>Change the \"File System\" parameter from the default value of \"xfs\" over to the more flexible option of \"ext4\". An ext4 based file system can be resized later on once the Linux OS is installed using a partition editing tool like \"gparted\".</p> <p>Note: If your hard disk was prepared with the default Linux setting using an \"xfs\" partition, it can make the relatively basic task of resizing an internal disk partition smaller, a real challenge later on.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#summary-of-changes","title":"Summary of changes","text":"<p>Summary of changes</p> <p>Click the \"Accept Changes\" button.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref9","title":"Installation Summary","text":"<p>Installation Summary</p> <p>Click the \"Begin Installation\" button.</p> <p>When the install completes, press the \"Reboot\" button. Remove the install media when the monitor goes black.</p> <p>Then open the BIOS by pressing \"delete\" on your keyboard as soon as the system restarts.</p> <p>Select the boot drive in the BIOS that holds the Rocky Linux OS install. Press F10 to save the settings and exit BIOS.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#rocky-linux-deployment-essentials","title":"Rocky Linux Deployment Essentials","text":"<p>Rocky Linux Deployment Essentials</p> <pre><code># Add Gnome and enable a graphical desktop.\nsudo dnf groupinstall \"Workstation\"\nsudo systemctl set-default graphical\n\n# Restart the system to autoload Gnome next.\nsudo reboot\n\n# Turn on auto-login for the rackmounted servers\n\n# This can be done only if the systems are in a secure access location, and you need startup items such as a graphical XPU GPU/CPU based userland application to run. Not all GPU tools can be launched as system services in 2022.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#firefox","title":"Firefox","text":"<p>Firefox</p> <p>In Firefox, right-click on the bookmark bar area at the top of the window. In the contextual popup menu, select the \"[x] Menu Bar\" item.</p> <p>A menu bar should now be visible at the top of the Firefox window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#add-3rd-party-repositories","title":"Add 3<sup>rd</sup> Party Repositories","text":"<p>Add 3<sup>rd</sup> Party Repositories</p> <pre><code># Add the EPEL software repository.\nsudo dnf install epel-release\n\n# Import the signing key for the EPEL repository.\nsudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\n\n# Add the EL Repo software repository.\nsudo dnf install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm\n\n# Add the kernel headers\nsudo dnf --enablerepo=elrepo-kernel install kernel-ml kernel-ml-devel kernel-ml-headers -y --allowerasing\n\n# Upgrade the Linux kernel from 4.x to 5.x\n# sudo dnf upgrade --refresh -y\n\n# Add the RPM Fusion repository free releases\nsudo dnf install --nogpgcheck https://mirrors.rpmfusion.org/free/el/rpmfusion-free-release-8.noarch.rpm -y\n\n# Add the RPM Fusion repository non-free releases\nsudo dnf install --nogpgcheck https://mirrors.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-8.noarch.rpm -y\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#add-developer-tools","title":"Add Developer Tools","text":"<p>Add Developer Tools</p> <pre><code># Add C/C++ compiler tools\nsudo dnf install gcc -y\n\n# Add more compiler resources\nsudo dnf groupinstall \"Development Tools\" -y\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-nvidia-drivers-on-linux","title":"Install NVIDIA Drivers on Linux","text":"<p>Install NVIDIA Drivers on Linux</p> <p>NVIDIA Driver Install References</p> <p>https://www.linuxcapable.com/how-to-install-or-upgrade-nvidia-drivers-on-rocky-linux-8/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#uninstall-old-nvidia-drivers","title":"Uninstall old NVIDIA drivers","text":"<p>Uninstall old NVIDIA drivers</p> <pre><code>sudo dnf remove nvidia-driver\nsudo dnf module reset nvidia-driver\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-nvidia-drivers","title":"Install NVIDIA Drivers","text":"<p>Install NVIDIA Drivers</p> <pre><code># Use the NVIDIA repo to source the GTX GPU drivers\nsudo dnf update -y\n\nsudo dnf config-manager --add-repo &lt;https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo&gt; -y\n\nsudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r) --allowerasing -y\n\nsudo dnf install nvidia-driver nvidia-settings -y\nsudo dnf install cuda-driver -y\n\n# Restart the workstation\nsudo reboot now\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#troubleshooting-linux-gpu-driver-issues","title":"Troubleshooting Linux GPU Driver Issues","text":"<p>Troubleshooting Linux GPU Driver Issues</p> <p>Question: Did the GPU setup get fully borked after the NVIDIA GPU Driver install?</p> <p>If the NVIDIA driver install has issues, one can change the \"Run Level\" to a text console input mode to help with the recovery process using:</p> <ul> <li> <p>To switch the display over to a \"Run Level 5\" textual console view press the \"Control + Alt + F5\" keyboard hotkey.</p> </li> <li> <p>To switch the display over to a \"Run Level 6\" graphical GNOME view press the \"Control + Alt + F6\" keyboard hotkey.</p> <p># Switch from a terminal session back to a gnome desktop session startx</p> </li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#nvidia-preferences","title":"NVIDIA Preferences","text":"<p>NVIDIA Preferences</p> <p>After the GPU Drivers are installed you get access to \"<code>nvidia-smi</code>\" and \"<code>nvidia-settings</code>\" as command-line tools:</p> <pre><code># Check the GPU hardware stats from the terminal\nsudo nvidia-smi\n</code></pre> <p></p> <pre><code># Adjust the proprietary NVIDIA GPU driver and display properties\nsudo nvidia-settings\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#x11-xorg-graphics-preferences","title":"X11 / XORG Graphics Preferences","text":"<p>X11 / XORG Graphics Preferences</p> <p>When running the \"nvidia-settings\" program, you should save the edited xorg settings back to disk at the following file path: \"/etc/X11/xorg.conf\"</p> <pre><code># Create a backup of the current xorg file\nsudo cp /etc/X11/xorg.conf  /etc/X11/xorg.conf.bak\n\n# Verify the XORG preference file was backed up successfully\nsudo ls -laX /etc/X11/xorg*\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#installing-linux-software","title":"Installing Linux Software","text":"<p>Installing Linux Software</p> <p>Make sure to check out the site \"pkgs.org\" when hunting for the right package for your current Linux distro. This site is a super efficient time saver when you need to locate the exact version matched with the RedHat .rpm package equivalent to a Ubuntu/Debian .deb package that might be listed in the documentation for a tool you need to install.</p> <pre><code># Add disk utilities\nsudo dnf install gparted sshpass -y\nsudo dnf install sysbench hardinfo -y\n\n# Add NFS storage support\nsudo dnf install nfs-utils -y\n\n# Add exfat and ntfs filesystem support\nsudo dnf install exfatprogs -y\nsudo dnf install exfat-utils -y\nsudo dnf install fuse-exfat -y\nsudo dnf install ntfs-3g -y\n\n# Add media tools like vlc, ffmpeg, Imagemagick, and hugin\nsudo dnf install vlc -y\nsudo dnf install ffmpeg --skip-broken --allowerasing -y\nsudo dnf install ImageMagick -y\n\n# Add network file transfer clients\nsudo dnf install filezilla -y\n\n# Add the thunderbird email client\nsudo dnf install thunderbird -y\n\n# Add sshpass which is a Bash scripting friendly remote access tool\nsudo dnf install sshpass -y\n\n# Add dialog curl wget unzip zip unrar nano for shell scripting\n\n# Add LuaJIT for scripting\nsudo dnf install luajit -y\n\n# Add xclip for clipboard copy/paste\n\n# Add virtual environment tools:\n# pip, py virtual environment, anaconda, rez\n\n# Add nodejs, electron, shelljs, and moment\n\n# Add OpenCV, GluonCV, OpenMMLab, MediaPipe, PyTorch, OpenColorIO, OpenImageIO, and Jupyter Notebook\n\n# Add the NVIDIA GPU control software \"Green With Envy\" for memory timing, core clock speed, and fan control.\n\n# Add the Intel OpenCL ICD Driver.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#rocky-linux-control-panels","title":"Rocky Linux Control Panels","text":"<p>Rocky Linux Control Panels</p> <ul> <li>Users &gt; Auto Login</li> <li>Sound output</li> <li>Unlink the Super/meta key so it doesn't affect Gnome.</li> <li>Customize the desktop pattern.</li> <li>Change the windows background color from a bright white shade to a neutral grey or dark theme</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#privacy-settings-screen-lock","title":"Privacy Settings | Screen Lock","text":"<p>Privacy Settings | Screen Lock</p> <p>If you are in a shared office like working environment it can be useful to have the \"Privacy\" setting for \"Screen Lock\" enabled.</p> <p></p> <p>You can fully customize the Screen Lock features timer value using the \"Lock screen after blank for X minutes\" control.</p> <p>Screen Lock OFF</p> <p>It's possible to select a very permissive value of Screen Lock \"OFF\" which could possibly be of use in a work-from-home based \"home office\" environment if you are doing XPU based GPU rendering and have physical access security for the workstations or render nodes.</p> <p></p> <p>Screen Lock ON</p> <p>If you are in a co-working space or traditional VFX Studio or a Design Boutique like shared office environment, you might go for a Screen Lock value of somewhere between 5 minutes to 30 minutes.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#details-users-settings-automatic-login","title":"Details &gt; Users Settings | Automatic Login","text":"<p>Details &gt; Users Settings | Automatic Login</p> <p>If your XPU based render nodes are running in a locked \"limited physical access\" secured location, or a home-office environment, you might find some workflow benefits from enabling \"Automatic Login\".</p> <p>This is relevant if some of your GPU rendering and image-based-modeling tools don't work particularly well when launched via a headless system service approach.</p> <p>Needless to say, if you are in a large office-like environment with many people present, this is not a viable approach to even think about... \ud83e\udd2a</p> <p>Once again, if your computer gear is in a limited access location then you might consider the following approach as possibly relevant to your pipeline needs:</p> <p>Open the Rocky Linux \"Settings &gt; Details &gt; Users\" view.</p> <p>Then unlock the panel and turn on \"Automatic Login\".</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#linux-networking","title":"Linux Networking","text":"<p>Linux Networking</p> <pre><code># Disable SE Linux\n# Open the /etc/selinux/config file and set the SELINUX mode to disabled.\n\nsudo nano /etc/selinux/config\n\n# Disable the firewall\nsudo systemctl disable firewalld\nsudo systemctl stop firewalld\nsudo systemctl status firewalld\n\n# Needs some work to update from Centos v7.9 to Rocky Linux v8.5\n{\nsudo systemctl enable rpcbind\nsudo systemctl enable nfs-server\nsudo systemctl enable nfs-lock\nsudo systemctl enable nfs-idmap\nsudo systemctl start rpcbind\nsudo systemctl start nfs-server\nsudo systemctl start nfs-lock\nsudo systemctl start nfs-idmap\nsudo systemctl restart nfs-server\n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#gedit-text-editor","title":"Gedit Text Editor","text":"<p>Gedit Text Editor</p> <ul> <li>Gedit Preferences &gt; View:</li> <li> Display line numbers</li> <li>Gedit Preferences &gt; View &gt; Highlighting<ul> <li> Highlight current line</li> <li> Highlight matching brackets</li> </ul> </li> <li>Gedit Preferences &gt; Editor &gt; Tap Stops &gt; 2</li> <li>Gedit Preferences &gt; Fonts &amp; Colors<ul> <li>Oblivion</li> </ul> </li> <li> use the system fixed width font (Monospace 11)</li> <li>Editor font: Monospace Regular 18</li> <li>Gedit Preferences &gt; Plugins<ul> <li> External Tools</li> <li> Python Console</li> <li> Quick Open</li> <li> Snippets</li> <li> Sort</li> </ul> </li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#linux-terminal-app","title":"Linux Terminal App","text":"<p>Linux Terminal App</p> <p>Terminal &gt; preferences &gt; Colors &gt; Text and Background Color</p> <p>Built-in schemes:</p> <p>Green on black</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#top-process-viewer-cli-app","title":"\"Top\" Process Viewer CLI App","text":"<p>\"Top\" Process Viewer CLI App</p> <p>Set up the Top \"IRIX\" mode customizations</p> <p>Launch top from the command-line using:</p> <p>top</p> <ul> <li>Press \"z\" for color</li> <li>Press \"E\" for memory scale to GB</li> <li>Press \"e\" several times to show memory of tasks as gb.</li> <li>Press \"i\" for Irix mode - shorter list of active tasks - not used this time...</li> <li>Press \"d\" 0.5 for faster updates</li> <li>Press \"t\" 3 times to hide the top line tasks summary and show a progress bar</li> <li>Press \"f\" to adjust sort order and columns</li> <li>Sort by %CPU = select it by pressing right arrow and then press the s key on the keyboard</li> </ul> <p>%CPU</p> <p>%MEM</p> <p>RES</p> <p>PID</p> <p>USER</p> <p>COMMAND</p> <ul> <li>Unselect items with spacebar for any remaining category</li> <li>Press \"q\" to exit column order editing</li> <li>Press \"Shift + W\" to write the prefs to disk</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#fix-folder-permissions","title":"Fix Folder Permissions:","text":"<p>Fix Folder Permissions:</p> <p>If you are using the Rocky Linux system as a single-user visual workstation the following two commands can help fix headaches while you finish installing your core tools. Once the software you use day-to-day is configured you can then roll the permissions back to \"755\" or whatever value you feel is appropriate.</p> <pre><code>sudo chmod -R 777 $HOME\nsudo chmod -R 777 /opt/\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#linux-user-account-tweaks","title":"Linux User Account Tweaks","text":"<p>Linux User Account Tweaks</p> <pre><code># Login via a localhost based SSH shell connection as the user \"root\"\nssh root@localhost\n\n# Login as the user \"root\"\nsudo -u root -i\n\n# Login as the user \"vfx\"\nsudo -u vfx -i\n\n# list the current folder path aka \"put working directory\":\npwd\n\n# navigate to the \"root\" user's home folder\ncd /root/\n\n# Navigate to the \"vfx\" user's home folder\ncd /home/vfx/\n\n# Navigate to the current user's home folder (inside /home/) using the $HOME environment variable\ncd $HOME/\n\n# list the current folder contents\nls\n\n# list folder contents\nls\n\n# Install a specific RPM package (in this case named \"SomePackage.rpm\") that is found in the current folder\nsudo rpm -Uvh SomePackage.rpm\n\n# Install all of the RPM file files in the current folder\nsudo rpm -Uvh *.rpm\n\n# Alternative way to Install all of the RPM file files in the current folder\nsudo rpm -i *.rpm\n\n# Run \"Visudo\" to edit the Sudoers list so you can add new users to the list of admin accounts capable of running \"sudo\" in the terminal\nsudo visudo\n\n# Edit the Sudoer's list\n# You need to start by pressing the \"i\" key to enable the VIM \"insert mode\" in the text editor to be able to add new lines of text to the document. Navigation is done by the up/down cursor keys. Add the following text, near the bottom part of the sudoers text file, to add a user account named \"vfx\" to the sudoers list:\n\nvfx            ALL = (ALL) ALL\n\n# The Visudo utility is VIM text editor based, so you will need to use some funky keypresses to save and exit visudo...\n\n# Press the \"Esc (escape)\" hotkey. Then type in \":wq\" to write the changes to disk, and quit the active Visudo (VIM) editing session. Then press the \"Enter\" hotkey to return to the Terminal.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-centos-linux-79-on-a-bare-metal-system","title":"Install CentOS Linux 7.9 on a Bare Metal System","text":"<p>Install CentOS Linux 7.9 on a Bare Metal System</p> <p>This part of the guide is here to help if you have an emergency on one of your computer systems and fixing the issue requires you to fully reload the operating system. This process can be scary the first few times you do it, especially if one has never performed a fresh install of CentOS Linux on a visual workstation or render node system.</p> <p>In your BIOS settings, make sure USB based media is bootable. The USB boot media needs to be listed at the top of the \"Boot Priority\" dialog, in advance of the internal hard disk in the list. This allows the computer to start up using the external USB boot media as the primary operating system during the install process.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref10","title":"Hard Drive Layout","text":"<p>Hard Drive Layout</p> <p>EFI System Partition (EFI System Partition)</p> <p>/boot/efi (EFI System Partition) 512 MiB</p> <p>/ (ext4)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref11","title":"Manual Partitioning","text":"<p>Manual Partitioning</p> <p>(x) I will configure partitioning</p> <p>Click on the hard disk icon</p> <p>Clicking on the (done) button will show partitioning options</p> <p>Switch from \"LVM\" to the \"Standard Partition\" Type</p> <p>(Click here to create partitions)</p> <p>Remove the \"Home\" and \"Swap\" partitions with the \"-\" minus icon.</p> <p>File System: EXT4</p> <p>Click the \"Done\" button.</p> <p>In the Summary of Changes window click \"Accept Changes\"</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#user-account-creation","title":"User Account Creation","text":"<p>User Account Creation</p> <p>During the CentOS install process you are given the option to create an admin user account for the Linux system.</p> <p>Add User:</p> <p>vfx</p> <p>Enable the checkbox for the control labelled:</p> <p>\"[x] make this user an admin\"</p> <p>Enable Automatic Login</p> <pre><code>sudo nano /etc/gdm/custom.conf\n</code></pre> <p>Overwrite the custom.conf file contents with:</p> <pre><code># GDM configuration storage\n\n[daemon]\nAutomaticLogin=linuxconfig\nAutomaticLoginEnable=True\n\n[security]\n\n[xdmcp]\n\n[chooser]\n\n[debug]\n# Uncomment the line below to turn on debugging\n#Enable=true\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref12","title":"Add 3<sup>rd</sup> Party Repositories","text":"<p>Add 3<sup>rd</sup> Party Repositories</p> <pre><code># Update CentOS:\nsudo yum update\n\n# Add the EPEL repository:\nsudo yum install epel-release\nsudo yum update\n\n# Add the Nux repository:\nsudo rpm -v --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro\nsudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm\n\n# Add the elrepo repository for Linux hardware drivers:\nsudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\nsudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm\n\n# If you want to be able to read an ExFat  formatted USB drive you will need to add:\nsudo yum install exfat-utils fuse-exfat\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#adjust-the-security-settings","title":"Adjust the Security Settings","text":"<p>Adjust the Security Settings</p> <p>If you are running a render node system inside a LAN you will likely want to adjust the firewall rules and disable SELinux.</p> <pre><code># Open the \"/etc/selinux/config\" file:\nsudo nano /etc/selinux/config\n\n# Set the SELINUX mode to disabled by changing the following SELinux line in the config file to read:\nSELINUX=disabled\n\n# Disable the firewall:\nsudo systemctl disable firewalld\nsudo systemctl stop firewalld\nsudo systemctl status firewalld\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#change-the-host-name","title":"Change the Host Name","text":"<p>Change the Host Name</p> <pre><code># Change the host name in Centos 7:\nsudo gedit /etc/hostname\n\n# You can also update the host name using:\nsudo gedit /etc/sysconfig/network\n\n# Look in the text file for the entry: \nlocalhost.localdomain\n\n# Change this line to edit the host name value to something like:\nR1\n\n# Print the current host name:\necho The current host name is: uname -n\n\n# Edit the hosts file:\nsudo gedit /etc/hosts\n127.0.0.1 R1 localhost\n::1       R1 localhost localhost.localdomain localhost6 localhost6.localdomain6\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#ref13","title":"Add Developer Tools","text":"<p>Add Developer Tools</p> <pre><code># Add the GCC compiler\nsudo yum install gcc\n\n# The NVIDIA installer requires the GCC compiler tools\nsudo yum -y groupinstall \"Development Tools\"\n\n# NVIDIA installer requires kernel source files\nsudo yum install kernel-devel\n\n# Install more libraries to satisfy the NVIDIA installer\nsudo yum install pkgconfig libglvnd-devel\n\n# The dkms package package will ensure continuous NVIDIA kernel module compilation and installation in the event of new Linux kernel update.\nsudo yum -y install dkms\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-the-cinnamon-window-manager","title":"Install the Cinnamon Window Manager","text":"<p>Install the Cinnamon Window Manager</p> <pre><code># Install the GTK theme engine Murrine that is used by gedit, and the installers for Maya / V-Ray\nsudo yum install gtk-murrine-engine\n\n# Install lshw\nsudo yum install lshw\n\n# Install Cinnamon\nsudo yum --enablerepo=epel -y install cinnamon*\n\n# Add Cinnamon to your rc file\necho \"exec /usr/bin/cinnamon-session\" &gt;&gt; ~/.xinitrc\n\n# Start the X Desktop session\nstartx\n</code></pre> <p>To change the active Linux window manager, you need to log out of the current user account session.</p> <p>On the login window, set Cinnamon as your active window manager by clicking on the \"gear wheel\" icon and selecting Cinnamon.</p> <p>Log back into your user account.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#install-the-nvidia-drivers-for-centos-linux","title":"Install the NVIDIA Drivers for CentOS Linux","text":"<p>Install the NVIDIA Drivers for CentOS Linux</p> <p>NVIDIA RTX 3090 Linux CentOS Driver webpage:</p> <p>https://www.nvidia.com/Download/driverResults.aspx/172376/en-us</p> <pre><code># Direct Driver Download Link:\ncd $HOME\nwget https://us.download.nvidia.com/XFree86/Linux-x86_64/460.73.01/NVIDIA-Linux-x86_64-460.73.01.run\n\n# The Nvidia drivers must be installed while the xorg server is stopped. Switch to text mode, or run this via ssh:\n\nsystemctl isolate multi-user.target\n\n# Alternatively you can terminate the xserver session which is the hard core route\n\nsudo killall /usr/bin/X\n\n# You can start linux in a text console using the Control + Alt + F2 hotkey after you have logged out of the user session\n\n# Install the drivers (the name of the executable would have to line up with the exact driver version you downloaded)\n\ncd $HOME\nsudo sh ./NVIDIA-Linux-x86_64-460.73.01.run\n\nThe NVIDIA installer options you want to select are:\n\nDMKS (yes)\n\nThe NVIDIA installer asks if you want to install 32 bit libraries (yes)\n\nThe NVIDIA installer asks about libglvnd (install and overwrite existing)\n\nThe NVIDIA installer asks about auto update X configuration file? (yes)\n\n\nIf you are running the default Nouveau graphics drivers on CentOS when you run the NVIDIA installer, you will likely see a message that says:\n\nERROR: The Nouveau kernel driver is currently in use by your system.  This driver is incompatible with the NVIDIA driver, and must be disabled before proceeding. Please consult the NVIDIA driver README and your Linux distribution's documentation for details on how to correctly disable the Nouveau kernel driver.\n\n# You can then disable nouveau driver by changing the configuration \"/etc/default/grub\" file. Add the entry \"nouveau.modeset=0\" to the line starting with GRUB_CMDLINE_LINUX.\n\nsudo nano /etc/default/grub\n\n# Below you can find example of grub configuration file reflecting the previously suggested change:\n\nGRUB_TIMEOUT=5\nGRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\"\nGRUB_DEFAULT=saved\nGRUB_DISABLE_SUBMENU=true\nGRUB_TERMINAL_OUTPUT=\"console\"\nGRUB_CMDLINE_LINUX=\"rhgb quiet nouveau.modeset=0\"\nGRUB_DISABLE_RECOVERY=\"true\"\n\n# You can optionally remove the \"quiet\" entry on \"GRUB_CMDLINE_LINUX\" to be able to see startup messages for issues like missing drive automounts.\n\n# The GRUB changes ensure that the open-source nouveau graphics driver is disabled the next time you boot your CentOS 7 Linux system. Once ready execute the following command to apply the new GRUB configuration change:\n\n# If you are running a legacy BIOS system:\nsudo grub2-mkconfig -o /boot/grub2/grub.cfg\n\n# If you are running an EFI based system:\nsudo grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\n\n# Reboot your CentOS 7 Linux System.\nsudo reboot\n\n# Once the boot is finished confirm that the nouveau open-source graphics driver is no longer in use:\n\nlshw -numeric -C display\n\n# WARNING: you should run this program as super-user.\n#   *-display UNCLAIMED       \n#        description: VGA compatible controller\n#        product: GK208B [GeForce GT 710] [10DE:128B]\n#        vendor: NVIDIA Corporation [10DE]\n#        physical id: 0\n#        bus info: pci@0000:01:00.0\n#        version: a1\n#        width: 64 bits\n#        clock: 33MHz\n#        capabilities: vga_controller bus_master cap_list\n#        configuration: latency=0\n#        resources: iomemory:6970-696f iomemory:6970-696f memory:ca000000-caffffff memory:69738000000-6973fffffff memory:69740000000-69741ffffff ioport:3000(size=128) memory:cb000000-cb07ffff\n# WARNING: output may be incomplete or inaccurate, you should run this program as super-user.\n\n\n# Install the Mesa utils package if you want to be able to run the glxgears and glxinfo programs.\nsudo yum install mesa-demos.x86_64\n\n# If you would like to have OpenCL v1.2 you will need to add extra repos before you can install the following package\nsudo yum install ocl-icd ocl-icd-devel\n\n# To make OpenCL run with programs like Blackmagic Fusion Studio happy, you might need to create this symlink\nsudo ln -s /usr/lib64/libOpenCL.so.1 /usr/lib/libOpenCL.so\n\n# Get the OpenGL info (No info is shown when run via ssh with no display)\nglxinfo | less\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#green-with-envy-gpu-utility","title":"Green With Envy GPU Utility","text":"<p>Green With Envy GPU Utility</p> <p>The \"Green with Envy\" utility can be used to help control the GPU fan speed, and the memory/core timing. This will ensure you get reliable performance when GPU rendering.</p> <p>This utility works best in systems with only a single NVIDIA GPU installed. The Cinnamon window manager can sometimes freak out with Linux \"kernel panic\" system lockups if you have multiple GPUs active.</p> <pre><code># Toggle the prefs for all GPUs connected:\nsudo nvidia-xconfig --enable-all-gpus\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#gnome-settings","title":"Gnome Settings","text":"<p>Gnome Settings</p> <ul> <li>Disable Screensaver</li> <li>Enable Automatic Login</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#gnome-hotkeys","title":"Gnome Hotkeys","text":"<p>Gnome Hotkeys</p> <p>To allow the Autodesk Maya user interface to function correctly, we need to unbind the ALT key in GNOME. This makes it possible to move windows and interact with views in a consistent fashion.</p> <p>Open the \"System Settings &gt; Window &gt; Behaviour\" tab. Change the \"special key to move and resize windows\" setting so it is disabled.</p> <p>It is handy to add a \"Control + Alt + t\" shortcut that will display a new terminal window.</p> <p>Go to \"System Settings &gt; keyboard &gt; Shortcuts tab &gt; Custom Shortcuts\"</p> <p>Click on the \"+\" button.</p> <pre><code>Name: Terminal Shortcut\nCommand: gnome-terminal\n</code></pre> <p>Now a new shortcut is added with status \"disabled\". Click on the \"disabled\" word and assign your shortcut.</p> <p>I prefer \"Control + Alt + t\" to run Terminal but you can customize this hotkey binding to meet your needs.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#common-linux-utilities","title":"Common Linux Utilities","text":"<p>Common Linux Utilities</p> <p>At this point you could add several extra Linux utilities.</p> <pre><code># As a quick tip, this is how you install an RPM package file via the terminal window:\nsudo rpm -ivh example.rpm\n\n# Add the nano text editor if it is missing on a minimal install of Centos 7\nsudo yum -y install nano\n\n# Add disk management / filesytem packages\nsudo yum install -y gparted nfs-utils exfat-utils.x86_64 fuse-exfat.x86_64 kmod-hfsplus.x86_64 kmod-hfs.x86_64\n\n# Add network packages\nsudo yum install -y sshpass filezilla tigervnc\n\n# Add general utilities\nsudo yum install -y sysbench hardinfo\nsudo yum install -y ImageMagick hugin wget vlc mplayer\nsudo yum install -y xclip unzip\n\n# Add Redhat compatibility libraries\nsudo yum install -y redhat-lsb-core\n\n# Add the X11 utils and fonts\nsudo yum -y install libXp xorg-x11-fonts-ISO8859-1-100dpi xorg-x11-fonts-ISO8859-1-75dpi liberation-mono-fonts liberation-fonts-common liberation-sans-fonts liberation-serif-fonts\n\n# Add and enable the NFS server package\nsudo yum install -y nfs-utils\nsudo systemctl enable rpcbind\nsudo systemctl enable nfs-server\nsudo systemctl enable nfs-lock\nsudo systemctl enable nfs-idmap\nsudo systemctl start rpcbind\nsudo systemctl start nfs-server\nsudo systemctl start nfs-lock\nsudo systemctl start nfs-idmap\nsudo systemctl restart nfs-server\n\n# Add libraries to support media tools\nsudo yum install -y mesa-libGLw libXp gamin audiofile audiofile-devel e2fsprogs-libs tcsh xorg-x11-fonts-ISO8859-1-100dpi xorg-x11-fonts-ISO8859-1-75dpi liberation-mono-fonts liberation-fonts-common liberation-sans-fonts liberation-serif-fonts glx-utils libpng12 mesa-libGLU libXpm libtiff libXcomposite gstreamer1 gstreamer-plugins-base gstreamer1-plugins-base ffmpeg\n\nsudo yum install -y libXScrnSaver\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20Operating%20Systems%20From%20Scratch/#solve-package-manager-issues-on-centos","title":"Solve Package Manager Issues on CentOS","text":"<p>Solve Package Manager Issues on CentOS</p> <pre><code># Clean up after a cancelled yum -y install:\nyum-complete-transaction --cleanup-only\n\n# Check the repos folder\nsudo nautilus /etc/yum.repos.d/\n\n# Clear the yum cache:\nsudo nautilus /var/cache/yum/\n\n# Clear any missing repo files\nsudo rpm -Va --nofiles --nodigest\nsudo yum -y update --skip-broken\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/","title":"Installing a Local Content Staging Web Server","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>A local content staging server allows you to create new revisions to a website without breaking the existing live website.</p> <p>If you want to work with large media files and develop content that will eventually be played back from a web server it is very important to do extensive local testing with a copy of your website content and web server tools.</p> <p>Spending a lot of time to upload and then re-download web site content over-and-over again during your ongoing development and testing phases is often time wasted.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#google-webfonts","title":"Google WebFonts","text":"<p>Google WebFonts</p> <p>https://www.fonts.com/web-fonts/google</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-nodejs-npm-electron-and-shelljs","title":"Installing nodeJS, npm, electron, and shellJS","text":"<p>Installing nodeJS, npm, electron, and shellJS</p> <p>https://nodejs.org/</p> <p>https://www.electronjs.org/</p> <p>https://www.npmjs.com/package/shelljs</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-mamp-on-macos-and-windows","title":"Installing MAMP on macOS and Windows","text":"<p>Installing MAMP on macOS and Windows</p> <p>If you are using macOS or Windows the easiest web sharing module to set up and install is MAMP. For local testing the MAMP program is likely all you need and you can skip running MAMP Pro.</p> <p>No discussion of web sharing programs would be complete without a brief suggestion that you talk with your system administrator about network security and firewalls before enabling an Apache web sharing mode on your system. You may also want to research Apache .htaccess files to learn how to lock down the htdocs sharing folder to only allow access from users with a specific realm login account and password.</p> <p>Step 1. Start by downloading and installing MAMP.</p> <p>On Windows MAMP is installed on your hard disk at:</p> <pre><code>C:\\MAMP\\MAMP.exe\n</code></pre> <p>On macOS MAMP is installed on your hard disk at:</p> <pre><code>/Applications/MAMP/MAMP.app\n</code></pre> <p>Step 2. Launch MAMP for the first time. An easy to use GUI will appear.</p> <p></p> <p>On the right side of the MAMP window is a button with a circular \"power\" icon that lets you Start and Stop the MAMP server. Click the Start Servers button if the MAMP server is not running yet.</p> <p>On the left side of the MAMP window is a \"Preferences\" button that will open up the Apache server controls. Click the Preferences button.</p> <p>Step 3. The Preferences window allows you to control the Apache server settings without having to manually edit any configuration files.</p> <p>Enable the \"Start Servers when starting MAMP\" and \"Stop Servers when quitting MAMP\" checkboxes in the Start/Stop tab.</p> <p>Turning on these two controls means you can easily use MAMP when you want to view locally served html content. Then when you have finished with that task you can quit the MAMP GUI, and MAMP will then immediately stop the Apache web sharing background system service.</p> <p></p> <p>There are several other settings in the MAMP preferences window you could adjust if you wanted to.</p> <p>Step 4. Click on the Ports tab in the MAMP preferences window. The Ports tab allows you to change the default server port settings for the Apache web sharing.</p> <p></p> <p>On Windows the Apache Port is set to 80 by default. This is the typical port used for all HTTP based web servers. The MAMP localhost address for your Windows system would be: http://localhost/</p> <p>On macOS the Apache Port is set to 8888 by default to avoid conflicts with the macOS built-in web sharing modes. In your web browser a custom port is defined in the URL by typing a colon and then the port number like \":8888\" after the website server address.</p> <p>The MAMP localhost address for your macOS system would be: http://localhost:8888/</p> <p>Step 5. Click on the Web Server tab in the MAMP preferences window.</p> <p>This tab allows you to change the \"Document Root\" folder that is shared by the Apache server module. By default this \"Document Root\" directory path is set to the \"htdocs\" directory in the MAMP program folder.</p> <p></p> <p>Unless you have a very specific technical reason to adjust the \"Document Root\" setting in MAMP it is a good idea to leave this text field at the default value in the MAMP preferences dialog.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#setting-up-apache-httpd-on-linux","title":"Setting up Apache httpd on Linux","text":"<p>Setting up Apache httpd on Linux</p> <p>If you are going to be using KartaVR automation scripts on Linux you will also need to install the clipboard tool xclip, along with the Apache (httpd) server modules for web sharing:</p> <pre><code>yum install xclip httpd\n</code></pre> <p>You can start Apache (httpd) using:</p> <pre><code>systemctl start httpd.service\nsystemctl enable httpd.service\n</code></pre> <p>On CentOS if you want to make the Apache HTTP port 80 accessible external to the machine you can open that port up on the firewall rules:</p> <pre><code>firewall-cmd --permanent --zone=public --add-service=http\nfirewall-cmd --reload\n</code></pre> <p>On Linux the Apache Port is set to 80 by default. This is the typical port used for all HTTP based web servers. If you need to use an alternative port address you could choose 8080.</p> <p>The HTTPD (HTTP Daemon) web server's localhost address for your Linux system would be:</p> <pre><code>http://localhost/\n</code></pre> <p>The Apache \"Document Root\" path is the /var/www/html/ directory. This is where the KartaVR scripts will save the VR webpage preview exports.</p> <p>Note: You will have to make the \"/var/www/html/\" folder writable for the users that are running the KartaVR VR preview script. You can either use chmod to change the folder permissions to do this, or you can use chown to add the user to a group with write permissions. The various Apache setup guides on the internet can provide details on this step.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-windows-subsystem-for-linux","title":"Installing Windows Subsystem for Linux","text":"<p>Installing Windows Subsystem for Linux</p> <ul> <li>Microsoft | What is WSL</li> <li>Microsoft | WSL Docs</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#winmtr-network-traceroute-utility","title":"WinMTR Network Traceroute Utility","text":"<p>WinMTR Network Traceroute Utility</p> <p>https://sourceforge.net/projects/winmtr/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#gitkraken-git-gui-client","title":"GitKraken Git GUI Client","text":"<p>GitKraken Git GUI Client</p> <p>This is an open-source cross-platform compatible git client GUI.</p> <p>https://www.gitkraken.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#tower-git-gui-client-for-macoswindows","title":"Tower Git GUI Client for macOS/Windows","text":"<p>Tower Git GUI Client for macOS/Windows</p> <p>https://www.git-tower.com/mac</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-dialog","title":"Installing Dialog","text":"<p>Installing Dialog</p> <p>Dialog is a Unix terminal based GUI system that functions over SSH connections and in terminal windows.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-cyberduck-for-windows","title":"Installing CyberDuck for Windows","text":"<p>Installing CyberDuck for Windows</p> <p>https://cyberduck.io/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-panic-transmit-for-macos","title":"Installing Panic Transmit for macOS","text":"<p>Installing Panic Transmit for macOS</p> <p>https://panic.com/transmit/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-putty-for-windows","title":"Installing Putty for Windows","text":"<p>Installing Putty for Windows</p> <p>https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-sshpass","title":"Installing SSHPass","text":"<p>Installing SSHPass</p> <p>SSHPass is a command-line utility that dramatically simplifies the process of allowing a shell script to make remote SSH based calls to render nodes.</p> <p>https://www.redhat.com/sysadmin/ssh-automation-sshpass</p> <p>This toolset is something that should only be used inside of a trusted closed LAN network environment, where you are comfortable and have full awareness of the SSH security implications and network access policies. Do not use this tool if you are in a low-trust environment.</p> <p>Install SSHPass on macOS:</p> <pre><code>curl -O -L http://downloads.sourceforge.net/project/sshpass/sshpass/1.05/sshpass-1.05.tar.gz &amp;&amp; tar xvzf sshpass-1.05.tar.gz\ncd sshpass-1.05\n./configure\nmake\nsudo make install\n</code></pre> <p>Install SSHPass on LINUX:</p> <pre><code>yum --enablerepo=epel -y install sshpass\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#sshpass-install-location","title":"SSHPass Install Location","text":"<p>SSHPass Install Location</p> <p>By default SSHPass is installed to one of the following installation locations.</p> <p>macOS SSHPass Install Path:</p> <pre><code>/usr/local/bin/sshpass\n</code></pre> <p>CentOS Linux SSHPass Install Path:</p> <pre><code>/usr/local/bin/sshpass\n</code></pre> <p>Ubuntu Linux SSHPass Install Path:</p> <pre><code>usr/bin/sshpass\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#using-sshpass","title":"Using SSHPass","text":"<p>Using SSHPass</p> <p>Here is an SSHPass shell scripting example that uses ffmpeg to carry out a macOS video capture device based framegrab over an SSH network connection.</p> <p>This code snippet assumes an environment variable named \"SSHPASS_DIR\" exists that defines the sshpass installation location. It also uses the macOS based AVFoundation library to grab an image from a webcam named \"Cisco VTCamera3\".</p> <pre><code>echo \"[Linux] Network Framegrab\"\n# Note on macOS the ssh -n -t -t flag helps with redirecting the output for tty password submission\n\n\"$SSHPASS_DIR\" -p 'correcthorsebatterystaple' ssh -n -t -t vfx@10.20.30.1  'opt/ffmpeg/bin/ffmpeg -y -f avfoundation -framerate 5.000000 -video_size 1600x1200 -pixel_format uyvy422 -vsync 2 -i \"Cisco VTCamera3\" -f image2 -vcodec mjpeg -vframes 1 -qscale:v 2 /Volumes/Media/screenshot.jpg'\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#installing-zenity-dialog","title":"Installing Zenity / Dialog","text":"<p>Installing Zenity / Dialog</p> <p>Zenity or Dialog are excellent choices for GUI toolkits if you need to create a quick and efficient user interface for a shell script that is run purely from a text-based terminal session or a remote SSH based session.</p> <p>https://gitlab.gnome.org/GNOME/zenity</p> <p>If you have used the \"dialog\" GUI toolkit in the past to create text-based interfaces, you will find Zenity is very natural to pick up and use as well.</p> <p>macOS Homebrew install:</p> <pre><code>brew install zenity\nbrew install dialog\n</code></pre> <p>Linux YUM Install:</p> <pre><code>yum install -y zenity\nyum install -y dialog\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#dialog-usage-in-a-terminal-window-session","title":"Dialog Usage in a Terminal Window session:","text":"<p>Dialog Usage in a Terminal Window session:</p> <pre><code># Display timer dialog window for 180 seconds\ndialog --pause \"Wake on LAN Timer\" 10 30 180\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#a-dialog-text-based-gui-example-that-runs-the-ping-command-line-utility","title":"A Dialog text-based GUI example that runs the PING command-line utility:","text":"<p>A Dialog text-based GUI example that runs the PING command-line utility:</p> <p></p> <p>Save this script to a \"Ping-Dialog.command\" file:</p> <pre><code>#!/usr/bin/env bash\n\n# Run ping in a dialog v1 2018-07-01 10.52 AM\n# Andrew Hazelden &lt;andrew@andrewhazelden.com&gt;\n\n# The default address to ping\nPING_ADDRESS_DEFAULT_FILE=\"$TMPDIR/ping_address_default.txt\"\nPING_ADDRESS_FILE=\"$TMPDIR/ping_address.txt\"\necho \"www.cbc.ca\" &gt; $PING_ADDRESS_DEFAULT_FILE\n# open \"$TMPDIR/\"\n# bbedit $PING_ADDRESS_FILE\n\n# Where the output from the ping program is saved\nPING_RESULT_FILE=\"$TMPDIR/ping_result.txt\"\n\n# Show the ping dialog window\ndialog --backtitle \"BucketTime Ping Test\" \\\n--title \"Ping\" \\\n--msgbox \"Enter the IP/Domain name you would like to ping.\" 8 40 \\\n--editbox \"$PING_ADDRESS_DEFAULT_FILE\" 8 40 2&gt; \"$PING_ADDRESS_FILE\"\n\n# Save out the IP/Domain name to a textfile\nPING_ADDRESS_URL_STRING=`cat \"$PING_ADDRESS_FILE\"`\n# echo $PING_ADDRESS_URL_STRING\n\n# Run the ping terminal program\nping -c 3 -i 0.5 $PING_ADDRESS_URL_STRING &gt; \"$PING_RESULT_FILE\"\nPING_RESULT=`cat \"$PING_RESULT_FILE\"`\n#echo $PING_RESULT\n\n# Show the result in a new dialog window\ndialog --backtitle \"BucketTime Ping Test\" \\\n--title \"Ping\" \\\n--msgbox \"$PING_RESULT\" 12 65\n\n# Done\nclear\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#wol-wake-on-lan-utilities","title":"WOL (Wake On Lan) Utilities","text":"<p>WOL (Wake on LAN) Utilities</p> <p>WOL (Wake on LAN) is a network management feature that is often built into 10/100/1000 Ethernet cards. It allows you to wake up computers on your local subnet that are in a low-power sleeping or \"OFF\" state.</p> <p>The WOL protocol works by sending a \"magic packet\" value to a specific computer's ethernet-based IP address/MAC address. The computer then exits from a dormant low-power state and either wakes up from sleep, or does a cold-boot.</p> <p>If you are working with high-speed networking gear, often a 10Gb+ Ethernet-based network device will have a separate management port for WOL usage that runs at a slower 10/1000 Ethernet speed.</p> <p>The \"wolcmd\" executable is a handy free command-line tool that allows a command prompt or terminal session to perform WOL operations:</p> <p>Wolcmd for Windows</p> <p>Wolcmd for macOS</p> <p>ZSH/Bash Syntax:</p> <pre><code># An example of using WOL (Wake on LAN)\necho \"[WOL] Waking up R01\"\nwolcmd 002590595b16 10.20.30.1 255.255.255.0 4343\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#winrar-compression","title":"WinRAR Compression","text":"<p>WinRAR Compression</p> <p>https://www.rarlab.com/download.htm</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#winscp-file-transfer","title":"WinSCP File Transfer","text":"<p>WinSCP File Transfer</p> <p>https://winscp.net/eng/index.php</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#rsync-network-file-syncing-and-transfer","title":"Rsync Network File Syncing and Transfer","text":"<p>Rsync Network File Syncing and Transfer</p> <p>https://rsync.samba.org</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#finding-your-ip-address","title":"Finding Your IP Address","text":"<p>Finding Your IP Address</p> <p>If you don't know the current IP address for your computer you can check in your operating system's \"Network\" control panel for more details.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#mac-network-preferences","title":"Mac Network Preferences","text":"<p>Mac Network Preferences</p> <p></p> <p>On macOS you need to click on the System Preferences icon in your Dock. Then open the Network control panel. On the left side of the Network control panel is a listing of each of the network adapters on your computer with entries for things like WiFi, and Ethernet devices.</p> <p>Select the network adapter you are currently using to access the internet. This network connection will have a green circle icon next to it. With the network adapter selected, the main part of the control panel displays your local IP address next to the words \"IP Address:\".</p> <p>You will also see information about this network adapter at the top of the network view next to the words Status: Connected [Device] is currently active and has the IP Address of [address].</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#windows-10-network-control-panel","title":"Windows 10 Network Control Panel","text":"<p>Windows 10 Network Control Panel</p> <p></p> <p>On Windows you need to open the Control Panel &gt; Network and Internet &gt; Network Connections window. Right click on your active network connection. Then select the \"Status\" item in the popup menu.</p> <p>A status window will open. Click on the Details... button to find out more information about this network device. Then a \"Network Connection Details\" window will appear. Your current local IP address is listed next to the IPv4 Address line.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#linux-network-settings","title":"Linux Network Settings","text":"<p>Linux Network Settings</p> <p>The easiest way to find out your IP address visually on Linux is to load the Network settings window.</p> <p>Open the triangle shaped menu at the top right of the screen and select the Settings icon. This will load the \"All Settings\" window that is used to configure the Linux system.</p> <p></p> <p>Look in the \"All Settings\" window for the Hardware section. Then click on the Network icon on the far right side of the window.</p> <p></p> <p>On the left side of the Network settings window is a listing of each of the network adapters on your computer with entries for things like WiFi, Bluetooth, and Wired Ethernet devices.</p> <p>Select the network adapter you are currently using to access the internet.</p> <p>This network connection will probably be called \"Wired\" on a Linux workstation. With the network adapter selected, the main part of the Network window displays your local IP address next to the words \"IPv4 Address\".</p> <p>If you have multiple network adapters on your Linux system the active interface will have the word \"Connected\" displayed next to in the main part of the Network window to the left of the ON/OFF button.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#finding-your-external-ip-address-using-your-web-browser","title":"Finding your External IP Address Using your Web Browser","text":"<p>Finding your External IP Address Using your Web Browser</p> <p>A quick and easy way to find out your external ip address is to visit a website like ipecho.net or whatsmyip.org.</p> <p>This external IP address is only reachable if your computer is directly connected to the internet and your IP address is not hidden by NAT (Network Address Translation) from your computer existing behind a router or hardware firewall.</p> <p>If you are behind a router that has NAT enabled then you may have to set up a port forward to route port 80 from your cable modem/router and map it to your computer's manually configured local IP address. This is something that your system administrator or ISP (internet service provider) can assist you with.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#finding-your-external-ip-address-on-mac-and-linux","title":"Finding your External IP Address on Mac and Linux","text":"<p>Finding your External IP Address on Mac and Linux</p> <p>Your current external internet facing IP address can be also found out on Mac and Linux systems using this terminal command:</p> <pre><code>curl ipecho.net/plain; echo\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#ifconfig-on-mac-and-linux","title":"ifconfig on Mac and Linux","text":"<p>ifconfig on Mac and Linux</p> <p>On Mac and Linux systems your local IP address can be found using the ifconfig program from the terminal:</p> <pre><code>ifconfig\n</code></pre> <p>You have to scroll through the output to look for an \"en\" network entry like:</p> <pre><code>net 192.168.0.100 netmask 0xffffff00 broadcast 192.168.0.255\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#hostname-on-linux","title":"hostname on Linux","text":"<p>hostname on Linux</p> <p>On CentOS 7 and RedHat 7 Linux systems your local IP address can often be found using the hostname program from the terminal:</p> <pre><code>hostname -i\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#ipconfig-on-windows","title":"ipconfig on Windows","text":"<p>ipconfig on Windows</p> <p>On Windows your local IP address can be found using the ipconfig program from the command prompt:</p> <pre><code>ipconfig\n</code></pre> <p>You have to scroll through the output to look for a network entry like:</p> <pre><code>IPv4 Address. . . . . . . . . . . : 192.168.0.100\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20a%20Local%20Content%20Staging%20Web%20Server/#get-wmiobject-on-windows","title":"get-wmiobject on Windows","text":"<p>get-wmiobject on Windows</p> <p>On Windows you could also use the get-wmiobject program from the command prompt to look up the local IP address:</p> <pre><code>powershell -Command \"&amp; {get-wmiobject -class Win32_NetworkAdapterConfiguration -Filter IPEnabled=true | select ipaddress}\"\n</code></pre> <p>This command will return the IP Address and network MAC address details in a long string of text like:</p> <pre><code>{192.168.0.100, fe80::e5cd:fce8:700d:1b4e, fdb2:2c26:f4e4:0:54d2:4949:9f22:c62b, fdb2:2c26:f4e4:0:e5cd:fce8:700d:1b4e}\n</code></pre> <p>The first <code>192.168.0.100</code> entry in this block of text is your computer's local network IP address.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/","title":"Installing the BMD Resolve / Fusion Software","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Blackmagic Design's Resolve software is a powerful editing and color correction environment. Resolve is a mainstay at many high-end post-production facilities in the film &amp; TV sector.</p> <p>Blackmagic Design's Fusion Studio software is a node-based compositing environment that allows for the creation of high-quality visual effects shots. Fusion provides artists with a very capable 2.5D compositing environment, and supports the design of complex animated 2D/3D motion graphics with a high level of node-based proceduralism. Fusion also enables 360VR content creation, and more.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#download-resolvefusion-studio-from-bmds-website","title":"Download Resolve/Fusion Studio from BMD's Website","text":"<p>Download Resolve/Fusion Studio from BMD's Website</p> <p>If you want to install the absolutely latest release of Resolve or Fusion you should go directly to the BMD Support Center Website to access the installers:</p> <p>https://www.blackmagicdesign.com/support/family/davinci-resolve-and-fusion</p> <p></p> <p>Alternatively, the Steak Underwater Fusion community forum has a concise list of all BMD Resolveand Fusion releases with download links.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#resolve-free","title":"Resolve (Free)","text":"<p>Resolve (Free)</p> <p>If you are looking for \"Resolve (free)\" it is listed in the BMD support center as simply \"Resolve\". Resolve (Free)'s software license terms allow for both personal and commercial use of the software at no cost.</p> <p>Resolve (free) 18.1 Linux Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/ce671c375b4d48e2bf9dc5fb422aa9c9/Linux</p> <p>Resolve (free) 18.1 Windows Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/ce671c375b4d48e2bf9dc5fb422aa9c9/Windows</p> <p>Resolve (free) 18.1 macOS Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/ce671c375b4d48e2bf9dc5fb422aa9c9/Mac%20OS%20X</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#about-resolve-and-the-fusion-page","title":"About Resolve and the Fusion Page","text":"<p>About Resolve and the Fusion Page</p> <p>Blackmagic Design provides access to a version of the Fusion compositing environment as a custom page in the Resolve software called the \"Fusion\" page.</p> <p></p> <p>The Fusion page environment allows video editors to create their own title templates in Fusion and use them on the Edit page. The Fusion page node-based environment makes it a quick job to perform basic visual effects compositing tasks inside a larger Resolve project.</p> <p>The Fusion page availability in Resolve (Free) led to the retirement of the earlier Fusion (Free) Standalone product at Fusion v9. If you want access to a standalone version of Fusion that is only found in the Fusion Studio product.</p> <p>The Fusion page adds a new analogy of a \"MediaIn\" and \"MediaOut\" node which interfaces with the Media Pool/Edit/Delivery pages, in addition to the traditional \"Loader\" and \"Saver\" nodes used in Fusion for working with image sequences like OpenEXR format media.</p> <p>The primary limitation of the free version of Resolve is that it can export footage at up to 3840x2160px resolution. This resolution limit is enforced as a maximum of 3840 px on the horizontal axis, and a maximum of 2160px on the vertical axis. A variety of advanced features like optical flow support, HMD previewing, and several other Fusion nodes are held back until you upgrade to Resolve Studio or Fusion Studio.</p> <p>All in all, most people can get quite far in their everyday workflows in Resolve (Free).</p> <p>If you are a freelancer doing multi-pass compositing with 4K UHD resolution EXR footage you can be very productive using merely the Resolve (Free) Fusion page environment. This is an optimal configuration to use while you are quickly mastering new skills and learning what is possible with the toolset.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#resolve-studio-paid","title":"Resolve Studio (Paid)","text":"<p>Resolve Studio (Paid)</p> <p></p> <p>The paid version of Resolve is known as \"Resolve Studio\".</p> <p>There is a separate installer for Resolve Studio that is available on the BMD Support Center website. This is a separate download from the previous free version of Resolve that you might already have installed while you were evaluating the software. The two Resolve installers place the files at the same location on your hard disk so only one of them can exist at a time.</p> <p>The paid version, Resolve Studio, is activated using either: a Resolve Studio \"activation card\" license, or a hardware-based USB licensing dongle that holds a Resolve Studio or a Fusion Studio v7-18+ license.</p> <p>Resolve Studio 18.1 Linux Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/2ff9be8a1a9c4082b1fe977133816b6a/Linux</p> <p>Resolve Studio 18.1 Windows Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/2ff9be8a1a9c4082b1fe977133816b6a/Windows</p> <p>Resolve Studio 18.1 macOS Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/2ff9be8a1a9c4082b1fe977133816b6a/Mac%20OS%20X</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#resolve-studio-improvements-over-the-resolve-free-fusion-page","title":"Resolve Studio Improvements over the Resolve (Free) Fusion page","text":"<p>Resolve Studio Improvements over the Resolve (Free) Fusion page</p> <p>Resolve Studio unlocks access to higher-resolution rendering support, provides improved GPU-based hardware acceleration options, unlocks FusionSDK compiled plugin support for running tools like Krokodove, and gives access to external command-line automation via FuScript/Lua/Python. The paid version also adds machine learning features, optical flow, z-depth/disparity generator tools, 360VR headset preview support in the Fusion page, stereo 3D tools, and more.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-studio-standalone-paid","title":"Fusion Studio Standalone (Paid)","text":"<p>Fusion Studio Standalone (Paid)</p> <p></p> <p>\"Fusion Studio\" is the term for the dedicated standalone version of the Fusion compositing environment. Fusion Studio v18 can be activated with a Fusion Studio v7-18+ hardware-based USB dongle license, a Resolve Studio dongle license, or with a Resolve Studio \"activation card\" license.</p> <p>Fusion Studio 18.1 Linux Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/5b520062049c4182bd3ee66ffad6df4d/Linux</p> <p>Fusion Studio 18.1 Windows Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/5b520062049c4182bd3ee66ffad6df4d/Windows</p> <p>Fusion Studio 18.1 macOS Download</p> <p>https://www.blackmagicdesign.com/ca/support/download/5b520062049c4182bd3ee66ffad6df4d/Mac%20OS%20X</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-studio-improvements-over-the-resolve-free-fusion-page","title":"Fusion Studio Improvements over the Resolve (Free) Fusion page","text":"<p>Fusion Studio Improvements over the Resolve (Free) Fusion page</p> <p>Fusion Studio provides a dedicated, full-screen, standalone environment for compositing without the overhead of having all of Resolve loaded into memory at the same time.</p> <p>Fusion Studio also saves your project files into .comp format documents. The .comp file format holds plain text encoded Lua table data which is easier to manage and backup inside of a larger visual effects production pipeline.</p> <p>The paid Fusion Studio product unlocks access to higher-resolution rendering support, provides improved GPU-based hardware acceleration options, unlocks FusionSDK compiled plugin support for running tools like Krokodove, and gives access to external command-line automation via FuScript/Lua/Python. The paid version also adds machine learning features, optical flow, z-depth/disparity generator tools, 360VR headset preview support in the Fusion page, stereo 3D tools, and more.</p> <p>If you have Fusion Studio installed on your system you also have the ability to access and use the Fusion Render Node program which allows for a near unlimited number of render nodes to be run on the same LAN based subnet with no additional license costs from BMD. This feature can massively speed up your rendering productivity on projects that require faster turn around.</p> <p>Fusion Studio Standalone has a built-in Render Manager feature that works well for freelance, and solo-artists who work primarily from a single workstation based GUI session in a home-office or small office environment. The Fusion Studio bundled Render Manager is accessed using the \"File &gt; Render Manager\" menu item or the \"Control + M\" hotkey.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-render-node","title":"Fusion Render Node","text":"<p>Fusion Render Node</p> <p>The Fusion Render Node program is available if you have a Fusion Studio license active on your LAN based subnet. Fusion Render Node is provided as a separate installer bundled alongside the Fusion Studio download from the BMD Support Center website.</p> <p></p> <p>When getting started, the Fusion Render Node program is typically controlled from inside a Fusion Studio based artist session using the \"Fusion Render Manager\".</p> <p>The Fusion render node program can also be launched directly from the command-prompt with CLI arguments, or you can control the render node software from an external render manager program of your choice.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#command-line-usage","title":"Command Line Usage","text":"<p>Command Line Usage</p> <p>If you launch Fusion Render Node from a Terminal/Command-Prompt window with the \"-h\" help flag added to the end of the line, you will see a list of the full commands that are available for your use:</p> <pre><code>\"/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node\" -h\n\nFusion Render Node [&lt;filename.comp&gt; | &lt;filename.dfq&gt;] [/quiet] [/render [/frames &lt;frameset&gt;] [/start &lt;frame&gt;] [/end &lt;frame&gt;] [/step &lt;step&gt;] [/quit]] [/listen] [/join &lt;host&gt;] [/log &lt;filename&gt;] [/cleanlog] [/verbose] [/quietlicense] [/version] [/pri high|above|normal|below|idle] [/args [...]] [/execute &lt;script string&gt;]\n</code></pre> <p>When you render a Fusion .comp file via the command prompt, the program control can be managed 100% manually under human control using the following style of shell syntax:</p> <pre><code>\"/Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node\" \"/Users/vfx/Documents/MyProject/MyProject.comp\" -render -verbose -quit\n</code></pre> <p>If you need a quick way to grab the filepath for your .comp document in the Finder (macOS) environment, you can right-click on the file with the ALT/Option key held down on the keyboard. A contextual menu item appears with a \"Copy as Pathname\" menu item. This will place the full absolute file path to the document in your macOS copy/paste clipboard.</p> <p></p> <p>On Windows 10/11 you have a similar feature that lets you right-click on a file, with the shift-key held down. A contextual menu item appears with a \"Copy as Path\" menu item.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#external-render-manager-usage","title":"External Render Manager Usage","text":"<p>External Render Manager Usage</p> <p>If you have a team of artists who rely on Fusion Render Node, as part of a larger post-production workflow, you will likely experience productivity benefits from adopting a 3<sup>rd</sup> party render manager like the Amazon AWS Thinkbox Deadline or Pixar Tractor software.</p> <p>Having an external render management tool, that was made by a 3<sup>rd</sup> party company, allows you to combine Fusion based comp rendering jobs alongside your existing 3D rendering workloads coming from a 3D department.</p> <p>Using a render manager like Deadline makes it easy to control the order of operations for a group of tasks, called a \"job batch\", when they are computed on a render farm. This is often called a linked \"dependent task\".</p> <p>Having a dependent job submitted to Deadline, in a single step, reduces the amount of manual \"render wrangling\" a human operator has to do when supervising complex jobs running on a large farm.</p> <p>The \"Submit Fusion Job to Deadline\" scripted tool is used to define the Fusion .comp file you would like to render, the frame range to render, how many frames should be rendered per-job task, the version of Fusion Render Node to use, and many other options.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#automated-fusion-studio-installs","title":"Automated Fusion Studio Installs","text":"<p>Automated Fusion Studio Installs</p> <p>Here is a guide that covers automated installation of Fusion Studio and Fusion Render Node from the command-line:</p> <p>https://www.steakunderwater.com/wesuckless/viewtopic.php?p=12528#p12528</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-studio-standalone-on-linux-preferences","title":"Fusion Studio Standalone on Linux Preferences","text":"<p>Fusion Studio Standalone on Linux Preferences</p> <ul> <li>Fusion Studio &gt; Preferences &gt; User Interface<ul> <li> Use gray background interface</li> <li> Auto control close tools</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; PathMap<ul> <li> Enable reverse mapping of non-user paths</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; Memory &gt; Interactive Render<ul> <li> Simultaneous Branching</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; Memory &gt; Final Render:<ul> <li>Render 10 frames at once</li> <li> Simultaneous Branching</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; Frame Format &gt; Color depth<ul> <li>32 bits float per channel (128 bit)</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; Flow &gt; [ ] Auto remove routers</li> <li>Fusion Studio &gt; Preferences &gt; Tweaks &gt; OpenGL &gt; [x] Use float16 textures</li> <li>Fusion Studio &gt; Preferences &gt; Script &gt; Options &gt; Script editor:<ul> <li>/usr/bin/gedit</li> </ul> </li> <li>Fusion Studio &gt; Preferences &gt; Script &gt; Python Version:<ul> <li>Python 2.7</li> <li>Python 3.10</li> </ul> </li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#install-resolve-studio-on-linux","title":"Install Resolve Studio on Linux","text":"<p>Install Resolve Studio on Linux</p> <p>Resolve Install Folder Path:</p> <pre><code>/opt/resolve/\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#resolve-studio-on-linux-preferences","title":"Resolve Studio on Linux Preferences","text":"<p>Resolve Studio on Linux Preferences</p> <ul> <li>User &gt; UI Settings<ul> <li> Reload last working project when logging in</li> <li> Use gray background for user interface</li> <li> Use gray background in viewers</li> </ul> </li> <li>User &gt; Project Save and Load<ul> <li> Live Save</li> <li> Project Backups</li> </ul> </li> <li>System &gt; General &gt; General Preferences<ul> <li>External scripting using: Network</li> </ul> </li> <li>System &gt; Media Storage<ul> <li> Direct I/O</li> <li>Mount: /home/vfx/Documents/BlackmagicDesign/DaVinci Resolve/ResolveCache</li> </ul> </li> <li>Fusion Settings &gt; Script &gt; Options &gt; Script editor:<ul> <li>/usr/bin/gedit</li> </ul> </li> <li>Fusion Settings &gt; Script &gt; Python Version:<ul> <li>Python 2.7</li> <li>Python 3.10</li> </ul> </li> <li>Fusion &gt; Fusion Settings &gt; General &gt; [x] Summarize Load Errors</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#getting-started-with-nodes-in-fusion","title":"Getting Started With Nodes in Fusion","text":"<p>Getting Started With Nodes in Fusion</p> <p>If you are getting started with Fusion it can be a bit scary using nodes for the first time.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#loading-imagery","title":"Loading Imagery","text":"<p>Loading Imagery</p> <p></p> <p>Imagery is imported into Fusion using Loader or MediaIn nodes.</p> <p>Imagery is exported from Fusion using Saver or MediaOut nodes.</p> <p>If your Fusion timeline is set to have a single frame range (the start frame and end frame values are the same) you will be rendering a still image with your Saver node. If your Fusion timeline has a start frame and end frame range with different values, you will be exporting an image sequence.</p> <p>When you are rendering imagery with a Saver node, frame padding is defined in an image sequence filename by writing in a frame number like 0000 to to match the number of zero padded digits you want in the final image:</p> <pre><code>C:\\media\\image_sequence.0000.exr\n</code></pre> <p>You can render an image to your operating system's temp folder using a Fusion feature called a \"path map\" which is a relative path that is used in place of the drive name:</p> <pre><code>Temp:\\image_sequence.0000.exr\n</code></pre> <p>There is a path map option \"Comp:\\\" that can be used to load imagery relative to the location of the current Fusion .comp compositing file. This makes it easy to move .comp projects between systems.</p> <pre><code>Comp:\\image.0000.exr\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#making-node-connections","title":"Making Node Connections","text":"<p>Making Node Connections</p> <p>Nodes are connected in Fusion by dragging a line from a red \"output\" box shape on one node into a triangle shaped \"input\" on another node.</p> <p></p> <p>If you want to connect a macro with multiple output \"red\" boxes like the \"VerticalCross2CubicFaces\" macro to your node graph, it helps if you hover your cursor over the red box shape so a tooltip will pop-up with the name of the specific output.</p> <p></p> <p>To view the current output of a node, you need to drag the node from the flow view to a viewer window. This will update the viewer window with that node's output.</p> <p>If you drag a node with the shift key held down you can completely disconnect it from a node graph.</p> <p>You can break the connection of a node by hovering over the starting part or ending part of a connection line. When the line end part turns light blue you can drag it away from the connection point and the node will be disconnected.</p> <p></p> <p>If you want to make a connection to a node that has multiple inputs, you can hold down the ALT/Option key on your keyboard as you drag a new connection line to the node shape. A handy popup will appear that lists each of the inputs by name.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#the-fusion-viewer-window","title":"The Fusion Viewer Window","text":"<p>The Fusion Viewer Window</p> <p>You can toggle to a single viewer or a double viewer window layout using the following icon at the top of the screen:</p> <p></p> <p>This is the typical viewer window layout in Fusion where there are two viewer windows available at the top of the Fusion UI.</p> <p></p> <p>When a node is selected in the \"flow\" area, you can load its imagery into a specific viewer window by clicking with the left mouse button and dragging that node icon into the viewer window.</p> <p>Another way to load a node's imagery into a specific viewer window is by pressing the \"1\" key for the left viewer window, or the \"2\" key for the right viewer window. To clear the imagery out of both viewer windows press the backquote \"tilde\" key that is located just below the escape key on most keyboards.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#color-and-viewer-luts","title":"Color and Viewer LUTs","text":"<p>Color and Viewer LUTs</p> <p></p> <p>You can access individual color channels in the viewer window's toolbar with the color channel menu, or by clicking in the viewer window and pressing the hotkeys C (Shows the Color RGB Channels), R (Shows the Red Channel), G (Shows the Green Channel), B (Shows the Blue Channel), or A (Shows the Alpha Channel).</p> <p>If you are working with EXR format multi-channel imagery that includes extra image channels, more entries will be displayed in the color channel menus for items like Z-Depth, Disparity X/Y, Motion Vectors, etc.</p> <p></p> <p>The LUT button allows you to change the viewer windows' preview LUT (Look Up Table) which means you can preview the effect of different color spaces on your imagery. This is useful for viewing RAW, sRGB, or Linear gamma based imagery. If your imagery looks washed out when loaded in Fusion it is typically due to a LUT setting mismatch.</p> <p></p> <p>If you need to preview imagery in a color space other than the footage's native format, I recommend you try out the OpenColorIO based LUT menu option called OCIO ColorSpace ViewLUT as it is one of the easiest to use.</p> <p>When the OCIO ColorSpace LUT is active, you can select the Edit... option in the LUT menu and change the OpenColorIO source space and output space to match your footage and monitor settings. This is handy for previewing LWF linear workflow based EXRs imagery in a monitor native sRGB format.</p> <p>As a tip, you can type a Color Gamma value of 2.2 into the OCIO ColorSpace LUT window to perform a \"live\" on the fly linear workflow gamma 1.0 to sRGB gamma 2.2 conversion that will be displayed only in the Viewer window but the linear color values in the final rendered imagery with be unaffected.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#viewer-zoom","title":"Viewer Zoom","text":"<p>Viewer Zoom</p> <p></p> <p>If an image is too large to easily be seen in the viewer window, you can press the \"FIT\" icon in the viewer window to scale the imagery to the size of the viewer window. The hotkey for fitting the image to the viewer window is Control + F (Win/Linux) or Command + F (macOS).</p> <p>You can adjust the image zoom level in the viewer window with the menu that is located to the left of the fit icon. To jump to the 100% zoom level you can use the Control + 1 (Win/Linux) or Command + 1 (macOS) hotkey on your keyboard.</p> <p>Holding down the Control key (Win/Linux) or Command key (macOS) and scrolling the mouse wheel also allows you to zoom in/out on the imagery in the viewer window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#viewer-transparency","title":"Viewer Transparency","text":"<p>Viewer Transparency</p> <p></p> <p>The viewer \"\u2022\u2022\u2022\" kebab menu (the menu entry with three dots) has a \"Checker Underlay\" option that is used to toggle on/off the transparent background checkerboard pattern in the viewer. This will allow you to either have a black background shown behind your transparent alpha channel image areas or a dark grey checker pattern.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#proxy-modes","title":"Proxy Modes","text":"<p>Proxy Modes</p> <p>There are two proxy mode buttons in the Fusion UI. The proxy buttons are labeled \"Prx\" and \"APrx\" and are located just below the timeline, to the right of the playback controls.</p> <p>When you use the left mouse button to click on the \"Prx\" button you can toggle the proxy mode ON or OFF.</p> <p></p> <p>When the proxy mode is enabled, the viewer windows are rendered at a reduced resolution compared to your final output setting. This makes Fusion's viewer windows more responsive and interactive which is quite noticeable when you start to adjust nodes and update the node settings on footage over 2K in resolution.</p> <p>Using proxies as you develop a new comp is a very effective way to improve the rendering speed in your Viewer windows which is an essential workflow technique when working with high resolution media or on demanding composites that are slow to render.</p> <p></p> <p>If you click on the \"Prx\" button with your right mouse button, a popup menu will appear that lets you adjust the level of the proxy resolution reduction that is used when the proxy mode is enabled.</p> <p>Proxy level \"1\" will render the viewer window at full resolution. Setting the proxy level to a value higher than \"1\" will cause Fusion to reduce the quality of the imagery in the viewport by drastically reducing the render resolution. The proxy control has the ability to massively increase the speed that Fusion can update the imagery that is displayed in the viewer windows.</p> <p>The \"APrx\" button is the Auto Proxy mode and it is used to provide a way to have a \"draft quality\" like proxy mode enabled. The APrx feature is activated the moment you start adjusting sliders and settings for a node, which allows you to have a real-time preview of the changes. When you stop adjusting the node settings, the auto proxy rendering state will deactivate and then your standard resolution / proxy settings will be used.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#adding-nodes-quickly","title":"Adding Nodes Quickly","text":"<p>Adding Nodes Quickly</p> <p></p> <p>When you are working in Fusion's flow area, you can press the Shift + Space hotkey to open up the Add Tool dialog. This window provides a quick way to add new tools and macros to your scene without having to navigate through the menu system to find the right item.</p> <p>As you type in the name of the tool or macro you want to add, the list is updated with matching entries. You can type in partial names and the window will search for the closest item. In this example I typed in \"Alpha\" in the text field at the bottom of the dialog and only the nodes and macros with alpha in part of their name are listed.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#resolvefusion-scripting","title":"Resolve/Fusion Scripting","text":"<p>Resolve/Fusion Scripting</p> <p>Resolve Studio's scripting API and pipeline customization support has slowly improved since Python and Lua scripting were added in Resolve v15 back in 2018. The Resolve scripting API was originally added at the same time as the Fusion page was brought into Resolve since it was derived from Fusion Studio's pre-existing FuScript bindings.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#scripting-options","title":"Scripting Options","text":"<p>Scripting Options</p> <p>Resolve Studio/Fusion Studio supports running scripts using Python 2.7 &amp; 3.6-3.10+, as well as Lua scripting. There is a \"Python Script Snippets for Fusion TDs\" Steakunderwater thread that collects useful Python compatible code snippets in one convenient place.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#gui-toolkits","title":"GUI Toolkits","text":"<p>GUI Toolkits</p> <p>If you create a Resolve script using Python or Lua you have the option of using an integrated GUI creation toolkit called \"UI Manager\" which is based upon the QT window manager. If you require more complex GUI creation tools you can also bring along your own PySide install.</p> <p>The Lua and Python scripting documentation for the Resolve API is located on-disk in the Developer folder. Additionally, there is a \"Workflow Integrations\" interface which adds NodeJS based scripting, too.</p> <p></p> <p>Note: The \"README.txt\" file in the Workflow Integrations folder also includes an aside that talks briefly about UI Manager. This readme document acts as the only official notes published by Blackmagic Design about the existence of the UI Manager GUI creation toolkit.</p> <p>In part, this sparse documentation situation is due to the fact that the Fusion 8 Scripting Guide PDF was published prior to the addition of the UI Manager library in Resolve/Fusion.</p> <p>This \"README.txt\" file is located on-disk at:</p> <p>Windows Docs:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Support\\Developer\\Workflow Integrations\\README.txt\n</code></pre> <p>macOS Docs:</p> <pre><code>/Library/Application Support/Blackmagic Design/DaVinci Resolve/Developer/Workflow Integrations/README.txt\n</code></pre> <p>Linux Docs:</p> <pre><code>Path to be validated.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#script-paths","title":"Script Paths","text":"<p>Script Paths</p> <p>User created Python and Lua scripts are placed on-disk in either of the two Resolve based \"Scripts\" folders:</p> <pre><code>C:\\Users\\&lt;User Account&gt;\\AppData\\Roaming\\Blackmagic Design\\DaVinci Resolve\\Support\\Fusion\\Scripts\\\n\nC:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Fusion\\Scripts\\\n</code></pre> <p>It is also possible to configure a relative filepath system called a \"PathMap'' which allows you to use a custom folder path for storing scripts, macros, and other resources. This is customized in the\"Fusion &gt; Fusion Settings...\" menu. In the Fusion Settings window, look under the left sidebar entry labelled \"PathMaps\".</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-class-browser-script","title":"Fusion Class Browser Script","text":"<p>Fusion Class Browser Script</p> <p>There is a 3<sup>rd</sup> Party Scripting API browser tool distributed in the Reactor Package Manager called the \"Fusion Class Browser\" that is helpful for learning more about undocumented scripting API features.</p> <p>This screenshot shows the results from examining the available Fairlight API functions using the Fusion Class Browser script.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#ui-manager-scripting-examples","title":"UI Manager Scripting Examples","text":"<p>UI Manager Scripting Examples</p> <p>The Steakunderwater Fusion community forum's \"Building GUIs With Fusion's UI Manager\" scripting thread provides example Lua and Python code to get you started.</p> <p>There is a companion \"UI Manager Lua &amp; Python Examples\" package in the Reactor Package Manager that simplifies the steps needed to download and install the collection of example script resources.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#scriptlib-files","title":"ScriptLib Files","text":"<p>ScriptLib Files</p> <p>Fusion has a .scriptlib file based-approach that can be used to run Lua code when a fresh Fusion session is started, or a new comp is created. Scriptlib files also allow the addition of new 3<sup>rd</sup> party Lua functions and global variables that are then available in all other Lua scripts you might run, and in fresh Fusion Console window sessions.</p> <p>The Reactor Package Manager provides a \"Resolve Essentials\" atom package that improves the QoL (Quality of Life) for Resolve based scripting enthusiasts. This package also restores a missing scriptlib file that comes included with Fusion Studio but not with Resolve Studio.</p> <p>This resource is copied into the scripts PathMap-based folder location of:</p> <p><code>Scripts:/bmd.scriptlib</code></p> <p>Which in Reactor terms equates to:</p> <p><code>Reactor:/Deploy/Scripts/bmd.scriptlib</code></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#actionsevent-callbacks","title":"Actions/Event Callbacks","text":"<p>Actions/Event Callbacks</p> <p>Resolve's Fusion page has an action/event callback system that is implemented via .fu and .zfu files. These documents are placed in the \"<code>Config:/</code>\" PathMap folder.</p> <p>A .fu file is a configuration document that is stored in a Lua table based text file. A .zfu file is a zip archive that holds a .fu file and any extra supporting resources like companion scripts or PNG formatted icons at the base level of the zip file with no encapsulating folders.</p> <p>If a user-created action needs access to an on-disk resource, there is a \"<code>$CFG/</code>\" token value that can be entered as a prefix to a Lua script's file path entry. This <code>$CFG</code> token represents the parent folder where the .zfu/.fu file is located on-disk:</p> <pre><code>Execute = [target:RunScript(\"$CFG/SomeScript.lua\", { mousex = args._sxpos, mousey = args._sypos })](&lt;../../target:RunScript(\"$CFG/SomeScript.lua\", { mousex = args._sxpos, mousey = args._sypos })&gt;),\n</code></pre> <p>A .fu file can be used to create new menus in Fusion Standalone, assign hotkeys to scripts and actions, and capture event hooks for many of the tasks a compositor carries out, as well as add drag-n-drop support for processing files dragged from a Desktop folder browsing window into the Nodes view.</p> <p>The UI Manager example scripts include a minimal prototype of a QT-based Action/Event script listener tool called \"Action Listener\". This script can help you discover new and novel ways to automate your compositing workflows.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#gpu-accelerated-effects","title":"GPU Accelerated Effects","text":"<p>GPU Accelerated Effects</p> <p>The Edit/Color/Fusion pages all support the use of OFX plugins.</p> <p>There is a customized version of the OFX plugin development documentation available in Resolve's Developer folder.</p> <p></p> <p>Resolve also has a DCTL (DaVinci Color Transform Language) that is used to create LUTS. More information about DCTL is available in BMD's Docs. Also check out the BaldAvenger GitHub repository for code examples.</p> <p></p> <p>The addition of the Fusion page in Resolve allowed for the inclusion of an \"Effects Template\" feature. These templates are installed using .setting and .drfx files which are based around Fusion macros that are packaged and used directly on clips in a video editing timeline.</p> <p>This system allows for any Fusion node to be wrapped into a Group/Macro container object and exported for use in the Edit page.</p> <p></p> <p>Custom GUI controls added to an Effects Template \"macro\" are accessible in the Inspector view on the Edit Page.</p> <p></p> <p>You are able to refine an Edit page effect using the controls provided by the Fusion page. This is done by clicking the small magic-wand icon next to the macro's name in the Inspector window. The magic-wand icon has a small arrow pointing towards the base of the wand.</p> <p></p> <p>Switching from the Edit page into the Fusion page in this fashion provides access to Fusion's traditional Spline and Keyframe editor views.</p> <p>These animation editing controls in Fusion are more full-featured for adjusting keyframes and spline curve tangents than is possible with traditional ResolveFX/OFX Plugins that are animated on the Edit page.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fusion-sdk","title":"Fusion SDK","text":"<p>Fusion SDK</p> <p>The Fusion page also has a Fusion SDK which is a C++ API. This development kit allows the creation of 2D Effects, 3D workspace based content, Renderer3D node based plugin rendering engines, the addition of new Loader/Saver node file formats, and more to be created.</p> <p>The FusionSDK C++ files are available by request to developers at zero cost but require the signing of an NDA (Non-Disclosure Agreement) with the BMD Developer program.</p> <p>I'd suggest you try contacting BMD's support team about this topic, or if you happen to see Steve Roberts or Matt Jefferson at a BMD booth at a tradeshow event near you, make sure to ask them for more details while meeting them in-person.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#fuse-sdk","title":"Fuse SDK","text":"<p>Fuse SDK</p> <p>The Fusion page has a Fuse API which allows DCTL (DaVinci Color Transform Language) based hardware accelerated graphics operations to be done inside a Lua scripted node that works seamlessly in a cross-platform way across Metal, OpenCL, and CUDA based GPUs.</p> <p>The Fuse API also supports LuaJIT based code to be used to do operations like render vector shapes, process image metadata, add custom image importer/exporter support, or apply effects. This Fuse API is the Fusion equivalent of Nuke Blink Scripting.</p> <p>BMD released a new Fuse SDK PDF guide this year which is an excellent document for getting developers and enthusiasts comfortable with the Fuse API. The guide comes with Resolve/Fusion v18 now but it is also possible to download the guide from the BMD Software Support Center's \"Latest Support Notes\" category: Fusion_Fuse_SDK.pdf</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#macros","title":"Macros","text":"<p>Macros</p> <p>A macro in the Fusion page is basically a grouped set of Fusion stock nodes that are collected inside a collapsible folder group.</p> <p>When a macro is created using a grouped object it can have an internal registry-based node identifier type of either a \"MacroOperator\" or a \"GroupOperator\".</p> <p>A macro is saved to disk as a plain text document that represents an ASCII-encoded Lua table structure on-disk. The macro file is saved with the file extension .setting.</p> <p>When making macros to share with other users, it is important to know that a GroupOperator node can be easily re-expanded and edited later in the Nodes view.</p> <p>A MacroOperator is harder to inspect as it needs you to copy the node into a programmer's plain text editor to revise its settings by hand.</p> <p>When you have a MacroOperator open in a text editor, you can find &amp; replace the word \"MacroOperator\" with \"GroupOperator\". This will allow you to visually expand that node's group in the Nodes view.</p> <p>When creating macros, expressions can be added, along with intool scripts, and custom UserControl based GUIs. This allows for the construction of unique purpose built nodes that can work in both the Fusion and Edit pages.</p> <p>There is an introductory \"Macro Building Essentials\" thread on the Steakunderwater forum that helps artists create their own macros in only a short period of time.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#building-guis-with-fusions-ui-manager","title":"Building GUIs With Fusion's UI Manager","text":"<p>Building GUIs With Fusion's UI Manager</p> <p>Resolve/Fusion supports the use of a native Lua and Python based GUI building system called the UI Manager library. This library is used whenever you need to create your own custom graphical user interface in a Fusion based Lua or Python script.</p> <p>The UI Manager allows you to add object oriented windows, buttons, text fields, sliders, tree list views, and controls that are accessible inside your script code. The UI Manager library is QT window manager based, and it is designed to replace Fusion 7's older IUP and AskUser dialog approaches when creating script based GUIs.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#available-gui-elements","title":"Available GUI Elements","text":"<p>Available GUI Elements</p> <p>As you start to construct new user interfaces in Resolve/Fusion, you can add the following GUI elements by placing them inside the window's <code>ui:VGroup{}</code> tag:</p> <ul> <li><code>ui:VGroup{}</code></li> <li><code>ui:HGroup{}</code></li> <li><code>ui:Stack{}</code></li> <li>\u25e6 <code>ui:VGap{}</code></li> <li><code>ui:HGap{}</code></li> <li><code>ui:Button{}</code></li> <li><code>ui:CheckBox{}</code></li> <li><code>ui:ColorPicker{}</code></li> <li><code>ui:ComboBox{}</code></li> <li><code>ui:DoubleSpinBox{}</code></li> <li><code>ui:Label{}</code></li> <li><code>ui:LineEdit{}</code></li> <li><code>ui:Slider{}</code></li> <li><code>ui:SpinBox{}</code></li> <li><code>ui:TabBar{}</code></li> <li><code>ui:TextEdit{}</code></li> <li><code>ui:Tree{}</code></li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#what-is-an-id-tag","title":"What is an ID Tag?","text":"<p>What is an ID Tag?</p> <p>In the UI Manager an important concept to understand at this point is that an ID tag string is placed inside the { } curly braces on every control in the GUI layout.</p> <p>The ID tag setting could be just a single letter in quotes or it could be a longer text string (written without spaces) that is used to define the name that Lua uses to access that specific GUI element from code.</p> <pre><code>ID = 'myCustomName',\n</code></pre> <p>ID tags are used to allow the UI Manager to respond uniquely to user interactions with each of the controls in a window such as handling button clicks, sliders, checkboxes, typing text in a textfield, etc...</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#addwindow","title":"AddWindow()","text":"<p>AddWindow()</p> <p>The AddWindow() command is used to create a new UI Manager window. This window holds the GUI elements in a user interface.</p> <p></p> <p>The following code snippet shows the bare minimum of code you need to add to a Lua script in order to create a new UI Manager based window that has a GUI element inside of it.</p> <p>In this piece of sample code a new window is created that has the title \"My First Window\". The label GUI element is added to the view that displays the textual message \"This is a Label\". You can close the new view by clicking on the standard window close box.</p> <pre><code>-- Create a new window\nlocal ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = { 100, 100, width, height },\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:Label{ ID = 'L', Text = 'This is a Label'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#how-do-i-use-the-new-gui-elements","title":"How do I use the new GUI elements?","text":"<p>How do I use the new GUI elements?</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uivgroup-uihgroup","title":"ui:VGroup{} / ui:HGroup{}","text":"<p>ui:VGroup{} / ui:HGroup{}</p> <p>The ui:VGroup{} and ui:HGroup{} GUI elements are used to create vertical and horizontal layouts inside the window. You can stack multiple of these group objects nested inside of each other to create complex GUIs with UI elements arranged onscreen in rows and columns, or even a grid style of layout is possible.</p> <p>Lua:</p> <pre><code>ui:VGroup{\n  ID = \"root\",\n  -- Add your GUI elements here:\n}.\n</code></pre> <p>Python:</p> <pre><code>ui.VGroup({\"ID\": \"root\"},[\n    # Add your GUI elements here:\n]),\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uivgap-uihgap","title":"ui:VGap{} / ui:HGap{}","text":"<p>ui:VGap{} / ui:HGap{}</p> <p>The ui:VGap{} and ui:HGap{} GUI elements are used to provide space between each of the GUI controls so it is easier to navigate inside the window and to create a more logical grouping of the elements inside of a ui:VGroup{} or ui:HGroup{} layout. The gap controls have options that allow you to define the space between controls using either pixels or a relative measurement.</p> <p>This example adds a 5 pixel wide horizontal gap between the controls that are placed on either side of a ui:HGap element in a ui:VGroup{} or ui:HGroup{} layout:</p> <p>Lua:</p> <pre><code>ui:HGap(5),\n</code></pre> <p>Python:</p> <pre><code>ui.HGap(5),\n</code></pre> <p>This example creates a flexible sized horizontal between the controls that are placed on either side of a ui:HGap element in a ui:VGroup{} or ui:HGroup{} layout:</p> <p>Lua:</p> <pre><code>ui:HGap(0, 1.0),\n</code></pre> <p>Python</p> <pre><code>ui.HGap(0, 1.0),\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uibutton","title":"ui:Button{}","text":"<p>ui:Button{}</p> <p>The ui:Button{} control will create a simple rectangular shaped clickable button.</p> <p></p> <p>You can assign a textual label to the new button by adding an attribute like: Text = 'The Button Label'. If your operating system's default font supports showing Emoji's or extended Unicode characters you can add them to the Text label string on a button, too.</p> <p>If you want to add a button to a UI Manager window layout that is done by writing an entry like this:</p> <pre><code>ui:Button{ID = \"MyButton\", Text = \"Connect\"},\n</code></pre> <p>The Text setting for the button is the actual label that is written on the button. You are able to use Unicode based Emoji icons as part of the Text label string if you are looking for an easy way to add a picture to the button.</p> <p>The ID setting for the button is the internal name that is used to access the button from other functions in your Lua script.</p> <p>After you have created a new ui:Button entry inside of your window creation code, further down in the Lua script you would add a matching function that responds to events that are triggered when the button is pressed.</p> <p>Since I have an ID setting of MyButton I would need to create a Lua function like this to handle the button clicking action:</p> <pre><code>function win.On.MyButton.Clicked(ev)\n    print('Hello World!')\nend\n</code></pre> <p>Inside of the win.On.MyButton.Clicked() function you are free to write in any Lua code you want.</p> <p>You can also rename the button's label once it has been clicked by assigning a new text string to the button label .Text attribute. The new string text that you can assign to the button label doesn't have to be a hard quoted object. It could be a string that is sourced at run-time from a dynamic element coming right from the active Fusion comp like the name of the active node selection, the current composite's filename, or it could come from any Lua variable you want to assign.</p> <p>Changing a button label at runtime using Lua:</p> <pre><code>function win.On.MyButton.Clicked(ev)\n    itm.MyButton.Text = \"Link Active\"\nend\n</code></pre> <p>Adding a button using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = { 100, 100, width, height },\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:HGroup{\n      Margin = 50,\n      ui:Button{ID = 'MyButton', Text = 'The Button Label'},\n    }\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nfunction win.On.MyButton.Clicked(ev)\n  print('Button Clicked')\n    disp:ExitLoop()\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Adding a button using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({'WindowTitle': 'My First Window', 'ID': 'MyWin', 'Geometry': [100, 100, 200, 50], 'Spacing': 0,},[\n    ui.VGroup({'Spacing': 0,},[\n        # Add your GUI elements here:\n        ui.HGroup({},[\n            # Add four buttons that have an icon resource attached and no border shading\n            ui.Button({\n                'ID': 'MyButton',\n                'Text': 'The Button Label',\n            }),\n        ]),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\ndef _func(ev):\n    print('Button Clicked')\n    disp.ExitLoop()\ndlg.On.MyButton.Clicked = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uicheckbox","title":"ui:CheckBox{}","text":"<p>ui:CheckBox{}</p> <p>The ui:CheckBox{} control will add a checkbox to the window layout. This control is used to define a boolean value which represents either a true (1) or false (0) logical state that corresponds visually to a checked or unchecked status for the control.</p> <p></p> <p>You can assign a label to the new checkBox by adding an attribute like:</p> <pre><code>Text = 'The Checkbox Label'.\n</code></pre> <p>Adding a Checkbox using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = { 100, 100, width, height },\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n    Margin = 50,\n\n    -- Add your GUI elements here:\n    ui:CheckBox{ID = 'MyCheckbox', Text = 'The Checkbox Label'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nfunction win.On.MyCheckbox.Clicked(ev)\n  print('[Checkbox] ' .. tostring(itm.MyCheckbox.Checked))\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Adding a Checkbox using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 400, 200],},[\n    ui.VGroup({\"Spacing\": 0,},[\n        # Add your GUI elements here:\n        ui.CheckBox({\"ID\": \"MyCheckbox\", \"Text\": \"The Checkbox Label\"}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndef _func(ev):\n    print(\"[Checkbox] \" + str(itm[\"MyCheckbox\"].Checked))\ndlg.On.MyCheckbox.Clicked = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uicolorpicker","title":"ui:ColorPicker{}","text":"<p>ui:ColorPicker{}</p> <p>The ui:ColorPicker{} control provides Red/Green/Blue color sliders and a preview color swatch that can be used to create a custom color value.</p> <p></p> <p>You can enter a default color for the ColorPicker using:</p> <pre><code>ui:ColorPicker{ ID = \"Color\", Color = { R = 0.753, G = 0.753, B = 0.753, A = 1}},\n</code></pre> <p>If you need an alpha channel slider in the ColorPicker then you can use:</p> <pre><code>ui:ColorPicker{ ID = \"Color\", Color = { R = 1, G = 1, B = 1, A = 1}, DoAlpha = true  },\n</code></pre> <p>You can read the color picker RGB float values using:</p> <pre><code>red = itm.Color.Color.R\ngreen = itm.Color.Color.G\nblue = itm.Color.Color.B\n</code></pre> <p>Adding a color picker using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = {100, 100, width, height},\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:ColorPicker{ID = 'Color'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uicombobox","title":"ui:ComboBox{}","text":"<p>ui:ComboBox{}</p> <p>The ui:ComboBox{} control allows you to show a ComboControl / Options Menu style of menu that allows you to select an individual menu item from a list of entries.</p> <p></p> <p>You can read the text string for the current ComboBox selection using \".CurrentText\" like this:</p> <pre><code>print(itm.MyCombo.CurrentText)\n</code></pre> <p>You can read the index value for the current ComboBox selection using \".CurrentIndex\" like this:</p> <pre><code>print(itm.MyCombo.CurrentIndex)\n</code></pre> <p>Note: You need to define the list of menu items outside the AddWindow() function using the AddItem() command.</p> <p>Adding a ComboBox using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,100\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = {100, 100, width, height},\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:ComboBox{ID = 'MyCombo', Text = 'Combo Menu'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\n-- Add the items to the ComboBox menu\nitm.MyCombo:AddItem('Apple')\nitm.MyCombo:AddItem('Banana')\nitm.MyCombo:AddItem('Cherry')\nitm.MyCombo:AddItem('Orange')\nitm.MyCombo:AddItem('Mango')\nitm.MyCombo:AddItem('Kiwi')\n\n-- This function is run when a user picks a different setting in the ComboBox control\nfunction win.On.MyCombo.CurrentIndexChanged(ev)\n  if itm.MyCombo.CurrentIndex == 0 then\n    -- Apple\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets make an apple crisp dessert.')\n  elseif itm.MyCombo.CurrentIndex == 1 then\n    -- Banana\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets make a banana split with ice cream.')\n  elseif itm.MyCombo.CurrentIndex == 2 then\n    -- Cherry\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets make some cherry tarts.')\n  elseif itm.MyCombo.CurrentIndex == 3 then\n    -- Orange\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets peel an orange and have sliced orange boats.')\n  elseif itm.MyCombo.CurrentIndex == 4 then\n    -- Mango\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets eat cubed mango chunks with yoghurt.')\n  elseif itm.MyCombo.CurrentIndex == 5 then\n    -- Kiwi\n    print('[' .. itm.MyCombo.CurrentText .. '] Lets have a fresh Kiwi snack.')\n  end\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Adding a ComboBox using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 400, 45], \"Spacing\": 10,},[\n    ui.VGroup({\"ID\": \"root\",},[\n        # Add your GUI elements here:\n        ui.ComboBox({\"ID\": \"MyCombo\", \"Text\": \"Combo Menu\"}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndef _func(ev):\n    if itm['MyCombo'].CurrentIndex == 0:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets make an apple crisp dessert.')\n    elif itm['MyCombo'].CurrentIndex == 1:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets make a banana split with ice cream')\n    elif itm['MyCombo'].CurrentIndex == 2:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets make some cherry tarts.')\n    elif itm['MyCombo'].CurrentIndex == 3:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets peel an orange and have sliced orange boats.')\n    elif itm['MyCombo'].CurrentIndex == 4:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets eat cubed mango chunks with yoghurt.')\n    elif itm['MyCombo'].CurrentIndex == 5:\n        print('[' + itm['MyCombo'].CurrentText + '] Lets have a fresh Kiwi snack.')\ndlg.On.MyCombo.CurrentIndexChanged = _func\n\n# Add the items to the ComboBox menu\nitm['MyCombo'].AddItem(\"Apple\")\nitm['MyCombo'].AddItem(\"Banana\")\nitm['MyCombo'].AddItem(\"Cherry\")\nitm['MyCombo'].AddItem(\"Orange\")\nitm['MyCombo'].AddItem(\"Mango\")\nitm['MyCombo'].AddItem(\"Kiwi\")\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uidoublespinbox","title":"ui:DoubleSpinBox{}","text":"<p>ui:DoubleSpinBox{}</p> <p>The ui:DoubleSpinBox{} control allows you to enter numeric values. This GUI element can be incremented by typing a number in directly, pressing the up and down arrow buttons, or by clicking in the number field and then scrolling your mouse scroll wheel.</p> <p></p> <p>You will typically want to control the size of the ui:DoubleSpinBox control in the GUI by placing it inside a ui:VGroup{} or ui:HGroup{} element.</p> <p>Adding a DoubleSpinBox number field using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,75\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = {100, 100, width, height},\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:DoubleSpinBox{ID='MySpinner'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nfunction win.On.MySpinner.ValueChanged(ev)\n  print('[DoubleSpinBox Value] '.. itm.MySpinner.Value)\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Adding a DoubleSpinBox number field using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 280, 45], \"Spacing\": 10,},[\n    ui.VGroup({\"ID\": \"root\"},[\n        # Add your GUI elements here:\n        ui.DoubleSpinBox({\"ID\": \"MySpinner\"}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndef _func(ev):\n    print( \"[DoubleSpinBox Value] \" + str(itm['MySpinner'].Value))\ndlg.On.MySpinner.ValueChanged = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uilabel","title":"ui:Label{}","text":"<p>ui:Label{}</p> <p>The ui:Label{} control allows you to add a block of non user editable text to the window.</p> <p></p> <p>Using several Label elements inside of your different ui:VGroup{} or ui:HGroup{} layouts can help visually break up a larger more complex window layout into smaller more logical groupings. This will make it easier for a user to understand what a set of controls can be used for.</p> <p>Adding a textual label using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = {100, 100, width, height},\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:Label{ID = 'L', Text = 'This is a Label', Alignment = { AlignHCenter = true, AlignTop = true },},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Adding a textual label using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 400, 200],},[\n    ui.VGroup({\"Spacing\": 0,},[\n        # Add your GUI elements here:\n        ui.Label({\"ID\": \"Label\", \"Text\": \"This is a Label\",}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uislider","title":"ui:Slider{}","text":"<p>ui:Slider{}</p> <p>The ui:Slider{} control provides a horizontal slider control.</p> <p></p> <p>Add a slider using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,100\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = {100, 100, width, height},\n  Spacing = 10,\n\n  ui:HGroup{\n    ID = 'root',\n\n    -- Add your GUI elements here:\n    ui:Slider{ID = 'MySlider'},\n\n    ui:Label{ID = 'MyLabel', Text = 'Value: ',},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n  disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nitm.MySlider.Value = 25\nitm.MySlider.Minimum = 0\nitm.MySlider.Maximum = 100\n\nfunction win.On.MySlider.ValueChanged(ev)\n  itm.MyLabel.Text = 'Slider Value: ' .. tostring(ev.Value)\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Add a slider using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 400, 100],},[\n    ui.HGroup({\"Spacing\": 0,},[\n        # Add your GUI elements here:\n        ui.Slider({\"ID\": \"MySlider\",}),\n        ui.Label({\"ID\": \"MyLabel\", \"Text\": \"Value:\",}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\nitm['MySlider'].Value = 25\nitm['MySlider'].Minimum = 0\nitm['MySlider'].Maximum = 100\n\ndef _func(ev):\n    itm['MyLabel'].Text = \"Slider Value: \" + str(ev['Value'])\n    print(\"Slider Value: \" + str(ev['Value']))\ndlg.On.MySlider.ValueChanged = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uilineedit","title":"ui:LineEdit{}","text":"<p>ui:LineEdit{}</p> <p>The ui:LineEdit{} control adds a single line based editable text field control.</p> <p></p> <p>The \"PlaceholderText\" attribute lets you define a label text that is shown when the field is empty. This is useful for indicating what the control is meant to be used for.</p> <p>Add a LineEdit field using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 400,200\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = { 100, 100, width, height },\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n    Margin = 50,\n\n    -- Add your GUI elements here:\n    ui:LineEdit{ID='MyLineTxt', Text = 'Hello Fusioneers!', PlaceholderText = 'Please Enter a few words.',},\n\n    ui:Button{ID = 'PrintButton', Text = 'Print Text'},\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nfunction win.On.PrintButton.Clicked(ev)\n  print(itm.MyLineTxt.Text)\nend\n\nfunction win.On.MyLineTxt.TextChanged(ev)\n    print(itm.MyLineTxt.Text)\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Add a LineEdit field using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 400, 125],},[\n    ui.VGroup({\"Spacing\": 10,},[\n        # Add your GUI elements here:\n        ui.LineEdit({\"ID\": \"MyLineTxt\", \"Text\": \"Hello Fusioneers!\", \"PlaceholderText\": \"Please Enter a few words.\", \"Weight\": 0.5}),\n        ui.Button({\"ID\": \"PrintButton\", \"Text\": \"Print Text\", \"Weight\": 0.5}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndef _func(ev):\n    print(itm['MyLineTxt'].Text)\ndlg.On.PrintButton.Clicked = _func\n\ndef _func(ev):\n    print(itm['MyLineTxt'].Text)\ndlg.On.MyLineTxt.TextChanged = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uitextedit","title":"ui:TextEdit{}","text":"<p>ui:TextEdit{}</p> <p>The ui:TextEdit{} control adds an editable text field. It is possible to render the text field contents using either unformatted plaintext or HTML.</p> <p></p> <p>A ui:TextEdit field's contents can be made read-only (and non-editable) by adding a \"ReadOnly\" tag like this:</p> <pre><code>ui:TextEdit{ID='Txt', Text = 'Hello', ReadOnly = true,}\n</code></pre> <p>You can change the contents of a ui:TextEdit field using either:</p> <pre><code>-- Plain unformatted text:\nitm.MyTxt.PlainText = 'Hello Fusioneers'\n\n-- HTML encoded text:\nitm.MyTxt.HTML = [&lt;h1&gt;HTML Formatted Text&lt;/h1&gt;&lt;p&gt;This this HTML rendered in a ui:TextEdit field!&lt;/p&gt;](&lt;../../&lt;h1&gt;HTML Formatted Text&lt;/h1&gt;&lt;p&gt;This this HTML rendered in a ui:TextEdit field!&lt;/p&gt;.md&gt;)\n</code></pre> <p>The \"PlaceholderText\" attribute lets you define a label text that is shown when the field is empty. This is useful for indicating what the control is meant to be used for.</p> <p>Add a TextEdit field using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 600,800\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'My First Window',\n  Geometry = { 100, 100, width, height },\n  Spacing = 10,\n\n  ui:VGroup{\n    ID = 'root',\n    Margin = 50,\n\n    -- Add your GUI elements here:\n    ui:TextEdit{ID='MyTxt', Text = 'Hello', PlaceholderText = 'Please Enter a few words.',}\n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\nfunction win.On.MyTxt.TextChanged(ev)\n    print(itm.MyTxt.PlainText)\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Add a TextEdit field using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({ \"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 600, 800], \"Spacing\": 10, \"Margin\": 10,},[\n    ui.VGroup({ \"ID\": \"root\",},[\n        # Add your GUI elements here:\n        ui.TextEdit({ \n            \"ID\": \"MyTxt\",\n            \"Text\": \"Hello\",\n            \"PlaceholderText\": \"Please Enter a few words.\",\n            \"Lexer\": \"fusion\",\n        }),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndef _func(ev):\n    print(itm['MyTxt'].PlainText)\ndlg.On.MyTxt.TextChanged = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#uitree","title":"ui:Tree{}","text":"<p>ui:Tree{}</p> <p>The ui:Tree{} control creates a spreadsheet like grid layout. This is useful for listing elements in a report with rows and columns.</p> <p></p> <p>The entries in a ui:Tree can be made clickable and sortable using the following tags:</p> <pre><code>ui:Tree{ID = 'Tree', SortingEnabled=true, Events = {  ItemDoubleClicked=true, ItemClicked=true }, },\n</code></pre> <p>You can detect a single click on a row using \"function win.On.Tree.ItemClicked(ev)\".</p> <p>You can detect a double click on a row using \"function win.On.Tree.ItemDoubleClicked(ev)\".</p> <p>Inside the single click or double click events you can read the row name text that was clicked with \"ev.item.Text[1]\". The index value in the [] brackets is the specific column heading text you want to display.</p> <p>You can edit the contents of a specific tree view cell that was clicked on using \"ev.column\" to access an individual cell:</p> <pre><code>-- A Tree view cell was clicked on\nfunction win.On.Tree.ItemClicked(ev)\n  -- You can use the ev.column value to edit a specific ui:Tree cell label\n  ev.item.Text[ev.column] = '*CLICK*'\nend\n</code></pre> <p>It is possible to add folding disclosure triangle sections to a tree view to have sub-headings. This is a more advanced topic so it will be discussed in a future tutorial.</p> <p>The width of each heading is adjusted using the \".ColumnWidth\" setting:</p> <pre><code>-- Resize the Columns\nitm.Tree.ColumnWidth[0] = 150\nitm.Tree.ColumnWidth[1] = 300\nitm.Tree.ColumnWidth[2] = 50\n</code></pre> <p>When you are dynamically re-building a tree view you can use the \"itm.Tree:Clear()\" command to clear out the existing items.</p> <p>Add a tree view using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 430,700\n\nwin = disp:AddWindow({\n  ID = 'MyWin',\n  WindowTitle = 'Tree',\n  Geometry = { 100, 100, width, height },\n  Spacing = 0,\n\n  ui:VGroup{\n    ID = 'root',\n    ui:Tree{ID = 'Tree', SortingEnabled=true, Events = {ItemDoubleClicked=true, ItemClicked=true}, },  \n  },\n})\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\n-- Add a header row.\nhdr = itm.Tree:NewItem()\nhdr.Text[0] = ''\nhdr.Text[1] = 'Column A'\nhdr.Text[2] = 'Column B'\nhdr.Text[3] = 'Column C'\nhdr.Text[4] = 'Column D'\nhdr.Text[5] = 'Column E'\nitm.Tree:SetHeaderItem(hdr)\n\n-- Number of columns in the Tree list\nitm.Tree.ColumnCount = 5\n\n-- Resize the Columns\nitm.Tree.ColumnWidth[0] = 100\nitm.Tree.ColumnWidth[1] = 75\nitm.Tree.ColumnWidth[2] = 75\nitm.Tree.ColumnWidth[3] = 75\nitm.Tree.ColumnWidth[4] = 75\nitm.Tree.ColumnWidth[5] = 75\n\n-- Add an new row entries to the list\nfor row = 1, 50 do\n  itRow = itm.Tree:NewItem();\n  -- String.format is used to create a leading zero padded row number like 'Row A01' or 'Row B01'.\n  itRow.Text[0] = string.format('Row %02d', row);\n  itRow.Text[1] = string.format('A %02d', row);\n  itRow.Text[2] = string.format('B %02d', row);\n  itRow.Text[3] = string.format('C %02d', row);\n  itRow.Text[4] = string.format('D %02d', row);  \n  itRow.Text[5] = string.format('E %02d', row);\n  itm.Tree:AddTopLevelItem(itRow)\nend\n\n-- A Tree view row was clicked on\nfunction win.On.Tree.ItemClicked(ev)\n  print('[Single Clicked] ' .. tostring(ev.item.Text[0]))\n\n  -- You can use the ev.column value to edit a specific ui:Tree cell label\n  ev.item.Text[ev.column] = '*CLICK*'\nend\n\n-- A Tree view row was double clicked on\nfunction win.On.Tree.ItemDoubleClicked(ev)\n  print('[Double Clicked] ' .. tostring(ev.item.Text[0]))\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre> <p>Add a tree view using Python:</p> <pre><code>ui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"Tree\", \"ID\": \"MyWin\", \"Geometry\": [100, 100, 430, 700], \"Spacing\": 0,},[\n    ui.VGroup({\"ID\": \"root\",},[\n        ui.Tree({\n            \"ID\": \"Tree\",\n            \"SortingEnabled\": True,\n            \"Events\": {\n                \"CurrentItemChanged\": True,\n                \"ItemActivated\": True,\n                \"ItemClicked\": True,\n                \"ItemDoubleClicked\": True,\n            },\n        }),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\n# Add a header row\nhdr = itm[\"Tree\"].NewItem()\n\nhdr.Text[0] = \"\"\nhdr.Text[1] = \"Column A\"\nhdr.Text[2] = \"Column B\"\nhdr.Text[3] = \"Column C\"\nhdr.Text[4] = \"Column D\"\nhdr.Text[5] = \"Column E\"\nitm[\"Tree\"].SetHeaderItem(hdr)\n\n# Number of columns in the Tree list\nitm[\"Tree\"].ColumnCount = 5\n\n# Resize the Columns\nitm[\"Tree\"].ColumnWidth[0] = 100\nitm[\"Tree\"].ColumnWidth[1] = 75\nitm[\"Tree\"].ColumnWidth[2] = 75\nitm[\"Tree\"].ColumnWidth[3] = 75\nitm[\"Tree\"].ColumnWidth[4] = 75\nitm[\"Tree\"].ColumnWidth[5] = 75\n\n# Add an new row entries to the list\nfor row in range(1,50):\n    itRow = itm[\"Tree\"].NewItem()\n\n    # .format is used to create a leading zero padded row number like \"Row A01\" or \"Row B01\".\n    itRow.Text[0] = \"Row {0:02d}\".format(row)\n\n    itRow.Text[1] = \"A {0:02d}\".format(row)\n    itRow.Text[2] = \"B {0:02d}\".format(row)\n    itRow.Text[3] = \"C {0:02d}\".format(row)\n    itRow.Text[4] = \"D {0:02d}\".format(row)\n    itRow.Text[5] = \"E {0:02d}\".format(row)\n\n    itm[\"Tree\"].AddTopLevelItem(itRow)\n\n# A Tree view row was clicked on\ndef _func(ev):\n    print(\"[Single Clicked] \" + str(ev[\"item\"].Text[0]))\ndlg.On.Tree.ItemClicked = _func\n\n# A Tree view row was double clicked on\ndef _func(ev):\n    print(\"[Double Clicked] \" + str(ev[\"item\"].Text[0]))\ndlg.On.Tree.ItemDoubleClicked = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#addconfig","title":"AddConfig","text":"<p>AddConfig</p> <p>AddConfig() is a function that is often used to capture window closing hotkeys events.</p> <p>This approach stops Fusion from closing your foreground composite document each time a user presses Escape, Control+W/Command+W, or Control+F4/Command+F4 when the user expects the hotkey will be used to actually close a UI Manager GUI window instead.</p> <p>AddConfig using Lua:</p> <pre><code>-- Check the current operating system platform\nlocal platform = (FuPLATFORM_WINDOWS and 'Windows') or (FuPLATFORM_MAC and 'Mac') or (FuPLATFORM_LINUX and 'Linux')\n\n-- Create the appropriate hotkey message if you are on Windows/Linux or Mac\nlocal hotkeyTextMessage = 'Press (Control + W) or (Control + F4) to close this window.'\nif platform == 'Mac' then\n    hotkeyTextMessage = 'Press (Command + W) or (Command + F4) to close this window.'\nend\n\n-- Create the UI Manager GUI\nlocal ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 900,132\n\nwin = disp:AddWindow({\n    ID = 'HotkeysWin',\n    TargetID = 'HotkeysWin',\n    WindowTitle = 'Dynamic Hotkeys',\n    Geometry = {0, 100, width, height},\n    Margin = 20,\n    Spacing = 0,\n\n    ui:HGroup{\n        ID = 'root',\n        -- Add your GUI elements here:\n\n        ui:Label{\n            ID = 'HotkeysLabel',\n            Alignment = {\n                AlignHCenter = true,\n                AlignTop = true,\n            },\n            Text = hotkeyTextMessage,\n            Font = ui:Font{\n                Family = 'Droid Sans Mono',\n                StyleName = 'Regular',\n                PixelSize = 24,\n                MonoSpaced = true,\n                StyleStrategy = {\n                    ForceIntegerMetrics = true,\n                },\n            },\n        },\n    },\n})\n\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\n-- The window was closed\nfunction win.On.HotkeysWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- The app:AddConfig() command that will capture the \"ESCAPE\", \"Control + W\", or \"Control + F4\" hotkeys so they will close the Dynamic Hotkeys window instead of closing the foreground composite.\napp:AddConfig('Hotkeys', {\n    Target {\n        ID = 'HotkeysWin',\n    },\n\n    Hotkeys {\n        Target = 'HotkeysWin',\n        Defaults = true,\n\n        CONTROL_W = 'Execute{cmd = [[app.UIManager:QueueEvent(obj, \"Close\", {})]]}',\n        CONTROL_F4 = 'Execute{cmd = [[app.UIManager:QueueEvent(obj, \"Close\", {})]]}',\n        ESCAPE = 'Execute{cmd = [[app.UIManager:QueueEvent(obj, \"Close\", {})]]}',\n    },\n})\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n\napp:RemoveConfig('Hotkeys')\ncollectgarbage()\n</code></pre> <p>AddConfig using Python:</p> <pre><code># The app:AddConfig() command that will capture the \"Escape\", \"Control + W\", or \"Control + F4\" hotkeys so they will close the window instead of closing the foreground composite. It is worth noting that comp.Execute() is run asynchronously so it might kick in the 2nd time the script is run in a Fusion session...\ncomp.Execute(\n\"\"\"\napp:AddConfig(\"MyWin\", {\n    Target {\n        ID = \"MyWin\",\n    },\n    Hotkeys {\n        Target = \"MyWin\",\n        Defaults = true,\n\n        CONTROL_W = \"Execute{cmd = [[app.UIManager:QueueEvent(obj, 'Close', {})]]}\",\n        CONTROL_F4 = \"Execute{cmd = [[app.UIManager:QueueEvent(obj, 'Close', {})]]}\",\n        ESCAPE = \"Execute{cmd = [[app.UIManager:QueueEvent(obj, 'Close', {})]]}\",\n    },\n})\n\"\"\")\n\nui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({\"WindowTitle\": \"My First Window\", \"ID\": \"MyWin\", \"TargetID\" : \"MyWin\", \"Geometry\": [25, 140, 950, 470], \"Spacing\": 0,},[\n    ui.VGroup({\"Spacing\": 0,},[\n        # Add your GUI elements here:\n        ui.Label({\"ID\": \"Label\", \"Text\": \"Press the \\\"Escape\\\", \\\"Control + W\\\", or \\\"Control + F4\\\" hotkeys to close this window.\",}),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#file-and-folder-browsing-dialogs","title":"File and Folder Browsing Dialogs","text":"<p>File and Folder Browsing Dialogs</p> <p>The RequestFile/RequestDir functions provide pre-made file browsing user interfaces for situations where you need to provide a \"Browse\" button that allows you to select files on-disk.</p> <p></p> <p></p> <p>Create a request file dialog using Python:</p> <pre><code># Display a file dialog using Python + UI Manager. This is an alternative to relying on a legacy AskUser dialog which only works in the Fusion page inside of Resolve.\n\nui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({'WindowTitle': 'Open File Dialog', 'ID': 'MyWin', 'Geometry': [100, 100, 500, 75],},[\n    ui.VGroup({'Spacing': 0,},[\n        # Add your GUI elements here:\n        ui.HGroup({'Weight': 0.0,},[\n            ui.Label({'ID': 'Label', 'Text': 'Filename', 'Weight': 0.1}),\n            ui.LineEdit({'ID': 'FileLineTxt', 'Text': '', 'PlaceholderText': 'Please Enter a filepath', 'Weight': 0.9}),\n            ui.Button({'ID': 'BrowseButton', 'Text': 'Browse', 'Geometry': [0, 0, 30, 50], 'Weight': 0.1}),\n        ]),\n        ui.VGap(),\n        ui.HGroup({'Weight': 0.1},[\n            ui.Button({'ID': 'OpenButton', 'Text': 'Open File', 'Geometry': [0, 0, 30, 50], 'Weight': 0.1}),\n        ]),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\ndef _func(ev):\n    print('[Open File] Button Clicked')\n    disp.ExitLoop()\ndlg.On.OpenButton.Clicked = _func\n\ndef _func(ev):\n    selectedPath = fu.RequestFile()\n    if selectedPath:\n        itm['FileLineTxt'].Text = str(selectedPath)\ndlg.On.BrowseButton.Clicked = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n\n# Expand relative filepaths using the Fusion based \"MapPath\" function:\nfilepath = app.MapPath(itm['FileLineTxt'].Text or '')\n# Alternatively you could expand comp file specific PathMaps using:\n# filepath = comp.MapPath(itm['FileLineTxt'].Text)\n\nprint('\\n\\n[Open File]', filepath)\n</code></pre> <p>Create a request directory dialog using Python:</p> <pre><code># Display a folder dialog using Python + UI Manager. This is an alternative to relying on a legacy AskUser dialog which only works in the Fusion page inside of Resolve.\n\nui = fu.UIManager\ndisp = bmd.UIDispatcher(ui)\n\ndlg = disp.AddWindow({'WindowTitle': 'Open Folder Dialog', 'ID': 'MyWin', 'Geometry': [100, 100, 500, 75],},[\n    ui.VGroup({'Spacing': 0,},[\n        # Add your GUI elements here:\n        ui.HGroup({'Weight': 0.0,},[\n            ui.Label({'ID': 'Label', 'Text': 'Foldername', 'Weight': 0.1}),\n            ui.LineEdit({'ID': 'FolderLineTxt', 'Text': '', 'PlaceholderText': 'Please Enter a folder path', 'Weight': 0.9}),\n            ui.Button({'ID': 'BrowseButton', 'Text': 'Browse', 'Geometry': [0, 0, 30, 50], 'Weight': 0.1}),\n        ]),\n        ui.VGap(),\n        ui.HGroup({'Weight': 0.1},[\n            ui.Button({'ID': 'OpenButton', 'Text': 'Open Folder', 'Geometry': [0, 0, 30, 50], 'Weight': 0.1}),\n        ]),\n    ]),\n])\n\nitm = dlg.GetItems()\n\n# The window was closed\ndef _func(ev):\n    disp.ExitLoop()\ndlg.On.MyWin.Close = _func\n\n# Add your GUI element based event functions here:\ndef _func(ev):\n    print('[Open Folder] Button Clicked')\n    disp.ExitLoop()\ndlg.On.OpenButton.Clicked = _func\n\ndef _func(ev):\n    selectedPath = fu.RequestDir()\n    if selectedPath:\n        itm['FolderLineTxt'].Text = str(selectedPath)\ndlg.On.BrowseButton.Clicked = _func\n\ndlg.Show()\ndisp.RunLoop()\ndlg.Hide()\n\n# Expand relative filepaths using the Fusion based \"MapPath\" function:\nfolderpath = app.MapPath(itm['FolderLineTxt'].Text or '')\n# Alternatively you could expand comp file specific PathMaps using:\n# folderpath = comp.MapPath(itm['FolderLineTxt'].Text)\n\nprint('\\n\\n[Open Folder]', folderpath)\n</code></pre> <p>Create file dialogs using Lua:</p> <pre><code>local ui = fu.UIManager\nlocal disp = bmd.UIDispatcher(ui)\nlocal width,height = 1024,200\n\nwin = disp:AddWindow({\n    ID = 'MyWin',\n    WindowTitle = 'Open File and Folder Dialogs',\n    Geometry = {100, 100, width, height},\n    Spacing = 10,\n    Margin = 50,\n\n    ui:VGroup{\n        ID = 'root',\n        Weight = 1,\n\n        -- Add your GUI elements here:\n        -- Open File\n        ui:HGroup{\n            ui:Label{\n                ID = 'FileLabel',\n                Text = 'File:',\n                Weight = 0.25,\n            },\n            ui:Label{\n                ID='FileTxt', \n                Text = 'Please Enter a file path.',\n                Weight = 1.5,\n            },\n            ui:Button{\n                ID = 'FileButton', \n                Text = 'Select a File',\n                Weight = 0.25,\n            },\n        },\n\n        -- Open Folder\n        ui:HGroup{\n            ui:Label{\n                ID = 'FolderLabel',\n                Text = 'Folder:',\n                Weight = 0.25,\n            },\n            ui:Label{\n                ID='FolderTxt',\n                Text = 'Please Enter a folder path.',\n                Weight = 1.5,\n            },\n            ui:Button{\n                ID = 'FolderButton', \n                Text = 'Select a Folder',\n                Weight = 0.25,\n            },\n        },\n    },\n})\n\n-- Add your GUI element based event functions here:\nitm = win:GetItems()\n\n-- The window was closed\nfunction win.On.MyWin.Close(ev)\n    disp:ExitLoop()\nend\n\n-- The Open File button was clicked\nfunction win.On.FileButton.Clicked(ev)\n    print('Open File Button Clicked')\n    selectedPath = tostring(fu:RequestFile('Brushes:/smile.tga'))\n\n    print('[File] ', selectedPath)\n    itm.FileTxt.Text = selectedPath\nend\n\n-- The Open Folder button was clicked\nfunction win.On.FolderButton.Clicked(ev)\n    print('Open Folder Button Clicked')\n    selectedPath = tostring(fu:RequestDir('Scripts:/Comp'))\n\n    print('[Folder] ', selectedPath)\n    itm.FolderTxt.Text = selectedPath\nend\n\nwin:Show()\ndisp:RunLoop()\nwin:Hide()\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#using-slashfor-to-batch-edit-nodes-in-a-comp","title":"Using SlashFor to Batch Edit Nodes in a Comp","text":"<p>Using SlashFor to Batch Edit Nodes in a Comp</p> <p>Normally a fuse is associated with creating visual imagery in Fusion's viewer window.</p> <p>There is another type of fuse that is possible and it is called a \"Console\" fuse. This is a tool that is designed simply to process text and print out results back into the Console window.</p> <p>In order to make it easier to build custom Python and Lua scripts that interface with Console fuses, a technology called a \"SlashCommand\" was created.</p> <p>The SlashCommands that are installed via Reactor exist on-disk at the PathMap location of:</p> <p><code>Reactor:/Deploy/Scripts/SlashCommand/</code></p> <p>When you type text into the Fusion Console window, with a leading slash character added, that line of text-based input is interpreted as a SlashCommand. This is used to launch a custom 3<sup>rd</sup> party Lua or Python script to parse the user input.</p> <p>Note: It would be theoretically possible to create a fully interactive \"MUD-like\" text-adventure game interpreter with a SlashCommand based script.</p> <p>SlashFor is by far the most significant SlashCommand fuse. It was created by WSL member tberakis in the following Reactor Submissions thread:</p> <p>WSL | [Submission] /for console slash-command</p> <p></p> <p>Here is an example of what the \"SlashFor\" tool returns in the Console when it is run without any parameters entered after the tool name:</p> <p></p> <p>Usage Example:</p> <pre><code>&gt; /for\nUsage: /for (selected|visible|all) [tooltype[,tooltype...]] [where &lt;condition&gt;] &lt;command&gt; [ &amp; &lt;command&gt;...]\nSupported commands:\n    animate &lt;input&gt; [(with &lt;modifier&gt;|remove)] [force]\n    color [tile &lt;color&gt;] [text &lt;color&gt;] [fill &lt;color&gt;]\n    get &lt;input&gt; ([at &lt;time&gt;])\n    getattrs &lt;attribute&gt;\n    select [(add|remove)]\n    set &lt;input&gt; ([at &lt;time&gt;] to &lt;value&gt;|expression &lt;exp&gt;)\n    setattrs &lt;attribute&gt; (to &lt;value&gt;)\n    setclip (to &lt;value&gt;)\n    setname (to &lt;value&gt;)\n    version [(up|down|to &lt;value&gt;)]\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#slashfor-syntax-examples","title":"SlashFor Syntax Examples","text":"<p>SlashFor Syntax Examples</p> <p>Set the Size of all selected tools to 1.0:</p> <pre><code>/for selected set Size to 1.0\n</code></pre> <p>Set \"Use GPU\" to Disable:</p> <pre><code>/for selected set UseGPU to 0\n/for all ColorCorrector set UseGPU to 0\n/for all Merge set UseGPU to 0\n/for all set UseGPU to 0\n</code></pre> <p>Set \"Use GPU\" to Auto:</p> <pre><code>/for selected set UseGPU to 1\n/for all ColorCorrector set UseGPU to 1\n/for all Merge set UseGPU to 1\n/for all set UseGPU to 1\n</code></pre> <p>Set \"Use GPU\" to Enable:</p> <pre><code>/for selected set UseGPU to 2\n/for all ColorCorrector set UseGPU to 2\n/for all Merge set UseGPU to 2\n/for all set UseGPU to 2\n</code></pre> <p>Set the SeetheRate of all FastNoise tools in the comp to 1.0:</p> <pre><code>/for all FastNoise set SeetheRate to 1.0\n</code></pre> <p>Double the current size of each Merge or Transform currently selected:</p> <pre><code>/for selected Merge,Transform set Size to value*2.0\n</code></pre> <p>Select all FastNoise tools:</p> <pre><code>/for all FastNoise select\n</code></pre> <p>Add all tools to the active selection where Size &gt; 1:</p> <pre><code>/for all where Size &gt; 1.0 select add\n</code></pre> <p>Remove all Merge tools from the active selection where Angle \\&lt; 0:</p> <pre><code>/for all Merge where Angle &lt; 0 select remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#loader-node","title":"Loader Node","text":"<p>Loader Node</p> <p>Set the EXR Part for a Loader node:</p> <pre><code>/for selected Loader set Clip1.OpenEXRFormat.Part to \"C\"\n\n/for selected Loader set Clip1.OpenEXRFormat.Part to \"directdiffuse\"\n</code></pre> <p>Set the RGBA EXR Channel names for Loader nodes, one command at a time:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\"\n/for all Loader set Clip1.OpenEXRFormat.GreenName to \"G\"\n/for all Loader set Clip1.OpenEXRFormat.BlueName to \"B\"\n/for all Loader set Clip1.OpenEXRFormat.AlphaName to \"A\"\n</code></pre> <p>Set the RGBA EXR Channel names for Loader nodes on a single line:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\" &amp; set Clip1.OpenEXRFormat.GreenName to \"G\" &amp; set Clip1.OpenEXRFormat.BlueName to \"B\" &amp; set Clip1.OpenEXRFormat.AlphaName to \"A\"\n</code></pre> <p>Set individual EXR Channel names for Loader nodes, one command at a time:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\"\n/for all Loader set Clip1.OpenEXRFormat.GreenName to \"G\"\n/for all Loader set Clip1.OpenEXRFormat.BlueName to \"B\"\n/for all Loader set Clip1.OpenEXRFormat.AlphaName to \"A\"\n/for all Loader set Clip1.OpenEXRFormat.ZName to \"Z\"\n/for all Loader set Clip1.OpenEXRFormat.CovName to \"pixelCover\"\n/for all Loader set Clip1.OpenEXRFormat.ObjIDName to \"objectID\"\n/for all Loader set Clip1.OpenEXRFormat.MatIDName to \"materialID\"\n/for all Loader set Clip1.OpenEXRFormat.UName to \"U\"\n/for all Loader set Clip1.OpenEXRFormat.VName to \"V\"\n/for all Loader set Clip1.OpenEXRFormat.XNormName to \"NX\"\n/for all Loader set Clip1.OpenEXRFormat.YNormName to \"NY\"\n/for all Loader set Clip1.OpenEXRFormat.ZNormName to \"NZ\"\n/for all Loader set Clip1.OpenEXRFormat.XVelName to \"velX\"\n/for all Loader set Clip1.OpenEXRFormat.YVelName to \"velY\"\n/for all Loader set Clip1.OpenEXRFormat.XRevVelName to \"rvelX\"\n/for all Loader set Clip1.OpenEXRFormat.YRevVelName to \"rvelY\"\n/for all Loader set Clip1.OpenEXRFormat.XPosName to \"posX\"\n/for all Loader set Clip1.OpenEXRFormat.YPosName to \"posY\"\n/for all Loader set Clip1.OpenEXRFormat.ZPosName to \"posZ\"\n/for all Loader set Clip1.OpenEXRFormat.XDispName to \"dispX\"\n/for all Loader set Clip1.OpenEXRFormat.YDispName to \"dispY\"\n</code></pre> <p>Set all of the available EXR Channel names for Loader nodes on a single line:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\" &amp; set Clip1.OpenEXRFormat.GreenName to \"G\" &amp; set Clip1.OpenEXRFormat.BlueName to \"B\" &amp; set Clip1.OpenEXRFormat.AlphaName to \"A\" &amp; set Clip1.OpenEXRFormat.ZName to \"Z\" &amp; set Clip1.OpenEXRFormat.CovName to \"pixelCover\" &amp; set Clip1.OpenEXRFormat.ObjIDName to \"objectID\" &amp; set Clip1.OpenEXRFormat.MatIDName to \"materialID\" &amp; set Clip1.OpenEXRFormat.UName to \"U\" &amp; set Clip1.OpenEXRFormat.VName to \"V\" &amp; set Clip1.OpenEXRFormat.XNormName to \"NX\" &amp; set Clip1.OpenEXRFormat.YNormName to \"NY\" &amp; set Clip1.OpenEXRFormat.ZNormName to \"NZ\" &amp; set Clip1.OpenEXRFormat.XVelName to \"velX\" &amp; set Clip1.OpenEXRFormat.YVelName to \"velY\" &amp; set Clip1.OpenEXRFormat.XRevVelName to \"rvelX\" &amp; set Clip1.OpenEXRFormat.YRevVelName to \"rvelY\" &amp; set Clip1.OpenEXRFormat.XPosName to \"posX\" &amp; set Clip1.OpenEXRFormat.YPosName to \"posY\" &amp; set Clip1.OpenEXRFormat.ZPosName to \"posZ\" &amp; set Clip1.OpenEXRFormat.XDispName to \"dispX\" &amp; set Clip1.OpenEXRFormat.YDispName to \"dispY\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#mediain-node","title":"MediaIn Node","text":"<p>MediaIn Node</p> <p>Set the MediaID tag on a MediaIn node:</p> <pre><code>/for selected MediaIn set MediaID to \"445f0cf6-8888-4f2d-9014-1fa8829e9acd\"\n</code></pre> <p>Set the EXR Part for a MediaIn node:</p> <pre><code>/for selected MediaIn set Layer to \"C\"\n/for selected MediaIn set Layer to \"directdiffuse\"\n</code></pre> <p>Set the RGBA EXR Channel names for a MediaIn node, one command at a time:</p> <pre><code>/for selected MediaIn set RedName to \"R\"\n/for selected MediaIn set GreenName to \"G\"\n/for selected MediaIn set BlueName to \"B\"\n/for selected MediaIn set AlphaName to \"A\"\n</code></pre> <p>Set the RGBA EXR Channel names for a MediaIn node, on a single line:</p> <pre><code>/for selected MediaIn set RedName to \"R\" &amp; set GreenName to \"G\" &amp; set BlueName to \"B\" &amp; set AlphaName to \"A\"\n\n/for selected MediaIn set RedName to \"C.R\" &amp; set GreenName to \"C.G\" &amp; set BlueName to \"C.B\" &amp; set AlphaName to \"C.A\"\n</code></pre> <p>Set the In/Out time range for a MediaIn node:</p> <pre><code>/for selected MediaIn set GlobalIn to 0 &amp; set GlobalOut to 47\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#animate","title":"Animate","text":"<p>Animate</p> <p>Animate Size of all selected tools with default modifier (BezierSpline):</p> <pre><code>/for selected animate Size\n</code></pre> <p>Animate Size of all visible tools (ie not modifiers) with CubicSpline:</p> <pre><code>/for visible animate Size with CubicSpline\n</code></pre> <p>Animate Size of all selected tools, replacing any already animated ones:</p> <pre><code>/for selected animate Size force\n</code></pre> <p>Animate Seethe of all FastNoise tools, creating a ramp from 1.0 to 5.0 over 100 frames:</p> <pre><code>/for all FastNoise animate Seethe &amp; set Seethe at 0 to 1.0 &amp; set Seethe at 100 to 5.0\n</code></pre> <p>Remove animation from Size of all selected tools:</p> <pre><code>/for selected animate Size remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#expressions","title":"Expressions","text":"<p>Expressions</p> <p><code>/for</code> can be limited to only affect a subset of the nodes in a comp using the term \"<code>where &lt;expression&gt;</code>\".</p> <p>Set the Size of all selected tools to 1.0, if it's already &gt; 1.0:</p> <pre><code>/for selected where Size &gt; 1 set Size to 1.0\n</code></pre> <p>Set is able to create Fusion-based expression entries on node inputs, too.</p> <p>Set a Seethe expression on selected FastNoise tools:</p> <pre><code>/for selected FastNoise set Seethe expression time/10.0\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#select","title":"Select","text":"<p>Select</p> <p>The 'select' command changes the active selection of nodes in the Nodes view area:</p> <p>Select all FastNoise tools:</p> <pre><code>/for all FastNoise select\n</code></pre> <p>Add all tools to the selection where Size &gt; 1:</p> <pre><code>/for all where Size &gt; 1.0 select add\n</code></pre> <p>Remove all Merge tools from the selection where Angle \\&lt; 0:</p> <pre><code>/for all Merge where Angle &lt; 0 select remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#color","title":"Color","text":"<p>Color</p> <p>The 'color' command is used to modify node colors in the Node view.</p> <p>Set the tile color to red for selected tools:</p> <pre><code>/for selected color tile 1,0,0\n</code></pre> <p>Set the text color to green for selected FastNoise tools with a non-zero SeetheRate:</p> <pre><code>/for selected FastNoise where SeetheRate ~= 0 color text 0,1,0\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#set-name","title":"Set Name","text":"<p>Set Name</p> <p>Rename a node:</p> <pre><code>/for selected Loader setname to \"MyLoader\"\n/for selected Saver setname to \"MySaver\"\n/for selected Fuse.vTextCreate setname to \"Txt\"\n/for selected Fuse.vNumberCreate setname to \"Num\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#set-clip-filenames","title":"Set Clip Filenames","text":"<p>Set Clip Filenames</p> <p>Set a Loader node's Clip filename:</p> <pre><code>/for all Loader setclip to \"Comp:/Import.0000.exr\"\n</code></pre> <p>Set a Saver node's Clip filename:</p> <pre><code>/for all Saver setclip to \"Comp:/Export.0000.exr\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#set-clip-version","title":"Set Clip Version","text":"<p>Set Clip Version</p> <p>If a Loader or Saver node has a version tag added to the clip filename like \"V001\" or \"v001\" then the <code>/for</code> versioning features will be your new best friend.</p> <p></p> <p>Set Loader or Saver Node Filename Version Tags:</p> <pre><code>/for selected version up\n/for selected version down\n/for selected version to 5\n\n/for all version up\n/for all version down\n/for all version to 99\n\n/for selected Loader version up\n/for selected Loader version down\n/for selected Loader version to 99\n\n/for selected Saver version up\n/for selected Saver version down\n/for selected Saver version to 99\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#set-attributes","title":"Set Attributes","text":"<p>Set Attributes</p> <p>Turn ON the passthrough option for the selected Loader nodes:</p> <pre><code>/for selected Loader setattrs TOOLB_PassThrough to true\n</code></pre> <p>Turn OFF the passthrough option for the selected Loader nodes:</p> <pre><code>/for selected Loader setattrs TOOLB_PassThrough to false\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#get-attributes","title":"Get Attributes","text":"<p>Get Attributes</p> <p>Read a node's attributes:</p> <pre><code>/for all getattrs TOOLS_RegID\n/for all getattrs TOOLST_Clip_Name\n/for all getattrs TOOLB_PassThrough\n</code></pre> <p>Read the most recent render time for the selected nodes:</p> <pre><code>/for selected getattrs TOOLN_LastFrameTime\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#get-input-values","title":"Get Input Values","text":"<p>Get Input Values</p> <p>Read a node's inputs:</p> <pre><code>/for all Transform get Aspect\n/for all get StyledText\n/for all get Font\n/for all get Center\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#modify-3d-meshes","title":"Modify 3D Meshes","text":"<p>Modify 3D Meshes</p> <p>FBX/OBJ 3D Meshes</p> <p>Rename the node:</p> <pre><code>/for selected SurfaceFBXMesh setname to \"pCubeFBX\"\n</code></pre> <p>FBX/OBJ - Modify the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceFBXMesh set ObjName to \"pCube\"\n</code></pre> <p>FBX/OBJ - Clear the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceFBXMesh set ObjName to \"\"\n</code></pre> <p>FBX/OBJ - Modify the take name:</p> <pre><code>/for selected SurfaceFBXMesh set TakeName to \"Take 999\"\n</code></pre> <p>FBX/OBJ - Modify the imported file name:</p> <pre><code>/for selected SurfaceFBXMesh set ImportFile to \"Comp:/Media/pCube.fbx\"\n\n/for selected SurfaceFBXMesh set ImportFile to \"Macros:/KartaVR/Images/roller_coaster_track.fbx\"\n</code></pre> <p>Alembic 3D Meshes</p> <p>Rename the node:</p> <pre><code>/for selected SurfaceAlembicMesh setname to \"pCubeABC\"\n</code></pre> <p>ABC - Modify the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceAlembicMesh set ObjName to \"Mesh/pCube\"\n</code></pre> <p>ABC - Clear the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceAlembicMesh set ObjName to \"\"\n</code></pre> <p>ABC - Modify the imported file name:</p> <pre><code>/for selected SurfaceAlembicMesh set ImportFile to \"Comp:/Media/pCube.abc\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#ofx-and-fuses","title":"OFX and Fuses","text":"<p>OFX and Fuses</p> <p>OFX plugins and Fuses can be targeted by SlashFor if you know their node type via the Registry ID value:</p> <pre><code>/for all ofx.com.frischluft.openFX.DepthOfField select\n/for all Fuse.Wireless select\n/for all Fuse.vImageWireless select\n/for all Fuse.vTextCreate select\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#render","title":"Render","text":"<p>Render</p> <p>The /for render flags make selective rendering of nodes in a comp easier:</p> <pre><code>/for render [step &lt;value&gt;]\n</code></pre> <p>Render Selected Nodes:</p> <pre><code>/for selected render\n</code></pre> <p>Render Selected nodes step by 25 frames at a time:</p> <pre><code>/for selected render step 25\n</code></pre> <p>Render all Saver nodes:</p> <pre><code>/for all Saver render\n</code></pre> <p>Render all Saver nodes step by 100 frames at a time:</p> <pre><code>/for all Saver render step 100\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#hypertext-compositor","title":"Hypertext Compositor","text":"<p>Hypertext Compositor</p> <p>Hypertext Compositor is an Interactive Documentation &amp; Walkthrough Tool for Compers</p> <p>The \"Hypertext Compositor\" tool is available in Reactor and it can be used to create e-documentation and templated comp walkthroughs. It is accessible in the Reactor \"Docs\" category.</p> <p></p> <p>The Hypertext Compositor script looks for an HTML formatted sidecar .htm webpage file in the same folder as a .comp file. This allows you to pass along an illustrated guide about the composite to other users.</p> <p>Hypertext Compositor supports the use of custom Fusion comp based HTML \"a href\" anchor codes to create guided tutorials that can control the Fusion timeline, adjust comp settings, add nodes/macros/media/3D models, run scripts, and display content in the viewer window when you click on the hyperlinks. If you (Shift + Click) on a hyperlink a preview of the URL will be displayed.</p> <p>In Resolve/Fusion you can also drag an .htm file from your desktop and drop it in the Nodes view and the webpage will be displayed in a new window.</p> <p>Hypertext Compositor was inspired by an old-school Fusion term called \"SBS\" or Side-by-Side that was used to represent an approach where a Lua script could be run by Fusion as soon as a .comp file of the same name was opened. The Hypertext Compositor extends this Side-by-Side system to support comp specific documentation.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#hypertext-compositor-screenshots","title":"Hypertext Compositor Screenshots","text":"<p>Hypertext Compositor Screenshots</p> <p>Here are two screenshots that show the Hypertext Compositor window active with a side-by-side webpage loaded. The clickable links are able to help guide the usage of the composite that is open.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#hypertext-compositor-usage","title":"Hypertext Compositor Usage","text":"<p>Hypertext Compositor Usage</p> <p>If you had a composite called \"wesuckless.comp\", the SBS HTML formatted sidecar file would be named \"wesuckless.htm\". When the composite is opened using the \"File &gt; Open...\" or \"File &gt; Open Recent &gt;\" menu items, the matching HTML guide would be displayed automatically.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Installing%20the%20BMD%20Resolve%20_%20Fusion%20Software/#hypertext-compositor-editor","title":"Hypertext Compositor Editor","text":"<p>Hypertext Compositor Editor</p> <p>An HTML code editor is provided that makes it easy to live-edit and preview the .htm documentation with the images visible, and special clickable hyperlinks are active, too. At the top left of the Editor UI is a ComboBox menu that allows you to quickly add the commands to control a Fusion session.</p> <p></p> <p>Images</p> <p>The HTML Viewer supports PNG images. You can refer to the media using a PathMap based image embedding source URL. To display an image with a relative path starting at the same folder as your .comp/.htm file is located use:</p> <pre><code>&lt;img src=\"Comp:/example.png\"&gt;\n</code></pre> <p>or you could make a \"docs\" subfolder in your comp directory using and display the image using:</p> <pre><code>&lt;img src=\"Comp:/docs/example.png\"&gt;\n</code></pre> <p>HTML Anchor Commands</p> <p>Select a node by name:</p> <pre><code>&lt;p&gt;&lt;a href=\"Select://Saver1\"&gt;Saver&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View the selected node:</p> <pre><code>&lt;p&gt;&lt;a href=\"View://\"&gt;View Selected Node&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View the selected node on the left viewer:</p> <pre><code>&lt;p&gt;&lt;a href=\"ViewLeft://\"&gt;View Selected on Left&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View the selected node on the right viewer:</p> <pre><code>&lt;p&gt;&lt;a href=\"ViewRight://\"&gt;View Selected on Right&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View a node by name:</p> <pre><code>&lt;p&gt;&lt;a href=\"View://FastNoise1\"&gt;FastNoise1&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View a node on the left viewer by name:</p> <pre><code>&lt;p&gt;&lt;a href=\"ViewLeft://FastNoise1\"&gt;FastNoise1&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>View a node on the right viewer by name:</p> <pre><code>&lt;p&gt;&lt;a href=\"ViewRight://FastNoise1\"&gt;FastNoise1&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Frame a view:</p> <pre><code>&lt;p&gt;&lt;a href=\"FrameAll://FlowView\"&gt;FrameAll FlowView&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Rename the selected node:</p> <pre><code>&lt;p&gt;&lt;a href=\"Rename://CharlieLoader\"&gt;Rename the node to CharlieLoader&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Render a node by name:</p> <pre><code>&lt;p&gt;&lt;a href=\"Render://Saver1\"&gt;Saver&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Start the sequence playback:</p> <pre><code>&lt;p&gt;&lt;a href=\"Play://\"&gt;Play&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Rewind the playback:</p> <pre><code>&lt;p&gt;&lt;a href=\"Rewind://\"&gt;Rewind Playback&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Go to a specific frame in the timeline:</p> <pre><code>&lt;p&gt;&lt;a href=\"Time://12\"&gt;Jump to frame 12&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Nudge the Playhead in the timeline to step between keyframes and in between keyframes:</p> <pre><code>&lt;p&gt;&lt;a href=\"NudgePlayhead://Right\"&gt;Nudge Playhead Right&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"NudgePlayhead://Left\"&gt;Nudge Playhead Left&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Stop the playback:</p> <pre><code>&lt;p&gt;&lt;a href=\"Stop://\"&gt;Stop the Playback&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Save the composite:</p> <pre><code>&lt;p&gt;&lt;a href=\"Save://\"&gt;Save the .comp&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Load a composite:</p> <pre><code>&lt;p&gt;&lt;a href=\"Load://Comp:/sidecar_demo_end.comp\"&gt;Load a .comp&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"Load://Reactor:/Deploy/Comps/Templates/UT_Anonymous_Water.comp\"&gt;Load a .comp&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Add a macro:</p> <pre><code>&lt;p&gt;&lt;a href=\"AddSetting://Reactor:/Macros/Creator/NyanCat.setting\"&gt;Add the NyanCat macro&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Add a node:</p> <pre><code>&lt;p&gt;&lt;a href=\"AddTool://GridWarp\"&gt;Add GridWarp node&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Add a Loader node:</p> <pre><code>&lt;p&gt;&lt;a href=\"AddMedia://Comp:/Render/image.0000.exr\"&gt;Add an image&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"AddMedia://Reactor:/Deploy/Macros/KartaVR/Images/latlong_wide_ar.jpg\"&gt;Add an image&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Run a script:</p> <pre><code>&lt;p&gt;&lt;a href=\"RunScript://Reactor:/Deploy/Scripts/Comp/hos_SplitEXR_Ultra.lua\"&gt;Split the selected EXR image&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Open Reactor:</p> <pre><code>&lt;p&gt;&lt;a href=\"AddAtom://\"&gt;Open the Reactor package manager&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Toggle the passthrough mode on a node:</p> <pre><code>&lt;p&gt;&lt;a href=\"PassthroughOn://Loader1\"&gt;Passthrough On Loader1&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"PassthroughOff://Loader1\"&gt;Passthrough Off Loader1&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Toggle the passthrough mode on the currently selected node:</p> <pre><code>&lt;p&gt;&lt;a href=\"PassthroughOn://\"&gt;Passthrough On Selected Node&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"PassthroughOff://\"&gt;Passthrough Off Selected Node&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Run a shell command from the terminal:</p> <pre><code>&lt;p&gt;&lt;a href=\"Shell://env\"&gt;List environment variables on Mac/Linux&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;&lt;a href=\"Shell://set\"&gt;List environment variables on Windows&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Run a Lua/Python command:</p> <pre><code>&lt;p&gt;&lt;a href=\"Execute://Print([=[Hello World]=])\"&gt;Print \"Hello World\" in the Fusion Console&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Run a Fusion action:</p> <pre><code>&lt;p&gt;&lt;a href=\"DoAction://App_CustomizeHotkeys\"&gt;Run the Customize Hotkeys Action&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Lock the comp to suppress file dialogs:</p> <pre><code>&lt;p&gt;&lt;a href=\"Lock://\"&gt;Lock the Comp&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Unlock the comp to show file dialogs:</p> <pre><code>&lt;p&gt;&lt;a href=\"Unlock://\"&gt;Unlock the Comp&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Undo the last action:</p> <pre><code>&lt;p&gt;&lt;a href=\"Undo://\"&gt;Undo&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Redo the last action:</p> <pre><code>&lt;p&gt;&lt;a href=\"Redo://\"&gt;Redo&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Show a preference window:</p> <pre><code>&lt;p&gt;&lt;a href=\"ShowPrefs://PrefsScript\"&gt;Show the scripting preference window&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Import an ABC file:</p> <pre><code>&lt;p&gt;&lt;a href=\"AbcImport://\"&gt;Import ABC Mesh&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Import an FBX/OBJ file:</p> <pre><code>&lt;p&gt;&lt;a href=\"FBXImport://\"&gt;Import FBX/OBJ Mesh&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Import an SVG Vector file:</p> <pre><code>&lt;p&gt;&lt;a href=\"SVGImport://\"&gt;Import SVG Vector&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Import a Shape file:</p> <pre><code>&lt;p&gt;&lt;a href=\"ShapeImport://\"&gt;Import Shape&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Toggle the display of the Bins window:</p> <pre><code>&lt;p&gt;&lt;a href=\"Bins://\"&gt;Toggle Bin Window&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>Toggle the display of the Render Manager window:</p> <pre><code>&lt;p&gt;&lt;a href=\"RenderManager://\"&gt;Toggle Render Manager Window&lt;/a&gt;&lt;/p&gt;\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Kartaverse%20Development%20Reference%20Hardware/","title":"Kartaverse Development Reference Hardware","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The Kartaverse v5 release was developed using the following reference computer hardware:</p> <p>Windows 10 &amp; 11 / Rocky Linux 8.5:</p> <ul> <li>ASRock TRX 40 Creator Motherboard</li> <li>AMD Ryzen Threadripper 3990X Desktop CPU</li> <li>NVIDIA GeForce RTX 3090 GPU 24 GB VRAM</li> <li>256 GB RAM</li> <li>10 GB Ethernet Networking</li> </ul> <p>macOS Monterey:</p> <ul> <li>M1 MacBook AIR 16GB RAM, 2 TB HD</li> <li>OWC Thunderbolt 3 Pro Dock with 10Gb Ethernet</li> </ul> <p>Oculus Quest \"Santa Cruz\" HMD Dev Kit</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Kartaverse%20Learning%20Resources/","title":"Kartaverse Learning Resources","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <ul> <li>Kartaverse Google Group</li> <li>KartaVR Documentation</li> <li>KartaVR Facebook Group (Paused)</li> <li>KartaVR Steakunderwater Forum Thread</li> <li>Reactor Package Manager Steakunderwater Forum Thread</li> </ul> <p>KartaLink</p> <ul> <li>Render Fusion Comps in Houdini TOPs</li> <li>KartaLink MediaCommand Steakunderwater Forum Thread</li> </ul> <p>Vonk Ultra</p> <ul> <li>Vonk Ultra Documentation</li> <li>Vonk Ultra GitLab Repository</li> <li>Vonk Ultra Steakunderwater Forum Thread</li> </ul> <p>Workflow Guides</p> <ul> <li>KartaVR Compositing Examples</li> <li>KartaVR Workflows | Creating ST Maps</li> <li>KartaVR Workflows | YouTube 360 to Equirectangular Conversions</li> <li>Kartaverse Workflows | Creating Volumetric NeRFs</li> <li>Kartaverse Workflows | Jupyter Notebook for Resolve/Fusion</li> <li>Kartaverse Workflows | SketchFab in VR Via QuestLink</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Kartaverse%20Project%20Assistance/","title":"Kartaverse Project Assistance","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>If you want to assist the Kartaverse effort, the best way to help is to provide access to camera original \"raw\" unprocessed footage from a wide range of digital cinema cameras, DSLR/mirrorless cameras, flagship multi-lens mobile phones, drones, 360VR camera rigs, structured light depth sensors, lightfield cameras, and LIDAR scanners with permissive licensing. Anything you can share helps greatly.</p> <p>Having new, modern, example footage to work with helps the whole Kartaverse community as it pushes forward the ongoing development of new tools, techniques and workflows.</p> <p>It is important, if possible, that the sample footage is shared with permissive license terms that would allow the media to be used under a Creative Commons Attribution-ShareAlike 4.0 International license. This media usage policy allows new example project files to be created and shared broadly with the community for learning purposes.</p> <p>If you have access to sample footage that you are willing to share and are the copyright holder, please email me. Thanks!</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Overview/","title":"Overview","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The pipeline integration guide is written with the goal of helping new visual effects teams get up-and-running with a BMD (Blackmagic Design) Resolve Studio v18 &amp; Fusion Studio v18 centric pipeline from scratch.</p> <p>Since this is a workflow automation focused document, it will also cover the WSL Reactor Package Manager, the installation and use of render managers, the installation and configuration of 3<sup>rd</sup> party DCC (digital content creation) tools from the perspective of a compositor's needs, an overview of common Windows/Linux/macOS command-line utilities, bare-metal Windows/Linux operating system reloads, OpenColorIO, OpenImageIO, and more.</p> <p>The end audience for this guide is primarily artists who are considering adopting \"The Kartaverse\" pipeline tools into their workflows.</p> <p>If you would like technical assistance with the Kartaverse, check out the project's new Kartaverse Google Group.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/","title":"Photogrammetry Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#agisoft-metashape-deployment","title":"Agisoft Metashape Deployment","text":"<p>Agisoft Metashape Deployment</p> <p>Metashape is a popular Russian-made photogrammetry toolset that has cross-platform support for Windows, Linux, and macOS.</p> <p>https://www.agisoft.com/</p> <p>The Metashape standard edition is very affordable. The professional version adds video processing, GPS coordinates, more advanced control registration options, command-line support, Python scripting access, and render cluster option for using multiple computers to process more data. It is possible to create high-quality MVS (Multi-View Stereo) generated depthmaps using Metashape Pro and its Python scripting interface.</p> <p>Note: The Agisoft Metashape software was previously known as Agisoft Photoscan prior to 2018.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#checking-metashape-command-line-parameters","title":"Checking Metashape Command-Line Parameters","text":"<p>Checking Metashape Command-Line Parameters</p> <p>If you need to check the current command-line parameters available in Metashape Pro, run the following code in the command-prompt:</p> <p>\"C:\\Program Files\\Agisoft\\Metashape Pro\\metashape.exe\" --help</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#setting-up-an-agi-metashape-pro-render-cluster","title":"Setting up an AGI Metashape Pro Render Cluster","text":"<p>Setting up an AGI Metashape Pro Render Cluster</p> <p>Let's enable network processing of data in Metashape Pro.</p> <pre><code># Start a single server instance and make sure all storage is NFS or SMB based.\n\"C:\\Program Files\\Agisoft\\Metashape Pro\\metashape.exe\" --server --control 10.20.30.1 --dispatch 10.20.30.1\n\n# Start up cluster nodes \n\"C:\\Program Files\\Agisoft\\Metashape Pro\\metashape.exe\" --node --dispatch 10.20.30.1\n</code></pre> <p>When you are in a Metashape Pro based GUI session, you should now enable the network processing option in the prefs.</p> <p>Switch in the Metashape Preferences window to the \"Network\" tab. Make sure to type in the address of the server that is controlling the whole compute farm into the \"Host name\" field. In my case this is a system with the IP address of \"10.20.30.1\". If you are running the session on your own local computer you can stick with the default value of \"127.0.0.1\".</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#kartavr-metashape-automation-script","title":"KartaVR Metashape Automation Script","text":"<p>KartaVR Metashape Automation Script</p> <p>KartaVR provides a \"Send to Photoscan\" script that allows you to export Loader/Saver based media from a Fusion composite into a new Agisoft Metashape .psx project file.</p> <p></p> <p>For More information</p> <ul> <li>Send Media to Photoscan Docs</li> <li>YouTube | Send Media to Photoscan Video</li> </ul> <p>With this Lua script you can select as many loader and saver node clips as you want in the Fusion flow area and all of those images will be added to the same \"chunk\" in the new AGI Photoscan project.</p> <p></p> <p>When a loader node with an image sequence is selected, the full frame range of the footage that is configured in the loader node will be sent to AGI Metashape as individual images. If a saver node is selected then an image sequence will be sent to AGI Metashape using the renderable start to end frame range values.</p> <p>The standard edition of Agisoft Metashape only knows how to open up JPEG, TIFF, PNG, BMP, EXR, TGA, PGM, PBM, and DNG images.</p> <p>If you have several video clips that you would like to use in Metashape standard edition then you should run that footage through the KartaVR Convert Movies to Image Sequences script first and it will process a folder full of movie files and output ready to use image sequences.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#colmap","title":"COLMAP","text":"<p>COLMAP</p> <p>COLMAP is a cross-platform compatible open-source photogrammetry toolset. It creates point cloud and polygon mesh based outputs and supports command-line operation as well as having a GUI.</p> <p>https://colmap.github.io/</p> <p>For More Information:</p> <ul> <li>COLMAP Installation</li> <li>COLMAP Tutorials</li> <li>COLMAP CLI</li> <li>COLMAP FAQ</li> </ul> <p>COLMAP is best known in recent times for being the command-line SfM based camera registration tool used by NVIDIA's InstantNGP toolset for NeRF based scene creation.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#reality-capture-ppi-deployment","title":"Reality Capture PPI Deployment","text":"<p>Reality Capture PPI Deployment</p> <p>Reality Capture is a Windows based photogrammetry toolset that was acquired by Epic Games.</p> <p>https://www.capturingreality.com/RealityCapture-PPI</p> <p>Reality Capture heavily relies on a NVIDIA CUDA GPU to perform the multi-view image registration and alignment stages. Reality Capture supports the use of a Windows command-prompt based command-line interface for automation.</p> <p>Reality Capture's best strength is being able to import and work with tens of thousands of images from a photogrammetry scanning project. You don't have to pre-filter the camera views to the same extent that other photogrammetry tools require.</p> <p>Reality Capture scene export parameters can be saved into an XML based file format:</p> <pre><code>&lt;ModelExport exportBinary=\"1\" exportInfoFile=\"1\" exportVertices=\"1\" exportVertexColors=\"0\"\n   exportVertexNormals=\"0\" exportTriangles=\"1\" exportTexturing=\"1\" meshColor=\"4294967295\"\n   tileType=\"0\" exportTextureAlpha=\"0\" exportToOneTexture=\"0\" oneTextureMaxSide=\"16384\"\n   oneTextureUsePow2TexSide=\"1\" exportCoordinateSystemType=\"1\" settingsAnchor=\"0 0 0\"\n   settingsScalex=\"1\" settingsScaley=\"1\" settingsScalez=\"1\" texturesFileType=\"png\"\n   formatAndVersionUID=\"obj 000 \" exportModelByParts=\"0\" exportRandomPartColor=\"0\"\n   exportCameras=\"0\" exportCamerasAsModelPart=\"0\" numberAsciiFormatting=\"%.16e\"&gt;\n  &lt;Header magic=\"5786949\" version=\"1\"/&gt;\n&lt;/ModelExport&gt;\n</code></pre> <p>Scene cropping in Reality Capture can be saved to a .rcbox file that internally is an XML based file format:</p> <pre><code>&lt;ReconstructionRegion globalCoordinateSystem=\"+proj=geocent +ellps=WGS84 +no_defs\" globalCoordinateSystemName=\"local:1 - Euclidean\"\n   isGeoreferenced=\"1\" isLatLon=\"0\" yawPitchRoll=\"0 -0 -0\"&gt;\n  &lt;widthHeightDepth&gt;6.86994028091431 7.52994060516357 6.13969278335571&lt;/widthHeightDepth&gt;\n  &lt;Header magic=\"5395016\" version=\"2\"/&gt;\n  &lt;CentreEuclid&gt;\n    &lt;centre&gt;-0.607471704483032 0.591201782226563 12.0405006408691&lt;/centre&gt;\n  &lt;/CentreEuclid&gt;\n  &lt;Residual R=\"1 0 0 0 1 0 0 0 1\" t=\"0 0 0\" s=\"1\"/&gt;\n&lt;/ReconstructionRegion&gt;\n</code></pre> <p>When automating multi-view Reality Capture\u00a0workflows, it is helpful to know that the toolset is able to export each of the active camera locators to an XMP metadata format that includes both the transform matrix and lens distortion parameters. XMP data is internally stored in an XML based file format:</p> <pre><code>&lt;x:xmpmeta xmlns:x=\"adobe:ns:meta/\"&gt;\n  &lt;rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"&gt;\n    &lt;rdf:Description xcr:Version=\"2\" xcr:PosePrior=\"locked\" xcr:ComponentId=\"{02FFA67D-FB37-48C9-AAAE-115D1A41F754}\"\n       xcr:DistortionModel=\"division\" xcr:DistortionCoeficients=\"-0.266409870680064 0 0 0 0 0\"\n       xcr:FocalLength35mm=\"15.8017301481925\" xcr:Skew=\"0\" xcr:AspectRatio=\"1\"\n       xcr:PrincipalPointU=\"0.00460590178527446\" xcr:PrincipalPointV=\"-0.00856809553444162\"\n       xcr:CalibrationPrior=\"locked\" xcr:CalibrationGroup=\"-1\" xcr:DistortionGroup=\"-1\"\n       xcr:InTexturing=\"1\" xcr:InColoring=\"0\" xcr:InMeshing=\"1\" xcr:latitude=\"179.984035152606480N\"\n       xcr:longitude=\"33.770888658912980E\" xcr:version=\"2.2.0.0\" xcr:altitude=\"643119440/10000\"\n       xmlns:xcr=\"http://www.capturingreality.com/ns/xcr/1.1#\"&gt;\n      &lt;xcr:Rotation&gt;-0.134784620568843 0.851774231082322 -0.506274397261226 0.00661363302515503 -0.510152020736598 -0.860058821009682 -0.990852847761129 -0.119271014930193 0.0631273243627475&lt;/xcr:Rotation&gt;\n      &lt;xcr:Position&gt;2.24050332940992 1.49823826996755 11.8964921935577&lt;/xcr:Position&gt;\n    &lt;/rdf:Description&gt;\n  &lt;/rdf:RDF&gt;\n&lt;/x:xmpmeta&gt;\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#alicevision-meshroom-deployment","title":"AliceVision Meshroom Deployment","text":"<p>AliceVision Meshroom Deployment</p> <p>AliceVision Meshroom is an open-source photogrammetry pipeline that is node-based. It includes a CUDA GPU optimized version of the SIFT utility to align images which means the toolset runs on Windows and Linux.</p> <p>https://alicevision.org/</p> <p></p> <p>An interesting feature of MeshRoom is its capability of performing photogrammetry and panoramic 360VR image stitching using the same node-based toolset.</p> <p>For More information:</p> <ul> <li>Google Groups | AliceVision</li> <li>SketchFab | AliceVision</li> <li>YouTube | AliceVision</li> <li>YouTube | A quick presentation of HDR 360 panorama in Meshroom</li> <li>YouTube | A quick presentation of 3D reconstruction pipeline in Meshroom</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#r3ds-wrap","title":"R3DS Wrap","text":"<p>R3DS Wrap</p> <p>Wrap and Wrap4D are used to perform optical-flow based mesh wrapping on photogrammetry derived raw scan meshes. It allows you to transfer the geometric detail onto a clean base-mesh model that has uniform topology.</p> <p>R3DS is a Russian based independent software developer.</p> <p>https://www.russian3dscanner.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#instant-meshes","title":"Instant Meshes","text":"<p>Instant Meshes</p> <p>Instant Meshes is an open-source program that can be used to perform mesh cleanup operations. The program has a GUI and a CLI interface. You can draw topology flow curves on a surface and this is used to dynamically retopo a polygon model.</p> <p>https://github.com/wjakob/instant-meshes</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#cloudcompare","title":"CloudCompare","text":"<p>CloudCompare</p> <p>CloudCompare is a cross-platform compatible open-source program that is extremely capable as a LIDAR, point cloud, and mesh editing tool. There is a dedicated CloudCompare viewer tool called CCViewer.</p> <p>https://www.cloudcompare.org/</p> <p>CloudCompare supports all common point cloud formats including .e57, .xyz, .ply. LIDAR scanner data can be imported from proprietary formats by installing the Faro SDK and other similar 3<sup>rd</sup> party libraries.</p> <p>CloudCompare can do direct mesh/point cloud editing, model rotations/levelling, point density filtering, and model slicing/bounding box trims.</p> <p>It has a command-line interface which allows CloudCompare to be automated for both 3D file format conversions, and editing operations.</p> <p>CloudCompare is written in Qt and has a C++ based plugin API that can be used by 3<sup>rd</sup> parties to extend the features of the toolset.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#cloudcompare-4x4-transform-matrix","title":"CloudCompare 4x4 Transform Matrix","text":"<p>CloudCompare 4x4 Transform Matrix</p> <p>CloudCompare allows you to copy/paste 4x4 transform matrix data that is used to apply model rotation, translation, and scaling operations.</p> <p>An ASCII formatted 4x4 Transform matrix looks like this:</p> <pre><code>1.000000000000 0.000000000000 0.000000000000 0.000000000000\n0.000000000000 1.000000000000 0.000000000000 0.000000000000\n0.000000000000 0.000000000000 1.000000000000 0.000000000000\n0.000000000000 0.000000000000 0.000000000000 1.000000000000\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#cloudcompare-cross-sections","title":"CloudCompare Cross Sections","text":"<p>CloudCompare Cross Sections</p> <p>CloudCompare CLI allows you to load in a pre-saved cross-section parameters template from an external XML file:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;CloudCompare&gt;\n    &lt;!-- BoxThickness: base clipping-box dimensions --&gt;\n    &lt;!-- Thickness values must be positive --&gt;\n    &lt;BoxThickness x=\"\" y=\"\" z=\"\"/&gt;\n    &lt;!-- BoxCenter: clipping-box center --&gt;\n    &lt;!-- Optional (if not defined, the center of the bounding-box of each entity will be used instead) --&gt;  \n    &lt;BoxCenter x=\"\" y=\"\" z=\"\"/&gt;\n    &lt;!-- 'Repeat' dimension for cross sections generation. Additional RepeatDims can be added to split in multiple dimensions. --&gt;\n    &lt;!-- Can be 0 (X), 1 (Y) or 2 (Z) --&gt;\n    &lt;RepeatDim&gt;0&lt;/RepeatDim&gt;\n    &lt;!-- Gap between two sections (might be negative, but bigger than the (minus) thickness along the repeat dimension). --&gt;\n    &lt;!-- Optional (gap = 0 by default) --&gt;\n    &lt;RepeatGap&gt;0&lt;/RepeatGap&gt;\n    &lt;!-- Input/Output folder path --&gt;\n    &lt;!-- 'FilePath' key: all files (but XML ones) present in the folder pointed by FilePath will be loaded (previously loaded entities will be removed!) --&gt;\n\n    &lt;!-- 'OutputFilePath' key: if defined, output files will be saved in this folder (if not, FilePath will be used or the current folder if neither are defined) --&gt;\n    &lt;!-- (Note: output entities are be saved in sub-folders) --&gt;\n    &lt;OutputFilePath&gt;E:\\Kartaverse\\projects\\untitled\\meshes\\obj&lt;/OutputFilePath&gt;\n    &lt;!-- Use this option if you want to use the previously loaded entities --&gt;\n\n    &lt;!--FilePath&gt;E:\\Kartaverse\\projects\\untitled\\meshes\\obj&lt;/FilePath--&gt; \n    &lt;!-- Use this option if you want to sequentially load files in a folder (it requires less memory if you have lots of entities) --&gt;\n&lt;/CloudCompare&gt;\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#meshlab","title":"MeshLab","text":"<p>MeshLab</p> <p>MeshLab is an open-source program that is capable of performing point cloud and mesh based editing operations.</p> <p>The earlier MeshLabServer CLI program has been retired and replaced with a Python scripting layer.</p> <p>https://www.meshlab.net/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#rply-binary-to-ascii-format-ply-model-converter","title":"RPLY Binary to ASCII Format PLY Model Converter","text":"<p>RPLY Binary to ASCII Format PLY Model Converter</p> <p>RPLY is a command-line tool with ANSI C-language source code that allows Stanford PLY formatted models and point clouds to be translated between binary and ASCII encoding formats.</p> <p>http://w3.impa.br/~diego/software/rply/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#lib-e57","title":"Lib e57","text":"<p>Lib e57</p> <p>The e57 file format is often used to hold LIDAR laser scanner generated compressed RGB point cloud data, along with RGB imagery, and other data samples.</p> <p>http://libe57.org/</p> <p>Saving intermediate scan data as a series of e57 files is far more compact to store on-disk than using either a PLY or XYZ based ASCII scene description format representation of the same point cloud records. Working with a data compressed volumetric file format like e57 significantly reduces disk and network bandwidth overhead when processing hundreds of GBs of volumetric information.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#aws-thinkbox-sequoia","title":"AWS Thinkbox Sequoia","text":"<p>AWS Thinkbox Sequoia</p> <p>Sequoia is a free point-cloud editing toolset from Amazon AWS. Sequoia is capable of being used with AWS Deadline for batch processing of volumetric information. It supports the export of scan data to e57 files.</p> <p>https://www.awsthinkbox.com/sequoia</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#faro-scene","title":"Faro Scene","text":"<p>Faro Scene</p> <p>The Faro Scene software is used to process LIDAR scan data from FARO brand LIDAR scanners like the Faro Focus model. The MSRP for Faro Scene is approx. $6500.</p> <p>https://www.faro.com/en/Products/Software/SCENE-Software</p> <p></p> <p>For more information about Faro Scene and Faro Focus Scanners:</p> <ul> <li>Faro Focus Scanners</li> <li>Faro Scene Software</li> <li>Vimeo | SEPRI (Spanish Language) | Using a laser scanner to map caves and caverns in Puerto Rico</li> </ul> <p></p> <p>Using Faro Scene, a semi-automated approach can be taken to register and align LIDAR information. The Faro Scene integrated masking tools helped to remove and \"clip out\" the LIDAR scanner tripods from each station scan. Finally, the point clouds are merged into a unified dataset that spans the full length of the scanned environment.</p> <p>Faro Scene is able to export finished point cloud data into a compressed e57 file format which is an excellent choice for volumetric post-production workflows.</p> <p></p> <p>A Faro Focus 360 LIDAR scanner captures both point cloud data, and RGB color images from an integrated CMOS image sensor. The RGB image data is primarily used to colorize the point cloud samples. Additionally, the same RGB data from the original camera views can be exported from FARO Scene as high-resolution 360VR stitched panoramic images.</p> <p>The following Faro Focus LIDAR scanner photos were provided by Robert Moreno of La Sociedad Espeleol\u00f3gica de Puerto Rico, Inc.\u00a0(SEPRI) \"Speleological Society of Puerto Rico\" http://sepri.org/</p> <p></p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#leica-cyclone-register-360","title":"Leica Cyclone Register 360","text":"<p>Leica Cyclone Register 360</p> <p>Leica Cyclone is the name for a suite of LIDAR scan processing tools. The Register 360 product has a simplified user interface that makes it convenient for a casual user to process scan data.</p> <p>https://leica-geosystems.com/products/laser-scanners/software/leica-cyclone/leica-cyclone-register-360</p> <p>The Cyclone software is able to work with LIDAR data from multiple vendors including Leica and Faro. The first time you import Faro Focus LIDAR scan data into Leica Cyclone you will be asked to install the Faro SDK plugin.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#pixar-openusd-tools","title":"Pixar OpenUSD Tools","text":"<p>Pixar OpenUSD Tools</p> <p>The Pixar OpenUSD repository includes several utility tools that perform handy operations on .usd, .usdc, .usda, .usdz and .abc files. If you want access to pre-compiled versions of these USD tools, NVIDIA's Omniverse team, and the SideFX Houdini software bundle the CLI tools inside a \"bin\" folder.</p> <p>https://github.com/PixarAnimationStudios/USD</p> <p>Details on how to compile your own builds of the OpenUSD repository provided CLI tools can be read here:</p> <p>The Ultimate Guide to OpenUSD Pipeline Development | Overview</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#usdview","title":"USDView","text":"<p>USDView</p> <p>USDView is an efficient 3D scene graph viewing tool provided by the OpenUSD repo. It is a program that makes it easy to inspect individual assets and composed USD scenes. You are able to render loaded scenes using any Hydra compatible plugin renderer that is installed on the system.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#j-cube-multiverse-for-maya-and-muse","title":"J-Cube Multiverse for Maya and Muse","text":"<p>J-Cube Multiverse for Maya and Muse</p> <p>J-Cube makes the excellent Multiverse for Maya plugin, along with the standalone Muse OpenUSD file editing tools.</p> <p>https://j-cube.jp/solutions/multiverse/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#kartaverse-openusd-tools","title":"Kartaverse OpenUSD Tools","text":"<p>Kartaverse OpenUSD Tools</p> <p>It's worth mentioning the Kartaverse KartaVR and Vonk data node toolsets unlock several additional export formats in Resolve/Fusion for volumetric data.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#export-point-cloud-script","title":"Export Point Cloud Script","text":"<p>Export Point Cloud Script</p> <p>The KartaVR Export point cloud script works with the currently selected PointCloud3D node in the Fusion node graph.</p> <p></p> <p>The \"Export to Point Cloud\" script can also be used to de-compose a Fusion FBXMesh3D loaded OBJ model into its individual vertices when the point cloud is exported.</p> <p></p> <p>KartaVR supports .ma (Maya ASCII) based exports from Fusion 3D system PointCloud3D nodes, and OBJ meshes.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#vonk-3d-node","title":"Vonk 3D Node","text":"<p>Vonk 3D Node</p> <p>The Vonk data node \"v3DToFile\" fuse makes it possible to export the PointCloud3D node data to disk in a parametric node-based fashion. This node works in the Fusion Studio and Resolve Studio GUI.</p> <p></p> <p>Connect a PointCloud3D node's output connection directly to the v3DToFile node input connection:</p> <p>PointCloud3D.Output -&gt; v3DToFile.Input</p> <p>The \"Point Cloud Format\" ComboControl allows you to select the export format used. Options include: \"XYZ ASCII (.xyz)\", \"PLY ASCII (.ply)\", and \"PIXAR USDA ASCII (.usda)\".</p> <p>The \"Filename\" text field supports Vonk vText based connections. This allows you to dynamically generate a filename via data node approaches.</p> <p>The Filename field contents can include relative PathMap values like \"Comp:/\" that will be expanded at render time.</p> <p>If a sub-folder is specified in the filename field, and it is missing at render time, the sub-folders will be re-created automatically when the file is saved to disk. This is helpful if you want to use per--timeline-frame numbered folders in the output filepath.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#vonk-3d-example-comp","title":"Vonk 3D Example Comp","text":"<p>Vonk 3D Example Comp</p> <p>There is a Fusion example comp provided with the Vonk data nodes that shows how the v3DToFile workflow is done.</p> <p></p> <p>The example is located on-disk at the following PathMap location:</p> <p>Reactor:/Deploy/Comps/Kartaverse/Vonk Ultra/Demo 3D/Demo 3D.comp</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Photogrammetry%20Tools/#nvidia-instantngp-deployment","title":"NVIDIA InstantNGP Deployment","text":"<p>NVIDIA InstantNGP Deployment</p> <p>This is an open-source NeRF toolset for interactive neural graphics based volumetric rendering. The testbed program runs with the help of the COLMAP utility for camera registration.</p> <p>https://github.com/NVlabs/instant-ngp</p> <p></p> <p>For more information:</p> <ul> <li>Kartaverse Workflows | Creating Volumetric NeRFs</li> <li>GitHub | Agisoft Metashape camera location to NERF conversion tool</li> </ul> <p>NeRF Studio</p> <p>https://docs.nerf.studio/</p> <p>For more information:</p> <ul> <li>GitHub | NeRF Studio</li> <li>Collab | NeRF Studio</li> </ul> <p>Adobe Substance 3D Painter</p> <p>https://www.adobe.com/products/substance3d-painter.html</p> <p>RizomUV</p> <p>https://www.rizom-lab.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Pixar%20Tractor%20Deployment/","title":"Pixar Tractor Deployment","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Pixar's Tractor render management tool is often installed and used alongside Pixar's RenderMan production renderer on Linux based headless render nodes.</p> <p>https://renderman.pixar.com/tractor</p> <p>A tractor license entitlement is often provided with RenderMan commercial licenses. This is defined as a \"FeatureInfo\" block in your Pixar.license file:</p> <pre><code>&lt;FeatureInfo&gt;\n    &lt;FeatureName&gt;Tractor&lt;/FeatureName&gt;\n    &lt;FeatureVersion&gt;2.000&lt;/FeatureVersion&gt;\n    &lt;ExpirationDate&gt;22-jul-2023&lt;/ExpirationDate&gt;\n    &lt;FeatureCount&gt;10&lt;/FeatureCount&gt;\n    &lt;FeatureCode&gt;...&lt;/FeatureCode&gt;\n    &lt;ExtraData&gt;&lt;/ExtraData&gt;\n&lt;/FeatureInfo&gt;\n</code></pre> <p>Tractor is also available separately as a standalone offering which can be purchased with maintenance from the Pixar RenderMan team sales staff.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Pixar%20Tractor%20Deployment/#controlling-tractor","title":"Controlling Tractor","text":"<p>Controlling Tractor</p> <p>Tractor can be controlled from a WebUI, as well as from a terminal based command-line session, or Python scripting.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Pixar%20Tractor%20Deployment/#tractor-and-macos-port-ranges","title":"Tractor and macOS Port Ranges","text":"<p>Tractor and macOS Port Ranges</p> <p>When running Tractor Blade on macOS systems it is important to change the default port number from trying to open a new connection to port 80. A popular alternative port number to use is 8080.</p> <p>For compatibility reasons, a higher port range number has to be defined manually in the Tractor preference files to avoid Tractor communication messages being blocked by the macOS network rules.</p> <p>The command-line syntax to start a Tractor Blade engine on port 8080 is:</p> <pre><code># Start Tractor Blade\n/opt/pixar/Tractor-2.4/bin/tractor-blade --engine=tractor-engine:8080 &amp;\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/","title":"RAW and HDRI Image Processing Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>HDRI (High Dynamic Range Imagery) is able to represent a wider range of visual information through the storage and use of floating point values.</p> <p>These RGB formatted high-dynamic range pixel samples exceed the typical 8-bit style 0-255 / 0-1 range of color information stored in a JPEG, BMP, or MP4 like file format that is often shown on a traditional computer monitor or mobile phone screen.</p> <p>HDRI imagery can be created from RAW image data, by merging bracketed photos taken across a wide range of exposure levels, or from 3D renderings. Common file formats for floating-point HDRI image data include EXR, HDR, and TIFF.</p> <p>In an HDRI image the center region of a super-white \"sun\" disc shape might read out as an RGB floating point value like 16+ when selected with a color picker. In an 8-bit image this sun disc RGB color value would typically be clamped at an integer value of 255, or a floating point value of 1.0.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#hdrsoft-photomatix-pro","title":"HDRsoft Photomatix Pro","text":"<p>HDRsoft Photomatix Pro</p> <p>Photomatix Pro is an easy to use HDR image bracket merging tool that features a batch automation interface that allows you to quickly process a large collection of exposure-bracketed images into HDRI media.</p> <p>With Photomatix's batch processing interface EXR format image output is supported which is an excellent choice for visual effects workflows.</p> <p>https://www.hdrsoft.com/resources/photomatix-pro-features-highlights.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#photomatix-batch-processing-workflows","title":"Photomatix Batch Processing Workflows","text":"<p>Photomatix Batch Processing Workflows</p> <p>These two screenshots show common settings for batch processing operations.</p> <p></p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dxo-optics-photolab","title":"DxO Optics PhotoLab","text":"<p>DxO Optics PhotoLab</p> <p>PhotoLab is the continuation of the earlier Nikon RAW photo processing tools. This suite of tools is useful for photogrammetry applications that need to maximize image quality.</p> <p>Few people have discovered that PhotoLab has a \"generally undocumented\" command-line interface that can allow for batch image processing.</p> <p>https://www.dxo.com/dxo-photolab/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dxo-photolab-command-line-settings","title":"DxO PhotoLab Command-Line Settings","text":"<p>DxO PhotoLab Command-Line Settings</p> <p>DxO PhotoLab has a CLI module called DopCor (DxO Correction Engine) which allows you to batch process DNG/RAW footage, and apply color correction presets. This is handy for pre-processing media before running photogrammetry workflows such as adding micro-contrast, reducing JPEG/MPEG compression artifacts, or fine tuning color correction settings.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#photolab-program-paths","title":"PhotoLab Program Paths","text":"<p>PhotoLab Program Paths</p> <p>PhotoLab v3</p> <p>Windows:</p> <pre><code>C:\\Program Files\\DxO\\DxO PhotoLab 3\\DopCor.exe\n</code></pre> <p>macOS:</p> <pre><code>/Applications/DXOPhotoLab3.app/Contents/XPCServices/XPCCor12.xpc/Contents/MacOS/XPCCor12\n</code></pre> <p>PhotoLab v2</p> <p>Windows:</p> <pre><code>C:\\Program Files\\DxO\\DxO PhotoLab 2\\DopCor.exe\n</code></pre> <p>macOS:</p> <pre><code>/Applications/DXOPhotoLab3.app/Contents/XPCServices/XPCCor12.xpc/Contents/MacOS/XPCCor12\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dopcor-usage-summary","title":"DopCor Usage Summary","text":"<p>DopCor Usage Summary</p> <p>Step 1. Create the DxO PhotoLab temp working folder</p> <pre><code>mkdir \"%TEMP%\\DxO\\\"\n</code></pre> <p>A logfile named \"<code>%TEMP%\\DxO\\DxO_Output_Log.txt</code>\" is written to disk. Make sure the folder named \"<code>%TEMP%\\DxO</code>\" exists in advance by creating the \"DxO\" sub-folder inside the temporary files folder using the Windows Command Prompt.</p> <p>Step 2. Place a sample image, and a corresponding .dop sidecar file at:</p> <pre><code>REM %TEMP%\\DxO\\Cam01.0001.jpg\nREM %TEMP%\\DxO\\Cam01.0001.jpg.dop\n</code></pre> <p>Step 3. Run DxO PhotoLab 3's DopCor CLI Program</p> <pre><code>\"C:\\Program Files\\DxO\\DxO PhotoLab 3\\DopCor.exe\" ^\n--debug ^\n--cafsdir=\"%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\\Modules\" ^\n--cafsdb=\"%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\\CAFList3.db\" ^\n--oclcache=\"%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\" ^\n--img=\"%TEMP%\\DxO\\Cam01.0001.jpg\" ^\n--sidecar=\"%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\\Presets\\2 - Neutral colors.preset\" ^\n--output=\"%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\\OutputSettings.xml\" ^\n--outputpath=\"%TEMP%\\DxO\"\n</code></pre> <p>You will need to change the following two DopCor CLI settings to match your current needs:</p> <p>A)  Edit the '<code>--img=\"%TEMP%\\DxO\\Cam01.0001.jpg\" ^</code>' entry to define the actual image you want to convert. Make sure this filename is unique and doesn't already exist on-disk.</p> <p>B)  Also define the DxO preset you want to use by editing the entry. (You will need to write in your own custom preset saved to disk from the PhotoLab GUI.)</p> <pre><code>'--sidecar=\"%USERPROFILE%`\\AppData`{=tex}`\\Local`{=tex}`\\DxO`{=tex}`\\DxO `{=tex}PhotoLab 3`\\Presets`{=tex}\\\\2 - Neutral colors.preset\" \\^'.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#photolab-command-line-usage-notes","title":"Photolab Command-Line Usage Notes","text":"<p>PhotoLab Command-Line Usage Notes</p> <p>Note 1: You need to port the DxO PhotoLab \"Export to disk\" dialog generated macOS .plist formatted \"<code>OutputSettings.plist</code>\" preference file into a Windows based pure XML document for DopCor.exe on Windows to run successfully. This requires you to extract inline encoded XML \"blob\" data and then save it to an external document.</p> <p>The DxO PhotoLab 3 on macOS OutputSettings file is located at:</p> <pre><code>$HOME/Library/DxO PhotoLab v3/OutputSettings.plist\n</code></pre> <p>The DxO PhotoLab 3 on Windows OutputSettings file is located at:</p> <pre><code>C:\\Users\\&lt;User name&gt;\\AppData\\Local\\DxO\\DxO.PhotoLab.exe_StrongName_addo3jomrfkt2faiwwfxxb444r1xfvlh\\3.2.0.4344\\user.config\n</code></pre> <p>The encoded blob data is found in the user.config/OutputSettings.plist file here:</p> <pre><code>&lt;setting name=\"OutputSettings\" serializeAs=\"String\"&gt;\n        &lt;value&gt;&amp;lt;ArrayOfanyType xmlns=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" xmlns:i=\"http://www.w3.org/2001/XMLSchema-instance\"&amp;gt;&amp;lt;anyType i:type=\"a:FileOutputSettings\" xmlns:a=\"http://schemas.datacontract.org/2004/07/DxO.OpticsPro.OutputSettings\"&amp;gt;&amp;lt;a:AllowResampling&amp;gt;false&amp;lt;/a:AllowResampling&amp;gt;&amp;lt;a:CanDisable&amp;gt;true&amp;lt;/a:CanDisable&amp;gt;&amp;lt;a:CustomIccProfile/&amp;gt;&amp;lt;a:CustomResolution&amp;gt;72&amp;lt;/a:CustomResolution&amp;gt;&amp;lt;a:DestinationFolder/&amp;gt;&amp;lt;a:DestinationIsOriginalFolder&amp;gt;true&amp;lt;/a:DestinationIsOriginalFolder&amp;gt;&amp;lt;a:Enabled&amp;gt;true&amp;lt;/a:Enabled&amp;gt;&amp;lt;a:FormatType&amp;gt;Tiff&amp;lt;/a:FormatType&amp;gt;&amp;lt;a:FullOutputPath/&amp;gt;&amp;lt;a:GenerateTemporaryFile&amp;gt;false&amp;lt;/a:GenerateTemporaryFile&amp;gt;&amp;lt;a:IccProfile&amp;gt;Original&amp;lt;/a:IccProfile&amp;gt;&amp;lt;a:Id&amp;gt;f6a2ef05-befc-44de-8e1e-36649cd33855&amp;lt;/a:Id&amp;gt;&amp;lt;a:InterpolationType&amp;gt;Bicubic&amp;lt;/a:InterpolationType&amp;gt;&amp;lt;a:JpegQuality&amp;gt;99&amp;lt;/a:JpegQuality&amp;gt;&amp;lt;a:OutputHeight&amp;gt;1024&amp;lt;/a:OutputHeight&amp;gt;&amp;lt;a:OutputName&amp;gt;DxO&amp;lt;/a:OutputName&amp;gt;&amp;lt;a:OutputSizeUnit&amp;gt;Pixels&amp;lt;/a:OutputSizeUnit&amp;gt;&amp;lt;a:OutputWidth&amp;gt;1024&amp;lt;/a:OutputWidth&amp;gt;&amp;lt;a:OverwriteOutputFile&amp;gt;false&amp;lt;/a:OverwriteOutputFile&amp;gt;&amp;lt;a:RawSuffix&amp;gt;_raw&amp;lt;/a:RawSuffix&amp;gt;&amp;lt;a:RenderingIntent&amp;gt;Perceptual&amp;lt;/a:RenderingIntent&amp;gt;&amp;lt;a:ResolutionUnit&amp;gt;dpi&amp;lt;/a:ResolutionUnit&amp;gt;&amp;lt;a:RgbSuffix/&amp;gt;&amp;lt;a:SavedExifFields&amp;gt;All&amp;lt;/a:SavedExifFields&amp;gt;&amp;lt;a:Sharpness i:nil=\"true\"/&amp;gt;&amp;lt;a:Suffix&amp;gt;_cor&amp;lt;/a:Suffix&amp;gt;&amp;lt;a:SuffixForSnaphot&amp;gt;_ds&amp;lt;/a:SuffixForSnaphot&amp;gt;&amp;lt;a:TemporaryFileSuffix&amp;gt;tmp&amp;lt;/a:TemporaryFileSuffix&amp;gt;&amp;lt;a:Tiff8Bits&amp;gt;false&amp;lt;/a:Tiff8Bits&amp;gt;&amp;lt;a:TiffCompression&amp;gt;false&amp;lt;/a:TiffCompression&amp;gt;&amp;lt;a:UseRawOrRgbSuffix&amp;gt;false&amp;lt;/a:UseRawOrRgbSuffix&amp;gt;&amp;lt;a:UseUniqueNaming&amp;gt;false&amp;lt;/a:UseUniqueNaming&amp;gt;&amp;lt;a:UseVirtualCopySuffix&amp;gt;false&amp;lt;/a:UseVirtualCopySuffix&amp;gt;&amp;lt;a:Watermark i:type=\"b:Watermark\" xmlns:b=\"http://schemas.datacontract.org/2004/07/DxO.OpticsPro.DopCommon.OutputSettings\"&amp;gt;&amp;lt;b:Active&amp;gt;false&amp;lt;/b:Active&amp;gt;&amp;lt;b:FileName i:nil=\"true\"/&amp;gt;&amp;lt;b:Position xmlns:c=\"http://schemas.datacontract.org/2004/07/System.Windows\"&amp;gt;&amp;lt;c:_x&amp;gt;1&amp;lt;/c:_x&amp;gt;&amp;lt;c:_y&amp;gt;1&amp;lt;/c:_y&amp;gt;&amp;lt;/b:Position&amp;gt;&amp;lt;/a:Watermark&amp;gt;&amp;lt;/anyType&amp;gt;&amp;lt;/ArrayOfanyType&amp;gt;&lt;/value&gt;\n      &lt;/setting&gt;\n</code></pre> <p>Attached inline below is an extracted, then un-encoded, and ready to use example OutputSettings.xml file that can be used with DxO PhotoLab on Windows. Place the \"OutputSettings.xml\" document in the folder location of:</p> <pre><code>%USERPROFILE%\\AppData\\Local\\DxO\\DxO PhotoLab 3\\OutputSettings.xml\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#outputsettingsxml-file-contents","title":"OutputSettings.xml file contents:","text":"<p>OutputSettings.xml file contents:</p> <pre><code>&lt;ArrayOfanyType xmlns=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" xmlns:i=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n  &lt;anyType xmlns:a=\"http://schemas.datacontract.org/2004/07/DxO.OpticsPro.OutputSettings\" i:type=\"a:FileOutputSettings\"&gt;\n    &lt;a:AllowResampling&gt;false&lt;/a:AllowResampling&gt;\n    &lt;a:CanDisable&gt;true&lt;/a:CanDisable&gt;\n    &lt;a:CustomIccProfile /&gt;\n    &lt;a:CustomResolution&gt;300&lt;/a:CustomResolution&gt;\n    &lt;a:DestinationFolder /&gt;\n    &lt;a:DestinationIsOriginalFolder&gt;true&lt;/a:DestinationIsOriginalFolder&gt;\n    &lt;a:Enabled&gt;true&lt;/a:Enabled&gt;\n    &lt;a:FormatType&gt;Jpeg&lt;/a:FormatType&gt;\n    &lt;a:FullOutputPath /&gt;\n    &lt;a:GenerateTemporaryFile&gt;false&lt;/a:GenerateTemporaryFile&gt;\n    &lt;a:IccProfile&gt;Original&lt;/a:IccProfile&gt;\n    &lt;a:Id&gt;9ac5986a-34e5-44f4-8cde-6aa93e4bce72&lt;/a:Id&gt;\n    &lt;a:InterpolationType&gt;Bicubic&lt;/a:InterpolationType&gt;\n    &lt;a:JpegQuality&gt;99&lt;/a:JpegQuality&gt;\n    &lt;a:OutputHeight&gt;1024&lt;/a:OutputHeight&gt;\n    &lt;a:OutputName&gt;DxO&lt;/a:OutputName&gt;\n    &lt;a:OutputSizeUnit&gt;Pixels&lt;/a:OutputSizeUnit&gt;\n    &lt;a:OutputWidth&gt;1024&lt;/a:OutputWidth&gt;\n    &lt;a:OverwriteOutputFile&gt;false&lt;/a:OverwriteOutputFile&gt;\n    &lt;a:RawSuffix&gt;_raw&lt;/a:RawSuffix&gt;\n    &lt;a:RenderingIntent&gt;Perceptual&lt;/a:RenderingIntent&gt;\n    &lt;a:ResolutionUnit&gt;dpi&lt;/a:ResolutionUnit&gt;\n    &lt;a:RgbSuffix /&gt;\n    &lt;a:SavedExifFields&gt;All&lt;/a:SavedExifFields&gt;\n    &lt;a:Sharpness i:nil=\"true\" /&gt;\n    &lt;a:Suffix&gt;_DxO&lt;/a:Suffix&gt;\n    &lt;a:SuffixForSnaphot&gt;_ds&lt;/a:SuffixForSnaphot&gt;\n    &lt;a:TemporaryFileSuffix&gt;tmp&lt;/a:TemporaryFileSuffix&gt;\n    &lt;a:Tiff8Bits&gt;true&lt;/a:Tiff8Bits&gt;\n    &lt;a:TiffCompression&gt;true&lt;/a:TiffCompression&gt;\n    &lt;a:UseRawOrRgbSuffix&gt;false&lt;/a:UseRawOrRgbSuffix&gt;\n    &lt;a:UseUniqueNaming&gt;false&lt;/a:UseUniqueNaming&gt;\n    &lt;a:UseVirtualCopySuffix&gt;false&lt;/a:UseVirtualCopySuffix&gt;\n    &lt;a:Watermark xmlns:b=\"http://schemas.datacontract.org/2004/07/DxO.OpticsPro.DopCommon.OutputSettings\" i:type=\"b:Watermark\"&gt;\n      &lt;b:Active&gt;false&lt;/b:Active&gt;\n      &lt;b:FileName i:nil=\"true\" /&gt;\n      &lt;b:Position xmlns:c=\"http://schemas.datacontract.org/2004/07/System.Windows\"&gt;\n        &lt;c:_x&gt;1&lt;/c:_x&gt;\n        &lt;c:_y&gt;1&lt;/c:_y&gt;\n      &lt;/b:Position&gt;\n    &lt;/a:Watermark&gt;\n  &lt;/anyType&gt;\n&lt;/ArrayOfanyType&gt;\n</code></pre> <p>Additional tip: If you don't have a valid OutputSettings file specified when running DopCor you will get the CLI error:</p> <pre><code>[DopCor|Error] OutputSettings file doesn't exists or is not a valid OutputSettings files\n(Exit code: -1)\n</code></pre> <p>Note 2: The Windows Command Prompt window supports the use of the \"^\" carat character as a \"line-continuing\" symbol. If you place this at the the end of each line of text, it allows you to use multi-line text submission that has a carriage return placed after each command. This is far easier to manage in Notepad++ compared to typing in one super long line of text. When the text block that uses the \"^\" carat is pasted into the Command Prompt window, the text with \"^\" carat character at the end of each line is treated as a single, super long, block of text and the new line characters are ignored. Always copy/paste a final trailing blank (empty) line of text when you run this type of text in the Command Prompt.</p> <p>Note 3: The DxO DopCor error message \"<code>[DopCor|Error] Parameters file doesn't exist or is not a valid sidecar</code>\" is caused by an invalid <code>.preset</code> file being linked into the <code>--sidecar</code> parameter. As far as I can tell a <code>.preset</code> file is wanted for this attribute, not the typical .dop sidecar file that would be named something like \"<code>image.ext.dop</code>\".</p> <p>Note 4: DopCor runs with a single stream socket via an XPC remote port connection. So don't try to queue multiple concurrent image streams at the same time on one system as they are handled FIFO (First In, First Out) so you won't see a performance improvement.</p> <p>DxO uses a tool called \"XPCCor\" to do remote procedure calls between its app for lower-level image conversions than the CLI offers:</p> <p>https://en.wikipedia.org/wiki/Remote_procedure_call</p> <p>This is done with these modules:</p> <ul> <li>DOPCor</li> <li>DXF EngineServer</li> <li>XPC Connection</li> <li>XPC Listener</li> </ul> <p>On macOS the executable \"remote procedure call\" interface program is located at:</p> <pre><code>/Applications/DxO PhotoLab 3.app/Contents/XPCServices/XPCor12.xpc/Contents/MacOS/XPCore12\n</code></pre> <p>The DxO PhotoLab toolset when running from Lightroom uses this XPCCor interface.</p> <p>On macOS this is the list of interface commands that appear to drive the remote socket communications between a client tool like Lightroom plugin of DxO and DopCore:</p> <ul> <li>DOPCor</li> <li>XPC Connection</li> <li>XPC Listener</li> <li>XPC Listener Delegate</li> <li>PL Crash Reporter</li> <li>DOP Crash Handler</li> <li>DOPCor Server Xpc Interface</li> <li>DOP Cmd Parser</li> <li>DOPCor Client</li> <li>DOPCor Server</li> <li>DOP Exception Handler</li> <li>DXF EngineServer</li> <li>DXF Image</li> <li>DXF Profile</li> <li>DXF Progress</li> <li>DXF Correction Agent</li> <li>DXF Thread Graph</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dopcor-standalone-cli-syntax","title":"DopCor Standalone CLI Syntax","text":"<p>DopCor Standalone CLI Syntax</p> <pre><code>Usage:\n    DopCor [OPTIONS]+\n\nGeneral switches:\n\nCommand line options:\n-h, -help   Display help and exit\n-l, --listening Server mode (Use -l --help for related help)\n--debug Increase verbosity\n\nCommand line switches:\n-c, --cafsdir=PATH  [Required] {PATH} to directory containing DxO Modules\n-d, --cafsdb=PATH   [Required] {PATH} to DxO Modules database\n-k, --oclcache=PATH [Required] {PATH} to Open Clcachefile (ocl64.cache)\n-i, --img=PATH  [Required] {PATH} to input image files\n-s, --sidecar=PATH  [Required] {PATH} to Preset file\n-o, --output=PATH   [Required] {PATH} to output settings file\n-p, --outputpath=PATH   [Required] {PATH} to folder where to write processed image\n-f, --outputsuffix=SUFFIX   to append to the name of processed image\n-t, --threads=VALUE     Max number of threads (default: 32)\n\n-cl, --opencl Enable OpenCL acceleration\n-tim, --tilemanager=VALUE Enable TileManager\n-tip1, --tilememorysize=VALUE Tile pool size. The value must be a power of 2, expressed in MB (default: 1024 MB).\n\n\nServer mode switches:\nTip: Use -l --help to list the Server mode switches\n\n-p, --port=PORT The PORT for Server mode (default: 9875)\n-d, --timeout=TIMEOOUT  The TIMEOUT for server shutdown without connection (defaut 60: seconds)\n\nPossible Spare Option:\n/Start\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dopcor-cli-exit-code-states","title":"DopCor CLI Exit Code States:","text":"<p>DopCor CLI Exit Code States:</p> <p>0 = Success</p> <p>-1 = Error</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#dopcor-cli-returned-status-message-strings","title":"DopCor CLI returned status message strings:","text":"<p>DopCor CLI returned status message strings:</p> <ul> <li>Invalid command line:</li> <li>Unknown option(s):</li> <li>Press Ctrl + C to quit</li> <li>Unable to start</li> <li>DopCor Errors found No error</li> <li>Crash On Startup</li> <li>#Debugger On Startup</li> <li>Unable to open parameters file</li> <li>Unable to open parameters file:</li> <li>Output directory '{0}' doesn't exist.</li> <li>Default directory will be used</li> <li>Invalid suffix '{0}'.</li> <li>Default suffix '{1} 'will beused.</li> <li>Processing error</li> <li>Current Step Progression</li> <li>Not supported property:</li> <li>Step changed:</li> <li>Step: Progression changed:</li> <li>Cafs directory must be specified</li> <li>Cafs directory doesn't exists</li> <li>Cafs database must be specified</li> <li>Cafs database doesn't exists</li> <li>Number of processing threads is invalid</li> <li>Tile memory pool size is invalid</li> <li>(OpenCl cache file path must be specified</li> <li>Source image is required</li> <li>Source image doesn't exists</li> <li>Parameters file is required</li> <li>Parameters file doesn't exists or is not a valid sidecar</li> <li>OutputSettings file is required</li> <li>OutputSettings file doesn't exists or is not a valid OutputSettings files</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/RAW%20and%20HDRI%20Image%20Processing%20Tools/#canon-digital-photo-professional","title":"Canon Digital Photo Professional","text":"<p>Canon Digital Photo Professional</p> <p>https://en.canon-cna.com/support/consumer_products/software/digital-photo-professional.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/","title":"Software Packaging and Deployment Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#pkgsorg","title":"Pkgs.org","text":"<p>Pkgs.org</p> <p>This is an essential website to help search and decode the compatibility matrix of 3<sup>rd</sup> party packages for Linux distros.</p> <p>https://pkgs.org/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#alien-package-converter-for-linux","title":"Alien Package Converter for Linux","text":"<p>Alien Package Converter for Linux</p> <p>The alien command-line utility for Linux makes it possible to extract RedHat style RPM packages and rebuild them so they can be used as .deb Debian Packages on Ubuntu-like Linux distros.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#rez-package-manager","title":"Rez Package Manager","text":"<p>Rez Package Manager</p> <p>The Rez package manager is a unique virtual environment toolset designed to meet the precise needs of feature-film level visual effects and animation workflows.</p> <p>https://github.com/AcademySoftwareFoundation/rez</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#pacifist-on-macos","title":"Pacifist on macOS","text":"<p>Pacifist on macOS</p> <p>Pacifist is a .pkg file editor and asset extractor for macOS systems. If a .pkg file fails to extract correctly you can use the Pacifist tool to extract all of the assets from the installer bundle to allow for manual software installation procedures to be used.</p> <p>https://macappstore.org/pacifist/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#nullsoft-nsis-scriptable-install-system-for-windows","title":"Nullsoft NSIS Scriptable Install System for Windows","text":"<p>Nullsoft NSIS Scriptable Install System for Windows</p> <p>https://nsis.sourceforge.io/</p> <p>https://nsis.sourceforge.io/Main_Page</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#vmware-install-builder-cross-platform","title":"VMWare Install Builder Cross-Platform","text":"<p>VMWare Install Builder Cross-Platform</p> <p>This toolset was formerly known as BitRock Install Builder.</p> <p>https://store-us.vmware.com/vmware-installbuilder-enterprise-5372464400.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#qt-creator","title":"QT Creator","text":"<p>QT Creator</p> <p>QT framework based programs are often distributed using the QT installer toolkit.</p> <p>https://www.qt.io/product/development-tools</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#snap-packages","title":"Snap Packages","text":"<p>Snap Packages</p> <p>Linux distros that support snap packages are able to streamline the process of running complex software that has the executable programs and all of the required library dependencies bundled into a single file.</p> <p>https://snapcraft.io/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#flatpack-packages","title":"FlatPack Packages","text":"<p>FlatPack Packages</p> <p>Linux distros that support FlatPack packages are able to streamline the process of running complex software that has the executable programs and all of the required library dependencies bundled into a single file.</p> <p>https://www.flatpak.org/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#windows-msi-installer-utility","title":"Windows MSI Installer Utility","text":"<p>Windows MSI Installer Utility</p> <p>Windows installers are often provided in a .msi file format.</p> <p>The MSI installer utility provides the following command-line options that can be used to automate an install process:</p> <pre><code>Windows \u00ae Installer. V 5.0.14393.0\n\nmsiexec /Option  [Optional Parameter]\n\nInstall Options\n    &lt;/package | /i&gt; \n        Installs or configures a product\n    /a \n        Administrative install - Installs a product on the network\n    /j&lt;u|m&gt;  [/t ] [/g ]\n        Advertises a product - m to all users, u to current user\n    &lt;/uninstall | /x&gt; \n        Uninstalls the product\nDisplay Options\n    /quiet\n        Quiet mode, no user interaction\n    /passive\n        Unattended mode - progress bar only\n    /q[n|b|r|f]\n        Sets user interface level\n        n - No UI\n        b - Basic UI\n        r - Reduced UI\n        f - Full UI (default)\n    /help\n        Help information\nRestart Options\n    /norestart\n        Do not restart after the installation is complete\n    /promptrestart\n        Prompts the user for restart if necessary\n    /forcerestart\n        Always restart the computer after installation\nLogging Options\n    /l[i|w|e|a|r|u|c|m|o|p|v|x|+|!|*] \n        i - Status messages\n        w - Nonfatal warnings\n        e - All error messages\n        a - Start up of actions\n        r - Action-specific records\n        u - User requests\n        c - Initial UI parameters\n        m - Out-of-memory or fatal exit information\n        o - Out-of-disk-space messages\n        p - Terminal properties\n        v - Verbose output\n        x - Extra debugging information\n        + - Append to existing log file\n        ! - Flush each line to the log\n        * - Log all information, except for v and x options\n    /log \n        Equivalent of /l* \nUpdate Options\n    /update [;Update2.msp]\n        Applies update(s)\n    /uninstall [;Update2.msp] /package \n        Remove update(s) for a product\nRepair Options\n    /f[p|e|c|m|s|o|d|a|u|v] \n        Repairs a product\n        p - only if file is missing\n        o - if file is missing or an older version is installed (default)\n        e - if file is missing or an equal or older version is installed\n        d - if file is missing or a different version is installed\n        c - if file is missing or checksum does not match the calculated value\n        a - forces all files to be reinstalled\n        u - all required user-specific registry entries (default)\n        m - all required computer-specific registry entries (default)\n        s - all existing shortcuts (default)\n        v - runs from source and recaches local package\nSetting Public Properties\n    [PROPERTY=PropertyValue]\n\nConsult the Windows \u00ae Installer SDK for additional documentation on the\ncommand line syntax.\n\nCopyright \u00a9 Microsoft Corporation. All rights reserved.\nPortions of this software are based in part on the work of the Independent JPEG Group.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Software%20Packaging%20and%20Deployment%20Tools/#macos-pkg-installer-utility","title":"macOS PKG Installer Utility","text":"<p>macOS PKG Installer Utility</p> <p>On macOS the .pkg installer utility provides the following command-line options that can be used to automate an install process:</p> <pre><code>**installer**\nUsage: installer [-help] [-dominfo] [-volinfo] [-pkginfo] [-allowUntrusted] [-dumplog]\n                 [-verbose | -verboseR] [-vers] [-config] [-plist]\n                 [-file ] [-lang ] [-listiso]\n                 [-showChoicesXML] [-applyChoiceChangesXML ]\n                 [-showChoicesAfterApplyingChangesXML ]\n                 -pkg \n                 -target &lt;[DomainKey|MountPoint]&gt;\nThe installer utility can list provide more verbose help options by adding the -help flag when you run it from the terminal:\n\n\n**installer -help**\nUsage: installer [options...] -pkg  -target\n\nOptions:\n    [-dominfo]                 # Display domains that can be installed into.\n    [-volinfo]                 # Display volumes that can be installed onto.\n    [-pkginfo]                 # Display package that will be installed\n                                   (for metapackages, shows contents).\n    [-query]             # Display information about package metadata.\n    [-allowUntrusted]          # Allow installing a package signed by an\n                                   untrusted (or expired) certificate.\n    [-dumplog]                 # Write log information to standard error\n                                   (in addition to the usual syslog).\n    [-help]                    # Display this help information.\n    [-verbose]                 # Display detailed information.\n    [-verboseR]                # Display detailed information with\n                                   simplified progress output.\n    [-vers]                    # Display this tool version.\n    [-config]                  # Display command line parameters in XML\n                                   plist format.\n    [-plist]                   # Display -dominfo, -volinfo, or -pkginfo in\n                                   XML plist format (ignored when performing\n                                   installation).\n    [-file ]       # Configuration file supplying parameters in\n                                   XML plist format.\n    [-lang ]  # Sets the default language Mac OS X will use\n                                   after installation.\n    [-listiso]                 # Lists the ISO language codes that are\n                                   recognized.\n    [-showChoicesXML]          # Output XML data describing the choices and\n                                   their properties and state.\n    [-showChoicesAfterApplyingChangesXML ]\n                               # Apply changes specified in the file to the\n                                   choices in the package and output the\n                                   resulting XML data.  See below for the\n                                   file format description.\n    [-applyChoiceChangesXML ]\n                               # Apply changes specified in the file to the\n                                   package and proceeds with installation.\n                                   See below for the file format\n                                   description.\n\nDevice:\n    The -target  parameter is any one of the following:\n\n    (1) One of the domains returned by -dominfo.\n    (2) Volume mount point.  Any entry of the form of /Volumes/Mountpoint.\n          ex: /Volumes/Untitled\n\nFlags:\n    RestartAction       # Can optionally return one of the following:\n                    None\n                    RecommendRestart\n                    RequireLogout\n                    RequireRestart\n                    RequireShutdown\n\nChoices file-format:\n    An XML file that is an array of choiceIdentifiers (as strings) to\n    toggle. Each choiceIdentifier specified will be toggled in order --\n    exactly as if a user had clicked on its checkbox in Installer.app's\n    customization pane.\n\nExamples:\n    installer -pkg InstallMe.pkg -target CurrentUserHomeDirectory\n    installer -pkg InstallMe.pkg -target '/Volumes/Macintosh HD2' -lang ja\n    installer -volinfo -pkg InstallMe.pkg\n    installer -pkginfo -pkg InstallMe.pkg\n    installer -query RestartAction -pkg InstallMe.pkg\n    installer -pkg InstallMe.pkg -target / -showChoicesXML\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/","title":"Spatial Audio Tools","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#impulse-response-simulation","title":"Impulse Response Simulation","text":"<p>Impulse Response Simulation</p> <p>Extensive research is underway to explore the feasibility of analytically generating sound impulse response files from the volumetric scan data.</p> <p>This approach helps increase the realism of the immersive XR experiences by allowing for a more accurate sound playback of field-recorded sound elements. These techniques can model sound sources and the audio level \"fall off\" when they are hidden by occlusions (large blocking objects) such as natural caverns, and interior spaces like hallways and tunnels.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#reaper-daw","title":"Reaper DAW","text":"<p>Reaper DAW</p> <p>Reaper is a free open-source DAW software package that is excellent for spatial audio workflows. It doesn't force any preconceptions onto the audio so you can flexibly work with multi-track sound information.</p> <p>https://www.reaper.fm/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#logic-pro","title":"Logic Pro","text":"<p>Logic Pro</p> <p>Apple's Logic Pro DAW software can be used to trim spatial audio based recordings down to the sound clip's final edited duration. The program runs on macOS systems.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#resolve-fairlight-daw","title":"Resolve Fairlight DAW","text":"<p>Resolve Fairlight DAW</p> <p>Blackmagic Design's NLE software Resolve (free) and Resolve Studio (Paid) include a copy of the Fairlight DAW.</p> <p>https://www.blackmagicdesign.com/products/davinciresolve/fairlight</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#about-fairlight","title":"About Fairlight","text":"<p>About Fairlight</p> <p>Fairlight has its own dedicated page environment inside the Resolve software:</p> <p></p> <p>Fairlight makes it possible for advanced audio post-production workflows to be completed inside the same Resolve project database that holds Media pool based footage, Fusion page composites, and Resolve Edit page video editing timelines.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#fairlight-sound-library","title":"Fairlight Sound Library","text":"<p>Fairlight Sound Library</p> <p>When you first open the Fairlight page Sound Library tab an option is presented to \"Download DaVinci Resolve's Free Sound Library\".</p> <p></p> <p>Clicking the \"Download\" button takes you to the BMD Support Center webpage in your default web browser. After completing the 2-part form on the webpage you can then download a macOS or Windows based install package.</p> <p></p> <p>Once you press the \"Register &amp; Download\" button a new download link will be generated for your session.</p> <p></p> <p>On macOS systems you would open up and mount the downloaded DMG (Disk Image) file named:</p> <p><code>Blackmagic_Fairlight_Sound_Library_Mac.dmg</code></p> <p>The disk image holds a \"Install Fairlight Sound Library 1.0.pkg\" installer.</p> <p></p> <p>The PKG installer then adds the 1.12 GB of sound resources to a folder that Resolve's Fairlight page can access.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#unreal-engine-metasounds","title":"Unreal Engine MetaSounds","text":"<p>Unreal Engine MetaSounds</p> <p>Epic Game's Unreal Engine 5 includes the MetaSounds DSP technology for ambisonic spatial audio playback on PC desktops, Consoles and VR HMDs.</p> <p>For more information about Unreal MetaSounds:</p> <ul> <li>MetaSounds Reference Guide</li> <li>MetaSounds: The Next Generation Sound Sources</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#cycling-74-max","title":"Cycling '74 Max","text":"<p>Cycling '74 Max</p> <p>Max is a node based creation environment used to create audio and interface with hardware like MIDI devices.</p> <p>https://cycling74.com/products/max</p> <p>For more information about Max:</p> <ul> <li>Max Downloads</li> <li>Learn Max</li> <li>Max Resources</li> <li>Max Docs</li> <li>Cycling Forums</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#spat-revolution","title":"Spat Revolution","text":"<p>Spat Revolution</p> <p>Spat allows artists, sound-designers, and sound-engineers to create and mix audio that is targeted at creating outstanding immersive experiences. The toolset provides options for WFS (Wave Field Synthesis). Spat Revolution comes with three integration plugins for use with DAW packages.</p> <p>https://www.flux.audio/project/spat-revolution/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#fraunhofer-spatialsound-wave","title":"Fraunhofer SpatialSound Wave","text":"<p>Fraunhofer SpatialSound Wave</p> <p>https://www.idmt.fraunhofer.de/en/institute/projects-products/spatialsound-wave.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#morrow-sound","title":"Morrow Sound","text":"<p>Morrow Sound</p> <p>https://www.morrowsound.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#dolby-atmos","title":"Dolby Atmos","text":"<p>Dolby Atmos</p> <p>https://www.dolby.com/technologies/dolby-atmos/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#spatial-audio-designer","title":"Spatial Audio Designer","text":"<p>Spatial Audio Designer</p> <p>https://newaudiotechnology.com/products/spatial-audio-designer/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#nvidia-vr-works-audio-tools","title":"NVIDIA VR Works | Audio Tools","text":"<p>NVIDIA VR Works | Audio Tools</p> <p>https://developer.nvidia.com/vrworks/vrworks-audio</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#noisemakers-ambi-plugin","title":"Noisemakers Ambi Plugin","text":"<p>Noisemakers Ambi Plugin</p> <p>The Noisemakers Ambi tools help create 3D audio scenes which can be used in the production of 360VR/180VR videos, and immersive experiences.</p> <p>https://www.noisemakers.fr/product/ambi-bundle-hd/</p> <p>Noisemakers creates ambisonic plugins including:</p> <ul> <li>AMBI PAN HD -- Position input sounds in the 3D scene</li> <li>AMBI VERB HD -- Add 360 reverberation</li> <li>AMBI LIMITER HD -- Control the ambisonic bus peak level</li> <li>AMBI HEAD HD -- Render the 3D scene to binaural audio</li> <li>AMBI EYES - Monitor 360 videos while authoring audio</li> <li>AMBI CONVERTER - Convert B-format signals between FuMa and ambiX</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#comsol-multiphysics-simulations","title":"Comsol Multiphysics Simulations","text":"<p>Comsol Multiphysics Simulations</p> <p>A friend of the Kartaverse project, Jared Sandrew (from InfiniteWorld), introduced our audio research group to Jason Riggs from Harman International. Jason volunteered his time over multiple sessions, and shared his insights via Zoom on advanced audio workflows, sound impulse response creation, and an overview of acoustic simulation technologies. Part of that effort by Jason was to explain how the Comsol Multiphysics software is used to pre-visualize detailed and accurate audio environments based upon measured real-world locations for HiFi home audio and automotive audio needs.</p> <p>Comsol Multiphysics, when combined with the Comsol acoustics simulation module, dramatically expands on what is possible for digitally simulating acoustic environments using hybrid FEM (Finite Element) solvers.</p> <p></p> <p>This is a sample Comsol website image of simulating sound emission from a source like a speaker element:</p> <p></p> <p>These techniques potentially take the volumetric research further by allowing for a greater understanding of the acoustic properties of the environments such as caves, and visualize how sounds in this space propagate.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#ultrasonic-sounds-in-caves","title":"Ultrasonic Sounds in Caves","text":"<p>Ultrasonic Sounds in Caves</p> <p>Through the use of software like Comsol, it is possible to fully visualize and simulate the acoustic properties of how ultrasonic avoidance is used by bats for navigation and hunting insects using sound recordings of bat vocalizations. One can see plots in 2D and in 3D of the sound waves propagating outwards as bats fly through a large underground cavern hunting for insects.</p> <p>This image shows a real-world ultrasonic audio recording of a pulse train of bat chirps from a cave in Puerto Rico:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#microsoft-triton-project-acoustics","title":"Microsoft Triton | Project Acoustics","text":"<p>Microsoft Triton | Project Acoustics</p> <p>The Microsoft Triton / Project Acoustics learning resources have been enormously helpful to Kartaverse development efforts. Project Acoustics ships with extensive background reference material that clarifies what is currently possible with real-time acoustic simulation-driven spatial audio playback and for insight into game engine-based uses of acoustic impulse responses.</p> <p>For more information:</p> <ul> <li>Web | Microsoft Project Triton Immersive Engine</li> <li>YouTube | Project Triton | Interactive Sound Simulation: Rendering immersive soundscapes in games</li> <li>Web | Microsoft | What is Acoustics</li> <li>Web | Microsoft Project Triton | FAQs</li> <li>GitHub | Microsoft Project Acoustics</li> <li>GitHub | Microsoft | Project Acoustics 2.0 now available!</li> </ul> <p>Project Triton | Unity Plugin</p> <ul> <li>Web | Microsoft Project Triton | Project Acoustics Unity3d Editor plug-in</li> <li>Web | Microsoft Project Triton | Project Acoustics Unity3d Quickstart</li> </ul> <p>Project Triton | Unreal Plugin</p> <ul> <li>Web | Microsoft Project Triton | Project Acoustics Unreal Editor plug-in and Wwise plug-in</li> <li>Web | Microsoft Project Triton | Project Acoustics Unreal Quickstart</li> </ul> <p>Project Triton | Talks</p> <ul> <li>YouTube | Microsoft | Project Triton | GDC 2017 - A general introduction to the ideas behind Project Triton and its integration in Gears of War 4</li> <li>YouTube | Microsoft | Project Triton | GDC 2019 - An introductory talk on Project Acoustics and plugins for Unity and Unreal</li> <li>Web | Microsoft | Project Triton | SIGGRAPH 2014 - Core algorithms and architecture of the system</li> <li>Web | Microsoft | Project Triton | SIGGRAPH 2018 - Extend the model spatial audio effects such as portaling</li> </ul> <p></p> <p>Project Acoustics Figure: Connecting simulation to audio DSP with parameters[^1]</p> <p>The Project Acoustics YouTube video \"Interactive sound simulation: Rendering immersive soundscapes in games and virtual reality\" is an excellent primer on next-gen real-time audio capabilities.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#audio-definition-model-osc-midi","title":"Audio Definition Model / OSC / MIDI","text":"<p>Audio Definition Model / OSC / MIDI</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#adm-audio-definition-model","title":"ADM - Audio Definition Model","text":"<p>ADM - Audio Definition Model</p> <p>https://adm.ebu.io/</p> <p>ADM-OSC</p> <p>https://github.com/immersive-audio-live/ADM-OSC</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#osc-open-sound-control","title":"OSC (Open Sound Control)","text":"<p>OSC (Open Sound Control)</p> <p>https://opensoundcontrol.stanford.edu/</p> <p>For more information:</p> <ul> <li>Wikipedia | OSC</li> <li>OSC | Specifications</li> <li>OSC | NIME Paper</li> <li>OSC | Application Support</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#spat-revolution-flux-adm-osc","title":"Spat Revolution | Flux | ADM OSC","text":"<p>Spat Revolution | Flux | ADM OSC</p> <p>https://doc.flux.audio/en_US/spat_revolution_doc/Ecosystem_&amp;_integration_ADM_OSC.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#touchosc","title":"TouchOSC","text":"<p>TouchOSC</p> <p>https://hexler.net/touchosc</p> <p>For More Information:</p> <ul> <li>Traktor for TouchOSC</li> <li>Vimeo | TouchOSC | Scripting Demo</li> <li>TouchOSC | Lua Scripting API</li> <li>TouchOSC | Manual</li> <li>Hexler | Protokol Utility</li> <li>Hexler | KodeLife</li> <li>Hexler | TochViZ</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#control-booster-for-tangent-panels","title":"Control Booster for Tangent Panels","text":"<p>Control Booster for Tangent Panels</p> <p>https://souandrerodrigues.com.br/controlbooster/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Spatial%20Audio%20Tools/#node-red","title":"Node Red","text":"<p>Node Red</p> <p>https://github.com/Streampunk/node-red-contrib-dynamorse-core</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/System%20Admin%20Resources/","title":"System Admin Resources","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/System%20Admin%20Resources/#system-admin-community-sites","title":"System Admin Community Sites","text":"<p>System Admin Community Sites</p> <p>The system admin and pipeline TD staff in the entertainment sector monitor the Slack channels of the following two sites:</p> <p>StudioSysAdmins</p> <p>http://www.studiosysadmins.com</p> <p>Academy Software Foundation (ASWF)</p> <p>https://www.aswf.io</p> <p>https://www.aswf.io/join/ (Slack Channel Signup)</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/System%20Admin%20Resources/#security-policies","title":"Security Policies","text":"<p>Security Policies</p> <p>Any studio that is an MPAA (Motion Picture Association) member will have signed onto the TPN (Trusted Partner Network) agreement. This process defines the best practices and security policies for all companies and vendors in the entertainment sector.</p> <p>https://www.ttpn.org</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/System%20Admin%20Resources/#vfx-reference-platform","title":"VFX Reference Platform","text":"<p>VFX Reference Platform</p> <p>Film &amp; TV industry focused post-production software tries to match the software library dependency requirements set out in the \"VFX reference platform\" document which is aligned to a specific calendar year.</p> <p>http://vfxplatform.com</p> <p>This guide is prepared and maintained by the VES (Visual Effects Society).</p> <p>https://www.vesglobal.org</p> <p>What the VFX reference platform does is spell out the compatibility needs (primarily relevant for Linux releases) of entertainment industry tools so they can be used inside a larger production environment without \"clashes occurring\" between each of the apps.</p> <p>This reference platform guide spells out very specific requirements for the precise host OS and library versions used to compile software.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/The%20Karta%20Development%20Journey/","title":"The Karta Development Journey","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Many of the workflow ideas and features found in the Kartaverse suite started development in the following toolsets that I had the opportunity to collaborate on as either a developer, co-developer, software maintainer, or technical writer.</p> <p>Domemaster Photoshop Actions Pack, Domemaster3D, Domemaster Fusion Macros, RocketComp, PlayblastVR, Lightfielder Suite, OBQ Shaders, CompX, dome2rect, Panoramic Geometry Collection, CameraSnap, Z360 6DOF Stereo VR Tools, Dover Planar Grid Array Camera, KartaVR Volumetric Capture Utility, HDR Pano Camera Rig PIC32 Microcontroller Firmware, IRIXBASIC, Mission Control, WarpStitch TD, Spicy Acorn Vonk, Cryptomatte, KickAss ShaderZ, SilhouetteFX Python Scripts, along with the Steakunderwater Reactor Package Manager, the Dover Studios, Inc.\u00a0in-house pipeline tools BucketTime/Popcorn, the CameraCommander volumetric video pipeline, the ongoing Kino TR2X virtual production project, and the Borikuaverse project.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/The%20Kartaverse%20Packages/","title":"The Kartaverse Packages","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Kartaverse is an extensive open-source media production pipeline that integrates seamlessly with a broad range of post-production tools used in VFX, VP, XR, 360VR, fulldome, volumetric video, computer vision, and machine learning workflows.</p> <p>The core technologies that are part of the Kartaverse v5 suite are namely:</p> <ul> <li>KartaVR</li> <li>KartaVP</li> <li>KartaVision</li> <li>KartaSonic</li> <li>KartaLink</li> <li>CompX</li> <li>Vonk Ultra</li> </ul> <p>These modules are based upon the culmination of many years of research &amp; development.</p> <p>Kartaverse is delivered via the web as free open-source software. It costs you nothing to download and use the Kartaverse tools for both personal and commercial usage. It even works fine with Resolve (Free) running as the host program. The main tool, KartaVR, is Apache 2.0 licensed. Several tools like Vonk Ultra are GPL v3 licensed.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/","title":"Using BBEdit on macOS","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>BBEdit is a very capable programmer's text editor on macOS that is quick to load, easy to customize, and minimalistic in its usage of screen space.</p> <p>http://www.barebones.com/products/bbedit/index.html</p> <p>For more information about BBEdit usage:</p> <ul> <li>FuScript Integration for BBEdit</li> <li>More TextWrangler and BBEdit Color Schemes</li> <li>BBEdit Syntax Highlighter Page</li> <li>Arnold Syntax Highlighter</li> <li>Vray Scene Syntax Highlighter</li> <li>Mental Ray Syntax Highlighter and Apple Scripts</li> <li>Softimage SPDL Codeless Language Module</li> <li>Fabric Engine KL Codeless Language Module</li> <li>DigitalSky Codeless Language Module</li> <li>IRIXBASIC Codeless Language Module</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#preview-css","title":"Preview CSS","text":"<p>Preview CSS</p> <p>It is possible to add your own Preview CSS document to the BBEdit preferences folder. This is used in the Markdown preview window to define the CSS tags for the HTML rendered content.</p> <p>Here is an initial \"$HOME/Library/Application Support/BBEdit/Preview CSS/DefaultCSS_Markdown.css\" file to get your development efforts underway:</p> <pre><code>/* Stylesheet for MarkdownPad (http://markdownpad.com) */\n\n/* RESET\n=============================================================================*/\n\nhtml, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {\n  margin: 0;\n  padding: 0;\n  border: 0;\n}\n\n/* BODY\n=============================================================================*/\n\n@font-face {\n    font-family: 'Source Sans Pro';\n    font-style: normal;\n    font-weight: 300;\n    src: url('fonts/SourceSansPro-Regular.ttf');\n}\n\n@font-face {\n    font-family: 'Source Code Pro';\n    font-style: normal;\n    font-weight: 400;\n    src: url('fonts/SourceCodePro-Regular.ttf');\n}\n\n@import url(\"fonts/font-awesome.min.css\");\n\nbody {\n  font-family: \"Source Sans Pro\", Helvetica, arial, sans-serif;\n  font-size: 14px;\n  line-height: 1.6;\n  color: #333;\n  background-color: #1C1C1C;\n  padding: 20px;\n  max-width: 960px;\n  margin: 0 auto;\n}\n\nbody&gt;*:first-child {\n  margin-top: 0 !important;\n}\n\nbody&gt;*:last-child {\n  margin-bottom: 0 !important;\n}\n\n/* BLOCKS\n=============================================================================*/\n\np, blockquote, ul, ol, dl, table, pre {\n  margin: 15px 0;\n  color: #AAAAAA;\n  /* color: #7D8686; */\n}\n\n/* HEADERS\n=============================================================================*/\n\nh1, h2, h3, h4, h5, h6 {\n  margin: 20px 0 10px;\n  padding: 0;\n  font-weight: bold;\n  -webkit-font-smoothing: antialiased;\n}\n\nh1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {\n  font-size: inherit;\n}\n\nh1 {\n  font-size: 28px;\n  font-weight: 600;\n  color: #FFFFFF;\n}\n\nh2 {\n  font-size: 24px;\n  font-weight: 500;\n  border-bottom: 2px solid #D0D0D0;\n  color: #D0D0D0;\n}\n\nh3 {\n  font-size: 18px;\n  font-weight: 400;\n  color: #D0D0D0;\n}\n\nh4 {\n  font-size: 16px;\n  color: #D0D0D0;\n}\n\nh5 {\n  font-size: 14px;\n  color: #D0D0D0;\n}\n\nh6 {\n  font-size: 14px;\n  color: #D0D0D0;\n}\n\nh7 {\n  font-size: 14px;\n  color: #D0D0D0;\n  /* color: #277BA5; */\n}\n\nbody&gt;h2:first-child, body&gt;h1:first-child, body&gt;h1:first-child+h2, body&gt;h3:first-child, body&gt;h4:first-child, body&gt;h5:first-child, body&gt;h6:first-child {\n  margin-top: 0;\n  padding-top: 0;\n}\n\na:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {\n  margin-top: 0;\n  padding-top: 0;\n}\n\nh1+p, h2+p, h3+p, h4+p, h5+p, h6+p {\n  margin-top: 10px;\n}\n\n/* LINKS\n=============================================================================*/\n\na {\n  color: #4183C4;\n  text-decoration: none;\n}\n\na:hover {\n  text-decoration: underline;\n}\n\n/* LISTS\n=============================================================================*/\n\nul, ol {\n  padding-left: 30px;\n  color: #C4C4C4;\n}\n\nul li &gt; :first-child, \nol li &gt; :first-child, \nul li ul:first-of-type, \nol li ol:first-of-type, \nul li ol:first-of-type, \nol li ul:first-of-type {\n  margin-top: 0px;\n}\n\nul ul, ul ol, ol ol, ol ul {\n  margin-bottom: 0;\n}\n\ndl {\n  padding: 0;\n}\n\ndl dt {\n  font-size: 14px;\n  font-weight: bold;\n  font-style: italic;\n  padding: 0;\n  margin: 15px 0 5px;\n}\n\ndl dt:first-child {\n  padding: 0;\n}\n\ndl dt&gt;:first-child {\n  margin-top: 0px;\n}\n\ndl dt&gt;:last-child {\n  margin-bottom: 0px;\n}\n\ndl dd {\n  margin: 0 0 15px;\n  padding: 0 15px;\n}\n\ndl dd&gt;:first-child {\n  margin-top: 0px;\n}\n\ndl dd&gt;:last-child {\n  margin-bottom: 0px;\n}\n\n/* CODE\n=============================================================================*/\n\npre, code, tt {\n  font-size: 12px;\n  font-family: \"Source Code Pro\", monospace;\n}\n\ncode, tt {\n  margin: 0 0px;\n  padding: 0px 0px;\n  white-space: nowrap;\n  border: 1px solid #262626;\n  background-color: #363636;\n  color: #D0D0D0;\n  border-radius: 3px;\n}\n\npre&gt;code {\n  margin: 0;\n  padding: 0;\n  white-space: pre;\n  border: none;\n  background: transparent;\n}\n\npre {\n  background-color: #363636;\n  border: 1px solid #262626;\n  font-size: 13px;\n  line-height: 19px;\n  overflow: auto;\n  padding: 6px 10px;\n  border-radius: 3px;\n}\n\npre code, pre tt {\n  background-color: transparent;\n  border: none;\n}\n\nkbd {\n    -moz-border-bottom-colors: none;\n    -moz-border-left-colors: none;\n    -moz-border-right-colors: none;\n    -moz-border-top-colors: none;\n    background-color: #DDDDDD;\n    background-image: linear-gradient(#F1F1F1, #DDDDDD);\n    background-repeat: repeat-x;\n    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;\n    border-image: none;\n    border-radius: 2px 2px 2px 2px;\n    border-style: solid;\n    border-width: 1px;\n    font-family: \"Source Sans Pro\", Helvetica, arial, sans-serif;\n    line-height: 10px;\n    padding: 1px 4px;\n}\n\n/* QUOTES\n=============================================================================*/\n\nblockquote {\n  border-left: 4px solid #DDD;\n  padding: 0 15px;\n  color: #777;\n}\n\nblockquote&gt;:first-child {\n  margin-top: 0px;\n}\n\nblockquote&gt;:last-child {\n  margin-bottom: 0px;\n}\n\n/* HORIZONTAL RULES\n=============================================================================*/\n\nhr {\n  clear: both;\n  margin: 15px 0;\n  height: 0px;\n  overflow: hidden;\n  border: none;\n  background: transparent;\n  border-bottom: 4px solid #ddd;\n  padding: 0;\n}\n\n/* TABLES\n=============================================================================*/\n\ntable th {\n  font-weight: bold;\n}\n\ntable th, table td {\n  /* border: 1px solid #ccc; */ \n  /* padding: 6px 13px; */ \n}\n\ntable tr {\n  /* border-top: 1px solid #ccc; */\n  /* background-color: #363636; */\n  /* color: #D0D0D0; */\n}\n\n\n/* IMAGES\n=============================================================================*/\n\nimg {\n  max-width: 80%;\n  /* max-width: 100%; */\n  display: block;\n  margin-left: auto;\n  margin-right: auto;\n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#bbedit-script-menu","title":"BBEdit Script Menu","text":"<p>BBEdit Script Menu</p> <p>BBEdit supports the use of custom shell scripts and Apple Scripts via the Script menu. You can bind hotkeys to any of the entries that are added to this menu.</p> <p></p> <p>If you select the \"Scripts &gt; Open Scripts Folder\" menu item you can quickly access the <code>$HOME/Library/Application Support/BBEdit/Scripts/</code></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#bbedit-script-code-examples","title":"BBEdit Script Code Examples","text":"<p>BBEdit Script Code Examples</p> <p>Here are several pre-made BBEdit scripts to get you starred:</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#zoom-in-text","title":"Zoom In Text","text":"<p>Zoom In Text</p> <p>An Apple Script named \"Zoom In Text.scpt\" can be linked to the BBEdit hotkey for \"Command + =\". The script content is:</p> <pre><code>-- From: http://bbedit-hints.tumblr.com/\ntell application \"BBEdit\"\n    tell window 1\n        set display magnification to display magnification * 1.25\n    end tell\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#zoom-out-text","title":"Zoom Out Text","text":"<p>Zoom Out Text</p> <p>An Apple Script named \"Zoom Out Text.scpt\" can be linked to the BBEdit hotkey for \"Command + -\". The script content is:</p> <pre><code>-- From: http://bbedit-hints.tumblr.com/\ntell application \"BBEdit\"\n    tell window 1\n        set display magnification to display magnification / 1.25\n    end tell\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#zoom-text-100","title":"Zoom Text 100%","text":"<p>Zoom Text 100%</p> <p>An Apple Script named \"Zoom Text 100%.scpt\" can be linked to a BBEdit hotkey. The script content is:</p> <pre><code>-- From: http://bbedit-hints.tumblr.com/\ntell application \"BBEdit\"\n    set display magnification of window 1 to 1.0 -- displays text at 2x\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#open-the-activity-monitor","title":"Open the Activity Monitor","text":"<p>Open the Activity Monitor</p> <p>An Apple Script named \"Open Tool Activity Monitor.scpt\" can be used to launch the macOS Activity Monitor program. The script content is:</p> <pre><code>-- Open Tool Activity Monitor\n-- Open up the macOS Activity Monitor program to inspect the running program and the CPU load.\n\ntell application \"Activity Monitor\"\n    activate\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#open-the-terminal-window","title":"Open the Terminal Window","text":"<p>Open the Terminal Window</p> <p>An Apple Script named \"Open Tool Terminal.scpt\" can be used to launch the macOS Terminal program. The script content is:</p> <pre><code>-- Open Tool Terminal\n-- Open up the macOS Terminal program.\n\ntell application \"Terminal\"\n    activate\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#open-the-console-window","title":"Open the Console Window","text":"<p>Open the Console Window</p> <p>An Apple Script named \"Open Tool Console.scpt\" can be used to launch the macOS Console program. The script content is:</p> <pre><code>-- Open Tool Console\n-- Open up the macOS Console program to inspect error logs.\n\ntell application \"Console\"\n    activate\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#open-the-temp-directory-folder","title":"Open the Temp Directory Folder","text":"<p>Open the Temp Directory Folder</p> <p>An Apple Script named \"Open Folder $TMPDIR.scpt\" can be used to display a Finder based view to the $TEMPDIR environment variable defined filepath location. The script content is:</p> <pre><code>-- Open Folder $TMPDIR\n-- Open up the macOS /private/var/folders/ based temporary folder.\n\n-- Open the shaders folder:\nset command to \"open \\\"/${TMPDIR}\\\"\"\n\n-- display alert command\nset result to do shell script command\n-- display alert result\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#open-the-zsh-zprofile-document","title":"Open the ZSH .zprofile document","text":"<p>Open the ZSH .zprofile document</p> <p>An Apple Script named \"Open .zprofile.scpt\" can be used to display the current $HOME/.zprofile document in a BBEdit text editing window. The script content is:</p> <pre><code>-- Open .zprofile\n-- Open up the  ~/.zprofile which is used to configure environment variables in zsh\n\n-- Choose where the .zprofile file is stored on disk\nset envFileAlias to (path to current user folder as text) &amp; \".zprofile\"\n\n-- Touch the file path to make it exist if it wasn't found on disk\nset command to \"touch \" &amp; the quoted form of POSIX path of envFileAlias\n\n-- display alert command\nset result to do shell script command\n-- display alert result\n\n\n-- Display the console standard output result\ntell application \"BBEdit\"\n    try\n        open {file envFileAlias} with LF translation\n    on error\n        set errorMessage to \"[BASH] The .zprofile file: \" &amp; the the quoted form of POSIX path of envFileAlias &amp; \" is was not found. Please edit this Apple Script to customize your current paths.\"\n        display dialog the errorMessage buttons {\"OK\"} default button 1 with icon 1 giving up after 10\n    end try\nend tell\n</code></pre> <p>Open the ZSH .zshenv document</p> <p>An Apple Script named \"Open .zshenv.scpt\" can be used to display the current <code>$HOME/.zshenv</code> document in a BBEdit text editing window. The script content is:</p> <pre><code>-- Open .zshenv\n-- Open up the  ~/.zshenv which is used to configure environment variables in zsh\n\n-- Choose where the .zshenv file is stored on disk\nset envFileAlias to (path to current user folder as text) &amp; \".zshenv\"\n\n-- Touch the file path to make it exist if it wasn't found on disk\nset command to \"touch \" &amp; the quoted form of POSIX path of envFileAlias\n\n-- display alert command\nset result to do shell script command\n-- display alert result\n\n-- Display the console standard output result\ntell application \"BBEdit\"\n    try\n        open {file envFileAlias} with LF translation\n    on error\n        set errorMessage to \"[BASH] The .zshenv file: \" &amp; the the quoted form of POSIX path of envFileAlias &amp; \" is was not found. Please edit this Apple Script to customize your current paths.\"\n        display dialog the errorMessage buttons {\"OK\"} default button 1 with icon 1 giving up after 10\n    end try\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#get-the-exiftool-help-text","title":"Get the EXIFTool Help Text","text":"<p>Get the EXIFTool Help Text</p> <p>An Apple Script named \"EXIFTool Help.script\" can be used to export the command-line help info for EXIFTool into a BBEdit text editing document. The script content is:</p> <pre><code>-- EXIFTool Help\n\n-- Choose where the program is installed\nset programPath to quoted form of POSIX path of \"/Users/vfx/Reactor/Deploy/Bin/exiftool/exiftool\"\n\n-- Define the command line arguments\nset programOptions to \" -h | /usr/local/bin/bbedit -t \\\"EXIFTool Help.txt\\\"\"\nset command to programPath &amp; programOptions\nset output to do shell script command\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#get-the-ffmpeg-help-text","title":"Get the FFMpeg Help Text","text":"<p>Get the FFMpeg Help Text</p> <p>An Apple Script named \"FFMpeg Help.script\" can be used to export the command-line help info for FFMpeg into a BBEdit text editing document. The script content is:</p> <pre><code>-- FFmpeg Help\n\n-- Choose where the program is installed\nset programPath to quoted form of POSIX path of \"/Users/vfx/Reactor/Deploy/Bin/ffmpeg/bin/ffmpeg\"\n\n\n-- Define the command line arguments\nset programOptions to \" -h | /usr/local/bin/bbedit -t \\\"FFmpeg Help.txt\\\"\"\nset command to programPath &amp; programOptions\nset output to do shell script command\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#get-the-imagemagick-convert-help-text","title":"Get the Imagemagick Convert Help Text","text":"<p>Get the Imagemagick Convert Help Text</p> <p>An Apple Script named \"Imagemagick Convert Help.script\" can be used to export the command-line help info for the convert utility into a BBEdit text editing document. The script content is:</p> <pre><code>-- Imagemagick Convert Help\n\n-- Choose where the program is installed\n-- set convertPath to quoted form of POSIX path of \"/usr/local/bin/convert\"\nset convertPath to quoted form of POSIX path of \"/opt/ImageMagick/bin/convert\"\n\n-- Define the command line arguments\nset convertOptions to \" | /usr/local/bin/bbedit -t \\\"Imagemagick Convert Help.txt\\\"\"\nset command to convertPath &amp; convertOptions\nset output to do shell script command\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#get-the-imagemagick-supported-file-formats-text","title":"Get the Imagemagick Supported File Formats Text","text":"<p>Get the Imagemagick Supported File Formats Text</p> <p>An Apple Script named \"Imagemagick Supported File Formats.script\" can be used to export the command-line help info for the convert utility into a BBEdit text editing document. The script content is:</p> <pre><code>-- Imagemagick Convert Supported File Formats\n\n-- Choose where the program is installed\n-- set convertPath to quoted form of POSIX path of \"/usr/local/bin/convert\"\nset convertPath to quoted form of POSIX path of \"/opt/ImageMagick/bin/convert\"\n\n-- Define the command line arguments\nset convertOptions to \" -version  | /usr/local/bin/bbedit -t \\\"Imagemagick Convert Formats.txt\\\"\"\nset command to convertPath &amp; convertOptions\nset output to do shell script command\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#get-the-v-ray-server-help-text","title":"Get the V-Ray Server Help Text","text":"<p>Get the V-Ray Server Help Text</p> <p>An Apple Script named \"V-Ray Help.script\" can be used to export the command-line help info for V-Ray CLI program into a BBEdit text editing document. The script content is:</p> <pre><code>-- V-Ray Standalone Help\n\n-- Choose where the V-Ray Standalone program is installed\nset vrayPath to quoted form of POSIX path of \"/Applications/ChaosGroup/V-Ray/Maya2023/vray/bin/vrayserver\"\n\n-- Define the Vray Standalone command line arguments\nset vrayOptions to \" -help\"\n\n-- set command to vrayPath &amp; vrayOptions\nset command to vrayPath &amp; vrayOptions\nset output to do shell script command\n\n-- Target a Worksheet\n--tell application \"BBEdit\"\n--  set uws to Unix worksheet window\n--  tell uws\n--      select insertion point after last character\n--      set selection to command &amp; \"\\n\" &amp; output\n--  end tell\n--end tell\n\n-- Target an new document\ntell application \"BBEdit\"\n    activate\n    make new text document\n    -- make new text document at project window 1\n    --select insertion point after last character\n    set selection to command &amp; \"\n\" &amp; output\nend tell\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#launch-a-lua-love-script-from-bbedit","title":"Launch a Lua Love Script from BBEdit","text":"<p>Launch a Lua Love Script from BBEdit</p> <p>A BASH/ZSH shell script named \"Lua-Love-Launcher.sh\" can be used to run a Lua Love \"main.lua\" script automatically. The terminal output from Lua Love is sent to a new BBEdit text editing document. The script content is:</p> <pre><code>#! /bin/sh\n# Lua-Love-Launcher.sh\n# by Andrew Hazelden\n# ---------------------------------------------------------------\n# Installation Prep:\n# Copy the script file to the \"$HOME/Library/Application Support/BBEdit/Scripts/\" folder\n# chmod -R 777 \"$HOME/Library/Application Support/BBEdit/Scripts/Lua-Love-Launcher.sh\"\n\n# Run the Love package\n{\n  LOVE_PATH=\"/Applications/love.app/Contents/MacOS/love\"\n\n  # Base folder for the active document\n  BB_DOC_FOLDER=\"$(dirname ${BB_DOC_PATH})\"\n\n  # echo Opening Love Folder: $BB_DOC_FOLDER\n\n  # Launch love with the parent folder for the active main.lua file\n  # \"$LOVE_PATH\" \"$BB_DOC_FOLDER\"\n  \"$LOVE_PATH\" \"$BB_DOC_FOLDER\" | BBEdit &amp; \n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#generate-a-markdown-file-to-html-export","title":"Generate a Markdown File to HTML Export","text":"<p>Generate a Markdown File to HTML Export</p> <p>A BASH/ZSH shell script named \"Markdown Generator.sh\" can be used to run the cmark command-line tool automatically. Custom HTML based header and footer content, along with a CSS file are appended to the final HTML file output. The script content is:</p> <pre><code>#! /bin/sh\n# Markdown Docs to HTML Converter\n# by Andrew Hazelden\n\n# Generate HTML docs from Markdown files\n{\n  # ---------------------------------------------------------------\n  # Markdown document to convert (without the .md file extension)\n  MARKDOWN_DOCUMENT=\"${BB_DOC_PATH}\"\n\n  # Define the output filename\n  # HTML_OUTPUT=\"${MARKDOWN_DOCUMENT}.html\"\n  HTML_OUTPUT=`echo \"${MARKDOWN_DOCUMENT}\" | sed \"s/\\..*$//\"`\".html\"\n\n  # ---------------------------------------------------------------\n  # Load the page elements\n\n  MARKDOWN_CSS=\"$HOME/Library/Application Support/BBEdit/Preview CSS/DefaultCSS_Markdown.css\"\n  MARKDOWN_HTML_HEADER=\"$HOME/Markdown/markdown_header.html\"\n  MARKDOWN_HTML_BODY=\"$HOME/Markdown/markdown_body.html\"\n  MARKDOWN_HTML_FOOTER=\"$HOME/Markdown/Markdown_footer.html\"\n\n  # ---------------------------------------------------------------\n  # Merge the HTML document\n\n  # Add the base HTML header to the new file\n  cat \"${MARKDOWN_HTML_HEADER}\" &gt; \"${HTML_OUTPUT}\"\n\n  # Append the CSS\n  cat \"${MARKDOWN_CSS}\" &gt;&gt; \"${HTML_OUTPUT}\"\n\n  # Add the HTML body tag to the new file\n  cat \"${MARKDOWN_HTML_BODY}\" &gt;&gt; \"${HTML_OUTPUT}\"\n\n  # Append the Markdown converted text using the cmark command-line tool\n  /usr/local/bin/cmark \"${MARKDOWN_DOCUMENT}\" --to html &gt;&gt; \"${HTML_OUTPUT}\"\n\n  # Append the HTML footer\n  cat \"${MARKDOWN_HTML_FOOTER}\" &gt;&gt; \"${HTML_OUTPUT}\"\n\n  # ---------------------------------------------------------------\n\n  # bbedit --language HTML \"${HTML_OUTPUT}\"\n  open \"${HTML_OUTPUT}\"\n}\n</code></pre> <p>The cmark \"CommonMark\" CLI utility can be installed using homebrew:</p> <pre><code>brew install commonmark\n</code></pre> <p>The cmark CLI executable is located on-disk at:</p> <pre><code>/usr/local/bin/cmark\n</code></pre> <p>The cmark man-page can be displayed using:</p> <pre><code>man cmark\n</code></pre> <p>The cmark command-line help output can be displayed using:</p> <pre><code>cmark --help\nUsage:   cmark [FILE*]\nOptions:\n  --to, -t FORMAT  Specify output format (html, xml, man, commonmark, latex)\n  --width WIDTH    Specify wrap width (default 0 = nowrap)\n  --sourcepos      Include source position attribute\n  --hardbreaks     Treat newlines as hard line breaks\n  --nobreaks       Render soft line breaks as spaces\n  --safe           Suppress raw HTML and dangerous URLs\n  --smart          Use smart punctuation\n  --normalize      Consolidate adjacent text nodes\n  --help, -h       Print usage information\n  --version        Print version\n</code></pre> <p>DefaultCSS_Markdown.css File Location:</p> <pre><code>$HOME/Library/Application Support/BBEdit/Preview CSS/DefaultCSS_Markdown.css\n</code></pre> <p>markdown_header.html File Contents:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Documentation&lt;/title&gt;\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /&gt;\n&lt;style type=\"text/css\"&gt;\n</code></pre> <p>markdown_body.html File Contents:</p> <pre><code>&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n</code></pre> <p>markdown_footer.html File Contents:</p> <pre><code>&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#bbedit-script-environment-variables","title":"BBEdit Script Environment Variables","text":"<p>BBEdit Script Environment Variables</p> <p>A BBEdit shell script is able to access several handy environment variables. This feature lets your external script know things about the current document that is open \"<code>${BB_DOC_PATH}</code>\", and what line is selected in the file \"<code>${BB_DOC_SELSTART_LINE}</code>\".</p> <p>Here is list of the most common environment variables you can use with BBEdit launched shell scripts:</p> <pre><code>${BB_DOC_LANGUAGE}        Name of the document's current language (not set if language is \"none\") BB_DOC_MODE            Emacs mode of the document's current language \n${BB_DOC_NAME}            name of the document \n${BB_DOC_PATH}            path of the document (not set if doc is unsaved) \n${BB_DOC_SELEND}          (zero-based) end of the selection range (not set if not text document) \n${BB_DOC_SELEND_COLUMN}   (one-based) de-tabbed column number of BB_DOC_SELEND \n${BB_DOC_SELEND_LINE}     (one-based) line number of BB_DOC_SELEND \n${BB_DOC_SELSTART}        (zero-based) start of the selection range (not set if not text document) \n${BB_DOC_SELSTART_COLUMN} (one-based) de-tabbed column number of BB_DOC_SELSTART \n${BB_DOC_SELSTART_LINE}   (one-based) line number of BB_DOC_SELSTART\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20BBEdit%20on%20macOS/#bbedit-hotkey-bindings","title":"BBEdit Hotkey Bindings","text":"<p>BBEdit Hotkey Bindings</p> <p>The BBEdit preferences allow you to bind custom hotkeys to any menu item in the program. Click on the \"Menus and Shortcut\" entry. This section makes it possible for your custom scripts to feel like a native feature that is integrated in BBEdit.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/","title":"Using Notepad++ for Fusion on Windows","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>There is a highly-customized Resolve/Fusion IDE usage centric version of Notepad++ available from Reactor. It is a 32-bit build of Notepad++ that has the TextFX module installed.</p> <p>Please hold off doing an automatic-update the moment Notepad++ launches as there are not likely too many features missing from this release that you require. If you accidentally hit the auto-update button you will likely download, and roll-back to a 100% stock build of Notepad++ if you immediately hit the update button. Resist the urge....</p> <p>https://notepad-plus-plus.org/</p> <p>Notepad++ for Fusion Customization Documentation:</p> <ul> <li>Notepad++ for Fusion Atom package</li> <li>NPP Atom Package Docs</li> <li>Web | Add \"Open with Notepad++\" to the Right-Click Menu</li> <li>Pixar USD Syntax Highlighter</li> </ul> <p>Notepad++ Related Docs:</p> <ul> <li>Web | Microsoft | Creating Shell Extension Handlers</li> <li>Web | Microsoft | Working with Shell Extensions</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#the-dark-mode-customized-ui","title":"The Dark Mode Customized UI","text":"<p>The Dark Mode Customized UI</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#the-language-menu","title":"The Language Menu","text":"<p>The Language Menu</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#the-run-menu","title":"The Run Menu","text":"<p>The Run Menu</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#right-click-contextual-menu-items","title":"Right-Click Contextual Menu Items:","text":"<p>Right-Click Contextual Menu Items:</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#edit-sub-menu","title":"Edit Sub-Menu","text":"<p>Edit Sub-Menu</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#search-sub-menu","title":"Search Sub-Menu","text":"<p>Search Sub-Menu</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#tools-sub-menu","title":"Tools Sub-Menu","text":"<p>Tools Sub-Menu</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#view-code-snippets","title":"View Code Snippets","text":"<p>View Code Snippets</p> <p>This user interface has pre-made code snippets of UI Manager Lua, UI Manager Python, and BBCode content.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Using%20Notepad%2B%2B%20for%20Fusion%20on%20Windows/#notepad-shell-extensions-for-windows","title":"Notepad++ Shell Extensions for Windows","text":"<p>Notepad++ Shell Extensions for Windows</p> <p>Shell; Extensions are a core-Windows feature that allows you to add an entry to the Windows Registry that will insert a new custom Explorer Right-Click contextual menu entry.</p> <p>A stock \"Add Open in Notepad++ Shell Ext Entry.reg\" shell extension text-file looks like this before the executable file-path has been revised to a custom installation location:</p> <pre><code>Windows Registry Editor Version 5.00\n\n[HKEY_CLASSES_ROOT\\*\\shell\\Open with Notepad++]\n\"Icon\"=\"C:\\\\Program Files (x86)\\\\Notepad++\\\\notepad++.exe\"\n\n[HKEY_CLASSES_ROOT\\*\\shell\\Open with Notepad++\\command]\n@=\"\\\"C:\\\\Program Files (x86)\\\\Notepad++\\\\notepad++.exe\\\" \\\"%1\\\"\"\n</code></pre> <p>You can remove this shell extension using the following Windows Registry file named \"Remove Notepad++ Shell Ext Entry.reg\":</p> <pre><code>Windows Registry Editor Version 5.00\n[-HKEY_CLASSES_ROOT\\*\\shell\\Open with Notepad++]\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/","title":"Virtual Production","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#virtual-production-software","title":"Virtual Production Software","text":"<p>Virtual Production Software</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#assimilate-livefx","title":"Assimilate LiveFX","text":"<p>Assimilate LiveFX</p> <p>https://www.assimilateinc.com/products/livefx/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#unreal-engine","title":"Unreal Engine","text":"<p>Unreal Engine</p> <p>https://www.unrealengine.com/en-US/virtual-production</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#unreal-ndisplay","title":"Unreal nDisplay","text":"<p>Unreal nDisplay</p> <p>https://docs.unrealengine.com/4.26/en-US/WorkingWithMedia/nDisplay/Overview/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#unreal-composure","title":"Unreal Composure","text":"<p>Unreal Composure</p> <p>https://docs.unrealengine.com/en-US/Engine/Composure/index.html</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#owl-streaming-toolkit-for-unreal","title":"OWL Streaming Toolkit for Unreal","text":"<p>OWL Streaming Toolkit for Unreal</p> <p>Off World produces a solution that improves the artist-friendly nature of Unreal based virtual production workflows. The streaming toolkit allows Unreal rendered low-latency NDI video streams to be passed with RGBA data directly into Assimilate LiveFX.</p> <p>https://offworld.live/products/unreal-engine-live-streaming-toolkit</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#disguise","title":"Disguise","text":"<p>Disguise</p> <p>https://www.disguise.one/en/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#unity","title":"Unity","text":"<p>Unity</p> <p>https://unity.com/roadmap/virtual-production</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#touchdesigner","title":"TouchDesigner","text":"<p>TouchDesigner</p> <p>https://derivative.ca/UserGuide/TouchDesigner</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#notch","title":"Notch","text":"<p>Notch</p> <p>https://www.notch.one/virtualproduction/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#nvidia-omniverse","title":"NVIDIA Omniverse","text":"<p>NVIDIA Omniverse</p> <p>At the base level, Omniverse is a DCC platform that helps users perform tasks like next-generation OpenUSD workflow design/collaboration, virtual production asset prep, ML synthetic training data generation, and metaverse content creation.</p> <p>https://www.nvidia.com/en-us/omniverse/</p> <p>The Omniverse toolset has been humorously described by end users as vaguely reminiscent of the entrepreneurial business model that existed in the Klondike era with the \"pick and shovel\" gear manufacturers.</p> <p>The meaning here is that Omniverse is a tool that exists to serve a specific utilitarian purpose --- to help the end user get work done fast and efficiently.</p> <p>The Omniverse end customer is then going off to use the pick and shovel tools they bought on large scale undertakings, to stake their gold claim, and do something big and impactful.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#aximmetry","title":"Aximmetry","text":"<p>Aximmetry</p> <p>https://aximmetry.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#virtual-production-hardware","title":"Virtual Production Hardware","text":"<p>Virtual Production Hardware</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#brompton-led-video-processors","title":"Brompton LED Video Processors","text":"<p>Brompton LED Video Processors</p> <p>https://www.bromptontech.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#roe-visual-led-display-panels","title":"ROE Visual LED Display Panels","text":"<p>ROE Visual LED Display Panels</p> <p>https://www.roevisual.com/en/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#aoto-led-display-panels","title":"AOTO LED Display Panels","text":"<p>AOTO LED Display Panels</p> <p>https://en.aoto.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#7th-sense-design-media-servers","title":"7<sup>th</sup> Sense Design Media Servers","text":"<p>7<sup>th</sup> Sense Design Media Servers</p> <p>https://7thsense.one/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#virtual-production-mocap-moco-and-camera-tracking-solutions","title":"Virtual Production MoCap, MoCo, and Camera Tracking Solutions","text":"<p>Virtual Production MoCap, MoCo, and Camera Tracking Solutions</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#vicon-mocap","title":"Vicon MoCap","text":"<p>Vicon MoCap</p> <p>https://www.vicon.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#xsens-mocap","title":"Xsens MoCap","text":"<p>Xsens MoCap</p> <p>https://www.xsens.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#faceware-mocap","title":"Faceware MoCap","text":"<p>Faceware MoCap</p> <p>https://facewaretech.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#moveai-mocap","title":"Move.ai MoCap","text":"<p>Move.ai MoCap</p> <p>https://www.move.ai</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#unreal-metahuman","title":"Unreal Metahuman","text":"<p>Unreal Metahuman</p> <p>https://www.unrealengine.com/en-US/metahuman</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#ziva-dynamics","title":"Ziva Dynamics","text":"<p>Ziva Dynamics</p> <p>https://zivadynamics.com</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#ncam-camera-tracking","title":"nCam Camera Tracking","text":"<p>nCam Camera Tracking</p> <p>https://www.ncam-tech.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#vive-mars-cam-tracking","title":"VIVE Mars Cam Tracking","text":"<p>VIVE Mars Cam Tracking</p> <p>https://mars.vive.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#eztrack-tracking-hub","title":"EZtrack Tracking Hub","text":"<p>EZtrack Tracking Hub</p> <p>https://eztrack.studio/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#gyroflow-flowshutter-imu-data-logger","title":"Gyroflow Flowshutter IMU Data Logger","text":"<p>Gyroflow Flowshutter IMU Data Logger</p> <p>https://github.com/gyroflow/flowshutter</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#mark-roberts-motion-control","title":"Mark Roberts Motion Control","text":"<p>Mark Roberts Motion Control</p> <p>https://www.mrmoco.com/</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#virtual-production-lens-metadata","title":"Virtual Production Lens Metadata","text":"<p>Virtual Production Lens Metadata</p> <p>A key aspect of virtual production is to have cine lenses that support the passing of lens metadata.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Virtual%20Production/#cooke-optics","title":"Cooke Optics","text":"<p>Cooke Optics</p> <p>Cooke Optics cinema lenses use the /i technology lens metadata protocol to store important lens information. The /i technology lens data is passed through a PL mount lens connector to the cinema camera body.</p> <p>This is a YAML based metadata encoding format that holds 4D time-based data for the lens parameters that is accurately synced to the current video frame. Also having the unique lens serial number record can be helpful in post-production as it provides artists with access to the original Cooke Optics factory lens calibration information which is useful when working with anamorphic lenses that have extensive lens breathing.</p> <p>Blackmagic Design URSA 12K camera bodies for example, are able to store the /i technology metadata in native BRAW format media.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/","title":"Working With Environment Variables","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>An environment variable can be thought of as a system wide preference that any program that is started is able to read. An environment variable is a technique that system administrators will often use to customize the operating environment that software runs inside of on a workstation or render node.</p> <p>This concept of customizing environment variables allows you to pass a common set of preferences to multiple executable programs in a consistent way. It helps inform software of the custom values you might want to define system wide and avoids using hard-coded fixed settings in each application.</p> <p>It is possible to read environment variables inside of just about every general purpose programming language or scripting language like C, C++, C#, Python, Lua, Perl, PHP, Batch, and BASH/ZSH, etc.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#windows-environment-variables","title":"Windows Environment Variables","text":"<p>Windows Environment Variables</p> <p>The \"PATH\" variable, which is written as %PATH% when accessed from the command prompt window, is used for several purposes. One of those use cases is to define which executable programs on your computer (.exe, .bat, etc files) can be run from a terminal session simply by typing in the program's base filename without having to always write in the full folder path to the program.</p> <p>This saves a lot of time when a user frequently navigates a filesystem hierarchy in a text based command prompt/terminal window and runs a series of command line tools.</p> <p>Editing the Windows OS %PATH% environment variable is done by opening your Windows System Control Panel. Click on the Advanced system settings button on the left side of the window.</p> <p></p> <p>The \"System Properties\" window will appear. Click on the Environment Variables... button.</p> <p></p> <p>In the \"Environment Variable\" window you need to scroll down in the \"System variables\" section of the view and select the Path entry. Click the Edit... button.</p> <p></p> <p>On Windows 10 a visual \"Edit environment variable\" editor window will appear. This dialog has separate path text fields that make it easier to add/remove and re-order the individual environment <code>%Path%</code> variable items.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#listing-the-active-windows-environment-variables","title":"Listing the Active Windows Environment Variables","text":"<p>Listing the Active Windows Environment Variables</p> <p>On Windows 10 you can type \"<code>set</code>\" into the Command Prompt window to see all of the active environment variables on the system.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#linux-environment-variables","title":"Linux Environment Variables","text":"<p>Linux Environment Variables</p> <p>If you are on a Linux system, system wide environment variables are typically defined by editing either a \"<code>$HOME/.profile</code>\" or \"<code>$HOME/.bash_profile</code>\" document based upon your current shell.</p> <p>You would then add new environment variable to the profile document that look a bit like this:</p> <pre><code>export REACTOR_DEBUG_FILES=true\nexport REACTOR_DEBUG=true\nexport REACTOR_INSTALL_PATHMAP=AllData:\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#listing-the-active-linux-environment-variables","title":"Listing the Active Linux Environment Variables","text":"<p>Listing the Active Linux Environment Variables</p> <p>On Linux you can type \"<code>env</code>\" into the Terminal window to see all of the active environment variables on the system.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#macos-environment-variables","title":"macOS Environment Variables","text":"<p>macOS Environment Variables</p> <p>If you are on macOS Monterey, you might have several environment variables active in your macOS ZSH session, that were defined via a \"<code>$HOME/.zshrc</code>\" file. If you add more and more environment variables to your workstation in this fashion, you will later on be quite surprised to find out these values are not used system wide in all of the programs you might run.</p> <p>In the long term, macOS power users tend to transition away from relying on .zshrc files as the way they define their environment variables over to using macOS Launch Agent .plist files. The .plist file approach is advantageous as it allows executables that are started by double-clicking on the .app package, or run from the dock, to access the same environment variables values that can be accessed in Terminal sessions and in AppleScripts, too.</p> <p>On a macOS system the easiest and most reliable way to set up new environment variables is with the help of LaunchAgent .plist files. If you want to make it easy to visually edit a LaunchAgent PLIST document as you get started, you can look at using a 3<sup>rd</sup> party utility like\"LaunchControl\" by Soma-Zone.</p> <p>Most often Launch Agent .plist files are edited by hand in a programmer's text editor, to customize them, before you would install them on your system.</p> <p>Here is an example of a Launch Agent PLIST text file that ships with the Reactor package manager. It is named \"setenv.reactor.REACTOR_DEBUG.plist\" and is used to turn on debug logging via a \"<code>REACTOR_DEBUG</code>\" environment variable that is set to a value of \"<code>true</code>\":</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;\n&lt;plist version=\"1.0\"&gt;\n    &lt;dict&gt;\n     &lt;key&gt;Label&lt;/key&gt;\n     &lt;string&gt;setenv.reactor.REACTOR_DEBUG&lt;/string&gt;\n     &lt;key&gt;ProgramArguments&lt;/key&gt;\n     &lt;array&gt;\n         &lt;string&gt;/bin/launchctl&lt;/string&gt;\n         &lt;string&gt;setenv&lt;/string&gt;\n         &lt;string&gt;REACTOR_DEBUG&lt;/string&gt;\n         &lt;string&gt;true&lt;/string&gt;\n     &lt;/array&gt;\n     &lt;key&gt;RunAtLoad&lt;/key&gt;\n     &lt;true/&gt;\n    &lt;/dict&gt;\n&lt;/plist&gt;\n</code></pre> <p>These type of Launch Agent .plist documents are designed to be installed on your macOS system using root permissions to the folder:</p> <pre><code>/Library/LaunchAgents/\n</code></pre> <p>Alternatively, you can install a Launch Agent .plist file in your home folder:</p> <pre><code>/Users/vfx/Library/LaunchAgents\n</code></pre> <p>When you go to install the .plist files you will need to change the documents to be owned by \"root\", have the group name of \"wheel\", and have a Unix \"octal\" file permission setting of 644.</p> <pre><code>sudo chown root /Library/LaunchAgents/setenv.reactor.*.plist\nsudo chgrp wheel /Library/LaunchAgents/setenv.reactor.*.plist\nsudo chmod 644 /Library/LaunchAgents/setenv.reactor.*.plist\n</code></pre> <p>You can take a look at the file permissions of the Launch Agent files on your system using the following terminal command:</p> <pre><code>ls -la /Library/LaunchAgents/\n</code></pre> <p>You will then see a directory listing that looks something like this:</p> <pre><code>drwxr-xr-x  24 root  wheel   816 Nov 17 12:28 .\ndrwxr-xr-x+ 62 root  wheel  2108 Nov 17 11:59 ..\n-rw-r--r--   1 root  wheel   715 Oct 26  2016 org.macosforge.xquartz.startx.plist\n-rw-r--r--@  1 root  wheel   474 Nov 17 05:42 setenv.reactor.REACTOR_BRANCH.plist\n-rw-r--r--@  1 root  wheel   463 Oct 25 07:25 setenv.reactor.REACTOR_DEBUG.plist\n-rw-r--r--@  1 root  wheel   475 Oct 25 07:27 setenv.reactor.REACTOR_DEBUG_FILES.plist\n-rw-r--r--@  1 root  wheel   473 Dec  7 22:23 setenv.reactor.REACTOR_INSTALL_PATHMAP.plist\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Immersive%20Pipeline%20Integration%20Guide/Working%20With%20Environment%20Variables/#listing-the-active-macos-environment-variables","title":"Listing the Active macOS Environment Variables","text":"<p>Listing the Active macOS Environment Variables</p> <p>On macOS you can type \"<code>env</code>\" into the Terminal window to see all of the active environment variables on the system.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Acknowledgements/","title":"Acknowledgements","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The original Spicy Acorn Vonk toolset was created by:</p> <ul> <li>Kristof Indeherberge</li> <li>C\u00e9dric Duriau</li> </ul> <p>The Vonk Ultra fork is maintained by:</p> <ul> <li>Andrew Hazelden</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Adding%20Data%20Nodes%20to%20a%20Composite/","title":"Adding Data Nodes to a Composite","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>In the Resolve Fusion page you have several ways to access the newly installed Vonk nodes:</p> <p>Select Tools Dialog</p> <p>Pressing the Shift + Space hotkey will display the \"Select Tools\" dialog. You can also type in a partial name match like \"Text\" or \"Number\" if you know the type of Vonk node you require in advance.</p> <p>It is helpful to know that the Vonk nodes all start with the letter \"v\" as a prefix. This helps cluster the nodes together alphabetically.</p> <p></p> <p>Nodes View Contextual Menu</p> <p>The Vonk nodes can be browsed in a hierarchical fashion using the Nodes view. Right-click to display a contextual pop-up menu system. At the top of this menu is the \"Add Tools &gt;\" entry. Navigate to the \"Kartaverse &gt; Vonk Ultra\" sub-menus.</p> <p></p> <p>Effects Library Tab</p> <p>The \"Effects Library\" tab at the top of the Resolve user interface can be used to browse Vonk nodes.</p> <p></p> <p>Tools Menu</p> <p>Fusion Studio has a \"Tools\" menu in the main menu bar that can be used to add nodes to a composite as well.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Fusion%20Render%20Node%20Customization/","title":"Fusion Render Node Customization","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>After installing Vonk using Reactor, a custom \"LuaModules:\" PathMap entry is required in the Fusion Render Node app preferences to avoid Fusion Render Manager errors when batch rendering comps that use Vonk data nodes.</p> <p>1. Open the Fusion Render Node program and select the \"Preferences...\" menu item.</p> <p>2. Click on the \"Global Settings &gt; Path Map\" category on the left side of the Preferences window.</p> <p>3. At the bottom of the window click on the \"New\" button to add a new entry to the \"User\" section of the \"Path Map\" view.</p> <p>4. Enter the following settings From: LuaModules: and To: UserPaths:Modules/Lua. Click the \"Save\" button to retain these settings.</p> <p>5. If you don't have Reactor Path Map entries added to Fusion Render Node already, then you might have to further customize the preferences to add values like:</p> <p>Windows:</p> <p>From: <code>Reactor:</code> and To: <code>C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\</code></p> <p>macOS:</p> <p>From: <code>Reactor:</code> and To: <code>/Library/Application Support/Blackmagic Design/Fusion/Reactor/</code></p> <p>Linux:</p> <p>From: <code>Reactor:</code> and To: <code>/var/BlackmagicDesign/Fusion/Reactor/</code></p> <p>Also you would need to edit the pre-existing UserPaths PathMap entry:</p> <p>From: <code>UserPaths:</code> and To: <code>UserData:;AllData:;Fusion:;Reactor:Deploy</code></p> <p>6. Restart Fusion Render Manager to lock in these values.</p> <p>Note: If the LuaModules PathMap entries were not added to Fusion Render Node's preferences, a typical error message in Fusion Render Node would look a bit like this:</p> <pre><code>14/Apr/22 16:12:50: .../Fusion/Fuses/Vonk Ultra/Text/Create/vTextFromArray.fuse:5: module 'vjsonutils' not found:\n    no field package.preload['vjsonutils']\n    no file 'LuaModules:vjsonutils.lua'\n    no file 'LuaModules:vjsonutils/init.lua'\n    no file 'LuaModules:vjsonutils.so'\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Install%20Vonk/","title":"Install Vonk","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>The Vonk Ultra toolset is installed using the Reactor Package Manager for Resolve/Fusion.</p> <p></p> <p>After you have Reactor installed and open, select the \"Kartaverse &gt; Vonk Ultra\" category on the left sidebar. Click on the package named \"Vonk Ultra\" and then press the \"Install\" button.</p> <p></p> <p>Once the installation is complete, restart Resolve or Fusion standalone. This will load the fuses.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Learning%20Resources/","title":"Learning Resources","text":"<ul> <li>Vonk Ultra Documentation</li> <li>Vonk Ultra GitLab Repository</li> <li>Vonk Ultra Steakunderwater Forum Thread</li> </ul>"},{"location":"Kartaverse/Vonk%20Ultra/Software%20Required/","title":"Software Required","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>To run Vonk based workflows on your system you will need the following tools:</p> <ul> <li> Reactor Package Manager (Free)</li> <li>BMD Resolve (Free) / Resolve Studio</li> <li>BMD Fusion Studio</li> <li> Imagemagick (Free) Optional</li> <li> FFMpeg (Free) Optional</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Essentials/","title":"Vonk Essentials","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Vonk nodes are modifiers that live in the node-graph. You can connect Vonk nodes together if they pass a common supported data type like text, numbers, etc.</p> <p></p> <p>If you right-click on an attribute in the Inspector window, the \"Connect To\" contextual pop-up menu appears. This technique allows you to directly link an existing Vonk node's output connection to a specific channel attribute that doesn't have an input connection exposed in the node graph.</p> <p></p> <p>When viewing Text or Number data types in the Fusion viewer windows, you may have to use the \"Fit\" or \"100%\" view resizing options to make the text visible. The text is anchored to the top left origin of the window.</p> <p>If you want to see text with line wrapping enabled, try connecting a \"vTextViewer\" node to the text output connection on your node. This will render the active text data stream into the Inspector view.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Essentials/#working-with-text-data","title":"Working With Text Data","text":"<p>Working With Text Data</p> <p></p> <p>The vTextCreate node is used to create the initial starting point for a text based data node graph. There are several varieties of text create nodes to choose from:</p> <p>The regular vTextCreate node has a simple unformatted text field.</p> <p>The vTextCreateBrowse node makes it easier to select files, and enter file paths with the addition of a \"Browse\" button that displays a file picker dialog.</p> <p>The vTextCreateMultiline node supports line wrapping. It is useful for entering longer blocks of text that contain indented text, tabs, carriage return, and newline characters.</p> <p>The vTextCreatePlatform node will vary what text is specified based upon the current operating system platform. The vTextCreateArch node will vary the output based upon the current CPU architecture.</p> <p>Multiple text create nodes can be appended together to create a custom string using the vTextSubFormat node. Each input connection on the vTextSubFormat node can be placed exactly where it's needed using a token approach. A token value is entered using curly braces that surround an integer number like \"{1}\" or \"{2}\" that represent an input connection number on the node.</p> <p>The vTextSubFormat node makes it easy to create strings that combine external number counters with the connection of a vTextFromNumber conversion node, or a vTextFromNumberPadded node that makes it quick to create a leading zero padded number counter.</p> <p>There is an alternative version of the vTextSubFormat node named vTextSubFormatMultiline which is handy if you want to create a longer block of text with templated values inserted across multiple lines of text.</p> <p>There is a vTextMerge node that directly concatenates separate strings together into a single output stream. This is useful if you are working with elements like external text files. The Separator control allows you to define what symbol is inserted between each of the combined string elements. Besides adding the usual separators like spaces, or semicolons, you could add newline characters with \"\\n\", return characters with \"\\r\", and tab characters with \"\\t\".</p> <p>It is possible to break apart absolute filepaths or relative PathMap based file names with the help of the vTextParseFilename node. You can then access each component of the filename like the file extension, image sequence frame number, the base filename, and the parent folder name.</p> <p>If you need to perform a find and replace operation on a string the text substring manipulation nodes are the right tool for the job. The vTextSubReplace node uses Lua Patterns to allow you to dynamically define what to search for. The 2<sup>nd</sup> field allows you to specify the new content you want to use in place of the original source text.</p> <p>The FileSystem fuses allow you to list the contents of a folder, check a file size, look to see if a file exists on disk, create a new folder, or copy a file. You can also expand a relative PathMap into an absolute file path.</p> <p>If you want to create an IFL (image file list) document to help with accessing arbitrarily named files in a Loader or Saver node, you can combine a vTextSubFormat node that builds the formatted image sequence filename, with a vTextAccumulator node that iterates over a timeline frame range to append the strings into a multi-line block of text. The vTextAccumulator node's Start Frame value could be driven via a vNumberCompRenderStart node, and the End Frame value could be driven via a vNumberCompRenderEnd node. Finally, a vTextToFile node allows you to write that block of text to disk.</p> <p>The vTextSortLines node is handy for re-ordering multi-line blocks of text into alphabetical order. The node has built-in controls to help remove duplicate entries in a list.</p> <p>If you have file names that include alternating forward and backslash characters the vTextNormalizeSlashes node can be used to unify the slash direction by setting the Slash Direction to either \"Windows\" or \"Linux\". The node can also help with removing doubled up slashes with the \"Remove Duplicate Slashes\" control.</p> <p>If your compositing project needs to include batch scripting tasks, the vTextProcessOpen node is able to run a shell task via popen() using the string of text that is supplied as the input. The standard I/O response from the shell is then passed through to the output connection port on the node. This allows you to use substring editing approaches on the popen() shell output to carry out secondary operations like opening a resulting image, or grabbing a filename result from inside a longer text block.</p> <p>The vTextEnv node makes it possible to read environment variables. This is helpful if you are working inside a pipeline that launches the current compositing session via a virtual environment with custom site, show, and shot based environment variables.</p> <p>If you want to vary what strings are passed downstream in a comp, there is a vTextSwitch node that can act as a dynamic router. An integer number entered in the Which field specifies what text input connection port number is passed downstream via the output port.</p> <p>If you are using a logical comparison as the basis of switching the output you may have to offset a 0-1 number value \"up by one\" number to represent a 1-2 switching index value. This is done with a vNumberAdd node adding literally a value of 1 to the input connection value.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Essentials/#fusion-data-types","title":"Fusion Data Types","text":"<p>Fusion Data Types</p> <p>The Fusion node-graph supports the following data types for node-to-node connections: (Some of the data types are accessible via the Fuse API, and others are only accessible via the Fusion Plugin SDK which is C++ based.)</p> <pre><code>3D\nAudio\nBSplinePolyline\nCardinalSplinePolyline\nClip\nColorCurves\nDataType3D\nDisplayList\nFlowClip\nFuID\nGradient\nHistogram\nImage\nLookUpTable\nLookUpTable3D\nMask\nMatrix\nMesh\nMtlGraph3D\nMultiClip\nNumber\nNURBSPolyline\nParticles\nPoint\nPolyline\nScriptVal\nStyledText\nText\nTransformMatrix\nUniformBSplinePolyline\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Essentials/#vonk-node-categories","title":"Vonk Node Categories","text":"<p>Vonk Node Categories</p> <p>The Vonk data nodes are separated into the following categories and sub-categories based upon what data types they work with, and the function they perform:</p> <pre><code>3D\n    Flow\n        v3DSwitch\n    IO\n        v3DToFile\n    Script\n        v3DProcessOpen\n        v3DSlashCommand\n    Utility\n        v3DDelay\nArray\n    Create\n        vArrayFromCSV\n        vArrayFromDataWindow\n        vArrayFromLuaTable\n        vArrayFromMediaIn\n        vArrayFromMetadata\n        vArrayFromXML\n        vArrayFromYAML\n    KeyValue\n        vArrayGet\n        vArrayGetIndex\n        vArrayGetKey\n        vArrayKeys\n    Substring\n        vArraySubReturn\n    Utility\n        vArrayConcatenate\n        vArrayJoin\n        vArrayMatch\n        vArraySize\n        vArraySlice\nBase64\n    Decode\n        vBase64DecodeFromText\n        vBase64DecodeImageFromFile\n        vBase64DecodeImageFromText\n    Encode\n        vBase64EncodeFromFile\n        vBase64EncodeFromText\n    Utility\n        vBase64ToHTML\nColor\n    vColorJuggler\n    vColorPermutations\n    vColorSet\nFileSystem\n    vFileSystemChmod\n    vFileSystemCreateDir\n    vFileSystemDirExists\n    vFileSystemFileCopy\n    vFileSystemFileExists\n    vFileSystemFileOpen\n    vFileSystemFileSize\n    vFileSystemListFiles\n    vFileSystemMapPath\n    vFileSystemRemoveDir\n    vFileSystemRemoveFile\n    vFileSystemRename\n    vFileSystemSymlink\n    vFileSystemTouch\n    vFileSystemURLOpen\nImage\n    Create\n        vImageCreateTiles\n    Flow\n        vImageHook\n        vImageSwitch\n        vImageWireless\n    IO\n        vImageEXRFromFile\n        vImageEXRToFile\n        vImageFromClipboard\n        vImageFromColor\n        vImageFromFile\n        vImageFromNet\n        vImageFromZip\n        vImageToFile\n    Matte\n        vCryptomatte\n    Script\n        vImageProcessOpen\n        vImageSlashCommand\n    Shape\n        vImageCreateLine\n    Utility\n        vImageDelay\nJSON\n    IO\n        vJSONFromFile\n        vJSONFromNet\n        vJSONToFile\n    KeyValue\n        vJSONGet\n        vJSONGetElement\n        vJSONSet\n    Utility\n        vJSONCountElement\nMatrix\n    Array\n        vMatrixFromArray\n    Color\n        vMatrixColorTransform\n    Create\n        vCreateMatrix4x4\n    Flow\n        vMatrixLink\n    Operators\n        vMatrixDeterminant\n        vMatrixDivide\n        vMatrixDivideNumber\n        vMatrixInvert\n        vMatrixMultiply\n    Transform\n        vEulerFromMatrix\n        vMatrixFromRotation\n        vMatrixFromScale\n        vMatrixFromTranslation\n        vMatrixToRotation\n        vMatrixToScale\n        vMatrixToTranslation\n        vMatrixTranspose\n    Utility\n        vMatrixConcatenateHorizontal\n        vMatrixConcatenateVertical\n        vMatrixSlice\nMeta\n    vMetadataFromMediaIn\n    vMetadataFromText\n    vMetadataToText\nNumber\n    Array\n        vNumberFromArray\n    Comp\n        vNumberCompCurrentTime\n        vNumberCompFPS\n        vNumberCompFrameFormat\n        vNumberCompGlobalEnd\n        vNumberCompGlobalStart\n        vNumberCompProxy\n        vNumberCompProxyScale\n        vNumberCompRenderEnd\n        vNumberCompRenderStart\n        vNumberCompReqTime\n    Create\n        vNumberCreate\n        vNumberCreateArch\n        vNumberCreateBool\n        vNumberCreatePlatform\n        vNumberCreateRandom\n        vNumberIntegerCreate\n        vNumberRange\n    Flow\n        vNumberSwitch\n        vNumberWireless\n    Logic\n        vNumberAnd\n        vNumberEqual\n        vNumberGreater\n        vNumberGreaterEqual\n        vNumberLess\n        vNumberLessEqual\n        vNumberNot\n        vNumberNotEqual\n        vNumberOr\n        vNumberTernary\n    Matrix\n        vNumberFromMatrix\n        vNumberToMatrix\n    Operators\n        vNumberAbsolute\n        vNumberAdd\n        vNumberCeil\n        vNumberClamp\n        vNumberDivide\n        vNumberEase\n        vNumberFactorial\n        vNumberFloor\n        vNumberFractional\n        vNumberIntegral\n        vNumberMax\n        vNumberMin\n        vNumberMix\n        vNumberModulus\n        vNumberMultiply\n        vNumberPartialPermutation\n        vNumberPower\n        vNumberReciprocal\n        vNumberSign\n        vNumberSmoothstep\n        vNumberSquareRoot\n        vNumberStep\n        vNumberSubtract\n    Resolve\n        vNumberResolvePID\n        vNumberResolveTimelineFPS\n    Script\n        vNumberProcessOpen\n        vNumberSlashCommand\n    Temporal\n        vNumberTimeSpeed\n        vNumberTimeStretch\n        vNumberXSheet\nText\n    vNumberFromCSV\n    vNumberFromText\n    Trigonometry\n        vNumberArcCosine\n        vNumberArcSine\n        vNumberArcTangent\n        vNumberArcTangent2\n        vNumberCosine\n        vNumberDegreesToRadians\n        vNumberHyperbolicCosine\n        vNumberHyperbolicSine\n        vNumberHyperbolicTangent\n        vNumberRadiansToDegrees\n        vNumberSine\n        vNumberTangent\n    Utility\n        vNumberDelay\n        vNumberEndPID\n    Vector\n        vNumberFromVector\nPoint\n    Create\n        vPointCreate\n        vPointCreateImage\n    vPointCreateRandom\n        vPointFromMousePos\n    Flow\n        vPointSwitch\n        vPointWireless\n    Number\n        vPointFromNumber\n        vPointToNumber\n    Operators\n    vPointAbsolute\n        vPointAdd\n        vPointClamp\n        vPointDivide\n    vPointMix\n        vPointModulus\n        vPointMultiply\n    vPointPower\n        vPointSubtract\n    Temporal\n    vPointTimeSpeed\n    vPointTimeStretch\n    Text\n    vPointFromText\n    vPointToText\n    Utility\n        vPointAngle\n    vPointDelay\n        vPointLength\nScriptVal\n    Array\n        vScriptValFromArray\n        vScriptValToArray\n    Create\n        vScriptValCreate\n        vScriptValFromApp\n        vScriptValFromDate\n        vScriptValFromListFiles\n        vScriptValFromListFonts\n        vScriptValFromPingHosts\n        vScriptValFromPrefs\n        vScriptValFromRegistry\n        vScriptValFromXML\n    CustomData\n        vScriptValFromCustomData\n        vScriptValToCustomData\n    Flow\n        vScriptValSwitch\n        vScriptValWireless\n    Font\n        vScriptValFontMetrics\n        vScriptValFromListFonts\n    Image\n        vScriptValFromEXRFile\n    IO\n        vScriptValFromFile\n        vScriptValToFile\n        vScriptValFromBinaryFile\n        vScriptValToBinaryFile\n    JSON\n        vScriptValFromJSON\n        vScriptValToJSON\n    KeyValue\n        vScriptValGetElementToTable\n        vScriptValGetElementToText\n        vScriptValGetToNumber\n        vScriptValGetToTable\n        vScriptValGetToText\n        vScriptValKeysToTable\n        vScriptValKeysToText\n        vScriptValRemoveElement\n        vScriptValTrimElement\n    Meta\n        vScriptValFromMetadata\n        vScriptValToMetadata\n    Number\n        vScriptValFromNumber\n        vScriptValToNumber\n    Point\n        vScriptValFromPoint\n        vScriptValToPoint\n    Script\n        vScriptValDoFile\n        vScriptValDoString\n    Shape\n        vScriptValCreatePolyline\n    Temporal\n        vScriptValAccumulator   \n        vScriptValTimeSpeed\n        vScriptValTimeStretch\n    Text\n        vScriptValFromText\n        vScriptValToText\n    Utility\n        vScriptValCount\n        vScriptValDump\n        vScriptValMerge\n    YAML\n        vScriptValFromYAML\nShape\n    Flow\n        vShapeSwitch\n        vShapeWireless\nText\n    Case\n        vTextCaseAlternate\n        vTextCaseInvert\n        vTextCaseLower\n        vTextCaseRandom\n        vTextCaseSentence\n        vTextCaseTitle\n        vTextCaseUpper\n    Comp\n        vTextCompAppUUID\n        vTextCompCurrentTime\n        vTextCompFilename\n        vTextCompName\n        vTextCompReqTime\n    Create\n        vTextCreate\n        vTextCreateArch\n        vTextCreateBrowse\n        vTextCreateMultiline\n        vTextCreateMultilineCode\n        vTextCreatePlatform\n        vTextCreatePlatformBrowse\n        vTextDate\n        vTextEnv\n        vTextFromArray\n        vTextFromASCII\n        vTextFromCSV\n        vTextFromHex\n        vTextFromNumber\n        vTextFromNumberPadded\n        vTextToHex\n        vTextUUID\n        vTextUUIDStatic\n    Decode\n        vTextDecodeUrl\n    Encode\n        vTextEncodeUrl\n    Flow\n        vTextSwitch\n        vTextWireless\n    Font\n        vTextFontMetrics\n    IO\n        vTextFromClipboard\n        vTextFromComp\n        vTextFromFile\n        vTextFromNet\n        vTextFromZip\n        vTextToFile\n    Logic\n        vTextEqual\n        vTextNotEqual\n        vTextTernary\n    Order\n        vTextOrderReverse\n        vTextOrderShuffle\n    Resolve\n        vTextResolvePID\n        vTextResolveProjectName\n\n    Script\n        vTextDoAction\n        vTextDoString\n        vTextExecute\n        vTextProcessOpen\n        vTextRenderComp\n        vTextRunScript\n        vTextShellBG\n        vTextSlashCommand\n    Substring\n        vTextMerge\n        vTextSubFormat\n        vTextSubFormatMultiline\n        vTextSubJoin\n        vTextSubReplace\n        vTextSubReturn\n        vTextSubSplit\n        vTextSubStripLeft\n        vTextSubStripRight\n    Temporal\n        vTextAccumulator\n        vTextTimeSpeed\n        vTextTimeStretch\n    Utility\n        vTextDelay\n        vTextDump\n        vTextLength\n        vTextLineCount\n        vTextNormalizeSlashes\n        vTextParseFilename\n        vTextParseFilenameOutputs\n        vTextReadLine\n        vTextSortLines\n        vTextViewer\nVector\n    Array\n        vVectorFromArray\n    Create\n        vVectorCreate\n    Operators\n        vVectorAdd\n        vVectorCrossProduct\n        vVectorDivideNumber\n        vVectorDotProduct\n        vVectorMultiplyNumber\n        vVectorNormalize\n        vVectorSlice\n        vVectorSubtract\n    Point\n        vPointToVector\n        vVectorFromPoint\n        vVectorToPoint\n    Utility\n        vVectorLength\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/","title":"Vonk Node Cookbook","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#iterating-over-files-in-a-directory","title":"Iterating Over Files in a Directory","text":"<p>Iterating Over Files in a Directory</p> <p>A typical node graph that lists a folder's contents, and then iterates per-timeline-frame over the individual files in the list is built like this:</p> <p></p> <p>The \"vFileSystemListFiles\" node generates a list of files. This multi-line block of text is fed into a \"vTextReadLine\" node that breaks the list down, into one line of data per frame.</p> <p>The \"vNumberCompReqTime\" node is preferable to use as the iterator node that increments the \"vTextReadLine\" output through each line of text in the list of filepaths.</p> <p>The vNumberCompReqTime\" node is typically a better choice than a stock \"vNumberCompCurrentTime\" node since a request time based tool is capable of advancing on both the current timeline frame, or working with temporal based fuses that would modify the time value when running in a loop.</p> <p>For visualizing the Text based output in the Inspector tab, a \"vTextViewer\" node is connected.</p> <p>Node Connections:</p> <pre><code>vFileSystemListFiles.Output -&gt; vTextReadLine.Input\nvNumberCompReqTime.Output -&gt; vTextReadLine.Index\nvTextReadLine.Output -&gt; vTextViewer.Input\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#check-if-a-file-exists","title":"Check if a File Exists","text":"<p>Check if a File Exists</p> <p>A node graph that checks if a file exists on disk, then varies the resulting text based output with a Switch node is built like this:</p> <p></p> <p>Node Connections:</p> <pre><code>vFileSystemFileExists.Output -&gt; vNumberAdd.Term1\nvNumberAdd.Output -&gt; vTextSwitch.Which\nvTextCreate1.Output -&gt; vTextSwitch.Input1\nvTextCreate2.Output  -&gt; vTextSwitch.Input2\n</code></pre> <p>Node Settings:</p> <pre><code>vNumberAdd.Term2 = 1\n</code></pre> <p>Node Screenshots</p> <p>The vFileSystemExists node is used to check if a file exists on disk. The false/true logic based output is a 0-1 number range.</p> <p>The vNumberAdd node's \"Term2\" control is set to a value of \"1\". This addition process offsets the \"Term1\" input connection range of a 0-1 number returned by a false/true logical comparison into a 1-2 number range that is suitable for use with the vTextSwitch node.</p> <p></p> <p>The vTextSwitch node's \"Which\" control performs the input switching action.</p> <p>The output from the vNumberAdd node is connected to the \"Which\" control by right-clicking on the attribute in the Inspector view. In the popup contextual menu item select the \"Connect To &gt; vNumberAdd &gt; Output\" entry.</p> <p></p> <p>Finally, you can now connect any pair of TextCreate nodes you want to the vTextSwitch node's Input1 and Input2 connections. The Input1 node will be used for the file does not exist (Which = 1) logic state. The Input2 node will be used for the file exists (Which = 2) logic state.</p> <p>This node structure is effectively simulating a traditional programming language's \"Ternary\" operator.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#create-an-ifl-image-file-list","title":"Create an IFL (Image File List)","text":"<p>Create an IFL (Image File List)</p> <p>An IFL (Image File List) is a text file that places one filename per line in the document. This approach creates a file that can be used in a Fusion Loader or Saver node as a way to work with image sequences that have unusual naming structures.</p> <p>A node graph that creates a new an IFL sequence based multi-line text file is built like this:</p> <p></p> <p>Node Connections:</p> <pre><code>vTextCompReqTime.Output -&gt; vTextSubFormat.Input1\nvTextSubFormat.Output -&gt; vTextAccumulator.Text\nvNumberCompRenderStart.Output -&gt; vTextAccumulator.StartFrame\nvNumberCompRenderEnd.Output -&gt; vTextAccumulator.EndFrame\nvTextAccumulator.Output -&gt; TextToFile.Input\n</code></pre> <p>Node Settings:</p> <pre><code>vTextCompReqTime.Padding = 4\nvTextSubFormat.Format = \"Image.{1}.exr\"\nvTextAccumulator.Separator = \"\\n\"\nvTextToFile.File = \"Comp:/Sequence.ifl\"\n</code></pre> <p>Node Screenshots</p> <p>The vTextCompReqTime node is a quick and convenient way to create a frame padded number that represents the current requested time value when the comp is rendered.</p> <p>If you wanted to, alternatively, you could use a vNumberCompReqTime node connected to a vNumberAdd node to offset the starting frame number to a value like 1000, or 1001. The vNumberAdd node would then be connected to a vTextFromNumberPadded node to convert the integer value into a leading zero padded based text output format.</p> <p>(vNumberCompReqTime -&gt; vNumberAdd -&gt; vTextFromNumberPadded -&gt; vTextSubFormat)</p> <p></p> <p>The vTextSubFormat node allows us to insert a token, in this case \"{1}\", to indicate the exact placement in the filename string we wish to add to the frame number component. The \"{1}\" token in the Format text field represents the text based input connection that is wired into the \"Input1\" slot on the vTextSubFormat node.</p> <p></p> <p>The vTextAccumulator node is used to turn the single line text input into a multi-line block of text by iterating over the start frame to end frame range using temporal effects.</p> <p>The temporal operations carried out by the vTextAccumulator node are the main reason why we chose to use the \"request time\" functionality of the vTextCompReqTime node instead of reading the current timeline value of where the playhead is at this exact moment.</p> <p></p> <p>The vTextToFile node is used to write the multi-line IFL document to disk.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#create-a-frame-based-number-cycle-using-modulus","title":"Create a Frame-Based Number Cycle Using Modulus","text":"<p>Create a Frame-Based Number Cycle Using Modulus</p> <p>The vNumberModulus operator is an efficient way to create a looping number cycle that continuously counts up to a certain predefined value.</p> <p></p> <p>The vNumberIntegerCreate node is used to specify the frame duration of the looping cycle.</p> <p>A Modulus operator causes a looping effect that runs from a starting point of the number zero, upwards to one number less than the value entered in the Divisor field.</p> <p>If we want the cycle to start at the number one, and run up to the exact value specified in the Divisor field, we can achieve this result with the use of a vNumberAdd node that is used to add the number one to the output value returned by the Modulus node.</p> <p>Node Connections:</p> <pre><code>vNumberCompReqTime.Output -&gt; vNumberModulus.Dividend\nvNumberIntegerCreate.Output -&gt; vNumberModulus.Divisor\nvNumberModulus.Output -&gt; vNumberAdd.Term1\n</code></pre> <p>Node Settings:</p> <pre><code>vNumberIntegerCreate.Integer = 10\nvNumberAdd.Term2 = 1\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#read-a-csv-comma-separated-value-file","title":"Read a CSV (Comma Separated Value) File","text":"<p>Read a CSV (Comma Separated Value) File</p> <p>CSV (Comma Separated Value) and TSV (Tab Separated Value) files are common ways to transfer spreadsheet exported data between programs.</p> <p>Being able to parse a CSV file inside of Fusion's node graph is something of a \"holy grail\" like thing for comp automation, (in addition to JSON reading support), as it allows for interesting capabilities like having external data sources drive fully templated compositing processes from media loading, node based operations, all the way to final media export.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#the-easy-approach-to-csv-parsing","title":"The Easy Approach to CSV Parsing","text":"<p>The Easy Approach to CSV Parsing</p> <p>There are now Vonk custom purpose CSV parsing nodes that can simplify operations. These nodes are named \"vTextFromCSV\", \"vNumberFromCSV\", and \"vArrayFromCSV\".</p> <p>Let's look at the minimal node based connections required to work with CSV data.</p> <p></p> <p>Node Connections:</p> <pre><code>vTextFromFile.Output -&gt; vTextFromCSV.Input\nvNumberCompReqTime.Output -&gt; vTextFromCSV.Row\n</code></pre> <p>Node Settings:</p> <pre><code>vTextFromCSV.IgnoreHeaderRow = 1\n\nThe \"IgnoreHeaderRow\" checkbox allows us to start the CSV line reading process at the 2nd row in the text file so the header text is ignored.\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#the-low-level-approach-to-csv-parsing","title":"The Low Level Approach to CSV Parsing","text":"<p>The Low Level Approach to CSV Parsing</p> <p></p> <p>Node Connections:</p> <pre><code>vTextFromFile.Output -&gt; vTextReadLine.Input\nvNumberCompReqTime.Output -&gt; vNumberAdd.Term1\nvNumberAdd.Output -&gt; vTextReadLine.Index\nvTextReadLine.Output -&gt; vTextSubSplit.Text\nvTextSubSplit.Output -&gt; vTextFromArray.Input\n</code></pre> <p>Node Settings:</p> <pre><code>vNumberAdd.Term2 = 1\nvTextSubSplit.Pattern = (.-),\n</code></pre> <p>Node Screenshots</p> <p>An initial CSV header row might look a bit like this:</p> <pre><code>Shot,Filename,Caption,Image,Duration,Comments\n</code></pre> <p>The vNumberAdd node's Term2 control is used to shift the initial starting line for the vTextReadLine Index value. This makes it possible to \"scroll\" the first row read from the external datafile \"downwards\" past the typical CSV initial text header row entries to output the next data record row in the file.</p> <p></p> <p>The vTextReadLine node is used to iterate line by line through the CSV file. This process is typically controlled by syncing the Fusion comp's timeline frame number as the incrementer used to access a specific index value.</p> <p>If required, you can shift over to using a pair of \"NumberIntegerCreate\" nodes to target the exact row/column numbers you want to extract from a CSV file. This is handy if you are trying to grab a specific spreadsheet cell to act as the source value that drives custom math formula based operations.</p> <p></p> <p>A vTextSubSplit node makes quick work of splitting the CSV document at each comma based separator character.</p> <p>A Pattern value of \"<code>(.-),</code>\" is a good starting point to use for a general purpose CSV parser.</p> <p>If you require extracting TSV (Tab Separated Value) items, or dealing with quoted entries, those options are all possible with a few small tweaks to the Pattern field contents.</p> <p></p> <p>The output from the vTextSubSplit node is formatted as an Array object which can then be iterated over to extract an exact column item in the next step.</p> <p>A CSV formatted line entry that is input to the vTextSubSplit node looks like this:</p> <pre><code>2,Title02.0001.exr,Take Off,2_Take_Off.0001.exr,12,\n</code></pre> <p>The extracted array line entry output from the vTextSubSplit node looks like this:</p> <pre><code>{\"size\":5,\"array\":[\"2\",\"Title02.0001.exr\",\"Take Off\",\"2_Take_Off.0001.exr\",\"12\"]}\n</code></pre> <p>The final step of extracting column based values from a CSV formatted spreadsheet is carried out with the \"vTextFromArray\" node. The \"Index\" control lets you grab a specific item from the multi-element Array structure.</p> <p>In this case an \"Index\" value of 4 would grab the record \"<code>2_Take_Off.0001.exr</code>\".</p> <p>It is worth noting that the \"Index\" value starts counting upwards from a value of 1 (not zero). Sometimes you might have an off-by-one counting error in your logic if you forget this fact and come from a longtime C-code programming background.</p> <p></p> <p>If you need to grab a Number based value from a CSV file, you can swap out the usage of a \"vTextFromArray\" node for a \"vNumberFromArray\" node. Or alternatively you could use a \"vNumberFromText\" node to convert the data type as needed.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#further-csv-usage-concepts","title":"Further CSV Usage Concepts","text":"<p>Further CSV Usage Concepts</p> <p>If you want to get fancy with CSV parsing techniques it is possible to automatically link an individual .comp file to the external resource on-the-fly. This is best done through the use of SxS (Side by Side) concepts where the base filename for the .comp file and the .csv file are the same.</p> <p>This is very similar to Fusion Studio/Fusion Render Node's handling of SxS (Side by Side) named .comp and .lua script files.</p> <p>A SxS + CSV technique allows the comp file to find its matching resource file as soon as it is opened. This approach can be achieved in Vonk through the use of a \"vTextCompFilename\" node that provides the active comp filename to the node graph.</p> <p></p> <p>A \"vTextSubReplace\" node can swap the file extension by looking for the Pattern \".comp\" and replacing it with the \".csv\" file extension.</p> <p></p> <p>The absolute filepath for the SxS .csv file is then supplied to the initial \"vTextFromFile\" node.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#read-a-json-file","title":"Read a JSON File","text":"<p>Read a JSON File</p> <p>JSON (JavaScript Object Notation) files provide a common way to export data between programs. JSON file parsing use cases in a compositing package are generally comparable to what an XML or CSV files might be used to hold.</p> <p>JSON files can be used to carry out comp automation, as it allows for interesting capabilities like having external data sources drive fully templated compositing processes from media loading, node based operations, all the way to final media export.</p> <p>Let's look at the minimal node based connections required to work with JSON data that has JSON array elements present.</p> <p></p> <p>Node Connections:</p> <pre><code>vJSONFromFile1.Output -&gt; vJSONGet1.Input\nvJSONGet1.Output -&gt; vJSONGetElement1.Input\nvNumberCompReqTime1.Output -&gt; vJSONGetElement1.Input\nvJSONGetElement1.Output -&gt; vJSONGet2.Input\nvJSONGet2.Output -&gt; vTextAccumulator1.Text\nvJSONGet1.Output -&gt; vJSONCountElement1.Input\nvJSONCountElement1.Output -&gt; vTextAccumulator1.EndFrame\n</code></pre> <p>Node Settings:</p> <pre><code>vJSONFromFile1.Input = \"Comp:/transforms.json\"\nvJSONGet1.Key = \"frames\"\nvJSONGet2.Key = \"file_path\"\nvTextAccumulator1.StartFrame = 1\nvTextAccumulator1.Sort = 1\nvTextAccumulator1.RemoveDuplicates = 1\n</code></pre> <p>Node Screenshots</p> <p>The JSON sample data used is a NVIDIA \"Instant NGP\" based NeRF camera alignment sample file. It has the metadata for 36 camera views present in the text file.</p> <p>vJSONFromFile1</p> <p>The JSON text file is accessed on-the-fly by the comp via the \"vJSONFromFile1\" node. The data is returned as a text data type to the vJSONFromFile1 node's output connection port.</p> <p>Fusion relative PathMaps like \"Comp:/\" can be used in the \"Input\" field when entering JSON filenames. This makes the Fusion .comp files more portable if you are working with other artists since it avoids using baked-in absolute filepaths.</p> <p></p> <p>This is what is shown in the Fusion viewer window when the \"vJSONFromFile1\" node output is displayed in the Fusion viewer window:</p> <p></p> <p>vJSONGet1</p> <p>The \"vJSONGet1\" node is used to access a Key named \"frames\". For the JSON sample file being used in this example, the result is a JSON array object.</p> <p></p> <p>This is the viewer window output from the \"vJSONGet1\" node. Each JSON array element is grouped inside its own set of curly braces:</p> <p></p> <p>vJSONCountElement1</p> <p>The \"vJSONCountElement1\" node returns the total number of JSON array elements present at the current level of the JSON hierarchy.</p> <p></p> <p>For this JSON file reading example there are 36 array values returned, which lines up precisely to 36 camera views.</p> <p></p> <p>vNumberCompReqTime1</p> <p>The \"vNumberCompReqTime1\" node returns the comp's current \"request time\" value which is the frame being processed. This node is used as the incrementor for the \"vJSONGetElement1\" node's \"Index\" control.</p> <p></p> <p>When the comp is rendered or viewed, the \"vNumberCompReqTime1\" node is able to cycle through the global time range of frame 1 to frame 36 to grab each JSON array \"Index\" item, one value at a time.</p> <p></p> <p>vJSONGetElement1</p> <p>The \"vJSONGetElement1\" node is used to scan through a JSON array object and extract a single element from a series of objects. The \"Index\" control is animated via a Vonk data node connection to parse each of the elements present in the file automatically.</p> <p></p> <p>The output from the \"vJSONGetElement1\" node looks like this:</p> <p></p> <p>vJSONGet2</p> <p>The \"vJSONGet2\" node is used to access the Key called \"file_path\". In our sample JSON file this will return a string that holds the name of a specific camera alignment image.</p> <p></p> <p>vTextAccumulator1</p> <p>The \"vTextAccumulator1\" node allows us to temporally concatenate the output. This builds a list of image filenames from each of the JSON array elements as Fusion scans through the Start Frame to End Frame range values on the node.</p> <p></p> <p>The \"Sort List\" checkbox will alphabetically sort the output. This is handy as JSON files are not guaranteed to be accessed in a consistent order when parsed.</p> <p>The \"End Frame\" attribute is connected to the \"vJSONCountElement1\" node. This causes Fusion to automatically increment through each of the JSON array elements and not miss out on any of the records.</p> <p>The \"Separator\" control defaults to \"<code>\\n</code>\". This represents a newline character that will be inserted on each frame that is temporally accumulated by the node into a multi-line block of text.</p> <p>This is the viewer window output from the \"vTextAccumulator1\" node:</p> <p></p> <p>JSON Samples</p> <p>When working with ASCII encoded JSON files, there are several different data types you will come across frequently when parsing files. The most common are listed below.</p> <p>JSON records can hold numbers. A number is entered without any quotes around the value:</p> <pre><code>\"size\": 596,\n</code></pre> <p>JSON records can hold strings. A string is entered with double quotes around the textual content:</p> <pre><code>\"filename\": \"Media/CameraA.0001.jpg\",\n</code></pre> <p>JSON records can hold multiple numbers in an array. Square brackets are used to indicate the start and end of an array:</p> <pre><code>\"size\": [2700,2700],\n\"outputcrop\": [0,0,1,1],\n</code></pre> <p>JSON records can also hold a series of parameters in an array such as per-frame data when working with metadata for image sequences. It is possible to nest an array inside another array, along with strings and number values, too:</p> <pre><code>    \"frames\": [\n     {\n         \"file_path\": \"images/lion.0001.jpg\",\n         \"sharpness\": 426.40289615279244,\n         \"transform_matrix\": [\n             [\n                 -0.3837311354109413,\n                 0.18139391420079445,\n                 -0.9054538439920087,\n                 -3.489564789981506\n             ],\n             [\n                 -0.9107712071674372,\n                 -0.23623269970342953,\n                 0.33865900222128514,\n                 1.2114282762117232\n             ],\n             [\n                 -0.15246712403082568,\n                 0.9546152939665091,\n                 0.25585819628787304,\n                 1.0404015326771352\n             ],\n             [\n                 0.0,\n                 0.0,\n                 0.0,\n                 1.0\n             ]\n         ]\n     },\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#creating-3d-materials-from-live-web-images","title":"Creating 3D Materials from Live Web Images","text":"<p>Creating 3D Materials from Live Web Images</p> <p></p> <p>An exciting element that can be added to data based graphics in Fusion are \"live\" internet sourced visuals. This includes just about any media resource you can connect to using an <code>http://</code>, <code>https://</code>, or <code>file://</code> based URL such as live frame-grabbed webcam imagery, traffic cam views, satellite weather graphics, or any other image resource from the web.</p> <p></p> <p>An important step if you are connecting a vImageFromNet created image context to a 3D workspace based polygon model is to add a surface material to the mesh first. Otherwise Fusion might instant-quit on you if you try to direct-connect the 2D image texture straight onto the mesh node.</p> <p>Node Connections:</p> <pre><code>vTextCreate.Output -&gt; vImageFromNet.Input\nvImageFromNet.Output -&gt; Texture2D.Input\nTexture2D.MaterialOutput -&gt; Blinn.Diffuse.Color.Material\nBlinn.MaterialOutput -&gt; Shape3D.MaterialInput\n</code></pre> <p>Node Settings:</p> <pre><code>vTextCreate.Text = &lt;https://weather.gc.ca/data/satellite/goes_ecan_1070_100.jpg&gt;\nvImageFromNet.FileType = \"JPEG\"\nShape3D.Shape = \"Plane\"\n</code></pre> <p>Node Screenshots</p> <p>The \"vTextCreate\" node is handy as it allows us to customize the image URL outside of the node that does the image downloading process.</p> <p>The sample image we are loading is an Eastern Canada weather satellite image from this URL:</p> <p>https://weather.gc.ca/data/satellite/goes_ecan_1070_100.jpg</p> <p>Note: If you wanted to create the URL string dynamically from a series of separate elements like the website domain name address, a custom user login or password, any sub-folders, the filename, or a series of custom request tokens, you could build this path using multiple text based inputs to a vTextSubFormat node instead.</p> <p></p> <p>The \"vImageFromNet\" node carries out the actual image resource downloading process.</p> <p>Don't forget to customize the \"File Type\" setting on the node to give Fusion a hint of the actual image format you are downloading.</p> <p></p> <p>The \"Texture2D\" node provides controls that help with texture placement such as UV coordinate driven scaling and UV translation.</p> <p></p> <p>The Blinn node is a general purpose surface material.</p> <p></p> <p>Fusion also supports the use of the CookTorrance (PBR) material, Phong material, Ward Material, and finally the Reflect material which is used for environmental reflections.</p> <p></p> <p>If you require examples of how to render models using a PBR material shader you can start out with the CookTorrance node and the sample shaders provided by the Reactor Package Manager's \"KickAss ShaderZ\" collection.</p> <p></p> <p>If you need even more surface material features you could explore the (paid) LearnNowFX AccuShaders PBR shading plugin for Resolve Studio/Fusion Studio v17.1+. If you are working on programmable shaders for Fusion Studio v9 on Windows then Chad Capeland's CustomShader3D plugin might be of interest.</p> <p></p> <p>The \"Shape3D\" node is used to create the stand-in geometry the texture is applied to. A variety of platonic solid geometry types are supported.</p> <p></p> <p>Note: If you need more control over the mesh, it is possible to switch from a Shape3D node over to using an AlembicMesh3D node to load in .abc format models, or an FBXMesh3D node to load in .fbx or .obj models.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#slashcommands","title":"SlashCommands","text":"<p>SlashCommands</p> <p>Vonk has the ability to evaluate and run SlashCommands. When you enter a block of text in a node like \"vTextSlashCommand\" you are able to apply persistent changes to the Fusion comp.</p> <p>A SlashCommand is a type of Lua or Python script in Fusion that is normally launched from the Console window by prefacing a command with a leading \"<code>/</code>\" character.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#installing-slashcommands","title":"Installing SlashCommands","text":"<p>Installing SlashCommands</p> <p>The SlashCommand items are typically installed via the Reactor Package Manager and live on disk at the PathMap location of either:</p> <pre><code>Scripts:/SlashCommand/\n</code></pre> <p>or</p> <pre><code>Reactor:/Deploy/Scripts/SlashCommand/\n</code></pre> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#using-slashcommands","title":"Using SlashCommands","text":"<p>Using SlashCommands</p> <p>Here is an example of the \"SlashFootage\" expression syntax:</p> <pre><code>/footage list\n</code></pre> <p>The most interesting SlashCommand from a usability perspective is \"SlashFor\". The \"/for\" slash-command is used to quickly and easily apply changes across a number of tools.</p> <p></p> <p>Here are examples of the \"SlashFor\" expression syntax:</p> <p>Usage</p> <pre><code>&gt; /for\nUsage: /for (selected|visible|all) [tooltype[,tooltype...]] [where &lt;condition&gt;] &lt;command&gt; [ &amp; &lt;command&gt;...]\nSupported commands:\n    animate &lt;input&gt; [(with &lt;modifier&gt;|remove)] [force]\n    color [tile &lt;color&gt;] [text &lt;color&gt;] [fill &lt;color&gt;]\n    get &lt;input&gt; ([at &lt;time&gt;])\n    getattrs &lt;attribute&gt;\n    select [(add|remove)]\n    set &lt;input&gt; ([at &lt;time&gt;] to &lt;value&gt;|expression &lt;exp&gt;)\n    setattrs &lt;attribute&gt; (to &lt;value&gt;)\n    setclip (to &lt;value&gt;)\n    setname (to &lt;value&gt;)\n    version [(up|down|to &lt;value&gt;)]\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#slashfor-syntax-examples","title":"SlashFor Syntax Examples","text":"<p>SlashFor Syntax Examples</p> <p>Set the Size of all selected tools to 1.0:</p> <pre><code>/for selected set Size to 1.0\n</code></pre> <p>Set \"Use GPU\" to Disable:</p> <pre><code>/for selected set UseGPU to 0\n/for all ColorCorrector set UseGPU to 0\n/for all Merge set UseGPU to 0\n/for all set UseGPU to 0\n</code></pre> <p>Set \"Use GPU\" to Auto:</p> <pre><code>/for selected set UseGPU to 1\n/for all ColorCorrector set UseGPU to 1\n/for all Merge set UseGPU to 1\n/for all set UseGPU to 1\n</code></pre> <p>Set \"Use GPU\" to Enable:</p> <pre><code>/for selected set UseGPU to 2\n/for all ColorCorrector set UseGPU to 2\n/for all Merge set UseGPU to 2\n/for all set UseGPU to 2\n</code></pre> <p>Set the SeetheRate of all FastNoise tools in the comp to 1.0:</p> <pre><code>/for all FastNoise set SeetheRate to 1.0\n</code></pre> <p>Double the current size of each Merge or Transform currently selected:</p> <pre><code>/for selected Merge,Transform set Size to value*2.0\n</code></pre> <p>Select all FastNoise tools:</p> <pre><code>/for all FastNoise select\n</code></pre> <p>Add all tools where Size &gt; 1 to the selection:</p> <pre><code>/for all where Size &gt; 1.0 select add\n</code></pre> <p>Remove all Merge tools where Angle \\&lt; 0 from the selection:</p> <pre><code>/for all Merge where Angle &lt; 0 select remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#loader-node","title":"Loader Node","text":"<p>Loader Node</p> <p>Set the EXR Part for a Loader node:</p> <pre><code>/for selected Loader set Clip1.OpenEXRFormat.Part to \"C\"\n\n/for selected Loader set Clip1.OpenEXRFormat.Part to \"directdiffuse\"\n</code></pre> <p>Set the RGBA EXR Channel names for Loader nodes, one command at a time:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\"\n/for all Loader set Clip1.OpenEXRFormat.GreenName to \"G\"\n/for all Loader set Clip1.OpenEXRFormat.BlueName to \"B\"\n/for all Loader set Clip1.OpenEXRFormat.AlphaName to \"A\"\n</code></pre> <p>Set the RGBA EXR Channel names for Loader nodes on a single line:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\" &amp; set Clip1.OpenEXRFormat.GreenName to \"G\" &amp; set Clip1.OpenEXRFormat.BlueName to \"B\" &amp; set Clip1.OpenEXRFormat.AlphaName to \"A\"\n</code></pre> <p>Set individual EXR Channel names for Loader nodes, one command at a time:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\"\n/for all Loader set Clip1.OpenEXRFormat.GreenName to \"G\"\n/for all Loader set Clip1.OpenEXRFormat.BlueName to \"B\"\n/for all Loader set Clip1.OpenEXRFormat.AlphaName to \"A\"\n/for all Loader set Clip1.OpenEXRFormat.ZName to \"Z\"\n/for all Loader set Clip1.OpenEXRFormat.CovName to \"pixelCover\"\n/for all Loader set Clip1.OpenEXRFormat.ObjIDName to \"objectID\"\n/for all Loader set Clip1.OpenEXRFormat.MatIDName to \"materialID\"\n/for all Loader set Clip1.OpenEXRFormat.UName to \"U\"\n/for all Loader set Clip1.OpenEXRFormat.VName to \"V\"\n/for all Loader set Clip1.OpenEXRFormat.XNormName to \"NX\"\n/for all Loader set Clip1.OpenEXRFormat.YNormName to \"NY\"\n/for all Loader set Clip1.OpenEXRFormat.ZNormName to \"NZ\"\n/for all Loader set Clip1.OpenEXRFormat.XVelName to \"velX\"\n/for all Loader set Clip1.OpenEXRFormat.YVelName to \"velY\"\n/for all Loader set Clip1.OpenEXRFormat.XRevVelName to \"rvelX\"\n/for all Loader set Clip1.OpenEXRFormat.YRevVelName to \"rvelY\"\n/for all Loader set Clip1.OpenEXRFormat.XPosName to \"posX\"\n/for all Loader set Clip1.OpenEXRFormat.YPosName to \"posY\"\n/for all Loader set Clip1.OpenEXRFormat.ZPosName to \"posZ\"\n/for all Loader set Clip1.OpenEXRFormat.XDispName to \"dispX\"\n/for all Loader set Clip1.OpenEXRFormat.YDispName to \"dispY\"\n</code></pre> <p>Set all of the available EXR Channel names for Loader nodes on a single line:</p> <pre><code>/for all Loader set Clip1.OpenEXRFormat.RedName to \"R\" &amp; set Clip1.OpenEXRFormat.GreenName to \"G\" &amp; set Clip1.OpenEXRFormat.BlueName to \"B\" &amp; set Clip1.OpenEXRFormat.AlphaName to \"A\" &amp; set Clip1.OpenEXRFormat.ZName to \"Z\" &amp; set Clip1.OpenEXRFormat.CovName to \"pixelCover\" &amp; set Clip1.OpenEXRFormat.ObjIDName to \"objectID\" &amp; set Clip1.OpenEXRFormat.MatIDName to \"materialID\" &amp; set Clip1.OpenEXRFormat.UName to \"U\" &amp; set Clip1.OpenEXRFormat.VName to \"V\" &amp; set Clip1.OpenEXRFormat.XNormName to \"NX\" &amp; set Clip1.OpenEXRFormat.YNormName to \"NY\" &amp; set Clip1.OpenEXRFormat.ZNormName to \"NZ\" &amp; set Clip1.OpenEXRFormat.XVelName to \"velX\" &amp; set Clip1.OpenEXRFormat.YVelName to \"velY\" &amp; set Clip1.OpenEXRFormat.XRevVelName to \"rvelX\" &amp; set Clip1.OpenEXRFormat.YRevVelName to \"rvelY\" &amp; set Clip1.OpenEXRFormat.XPosName to \"posX\" &amp; set Clip1.OpenEXRFormat.YPosName to \"posY\" &amp; set Clip1.OpenEXRFormat.ZPosName to \"posZ\" &amp; set Clip1.OpenEXRFormat.XDispName to \"dispX\" &amp; set Clip1.OpenEXRFormat.YDispName to \"dispY\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#mediain-node","title":"MediaIn Node","text":"<p>MediaIn Node</p> <p>Set the MediaID tag on a MediaIn node:</p> <pre><code>/for selected MediaIn set MediaID to \"445f0cf6-8888-4f2d-9014-1fa8829e9acd\"\n</code></pre> <p>Set the EXR Part for a MediaIn node:</p> <pre><code>/for selected MediaIn set Layer to \"C\"\n/for selected MediaIn set Layer to \"directdiffuse\"\n</code></pre> <p>Set the RGBA EXR Channel names for a MediaIn node, one command at a time:</p> <pre><code>/for selected MediaIn set RedName to \"R\"\n/for selected MediaIn set GreenName to \"G\"\n/for selected MediaIn set BlueName to \"B\"\n/for selected MediaIn set AlphaName to \"A\"\n</code></pre> <p>Set the RGBA EXR Channel names for a MediaIn node, on a single line:</p> <pre><code>/for selected MediaIn set RedName to \"R\" &amp; set GreenName to \"G\" &amp; set BlueName to \"B\" &amp; set AlphaName to \"A\"\n\n/for selected MediaIn set RedName to \"C.R\" &amp; set GreenName to \"C.G\" &amp; set BlueName to \"C.B\" &amp; set AlphaName to \"C.A\"\n</code></pre> <p>Set the In/Out time range for a MediaIn node:</p> <pre><code>/for selected MediaIn set GlobalIn to 0 &amp; set GlobalOut to 47\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#animate","title":"Animate","text":"<p>Animate</p> <p>Animate Size of all selected tools with default modifier (BezierSpline):</p> <pre><code>/for selected animate Size\n</code></pre> <p>Animate Size of all visible tools (ie not modifiers) with CubicSpline</p> <pre><code>/for visible animate Size with CubicSpline\n</code></pre> <p>Animate Size of all selected tools, replacing any already animated ones:</p> <pre><code>/for selected animate Size force\n</code></pre> <p>Animate Seethe of all FastNoise tools, creating a ramp from 1.0 to 5.0 over 100 frames:</p> <pre><code>/for all FastNoise animate Seethe &amp; set Seethe at 0 to 1.0 &amp; set Seethe at 100 to 5.0\n</code></pre> <p>Remove animation from Size of all selected tools:</p> <pre><code>/for selected animate Size remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#expressions","title":"Expressions","text":"<p>Expressions</p> <p><code>/for</code> can be limited to a subset of tools using <code>where &lt;expression&gt;</code>:</p> <p>Set the Size of all selected tools to 1.0, if it's already &gt; 1.0:</p> <pre><code>/for selected where Size &gt; 1 set Size to 1.0\n</code></pre> <p>Set is also able to set actual expressions on node inputs:</p> <p>Set a Seethe expression on selected FastNoise tools:</p> <pre><code>/for selected FastNoise set Seethe expression time/10.0\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#select","title":"Select","text":"<p>Select</p> <p>The 'select' command changes the active selection of nodes in the Nodes view area:</p> <p>Select all FastNoise tools:</p> <pre><code>/for all FastNoise select\n</code></pre> <p>Add all tools where Size &gt; 1 to the selection:</p> <pre><code>/for all where Size &gt; 1.0 select add\n</code></pre> <p>Remove all Merge tools where Angle \\&lt; 0 from the selection:</p> <pre><code>/for all Merge where Angle &lt; 0 select remove\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#color","title":"Color","text":"<p>Color</p> <p>The 'color' command is used to modify node colors in the Node view.</p> <p>Set the tile color to red for selected tools:</p> <pre><code>/for selected color tile 1,0,0\n</code></pre> <p>Set the text color to green for selected FastNoise tools with a non-zero SeetheRate:</p> <pre><code>/for selected FastNoise where SeetheRate ~= 0 color text 0,1,0\n</code></pre> <p>Set Name</p> <p>Rename a node:</p> <pre><code>/for selected Loader setname to \"MyLoader\"\n/for selected Saver setname to \"MySaver\"\n/for selected Fuse.vTextCreate setname to \"Txt\"\n/for selected Fuse.vNumberCreate setname to \"Num\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#set-clip-filenames","title":"Set Clip Filenames","text":"<p>Set Clip Filenames</p> <p>Set a Loader node's Clip filename:</p> <pre><code>/for all Loader setclip to \"Comp:/Import.0000.exr\"\n</code></pre> <p>Set a Saver node's Clip filename:</p> <pre><code>/for all Saver setclip to \"Comp:/Export.0000.exr\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#set-clip-version","title":"Set Clip Version","text":"<p>Set Clip Version</p> <p>If a Loader or Saver node has a version tag added to the clip filename like \"<code>V001</code>\" or \"<code>v001</code>\" then the <code>/for</code> versioning features will be your new best friend.</p> <p></p> <p>Set Loader or Saver Node Filename Version Tags</p> <pre><code>/for selected version up\n/for selected version down\n/for selected version to 5\n\n/for all version up\n/for all version down\n/for all version to 99\n\n/for selected Loader version up\n/for selected Loader version down\n/for selected Loader version to 99\n\n/for selected Saver version up\n/for selected Saver version down\n/for selected Saver version to 99\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#set-attributes","title":"Set Attributes","text":"<p>Set Attributes</p> <p>Turn ON the passthrough option for the selected Loader nodes:</p> <pre><code>/for selected Loader setattrs TOOLB_PassThrough to true\n</code></pre> <p>Turn OFF the passthrough option for the selected Loader nodes:</p> <pre><code>/for selected Loader setattrs TOOLB_PassThrough to false\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#get-attributes","title":"Get Attributes","text":"<p>Get Attributes</p> <p>Read a node's attributes:</p> <pre><code>/for all getattrs TOOLS_RegID\n/for all getattrs TOOLST_Clip_Name\n/for all getattrs TOOLB_PassThrough\n</code></pre> <p>Read the most recent render time for the selected nodes:</p> <pre><code>/for selected getattrs TOOLN_LastFrameTime\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#get-input-values","title":"Get Input Values","text":"<p>Get Input Values</p> <p>Read a node's inputs:</p> <pre><code>/for all Transform get Aspect\n/for all get StyledText\n/for all get Font\n/for all get Center\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#modify-3d-meshes","title":"Modify 3D Meshes","text":"<p>Modify 3D Meshes</p> <p>FBX/OBJ 3D Meshes</p> <p>Rename the node:</p> <pre><code>/for selected SurfaceFBXMesh setname to \"pCubeFBX\"\n</code></pre> <p>FBX/OBJ - Modify the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceFBXMesh set ObjName to \"pCube\"\n</code></pre> <p>FBX/OBJ - Clear the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceFBXMesh set ObjName to \"\"\n</code></pre> <p>FBX/OBJ - Modify the take name:</p> <pre><code>/for selected SurfaceFBXMesh set TakeName to \"Take 999\"\n</code></pre> <p>FBX/OBJ - Modify the imported file name:</p> <pre><code>/for selected SurfaceFBXMesh set ImportFile to \"Comp:/Media/pCube.fbx\"\n\n/for selected SurfaceFBXMesh set ImportFile to \"Macros:/KartaVR/Images/roller_coaster_track.fbx\"\n</code></pre> <p>Alembic 3D Meshes</p> <p>Rename the node:</p> <pre><code>/for selected SurfaceAlembicMesh setname to \"pCubeABC\"\n</code></pre> <p>ABC - Modify the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceAlembicMesh set ObjName to \"Mesh/pCube\"\n</code></pre> <p>ABC - Clear the object name selected from the 3D model hierarchy:</p> <pre><code>/for selected SurfaceAlembicMesh set ObjName to \"\"\n</code></pre> <p>ABC - Modify the imported file name:</p> <pre><code>/for selected SurfaceAlembicMesh set ImportFile to \"Comp:/Media/pCube.abc\"\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#ofx-and-fuses","title":"OFX and Fuses","text":"<p>OFX and Fuses</p> <p>OFX plugins and Fuses can be targeted by SlashFor if you know their node type via the Registry ID value:</p> <pre><code>/for all ofx.com.frischluft.openFX.DepthOfField select\n/for all Fuse.Wireless select\n/for all Fuse.vImageWireless select\n/for all Fuse.vTextCreate select\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#render","title":"Render","text":"<p>Render</p> <p>Render Selected Nodes:</p> <pre><code>/for selected render\n</code></pre> <p>Render Selected nodes step by 25 frames at a time:</p> <pre><code>/for selected render step 25\n</code></pre> <p>Render all Saver nodes:</p> <pre><code>/for all Saver render\n</code></pre> <p>Render all Saver nodes step by 100 frames at a time:</p> <pre><code>/for all Saver render step 100\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#slashfor-development","title":"SlashFor Development","text":"<p>SlashFor Development</p> <p>On the Steakunderwater forms Reactor Submissions thread for SlashFor there is an ongoing effort to evolve the feature set. If you have an idea for a must-have feature. Post it on that thread.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#script-to-add-all-vonk-nodes-to-a-comp","title":"Script to add all Vonk Nodes to a Comp","text":"<p>Script to add all Vonk Nodes to a Comp</p> <p>The following Lua code snippet will add all of the currently installed Vonk fuse nodes to the foreground Fusion composite:</p> <pre><code>-- Based upon Cedric's \"Create All Nodes\" Lua Script:\n-- &lt;https://gist.github.com/cedricduriau/125cd3b84ab72cc1afc85ebfe943193c#file-fusion_createallnodes-lua&gt;\n\nprint(\"[Create All Vonk Nodes]\")\nreg_map = fusion:GetRegList()  -- dict[int, Registry]\nfor _i, reg in ipairs(reg_map) do\n    if reg.ID:match(\"^Fuse.v\")  then\n     print(\"[\" .. _i .. \"]\", reg.ID)\n     comp:AddTool(reg.ID)\n    end\nend\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vonk-example-projects","title":"Vonk Example Projects","text":"<p>Vonk Example Projects</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vonk-mission-control","title":"Vonk Mission Control","text":"<p>Vonk Mission Control</p> <p>The \"Mission Control\" Vonk data node example simulates a small propellor-powered aircraft's cockpit dashboard by rendering a mix of digital and analog style gauges. The logic for the controls is wired together using Vonk Number and Text data types.</p> <p></p> <p>This example is available for installation using the Reactor Package Manager. Navigate to the \"Kartaverse/Vonk Ultra\" category on the left side of the Reactor window to locate the atom package named \"Vonk Example | Mission Control\".</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vonk-tips","title":"Vonk Tips","text":"<p>Vonk Tips</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#customize-the-control-range","title":"Customize the Control Range","text":"<p>Customize the Control Range</p> <p>When you place Vonk data nodes, or any other type of Fusion node in a composite, you have the option of opening the Inspector and using the right-click \"Edit Controls...\" dialog to remap the default control range for any parameter to fit the natural range for the attribute you are adjusting.</p> <p></p> <p>If you need a value to be adjusted by default for a slider or screw control so the range of motion would go from 0-10, 0-100, -100 to 100, 0 - 255, 0 - 1000, etc you can customize the \"Range\" parameters two attributes to work on that range that feels comfortable.</p> <p>This makes the user experience better so an artist gets the desired control responsiveness needed when they drag the slider fully to the left or right.</p> <p></p> <p>It is also possible to apply hard limits to the valid minimum/maximum number you can enter in the number fields, too. This is done with the \"Allowed\" number fields in the Edit Control dialog.. Normally a lot of numbers in Fusion's own native tools look like they are limited to 1 million. If you enter the allowed range as \"-1e+38\" and \"1e+38\" you can fully unlock the maximum numerical size allowed in a floating-point 32 bit number representation.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#applying-usercontrols-on-a-node","title":"Applying UserControls on a Node","text":"<p>Applying UserControls on a Node</p> <p></p> <p>Listed below is a macro \".settings\" snippet of code for a vNumberCreate node that has a UserControls based customization applied. The Number input is displayed as a SliderControl type, and the slider goes from 0 - 100. The number is set to increment as an integer, and the default for the control is 0.</p> <pre><code>{\n    Tools = ordered() {\n     vNumberCreate1 = Fuse.vNumberCreate {\n         CtrlWZoom = false,\n         ViewInfo = OperatorInfo { Pos = { 327.333, 115.848 } },\n         UserControls = ordered() {\n             Number = {\n                 LINKS_Name = \"Number\",\n                 LINKID_DataType = \"Number\",\n                 INPID_InputControl = \"SliderControl\",\n                 INP_Default = 0,\n                 INP_Integer = true,\n                 INP_MinScale = 0,\n                 INP_MaxScale = 100,\n                 INP_MinAllowed = -1e+38,\n                 INP_MaxAllowed = 1e+38,\n                 ICD_Center = 50,\n                 IC_Steps = 10,\n                 ICS_ControlPage = \"Controls\"\n             }\n         }\n     }\n    },\n    ActiveTool = \"vNumberCreate1\"\n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#clamping-number-values","title":"Clamping Number Values","text":"<p>Clamping Number Values</p> <p>One other final process that can be done to keep values sane when user inputs allow an artist to enter whatever they want, is to add a vNumberClamp node after several math operations are carried out. The vNumberClamp node gives you a parametric governor / limiter result. The clamp node input connections can live update on what is a valid Minimum/Maximum range as well with their own vNumber datatype connections on the clamp node.</p> <p>This means the node graph can self-limit the minimum and maximum vNumber range allowed at that point in the comp niode-graph. This limiting process can be fed with values like the current array size, or JSON element count, a text file's total line number count, or the global/render start and end frame ranges.</p> <p>Taking this step to keep the numbers from overshooting a realistic value keeps macros and automated templates you build from breaking by accidental out-of-bounds user input.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vonk-known-issues","title":"Vonk Known Issues","text":"<p>Vonk Known Issues</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#fusion-timeline","title":"Fusion Timeline","text":"<p>Fusion Timeline</p> <p>The Fusion timeline is limited to 1 million frames in maximum duration. This can be an issue if rendering Fusion comps that process multi-hour long action camera footage at 60 FPS.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#lua-patterns","title":"Lua Patterns","text":"<p>Lua Patterns</p> <p>When carrying out sub-string operations like find &amp; replace edits with Vonk data nodes you can come across the need to escape Lua pattern special characters. This can typically be done by prefacing a character with a <code>%</code> sign like \"<code>%%</code>\".</p> <p>This approach can be used with the \"vTextSubFormat\" node when trying to pass through an element like \"<code>{1}</code>\" by escaping the curly braces like this \"<code>%{1%}</code>\" if you are trying to place a string inside another string in a nested vTextSubFormat node usage fashion.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vnumber","title":"vNumber","text":"<p>vNumber</p> <p>Prior to Vonk v1.10 the Number DataTypes had the Fusion default clamped value limit of 1 million (1e+06). This limitation was removed by adding the following attributes on the fuse vNumber inputs:</p> <pre><code>INP_MinAllowed = -1e+38,\nINP_MaxAllowed = 1e+38,\n</code></pre> <p>Several of the vNumber nodes in the \"Comp\" sub-category will cache their values and not update when the user changes parameters. This means you will likely need to close and re-open the comp file in the Fusion Studio GUI if you change the Fusion timeline's Global/Render based start/end frame range values and want to see that value reflected in the Vonk \"Comp\" node outputs. This is due to the following fuse parameters being commented out for performance reasons:</p> <pre><code>--REG_TimeVariant = true, -- required to disable caching of the current time parameter\n--REGB_Temporal = true, -- ensures reliability in Resolve 15\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vtext","title":"vText","text":"<p>vText</p> <p>Vonk Text DataType based outputs that contain certain non-printable ASCII control characters embedded in the output stream can have the content terminated prematurely. This is a Fusion API limitation. Passing the information down the flow can be achieved either through passing a reference to a filename on disk as the text output, or by encoding the string in a format like Base64 text so the control characters are encapsulated.</p> <p>The Fusion viewer window context doesn't render text blocks with newline characters precisely. Feeding the text content into a vTextViewer node will give more precise previews for display of multi-line textual content.</p> <p>JSON key/value pair data has an indeterminate reading order when re-imported several times. Possible solutions to this issue is to sort the results alphabetically if you are building a multi-line based list of textual results.</p> <p>The \"vTextAccumulator\" node generates out-of-sequence results in the concatenated output if the \"start_frame\" control's value is changed from a \"normal-ish\" render start frame range value of frame 0 or 1 over to a VFX industry style of start frame value of frame 1000 or 1001. The issue is still being explored.</p> <p>The \"vTextProcessOpen\" node does not return standard error messages on the text output connection. You will have to redirect the shell's standard output and standard error streams together in the command string being run if you need to troubleshoot issues. This is done by appending the following text, while omitting the quotes \" 2&gt;&amp;1\" to the end of the command being run.</p> <p>An example of a macOS or Linux string that would generate a shell error that you would not otherwise see would be \"<code>mkdir \"/hello\" 2&gt;&amp;1</code>\". By adding the STDERR to STDOUT redirection we can now see the error message text \"<code>mkdir: /hello: Read-only file system</code>\".</p> <p>The \"vTextRenderComp\" node works on macOS and Linux. The Fusion Render Node executable on Windows does not function correctly when launched internally by the vTextRenderComp node. A work-around for Windows users looking for the same functionality would be to use the Fusion built-in RunCommand node to carry out a similar nested rendering task.</p> <p>The \"vTextExecute\" node runs asynchronously from the main rendering task. This is due to the use of the function \"<code>self.Comp:Execute()</code>\". This means the output is returned in a thread separate from the order of the comp branch rendering operation.</p> <p>The cURL based Vonk nodes will not follow HTTP redirection commands returned by web servers hidden behind CloudFlare and other CDNs. You can explore workarounds like using a vProcessOpen node to run cURL from the command-prompt to be able to use Vonk in these types of situations. Note: Windows now includes the cURL executable by default with the OS so you can reasonably expect cURL to be present on all platforms. Note: If you need to specify the full absolute path to cURL for each OS platform, you can use the Vonk vTextCreatePlatformBrowse node to assist.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#varray","title":"vArray","text":"<p>vArray</p> <p>The \"vArrayFromMediaIn\" node requires you to be in a Fusion page compositing context and have the source footage loaded in the viewer before the MediaIn based metadata is accessible to downstream nodes.</p> <p>The \"vArrayFromXML\" node is experimental. There appears to be a memory leak in the array structure size that results in duplicate array elements being created and appended to the xml2lua based Lua table record over concurrently rendered timeline frames.</p> <p>This vArrayFromXML node based issue is visible when a downstream \"vJSONGetElement\" node is rendered for the first time while accessing an array index value. In this situation a console error is output, while subsequent re-renderings succeed further along in the timeline sequence. A solution to this issue is being investigated.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vmeta","title":"vMeta","text":"<p>vMeta</p> <p>The \"vMetadataFromMediaIn\" node requires you to be in a Fusion page compositing context and have the source footage loaded in the viewer before the MediaIn based metadata is accessible to downstream nodes.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vimage","title":"vImage","text":"<p>vImage</p> <p>The \"vImageFromClipboard\" node only works on Windows since it uses a supporting executable called \"Clipboard2bmp.exe\". There appears to be an issue running this node in Fusion Studio v18 that is being investigated.</p> <p>The \"vCryptomatte\" node cannot access EXR based multi-part elements. This node is designed to work with multi-channel EXR images. It is possible down the road to update the Cryptomatte fuses to access multi-part image elements (from renderers like Houdini KARMA) with the Fuse based EXRIO library but the required API documentation to do this has not been publicly released by BMD yet.</p> <p>The \"vCryptomatte\" node relies on the Lua Metadata based \"Filename\" record when loading cryptomatte channel data. This means the node works successfully with a Loader node as it provides the Filename record. A Resolve based MediaIn node does not provide this Filename record information, so you would need to either switch over to using a Loader node, or append the Filename record to MediaIn node's output stream using a SetMetadata fuse or the vMetadataFromText fuse.</p> <p>The \"vImageCreateTiles\" works by appending temporally a series of images fed into the node to create a grid layout. If you aren't paying attention you can get rendering error messages by exhausting the available frame range that Fusion can query. Each image that is combined together in the grid layout is loaded by querying the timeline's render start frame - global end frame range. If you want to render a single tiled grid image output that is 1 frame long but has 100 tiles compacted together (Tiles X = 10, Tiles Y = 10) then you could set the Render Start Frame = 1, the Render End Frame = 1, and the Global Start Frame =1, and Global End Frame = 100.</p> <p>The \"vImageFromFile\" node needs special care when used as a source texture on a Fusion 3D workspace based surface material. Look at the Vonk Cookbook topic for the \"Creating 3D Materials from Live Web Images\" example to see how to hook a 2D image to a Texture2D node, then a surface material like Blinn before connecting the image data to a mesh.</p> <p>The \"vImageEXRFromFile\" node's \"EXR Part Number\" control is experimental and should be left alone. Adjusting this parameter on a single part-based image will likely result in Fusion crashing due to an out of bounds exception like error.</p> <p>The \"vImageEXRToFile\" node saves out RGBA channels from the input image frame buffer. If you require more control over the exported imagery look at the Reactor provided \"pioSaver\" or \"LifeSaver\" nodes.</p> <p>The \"vImageToFile\" node requires Fusion v16.x+ or higher due to the reliance on the Fuse API based \"<code>clip:Open()</code>\" function and the <code>clip:PutFrame()</code> function.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vscriptval","title":"vScriptVal","text":"<p>vScriptVal</p> <p>A ScriptVal node's output is typically an encoded Lua table structure. If you want to work effectively and preview the live data outputs you will need to wire in a vScriptValDump node, or a combination of the vScriptValToText + vTextViewer nodes.</p> <p>The vScriptValDump node writes the Lua table structure to the Console window.</p> <p>The vScriptValToText + vTextViewer node approach makes the output selectable in the Inspector tab. This makes it easier to copy a \"Key\" from the output text and use it in a subsequent vScriptValGetToTable node.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#vpoint","title":"vPoint","text":"<p>vPoint</p> <p>Make sure to load the vPointFromMousePos node's output into the left or right viewer window before displaying a downstream node like a b-spline shape and a Transform node that is driven by the mouse position value via a \"Connect To\" approach.</p> <p>Failure to view the vPointFromMousePos node before displaying the downstream node will likely lead to lockups in Fusion v18.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#shapetree-datatype","title":"ShapeTree DataType","text":"<p>ShapeTree DataType</p> <p>A Fusion ShapeTree datatype accessibility bug was reported to BMD at the end of July 2022 and the issue was confirmed. This bug affects the usability of all ShapeTree based fuses in Fusion v17-v18.0.x. Hopefully a bugfix from BMD will solve an issue where a connected sRender nodes' input is rendered as a transparent canvas if a Fuse is placed upstream in the toolchain.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#yaml-parsing-libraries","title":"YAML Parsing Libraries","text":"<p>YAML Parsing Libraries</p> <p>The initial implementation of the Vonk YAML nodes like \"vArrayFromYAML\" and \"vScriptValFromYAML\" are powered by a Lua Module called \"Exosite LuaYAML\" which is written in pure Lua code.</p> <p>There is an effort underway to allow users to select from a variety of drop-in compatible YAML parsers so you could optionally access c-code compiled libraries like LibYAML. This will extend the supported YAML syntax, and features, available in Vonk while also improving the performance when processing large YAML data files. LibYAML will make it possible to support YAML data export.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#fusion-and-resolve-connections-from-a-fuse","title":"Fusion() and Resolve() Connections from a Fuse","text":"<p>Fusion() and Resolve() Connections from a Fuse</p> <p>Several Vonk nodes connect to the Fusion() and Resolve() functions from inside the Process part of the fuses. In these types of situations, typically having multiple copies of the host program active at the same time on the host system would cause issues with the remote FuScript binding processes.</p> <p>In Vonk Ultra v1.124 the following changes were made to ensure the correct FuScript connection is made automatically:</p> <pre><code>local fusion = Fusion(\"localhost\", 0, bmd.getappuuid())\nlocal resolve = Resolve(\"localhost\", 0, bmd.getappuuid())\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Cookbook/#data-nodes-in-macros","title":"Data Nodes in Macros","text":"<p>Data Nodes in Macros</p> <p>It has been occasionally noticed during Vonk development work that MacroOperator and GroupOperator encapsulations of Text datatype input connections can have the input \"triangle-shaped\" connection points mangled on a larger combined macro node group object. This bug still has to be troubleshooted and reported to BMD once the root cause has been determined.</p> <p>You will notice this issue has happened to you when you expand the GroupOperator in the Nodes view area. When you look inside the group node's working area, the input connection wire goes off to the top/left corner zone \"outwards and upwards\" to a near infinity of panning the view. Strange stuff.</p> <p>A temporary workaround solution to this issue is to place a vTextWireless link node inside your macro. Expose the wireless node's \"ImageControl\" attribute in the Inspector GUI for the macro and use that as the way to make connections to data nodes packaged inside this Macro object.</p> <p></p> <p>FWIW, if your end goal was to create a data node that could be used in a Resolve Edit page Effects Template, you are going to have to pass only image data on the macro's input and output connections in the end anyway. This means data nodes inside the macro group should be accessed via wireless links, or the Inspector view's right-click \"ConnectTo\" pop-up contextual menu by outside nodes.</p> <p>Another alternative would be to skip the GroupOperator \"shell\" on the macro, and for intermediate/advanced users simply expose the Vonk nodes placed inside an Underlay object. Then let the user always have access to the nodes for customization/reworking.</p> <p>This Group node based input connection linking bug will likely be solved in time, but currently this is the situation faced today (2022-08-05).</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/","title":"Vonk Node Reference Guide","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#3d-nodes","title":"3D Nodes","text":"<p>3D Nodes</p> <p>v3DToFile</p> <p>Writes PointCloud3D data from the Fusion 3D node-graph to a file.</p> <p>Connect a PointCloud3D node's output connection directly to the v3DToFile node:</p> <pre><code>PointCloud3D.Output -&gt; v3DToFile.Input\n</code></pre> <p>The \"Input 3D\" connection accepts a wireless link style drag-and-drop attachment of a PointCloud3D node.</p> <p>Clicking the \"Show 3D Source\" button will select the connected upstream node in the Nodes view, which displays the node in the Inspector view.</p> <p>The \"Point Cloud Format\" ComboControl allows you to select the export format used. Options include: \"XYZ ASCII (.xyz)\", \"PLY ASCII (.ply)\", and \"PIXAR USDA ASCII (.usda)\".</p> <p>The \"Filename\" text field supports Vonk vText based connections. This allows you to dynamically generate a filename via data node approaches.</p> <p>The Filename field contents can include relative PathMap values like \"Comp:/\" that will be expanded at render time.</p> <p>If a sub-folder is specified in the filename field, and it is missing at render time, the sub-folders will be re-created automatically when the file is saved to disk. This is helpful if you want to use per--timeline-frame numbered folders in the output filepath.</p> <p></p> <p>v3DSwitch</p> <p>Switch between Fusion 3D objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a v3DSwitch node's Which input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p> <p>v3DProcessOpen</p> <p>Launch a command-line process via popen.</p> <p>The \"Input 3D\" field is used to connect 3D nodes that interact with Fusion's 3D workspace.</p> <p>The \"Text\" field is used to define the executable program name and the command-line arguments you want to run from a shell session.</p> <p>Typically a vTextSubFormat node is used to build the executable command line string that is supplied to the Text input on a vImageProcessOpen node.</p> <p>If you need cross-platform support, you can use a vTextCreatePlatform or vTextCreatePlatformBrowse node to automatically define the per-OS specific elements like the executable program name and its file extension (.exe, .app, .bat, .sh, .command).</p> <p></p> <p>v3DSlashCommand</p> <p>Run a Console Fuse SlashCommand as a node</p> <p>v3DDelay</p> <p>Creates a delay while passing a Fusion 3D object.</p> <p>The \"Input 3D\" field is used to connect 3D nodes that interact with Fusion's 3D workspace.</p> <p>The delay effect is measured in seconds. This node is implemented internally using the \"bmd.wait()\" function.</p> <p>Among several use cases one can find for a tool that can momentarily pause rendering; it can be used to simulate a slow to render comp task when testing a render farm program. It also has applications when running a command line task via the Vonk 3DProcessOpen node the system requires a momentary pause to work reliably.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#array-nodes","title":"Array Nodes","text":"<p>Array Nodes</p> <p>vArraySubReturn</p> <p>Concatenates an array</p> <p></p> <p>vArrayKeys</p> <p>Returns the keys present in an array</p> <p></p> <p>vArrayGetKey</p> <p>Gets the value of a key in an array</p> <p></p> <p>vArrayGet</p> <p>Gets the value of a key in an array</p> <p></p> <p>vArrayGetIndex</p> <p>Creates Text from an array</p> <p></p> <p>vArrayFromLuaTable</p> <p>Casts a Lua Table to an array</p> <p>A Lua table structure is used as the underlying format for Fusion .comp files, Fusion macro/effects template .setting files, Reactor .atom packages, Fusion preference .prefs, and for Lua metadata table results.</p> <p></p> <p>vArrayFromMetadata</p> <p>Casts metadata to an array</p> <p>This node translates metadata records into a JSON based array structure. This supports tasks like parsing EXR formatted image metadata to extract Cryptomatte matte manifest records.</p> <p></p> <p>vArrayFromMediaIn</p> <p>Casts a Resolve MediaIn MediaProps to an array</p> <p>This makes it possible to read MediaPool/Edit page timeline information provided by a MediaIn node.</p> <p></p> <p>vArrayFromCSV</p> <p>Creates a JSON array from a CSV row or column</p> <p>The \"Array Mode\" control provides two options: \"Extract Row\", and \"Extract Column\". This makes it easy to select which axis of CSV data you would like to grab a sample from.</p> <p>The \"Ignore Header Row\" checkbox will offset the first index position to start at line 2 in the CSV file. This will skip over a labelled header row in the source document to avoid that information being accessed as part of the ingested data.</p> <p></p> <p>The output from vArrayFromCSV is typically connected to an vArrayGetIndex node. This makes it possible to select an individual cell of data.</p> <p>vArrayFromXML</p> <p>Creates a JSON array from XML</p> <p>The vArrayFromXML node works with XML formatted plain-text data. The XML data is read from a \"vTextFromFile\", \"vTextFromNet\", or \"vTextFromZip\" node.</p> <p>The output from the vArrayFromXML node is a text data type. The XML records are converted on-the-fly and stored in a JSON based array structure.</p> <p>This JSON array formatted data can be navigated and extracted using the Vonk provided \"vArray\" nodes along with the \"vJSONGetElement\" node.</p> <p></p> <p>vArrayFromYAML</p> <p>Creates a JSON array from YAML</p> <p>Technology Note: YAML is used as part of Film &amp; TV production lens metadata workflows by Cine lenses with sensors and encoders like the Cooke Optics /i Technology metadata system. YAML metadata exchange is also starting to be used by other Cine lens manufacturers, in match-moving and tracking packages like SynthEyes and PFTrack, and as part of data exchange approaches like OpenTimelineIO, too.</p> <p>Blackmagic BRAW media filmed on a BMD URSA Mini Pro 12K camera with a Cooke Optics PL-mount lens is capable of holding this YAML metadata recorded lens information internally. This is useful for supporting better data interchange between VP (Virtual Production) onset ICVFX (In-Camera VFX) departments and subsequent post-production workflows carried out by external vendors.</p> <p></p> <p>vArrayFromDataWindow</p> <p>Casts DataWindow to an array</p> <p></p> <p>vArrayConcatenate</p> <p>Concatenates an array</p> <p></p> <p>vArraySlice</p> <p>Creates Text from an array</p> <p></p> <p>vArraySize</p> <p>Gets the size of an array</p> <p></p> <p>vArrayJoin</p> <p>Gets the value of a key in an array</p> <p></p> <p>vArrayMatch</p> <p>Gets the value of a key in an array</p> <p>The \"Pattern\" text field uses Lua Patterns to isolate values from a JSON based Array object. Additional information about patterns can be read in the Lua manual.</p> <p>\"<code>cryptomatte/[a-z0-9]+/manifest</code>\" is a vArrayMatch Pattern that can be used to access Cryptomatte manifest image metadata. This information can be read from an EXR image via a Loader -&gt; vArrayFromMetadata -&gt; vArrayMatch node graph connection process.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#color-nodes","title":"Color Nodes","text":"<p>Color Nodes</p> <p>vColorJuggler</p> <p></p> <p>vColorSet</p> <p>This node was created by Chad Capeland.</p> <p>The \"Palette Array\" field allows you to use HTML hex style RGB color values to fill in the background of image elements with the format of \"RRGGBB\" color values.</p> <p>A hex number range includes the digits from 0-9 then it continues along to include the extra characters A-F as a representation of a single value.</p> <p>Palette Array Sample Colors:</p> <pre><code>\"FFFFFF\" = White\n\"000000\" = Black\n\"404040\" = 25% Grey\n\"808080\" = 50% Grey\n\"BFBFBF\" = 75% Grey\n\"FF0000\" = Red\n\"00FF00\" = Green\n\"0000FF\" = Blue\n\"00FFFF\" = Cyan\n\"FF00FF\" = Magenta\n\"FFFF00\" = Yellow\n</code></pre> <p>The \"Preserve Alpha\" checkbox is used to retain the alpha channel input data.</p> <p>The \"Multiply by Alpha\" checkbox is used to perform pre-multiplication math on the imagery. This control will make the transparent areas in the image, as defined by the source alpha channel data, turn black in the RGB channels.</p> <p>The \"Affect Canvas\" checkbox is used to extend the color fill operation beyond the current DoD (Domain of Definition) region in the viewer window. When this checkbox is enabled, the background canvas color is pre-defined, if you ever expand the image larger than its original dimensions using a Crop node.</p> <p></p> <p>vColorPermutations</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#base64-nodes","title":"Base64 Nodes","text":"<p>Base64 Nodes</p> <p>vBase64EncodeFromText</p> <p>Base64 encodes text into a Fusion Text object.</p> <p>This node converts a block of ASCII text into a Base64 format.</p> <p>The \"Text\" input field is used to specify the source ASCII string to process.</p> <p></p> <p>vBase64EncodeFromFile</p> <p>Base64 encodes a file into a Fusion Text object.</p> <p>This node converts the contents of an external file into a Base64 format. This can help with tasks like creating PNG format imagery that can be embedded inside a Fuse GUI as a block of base64 encoded data.</p> <p>The \"File\" input field is used to specify the filepath to a document.</p> <p></p> <p>vBase64DecodeImageFromFile</p> <p>Base64 decodes an image into a file.</p> <p>A Base64 encoded image is extracted from an external file, and converted into an image data type that can be displayed in the Fusion viewer window context.</p> <p>The \"Input\" field is used to specify the filepath to an image that is currently Base64 encoded.</p> <p></p> <p>vBase64DecodeFromText</p> <p>Base64 decodes text from a Fusion Text object.</p> <p>A Base64 formatted block of text is converted back into plain ASCII text that can be passed downstream via a text data type.</p> <p>The \"Text\" field is used to specify a block of text that is currently Base64 encoded.</p> <p>The \"Show Input\" checkbox allows you to source the Text information from an external Text based data node connection.</p> <p></p> <p>vBase64DecodeImageFromText</p> <p>Base64 decodes an image from a Fusion Text object.</p> <p>This node extracts a Base64 encoded image resource. A Base64 formatted image is extracted from a block of text, and converted into an image data type that can be displayed in the Fusion viewer window context.</p> <p>The \"Text\" field is used to specify a block of text that holds Base64 encoded image data.</p> <p>The \"Show Input\" checkbox allows you to source the Text information from an external Text based data node connection.</p> <p></p> <p>vBase64ToHTML</p> <p>Converts a Base64 encoded PNG image into an inline HTML <code>&lt;IMG&gt;</code> embed.</p> <p></p> <p>This node is useful to help prepare an inline Base64 encoded PNG image block. The most common use case for this node is to help fuse coders prepare new icons for use in a fuse's LabelControl element. This supports building Inspector view based icons for your custom fuses or macros.</p> <p>In your fuse the base64 encoded image element would be placed into a variable that is linked into the LabelControl like this:</p> <pre><code>BrandLogo = [[\n&lt;center&gt;&lt;img width=\"160\" height=\"75\" src='data:image/png;base64,...'/&gt;&lt;/center&gt;\n]]\n\nInLabel = self:AddInput(BrandLogo, \"Label\",{\n    LINKID_DataType = \"Text\",\n    INPID_InputControl = \"LabelControl\",\n    LBLC_MultiLine = true,\n    INP_External = false,\n    INP_Passive = true,\n    IC_ControlPage = -1,\n    IC_NoLabel = true,\n    IC_NoReset = true,\n})\n</code></pre> <p>The \"<code>IC_ControlPage = -1,</code>\" tag will move the UI element above the Control Page tabs which makes the same icon visible as you switch between Control Pages.</p> <p>The end result from adding the Base64 icon to a LabelControl is the ability to create a more polished UI for your fuse:</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#metadata-nodes","title":"Metadata Nodes","text":"<p>Metadata Nodes</p> <p>vMetadataToText</p> <p>Creates a Fusion Text object from metadata</p> <p>This node is similar to the GetMetadata.fuse with the addition of a \"Key\" input connection on the node that accepts a Text data type.</p> <p>The \"Key\" field is used to specify the metadata record.</p> <p>An example of an image metadata record \"Key\" entry would be the Loader node added attribute of \"Filename\".</p> <p></p> <p>vMetadataFromText</p> <p>Creates a Fusion image with metadata added from text</p> <p>This node is similar to the SetMetadata.fuse with the addition of input connections on the node that accepts a Text data type for the \"Field Name\", and \"Field Value\".</p> <p></p> <p>A metadata example for Fusion Viewer based Stereo3D \"Over/Under\" image content is:</p> <pre><code>Field Name: Stereo\nField Value: {Method  = \"vstack\"}\n</code></pre> <p>A metadata example for Fusion Viewer based Stereo3D \"Side by Side\" image content is:</p> <pre><code>Field Name: Stereo\nField Value: {Method  = \"hstack\"}\n</code></pre> <p>A metadata example for Fusion Viewer window based 360VR \"Latitude/Longitude\" image projection content is:</p> <pre><code>Field Name: Pano\nField Value: {Format = \"LatLong\"}\n</code></pre> <p>vMetadataFromMediaIn</p> <p>Creates a Fusion image with MediaIn MediaProps metadata</p> <p>This node is connected directly to a MediaIn node. It extracts the MediaProps record from a MediaIn node and places that data into the image's metadata Lua table.</p> <p></p> <p>The MediaProps based Metadata Lua table output is formatted like:</p> <pre><code>{\n    \"MEDIA_FORMAT_TYPE\":\"PNG\",\n    \"MEDIA_HEIGHT\":64,\n    \"MEDIA_IS_SOURCE_RES\":true,\n    \"MEDIA_LAYER_DESC\":[],\n    \"MEDIA_MARK_IN\":0,\n    \"MEDIA_MARK_OUT\":0,\n    \"MEDIA_NAME\":\"Fusion-Logo.png\"\n    \"MEDIA_NUM_FRAMES\":1,\n    \"MEDIA_NUM_LAYERS\":0,\n    \"MEDIA_PAR\":1,\n    \"MEDIA_PATH\":\"/Users/vfx/Reactor/Deploy/Comps/Kartaverse/Vonk Ultra/Media/Fusion-Logo.png\",\n    \"MEDIA_SRC_FRAME_RATE\":24,\n    \"MEDIA_START_FRAME\":0,\n    \"MEDIA_WIDTH\":64,\n}\n</code></pre>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#filesystem-nodes","title":"Filesystem Nodes","text":"<p>Filesystem Nodes</p> <p>vFileSystemChmod</p> <p>Change a file/folder's access permissions</p> <p>The \"File\" textfield is used to specify a file or folder path.</p> <p>The \"Mode\" control is used to specify the file mode (access permission) as an integer number. This is typically an octal value like \"777\", \"755\", etc.</p> <p>The \"Recursive\" checkbox allows you to apply the access permission changes to items inside a folder.</p> <p>Note: This node works on macOS and Linux systems only due to the use of the UNIX \"chmod\" utility.</p> <p></p> <p>vFileSystemCreateDir</p> <p>Creates a new directory</p> <p>This node will create a new directory. The \"Text\" field is used to define the desired folder path. Any required intermediate subfolders are created at the same time.</p> <p>When enabled, the \"[x] Use Parent Directory\" checkbox allows you to enter a filepath into the \"Text\" field. The base folder path for the specified file will be used for the directory creation task.</p> <p></p> <p>vFileSystemDirExists</p> <p>Check if a directory exists</p> <p></p> <p>vFileSystemFileCopy</p> <p>Copies a file</p> <p>This node allows you to define a \"Source File\" that will be copied to the disk-based filepath defined in the \"Destination File\" field.</p> <p>The \"Create Destination Directory\" checkbox is useful if you need to dynamically create the output folder at the same time.</p> <p></p> <p>vFileSystemFileExists</p> <p>Checks if a file exists</p> <p>This node reads a filepath defined in the \"Text\" field and checks if the document exists on disk. The output is the number 0 if the file does not exist, and the number 1 if the file does exist.</p> <p>If you want to connect this node to a Switch node's \"Which\" field, you will have to use a vNumberAdd node to offset the value up by one to go from a 0-1 range to a 1-2 range.</p> <p></p> <p>vFileSystemFileOpen</p> <p>Opens a file</p> <p>This node will open the \"Source File\" using the operating system's default file handler. The exact program launched is defined by the file extension.</p> <p></p> <p>vFileSystemFileSize</p> <p>Returns the file size</p> <p>This node takes a single filename as a text based input. It checks the file size of the document and returns the value in the unit of measure you specify.</p> <p></p> <p>The Unit field supports a wide range of file size output scales including:</p> <p>\"Byte (B)\", \"Kilobyte (KB)\", \"Kibibyte (KiB)\", \"Megabyte (MB)\", \"Mebibyte (MiB)\", \"Gigabyte (GB)\", \"Gibibyte (GiB)\", \"Terabyte (TB)\", and \"Tebibyte (TiB)\".</p> <p></p> <p>The node has two output connections labelled \"Output\" and \"OutputUnit\". The \"OutputUnit'' connection is handy if you need to create a visual overlay with a Text+ node of file size and want to indicate the scale of measure.</p> <p>vFileSystemListFiles</p> <p>Creates a Fusion Text object with a list of the folder contents</p> <p>This node scans the contents of a folder path defined in the \"Text\" field. The output is created as a text based multi-line list of files or folders.</p> <p>The \"Pattern\" field is used to enter part of the filename that you would like to match in the output. An asterisk character is supported as a wildcard symbol to help with partial filename entry. The Pattern field is typically used to help find files by their extension by entering a value like \"<code>*.exr</code>\", \"<code>*.png</code>\", \"<code>*.mov</code>\", \"<code>*.mp4</code>\", etc.</p> <p>The Mode control can be set to \"List Files\" or \"List Directories\". This allows you to filter the output.</p> <p>If you enable the \"Export Fullpath\" checkbox the full absolute filepath for each item is returned. If the checkbox is disabled, only the filename of the resource is returned without any folder path elements included.</p> <p>The \"Expand PathMaps\" checkbox will automatically convert any relative filepaths into absolute filepaths on the output.</p> <p>The \"Skip Hidden Files\" checkbox is used to ignore hidden files like \"<code>.DS_Store</code>\" and \"Thumbs.db\" documents, along with UNIX style filenames that start with a period. This helps reduce clutter on file listing based outputs.</p> <p></p> <p>vFileSystemMapPath</p> <p>Expands a PathMap</p> <p>This node automatically converts a relative filepath into an absolute filepath on the output.</p> <p>This is useful if you want to supply an executable program name, or a filename to an operation like the ProcessOpen node that carries out command-line tasks.</p> <p></p> <p>vFileSystemRemoveDir</p> <p>Remove a directory</p> <p></p> <p>vFileSystemRemoveFile</p> <p>Rename a file or folder</p> <p></p> <p>vFileSystemRename</p> <p>Rename a file or folder</p> <p></p> <p>vFileSystemSymlink</p> <p>Create a Symbolic Link to a file or folder on macOS, Linux, and Windows</p> <p>A Symlink (also known as a Symbolic link) can be thought of as a fancier (and far more posh) Linux file system style version of a Windows shortcut, or a macOS alias. This node creates Symlinks that are known as \"soft-links\".</p> <p>If you are working with locally stored and managed temp files on a render node, instead of copying an image sequence, and doubling disk space usage, you can Symlink the files and save your storage for new data. Be sure to document in your workflow notes that these files are interim scratch files that are to be automatically cleaned up/removed, and not to be backed up or managed as assets.</p> <p>Symlinks can be an attractive technique to use if you are copying a large quantity of files on disk, merely for the purpose of renaming the files temporarily in order to unify the naming convention of an image sequence. This happens when you are trying to manage original \"camera named\" footage into something tidy and symmetrical. This type of operation is typically done for convenience when doing data processing in a temp folder where you need to separate the intermediate files, and your output files from the source media.</p> <p></p> <p>How to tell a file is a Symlink</p> <p>macOS / Linux</p> <p>If you are looking at files on disk and trying to tell if it is a symlink or not, you can type \"ls -la\" into a Terminal window on macOS/Linux and you will see a file is indicated as a soft-link with an arrow listed next to the filename in the output like this:</p> <pre><code>% ls -la\nCameraA-Link.0001.jpg -&gt; /Users/vfx/Reactor/Deploy/Comps/KartaVR/WarpStitch/WarpStitch Under the Bridge/Media/CameraA.0001.jpg\n</code></pre> <p>In the macOS Finder folder browsing window a symlinked file has an \"arrow icon\" overlaid over the document icon:</p> <p></p> <p>Windows</p> <p>If you are looking at files on disk and trying to tell if it is a symlink or not, you can type \"dir\" into a Command Prompt window on Windows and you will see a file is indicated as a soft-link with the word \"<code>&lt;SYMLINK&gt;</code>\" in the directory contents listing output like this:</p> <p></p> <pre><code>dir\n Volume in drive C has no label.\n Volume Serial Number is X00X-XX00\n\n Directory of C:\\Users\\vfx\\AppData\\Local\\Temp\\Vonk\\0001\n\n08/20/2022  10:51 PM    &lt;DIR&gt;       .\n08/20/2022  10:51 PM    &lt;DIR&gt;       ..\n08/20/2022  10:51 PM    &lt;SYMLINK&gt;   CameraA-Link.0001.jpg [C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\Deploy\\Comps\\KartaVR\\WarpStitch\\WarpStitch Under the Bridge\\Media\\CameraA.0001.jpg]\n            1 File(s)           0 bytes\n            2 Dir(s)  277,488,435,200 bytes free\n</code></pre> <p>In the Windows Explorer folder browsing window a symlinked file has an \"arrow icon\" overlaid over the document icon as well:</p> <p></p> <p>Windows and Symlink Based File Permissions</p> <p>If you want to create a symlink without using Administrator permissions on Windows systems, you need to open the Windows operating system \"Settings &gt; Privacy &amp; security &gt; For developers\" preference to enable the \"Developer Mode\".</p> <p></p> <p>vFileSystemTouch</p> <p>Touch a file/folder's creation and modification dates on macOS and Linux</p> <p></p> <p>vFileSystemURLOpen</p> <p>Opens a file</p> <p>This node opens a URL in an external web-browser. This is useful if you need to display reference material, or assist a user in checking out an asset from a web-based content management system.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#image-nodes","title":"Image Nodes","text":"<p>Image Nodes</p> <p>vImageCreateLine</p> <p>Creates a Line Shape object</p> <p></p> <p>vImageDelay</p> <p>Creates a Delay while passing a Fusion Image object</p> <p></p> <p>The delay effect is measured in seconds. This node is implemented internally using the \"<code>bmd.wait()</code>\" function.</p> <p>Among several use cases one can find for a tool that can momentarily pause rendering; it can be used to simulate a slow to render comp task when testing a render farm program. It also has applications when running a command line task via the Vonk ProcessOpen node and the system requires a momentary pause.</p> <p>vImageToFile</p> <p>Saves a jpg/exr/png/bmp/raw/fusepic image sequence to disk</p> <p>The \"File\" control can be driven externally by a Text data type connection to the node.</p> <p></p> <p>vImageEXRToFile</p> <p>Saves an EXR image to disk</p> <p>The \"Filename\" control can be driven externally by a Text data type connection to the node.</p> <p></p> <p>vImageFromColor</p> <p>Creates an image from a color</p> <p>This node can act as a fuse based alternative to a Background node if you need to create a fixed size image and fill the image canvas with a flat color.</p> <p></p> <p>vImageEXRFromFile</p> <p>Reads an EXR image from a file</p> <p>The \"Filename\" control is used to define the image filename to load. It can be driven externally by a Text data type connection to the node.</p> <p>The \"EXR Part Number\" control allows you to select another part element from a multi-part image document. This control can be a bit temperamental so make sure to save the comp document first before changing this value to avoid any loss of time and productivity.</p> <p>The \"Time Mode\" control allows you to adjust how the frame number for image sequences is processed.</p> <p></p> <p>vImageFromClipboard</p> <p>Grabs, saves, then loads the current clipboard image</p> <p>The \"Grab\" button is used to capture the clipboard contents. It is a handy way to quickly load an image into the compositing node graph without needing to worry about the filename.</p> <p>This node was designed to work with Fusion Standalone v9 on Windows.</p> <p></p> <p>vImageFromFile</p> <p>Reads an Image object from a file</p> <p>The \"Input\" control is used to define the image filename to load. It can be driven externally by a Text data type connection to the node.</p> <p>The \"Time Mode\" control allows you to adjust how the frame number for image sequences is processed.</p> <p></p> <p>vImageFromNet</p> <p>Reads an Image object from a network URL</p> <p>The \"Input\" control is used to define the image URL such as an http://, https://, or file:/// based resource. The URL can be driven externally by a Text data type connection to the node.</p> <p>The \"File Type\" ComboBox control helps Fusion decode the exact type of content being downloaded when the media is loaded into the Fusion viewer window context.</p> <p>An example image you can use to test this node is an Eastern Canada weather satellite URL:</p> <p>https://weather.gc.ca/data/satellite/goes_ecan_1070_100.jpg</p> <p></p> <p>vImageFromZip</p> <p>Reads an Image object from a zip archive</p> <p>This node accesses an image resource that is stored inside a Zip archive using the Fusion v16+/Resolve v15+ based ZipIO library.</p> <p>The \"Zip File\" field is used to define the filename of the zip archive.</p> <p>The \"Extract Image\" field is used to define the image resource that is stored inside the zip archive.</p> <p>Both attributes can be driven externally by a Text data type connection to the node.</p> <p></p> <p>vCryptomatte</p> <p>This node is a version of the Cryptomatte fuse that supports an exposed Text data type based input connection to the \"Matte List\".</p> <p>This is handy if you want to use the Vonk JSON + Metadata + Array features to create technical animations that browse through every matte element stored in the image's manifest records.</p> <p></p> <p>vImageProcessOpen</p> <p>Launches a command-line process via popen</p> <p>The \"Text\" field is used to define the executable program name and the command-line arguments you want to run from a shell session.</p> <p>Typically a vTextSubFormat node is used to build the executable command line string that is supplied to the Text input on a vImageProcessOpen node.</p> <p>If you need cross-platform support, you can use a vTextCreatePlatform or vTextCreatePlatformBrowse node to automatically define the per-OS specific elements like the executable program name and its file extension (.exe, .app, .bat, .sh, .command).</p> <p></p> <p>vImageSlashCommand</p> <p>Run a Console Fuse SlashCommand as a node</p> <p>vImageCreateTiles</p> <p>Creates an image grid layout from an image sequence</p> <p>This node makes it easy to create tiled \"texture atlas\" like grid layouts. If you need the imagery to be scaled down to a specific size, attach a resize or scale node to the image stream before you connect it to the vImageCreateTiles node.</p> <p>The \"Tiles X\" control specifies how many images are stacked horizontally.</p> <p>The \"Tiles Y\" control specifies how many images are stacked vertically.</p> <p>The \"Reverse X Order\" and \"Reverse Y Order\" checkboxes are used to provide control over the image placement ordering when the grid layout is built. This allows you to start frame 1 at either of the 4 corners of the frame border.</p> <p></p> <p>vImageHook</p> <p></p> <p>vImageWireless</p> <p>The vImageWireless node allows you to connect to other image based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p></p> <p>vImageSwitch</p> <p>Switches between Fusion Image objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a vNumberSwitch node's Which input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#number-nodes","title":"Number Nodes","text":"<p>Number Nodes</p> <p>vNumberTimeSpeed</p> <p>Time based operation on numbers</p> <p></p> <p>vNumberXSheet</p> <p>Time based operation on numbers</p> <p></p> <p>vNumberTimeStretch</p> <p>Time based operation on numbers</p> <p></p> <p>vNumberDelay</p> <p>Creates a Delay while passing a Fusion Number object</p> <p></p> <p>The delay effect is measured in seconds. This node is implemented internally using the \"<code>bmd.wait()</code>\" function.</p> <p>Among several use cases one can find for a tool that can momentarily pause rendering; it can be used to simulate a slow to render comp task when testing a render farm program. It also has applications when running a command line task via the Vonk ProcessOpen node and the system requires a momentary pause.</p> <p>vNumberEndPID</p> <p>Quit a program using its PID (Process ID) on macOS and Linux</p> <p></p> <p>It is possible to use the following terminal command to list a specific program's PID value:</p> <pre><code>ps aux | grep writeInSomeProgramNameHere\n</code></pre> <p>A sample output from this usage of the ps aux + grep command is:</p> <pre><code>% ps aux | grep safari\nvfx             10239   0.0  0.0 408637584   1760 s000  S+  4:21PM   0:00.00 grep safari\n</code></pre> <p>You can see a list of running programs and their PID values in the terminal using the \"top\" utility:</p> <pre><code>% top\nProcesses: 540 total, 3 running, 537 sleeping, 2455 threads                     16:24:24\nLoad Avg: 1.05, 1.09, 1.17  CPU usage: 2.1% user, 2.48% sys, 95.50% idle\nSharedLibs: 670M resident, 122M data, 71M linkedit.\nMemRegions: 79919 total, 3430M resident, 570M private, 2089M shared.\nPhysMem: 15G used (2487M wired), 204M unused.\nVM: 204T vsize, 3823M framework vsize, 0(0) swapins, 0(0) swapouts.\nNetworks: packets: 14481172/7542M in, 10866206/9338M out.\nDisks: 1618664/32G read, 799320/24G written.\n\nPID COMMAND     %CPU TIME   #TH   #WQ  #PORT MEM    PURG   CMPRS  PGRP  PPID\n171 WindowServer 6.5  47:39.13 17   3   1775- 220M-  9600K- 7792K  171   1\n10555  top          5.2  00:00.58 1/1   0   27+   6545K  0B     0B  10555 10519\n466 Terminal    2.0  00:03.48 6/1   1   258+  44M   15M 1664K  466   1\n**10239  Safari     1.4  00:31.49 6     2   514   62M   0B  0B  10239 1**\n</code></pre> <p>It is also possible to see programs and their PID values in the macOS \"Activity Monitor.app\" utility. In the top right corner of the Activity Monitor window you can type in the name of the program in the search field to filter the results in the view down to what matters.</p> <p></p> <p>vNumberResolvePID</p> <p>Returns the Resolve/Fusion PID (Process ID)</p> <p>A PID value is an integer style number that is used by the operating system to track a running executable.</p> <p>Often PID values are the identifier used to tell an external program to gracefully quit. A PID number can also be used by the \"renice\" terminal utility to help balance the compute load on a system by scaling back the resource hogging level of a single dominant program that is reducing the overall interactivity of the host computer.</p> <p></p> <p>vNumberResolveTimelineFPS</p> <p>Returns the Resolve Timeline frame rate</p> <p>This node is useful if you need to perform math operations that need to be informed of the Resolve project's current frame rate value.</p> <p></p> <p>vNumberSlashCommand</p> <p>Run a Console Fuse SlashCommand as a node</p> <p>vNumberProcessOpen</p> <p>Launch a command-line process via popen</p> <p>vNumberAbsolute</p> <p>Returns the absolute value of a number</p> <p>This node is handy if you need to remove the negative sign (-) element from a value so you only have the positive component of the number remaining.</p> <p></p> <p>vNumberMax</p> <p>Returns the maximum of two numbers</p> <p></p> <p>vNumberStep</p> <p>Generates a step function by comparing two values</p> <p></p> <p>vNumberSquareRoot</p> <p>Returns the square root of a number</p> <p></p> <p>vNumberDivide</p> <p>Returns the quotient of two numbers</p> <p></p> <p>vNumberMin</p> <p>Returns the minimum of two numbers</p> <p></p> <p>vNumberModulus</p> <p>Returns the remainder of the division of x by y that rounds the quotient towards zero</p> <p>If a vNumberCompReqTime or vNumberCompCurrentTime node is piped into the \"Dividend\" input connection, you can use the modulus operator to create a looping number range with the Divisor control.</p> <p>For example, a Divisor value of 10 will cause the output from modulus to cycle from 0-9 in loops 5 times as the playhead advances through a render start/end frame range of 0 - 50.</p> <p></p> <p>vNumberReciprocal</p> <p>Returns the reciprocal of a number</p> <p></p> <p>vNumberClamp</p> <p>Clamps a number to specific boundaries</p> <p></p> <p>vNumberFractional</p> <p>Returns the fractional part of a number</p> <p></p> <p>vNumberSubtract</p> <p>Returns the difference of two numbers</p> <p></p> <p>vNumberCeil</p> <p>Returns the integer no greater than a number</p> <p>This provides a way to round a floating point number to a whole number (an integer value) by rounding upwards to remove the digits to the right of the decimal place.</p> <p>Ceil (ceiling) is the counterpoint to the floor rounding method.</p> <p></p> <p>vNumberPower</p> <p>Returns the power of a number</p> <p></p> <p>vNumberFloor</p> <p>Returns the integer no less than a number</p> <p>This provides a way to round a floating point number to a whole number (an integer value) by rounding downwards to remove the digits to the right of the decimal place.</p> <p></p> <p>vNumberEase</p> <p>Performs a specific interpolation between two numbers during a defined time duration</p> <p></p> <p>vNumberSign</p> <p>Returns the sign of a number</p> <p>The output from the node will be either \"-1\", \"0\", or \"1\".</p> <p></p> <p>vNumberIntegral</p> <p>Returns the integral part of a number</p> <p></p> <p>vNumberSmoothstep</p> <p>Generates a smoothstep function</p> <p></p> <p>vNumberMultiply</p> <p>Returns the product of two numbers</p> <p></p> <p>vNumberMix</p> <p>Performs a linear interpolation between two numbers</p> <p></p> <p>vNumberAdd</p> <p>Returns the sum of two numbers</p> <p></p> <p>vNumberPartialPermutation</p> <p>Returns the sum of two numbers</p> <p></p> <p>vNumberFactorial</p> <p>Returns the product of all positive integers less than or equal to InNumber</p> <p></p> <p>vNumberCosine</p> <p>Returns the cosine for a number in radians</p> <p></p> <p>vNumberArcTangent</p> <p>Returns the inverse tangent for a number in radians</p> <p></p> <p>vNumberSine</p> <p>Returns the sine for a number in radians</p> <p></p> <p>vNumberArcCosine</p> <p>Returns the inverse cosine for a number in radians</p> <p></p> <p>vNumberHyperbolicSine</p> <p>Returns the hyperbolic sine of a number in radians</p> <p></p> <p>vNumberHyperbolicTangent</p> <p>Returns the hyperbolic tangent of a number in radians</p> <p></p> <p>vNumberHyperbolicCosine</p> <p>Returns the hyperbolic cosine for a number in radians</p> <p></p> <p>vNumberDegreesToRadians</p> <p>Returns the radian value as a number in degrees</p> <p></p> <p>vNumberTwoArgumentArcTangent</p> <p>Returns the arc tangent of y/x (in radians) but uses the signs of both parameters to find the quadrant of the result</p> <p></p> <p>vNumberArcSine</p> <p>Returns the inverse sine for a number in radians</p> <p></p> <p>vNumberRadiansToDegrees</p> <p>Returns the degree value as a number in radians</p> <p></p> <p>vNumberTangent</p> <p>Returns the tangent for a number in radians</p> <p></p> <p>vNumberFromArray</p> <p>Creates a Number from an array</p> <p>The \"Index\" control allows you to select the array item (cell) to return as a number based value.</p> <p></p> <p>vNumberAnd</p> <p>Performs a logical AND operation on two numbers</p> <p></p> <p>vNumberOr</p> <p>Performs a logical OR operation on two numbers</p> <p></p> <p>vNumberTernary</p> <p>Compare a value and return one of two possible results</p> <p></p> <p>vNumberNotEqual</p> <p>Compares two numbers to see if they are not equal</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberEqual</p> <p>Compares two numbers to see if they are equal</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberNot</p> <p>Performs a logical NOT operation on a number</p> <p></p> <p>vNumberGreater</p> <p>Compares two numbers to see if Term 1 is greater than Term 2</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberGreaterEqual</p> <p>Compares two numbers to see if Term 1 is greater than or equal to Term 2</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberLessEqual</p> <p>Compares two numbers to see if Term 1 is less than or equal to Term 2</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberLess</p> <p>Compares two numbers to see if Term 1 is less than Term 2</p> <p>A zero (false) or one (true) based number is returned from the comparator operation.</p> <p></p> <p>vNumberCompCurrentTime</p> <p>Returns the comp's Current Time</p> <p>The current time represents the point where the timeline playhead is positioned regardless of any temporal effects that might be happening.</p> <p></p> <p>vNumberCompProxy</p> <p>Returns the comp's Proxy state</p> <p>The True and False inputs on the node let you define a custom value that is returned for the Proxy logic state.</p> <p>Setting the True and False inputs to a value of \"True = 2\" &amp; \"False = 1\" makes it easier to directly connect the vNumberCompProxy output to a Switch node's Which input that starts the first switchable input connection as \"Which = 1\".</p> <p>Note: There is a slight instability that can occur with this node if you rapidly toggle the \"Prx\" state On/Off while playing back footage in the Fusion timeline with the vNumberCompProxy node active. A solution to this issue is being explored.</p> <p></p> <p>vNumberCompProxyScale</p> <p>Returns the comp's Proxy Scale</p> <p></p> <p>vNumberCompGlobalEnd</p> <p>Returns the comp's Global End</p> <p>This is the last frame of the full Fusion timeline range. This number is not always set to the same range as the render end timeline control.</p> <p></p> <p>vNumberCompRenderEnd</p> <p>Returns the comp's Render End</p> <p>This is the last renderable frame when a batch render is carried out.</p> <p></p> <p>vNumberCompReqTime</p> <p>Returns the comp's request time</p> <p>This is the currently requested frame that is being processed at render time. It supports temporal effects like the vTextAccumulator node that iterates over a frame duration.</p> <p></p> <p>vNumberCompFrameformat</p> <p>Returns the comp's frame format</p> <p>This node outputs a Width and Height parameter derived from the current comp's FrameFormat settings.</p> <p></p> <p>vNumberCompRenderStart</p> <p>Returns the comp's Render Start</p> <p>This is the first renderable frame when a batch render is carried out.</p> <p></p> <p>vNumberCompFPS</p> <p>Returns the comp's frame rate</p> <p></p> <p>vNumberCompGlobalStart</p> <p>Returns the comp's Global Start</p> <p>This is the first frame of the full Fusion timeline range. This number is not always set to the same range as the render start timeline control.</p> <p></p> <p>vNumberFromText</p> <p>Returns a number from a Fusion Text object</p> <p>This node converts an ASCII text based string that holds numerical content like \"5\" into an actual number data type that can have math operations performed on the value. This is a useful step if you need to connect a numerical value to an Inspector based attribute on another node.</p> <p></p> <p>vNumberFromCSV</p> <p>Creates a Fusion Number object by extracting a single cell from a CSV formatted block of text</p> <p>The \"Row\" control is used to define the CSV line number to read.</p> <p>The \"Column\" control is used to increment through each set of comma separated entries on a single line of CSV input data.</p> <p>The \"Ignore Header Row\" checkbox will offset the first index position to start at line 2 in the CSV file. This will skip over a labelled header row in the source document to avoid that information being accessed as part of the ingested data.</p> <p></p> <p>vNumberRange</p> <p>Creates a Fusion Number object</p> <p>The range node creates a list of numbers that vary between the \"From\" and \"To\" values. The \"Step\" control increases the incremental rate of change in the output.</p> <p>If the \"From\" value was set to 0, and the \"To\" value was set to 5 the output from the node would be formatted like:</p> \\[0,1,2,3,4,5\\] <p></p> <p>vNumberIntegerCreate</p> <p>Creates an integer Fusion Number object</p> <p>This node creates whole number based values with no floating point decimal based component. This node is an excellent choice if you want to drive the \"Which\" attribute on any of the Switch nodes available in Vonk.</p> <p></p> <p>vNumberCreateArch</p> <p>Creates a unique Fusion Number object per CPU architecture</p> <p>If the fuse is rendered on a 32-bit Intel/AMD CPU based system a value of 1 is returned. (Note: Fusion Studio v8+ were only released as 64-bit builds so it is of low likelihood you are going to see an x86 value returned from this node.)</p> <p>If the fuse is rendered on a 64-bit Intel/AMD CPU based system a value of 2 is returned.</p> <p>If the fuse is rendered on an ARM 64-bit system, like an Apple Silicon CPU, a value of 3 is returned.</p> <p></p> <p>vNumberCreateBool</p> <p>Returns a 0-1 range integer Fusion Number object</p> <p>This node uses a checkbox control to output a true (1) or false (0) logic state.</p> <p></p> <p>Usage tip: This node's boolean like checkbox value can be used to drive a Switch node's \"Which\" control. This checkbox control makes it a single click operation in a macro node (MacroOperator or GroupOperator) to be able to toggle between an input1 / input2 connection. To do this you simply have to insert an vNumberAdd node, (that is set to increment the value up by 1), between the vNumberCreate node's output (0-1) logic state, and the Switch node:</p> <pre><code>vNumberCreateBool.Output &gt; vNumberAdd.Term1 &gt; Switch.Which\n</code></pre> <p>Node setting to change:</p> <pre><code>vNumberAdd.Term2 = 1\n</code></pre> <p>vNumberCreatePlatform</p> <p>Creates a unique Fusion Number object per OS platform</p> <p>If the fuse is rendered on a macOS system a value of 1 is returned.</p> <p>If the fuse is rendered on a Windows system a value of 2 is returned.</p> <p>If the fuse is rendered on a Linux system a value of 3 is returned.</p> <p></p> <p>vNumberCreateRandom</p> <p>Creates a Fusion Number object</p> <p>This node uses a pseudo-random number generator to create a number that fits within the upper and lower range that is defined. If you animate the seed value, the number will change on each frame.</p> <p></p> <p>vNumberCreate</p> <p>Creates a Fusion Number object</p> <p>This node is the starting point for most number data type based node graphs. The output is a floating point number that can go up to \"1e+38\".</p> <p></p> <p>vNumberFromVector</p> <p>Returns a number from a vector</p> <p></p> <p>vNumberToMatrix</p> <p>Returns a matrix from a number</p> <p></p> <p>vNumberFromMatrix</p> <p>Returns a number from a matrix</p> <p></p> <p>vNumberWireless</p> <p>The vNumberWireless node allows you to connect to other number based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p></p> <p>vNumberSwitch</p> <p>Switches between Fusion Number objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a vNumberSwitch node's \"Which\" input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#point-nodes","title":"Point Nodes","text":"<p>Point Nodes</p> <p>vPointCreate</p> <p>Create a Fusion Point object</p> <p></p> <p>vPointCreateImage</p> <p>Create a Fusion Point object with an image visible in the background</p> <p></p> <p>The \"Add Metadata\" checkbox creates image output metadata entries for the point coordinates formatted as:</p> <pre><code>XOffset = 0.5\nYOffset = 0.5\n</code></pre> <p>If you enable the viewer window's \"Metadata\" sub-viewer entry you can quickly see the information that is appended to the image output stream.</p> <p></p> <p></p> <p>vPointFromMousePos</p> <p>Return a Fusion Point object that holds the current mouse X &amp; Y cursor position</p> <p></p> <p>Coord Mode</p> <p>The \"Coord Mode\" multi-button control allows you to define the units used when reporting the mouse position. The \"Native\" option will return the original unmodified \"raw\" cursor position coordinates. The \"Normalized\" option will return a 0-1 range value for the X/Y cursor position.</p> <p>Screen Dimensions</p> <p>The normalization process can be carried out using either the \"Manual Entry\" option which is based upon manually entered screen width and height parameters along with a screen ui size scaling parameter, or through using the \"Fu Prefs\" option which is based upon the existence of a Fusion preferences \"Layout\" page based saved window size value.</p> <p>If no Fusion preferences based window sizing parameters are found you will see an error reported to the Console window when the \"Fu Prefs\" option is enabled. The message reported is:</p> <pre><code>[Error] The Fusion window size preference is undefined. Please save an initial window position in the Layout Preference section.\n</code></pre> <p>Note: Make sure to load the vPointFromMousePos node's output into the left or right viewer window before displaying a downstream node like a b-spline shape and a Transform node that is driven by the mouse position value via a \"Connect To\" approach.</p> <p>Failure to view the vPointFromMousePos node before displaying the downstream node will likely lead to lockups in Fusion v18.</p> <p>vPointFromNumber</p> <p>Return a Fusion Point object from two numbers</p> <p></p> <p>vPointToNumber</p> <p>Return a pair of numbers from a Fusion Point object</p> <p>If you want a quick way to be able to view the individual number outputs from this node in the viewer window, try adding a pair of pipe-routers to the output connections.</p> <p></p> <p>vPointCreateRandom</p> <p>Create a Fusion Point object with a random position</p> <p></p> <p>vPointAbsolute</p> <p>Returns a Fusion Point object with an absolute value</p> <p></p> <p>vPointMix</p> <p>Performs linear interpolation between two Fusion Point objects</p> <p></p> <p>vPointPower</p> <p>Returns the power of a Fusion Point object</p> <p></p> <p>vPointTimeStretch</p> <p>Time based operations on a Fusion Point object</p> <p></p> <p>vPointTimeSpeed</p> <p>Time based operations on a Fusion Point object</p> <p></p> <p>vPointDelay</p> <p>Creates a Delay while passing a Fusion Point object</p> <p></p> <p>vPointFromText</p> <p>Returns a Fusion Point object from two Text inputs</p> <p></p> <p>vPointToText</p> <p>Return a pair of Text objects from a Fusion Point object</p> <p></p> <p>vPointAdd</p> <p>Returns the sum of two Fusion Point objects</p> <p>This node can be used to apply a positive offset to the origin of the 1<sup>st</sup> point by the 2<sup>nd</sup> point's displacement distance.</p> <p></p> <p>vPointClamp</p> <p>Clamp a Fusion Point object to specific boundaries</p> <p>This acts as a hard limiter on the range of numbers that can pass through the Point control. Numbers that exist below the minimum range, or above the maximum range are clipped to those boundaries.</p> <p></p> <p>vPointDivide</p> <p>Returns the quotient of two Fusion Point objects</p> <p>This node can be used to apply a scale reducing effect to the origin of the 1<sup>st</sup> point by the 2<sup>nd</sup> point's displacement distance.</p> <p></p> <p>vPointModulus</p> <p>Returns the remainder of the division of a Fusion Point object that rounds the quotient towards zero</p> <p>The \"Divisor X\" and \"Divisor Y\" controls make it possible to create a looping effect that wraps the Point locator on each axis of motion so it stays within a range of 0 to (one less than the Divisor value).</p> <p></p> <p>vPointMultiply</p> <p>Returns the product of two Fusion Point objects</p> <p>This node can be used to apply a scale enlargement effect to the origin of the 1<sup>st</sup> point by the 2<sup>nd</sup> point's displacement distance.</p> <p></p> <p>vPointSubtract</p> <p>Returns the difference of two Fusion Point objects</p> <p>This node can be used to apply a negative offset to the origin of the 1<sup>st</sup> point by the 2<sup>nd</sup> point's displacement distance.</p> <p></p> <p>vPointAngle</p> <p>Measure the angle in degrees between two Fusion Point objects</p> <p>The output from this node is a Number datatype that reports the angle between Point1 and Point2.</p> <p></p> <p>vPointLength</p> <p>Measure the distance between two Fusion Point objects</p> <p>The output from this node is a Number datatype that reports the distance between Point1 and Point2.</p> <p></p> <p>If you have an image loaded in the viewer window, and then select the vPointLength node to edit its attributes in the Inspector tab, you will see the Point1 and Point2 locator handle overlays onscreen.</p> <p></p> <p>vPointSwitch</p> <p>Switch between Fusion Point objects</p> <p></p> <p>vPointWireless</p> <p>The vPointWireless node allows you to connect to other 2D Point datatype based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#scriptval-nodes","title":"ScriptVal Nodes","text":"<p>ScriptVal Nodes</p> <p>vScriptValCreate</p> <p>Create a Fusion ScriptVal object</p> <p>The ScriptVal datatype in Fusion is used to pass Lua tables that hold arbitrary data between nodes. This makes it possible to create custom c-code struct like records that travel through the node graph in a seamless fashion.</p> <p>An example of Lua table formatted information is:</p> <pre><code>{\n    num = 3.14,\n    foo = \"Hello\",\n    snafu = {\n        tarfu = \"Fuse\",\n    },\n    bar = \"World\",\n}\n</code></pre> <p></p> <p>vScriptValFromApp</p> <p>Create a Fusion ScriptVal object from the Resolve/Fusion application and comp UserData</p> <p>This node explores the output from Resolve() and Fusion(), along with the current composition attributes via GetAttrs(). The result of this process is a very detailed memory dump of the active parameters users typically interface with.</p> <p>In Resolve it is possible to see a report of the Project Manager, Project, Media Pool, Clips, Folders, Markers, and Timelines.</p> <p></p> <p>Sample \"vScriptValFromApp\" output from Fusion Studio:</p> <p></p> <p>Sample \"vScriptValFromApp\" output from Resolve Studio:</p> <p></p> <p>vScriptValFromArray</p> <p>Casts a JSON array into a ScriptVal object</p> <p>This node takes a Text datatype based JSON array as the input which is translated into a ScriptVal based output.</p> <p>The \"Sort List\" checkbox will alphabetically sort the Lua table formatted results generated by the node.</p> <p></p> <p>vScriptValToArray</p> <p>Casts a ScriptVal object into a JSON array</p> <p>This node takes a ScriptVal datatype as the input which is translated into a Text based JSON array output.</p> <p></p> <p>vScriptValFromDate</p> <p>Create a Fusion ScriptVal object from the Lua os.date() table output</p> <p></p> <p>vScriptValFromListFiles</p> <p>Create a Fusion ScriptVal object from a bmd.readdir() listing of files</p> <p></p> <p>vScriptValFromListFonts</p> <p>Create a Fusion ScriptVal object from a listing of fonts</p> <p>Sample output from the \"vScriptValFromListFonts\" node when formatted as text based Lua table output looks like:</p> <pre><code>{\n    \"Academy Engraved LET\",\n    \"Al Bayan\",\n    \"Al Nile\",\n    \"Al Tarikh\",\n    \"American Typewriter\",\n    \"Andale Mono\",\n    \"Apple Braille\",\n    \"Apple Chancery\",\n    \"Apple SD Gothic Neo\",\n    \"Apple Symbols\",\n    \"AppleGothic\",\n    \"AppleMyungjo\",\n    \"Arial\",\n    \"Arial Black\",\n    \"...\",\n}\n</code></pre> <p></p> <p>vScriptValFontMetrics</p> <p>Return font measurements as a Fusion ScriptVal object</p> <p>Sample output from the \"vScriptValFontMetrics\" node when formatted as text based Lua table output looks like:</p> <pre><code>{\n    FontMetrics = {\n        TypeName = \"TextStyleFontMetrics\",\n        CharWidthAverage = 0,\n        UnderlineThickness = 123,\n        TextExternalLeading = 0,\n        TextInternalLeading = 0.0232686980609418,\n        TypeNamePtr = \"TextStyleFontMetrics*\",\n        TextDescent = 0.0175623268698061,\n        Scale = 3610,\n        TextAscent = 0.0624376731301939,\n        FontSize = 0.1,\n        CharWidthSpace = 0.0189196675900277\n    },\n    Font = \"Arial Black\",\n    Text = \"Hello\",\n    Style = \"Regular\",\n    Size = 0.1\n}\n</code></pre> <p></p> <p>vScriptValFromEXRFile</p> <p>Convert OpenEXR header, part, and channel data into a ScriptVal</p> <p>This node is useful for generating a listing of the channel and part data from an EXR image without having to load the pixel data into a frame buffer.</p> <p>Sample output from the \"vScriptValFromEXRFile\" node when formatted as text based Lua table output looks like:</p> <pre><code>{\n    Source = \"/Volumes/Farm/Houdini Karma.exr\",\n    Filename = \"Houdini Karma.exr\"\n    Ext = \".exr\",\n    Type = \"EXRPart\",\n    Parts = {\n     {\n         Name = \"C\",\n         Width = 3840,\n         Height = 1600,\n         PixelAspectRatio = 1,\n         CenterX = 0,\n         CenterY = 0,\n         Channels = {\n             {\n                 XSampling = 1,\n                 YSampling = 1,\n                 PLinear = false,\n                 Name = \"A\",\n                 Type = 1\n             },\n             {\n                 XSampling = 1,\n                 YSampling = 1,\n                 PLinear = false,\n                 Name = \"B\",\n                 Type = 1\n             },\n             {\n                 XSampling = 1,\n                 YSampling = 1,\n                 PLinear = false,\n                 Name = \"G\",\n                 Type = 1\n             },\n             {\n                 XSampling = 1,\n                 YSampling = 1,\n                 PLinear = false,\n                 Name = \"R\",\n                 Type = 1\n             }\n         }\n     },\n    },\n}\n</code></pre> <p></p> <p>vScriptValFromMetadata</p> <p>Casts image metadata to a Fusion ScriptVal object</p> <p>This node takes an image as the input. The output is the image metadata encoded in a ScriptVal object format.</p> <p></p> <p>vScriptValToMetadata</p> <p>Creates a Fusion image with metadata added from a ScriptVal object</p> <p>This node has two input connections which are used for connecting an image and a ScriptVal data type. The output from the node is the image with metadata added.</p> <p></p> <p>vScriptValFromPoint</p> <p>Creates a ScriptVal from a point</p> <p>The ScriptVal formatted Lua table output of an X/Y 2D Point looks like this:</p> <pre><code>{\n    0.5,\n    0.5\n}\n</code></pre> <p></p> <p>vScriptValToPoint</p> <p>Return a Fusion Point object from a ScriptVal</p> <p></p> <p>vScriptValFromPingHosts</p> <p>Create a Fusion ScriptVal object from a Fusion ping hosts subnet scan</p> <p></p> <p>vScriptValFromPrefs</p> <p>Create a Fusion ScriptVal object from the Fusion preferences</p> <p>The ScriptVal formatted Lua table output looks like this:</p> <pre><code>{\n    {\n     Platform = \"Windows\",\n     Version = \"18.0\",\n     Hosts = {\n         \"FusionServer\",\n         \"Fusion\",\n         \"Fusion\",\n         \"Fusion\"\n     },\n     HostName = \"R1\",\n     IP = \"10.20.30.1\",\n     UserName = \"R1$\"\n    },\n}\n</code></pre> <p></p> <p>vScriptValFromRegistry</p> <p>Create a Fusion ScriptVal object from the Fusion registry</p> <p></p> <p>vScriptValFromXML</p> <p>Creates a ScriptVal object from XML</p> <p>This node accepts a text based input in an XML format. The result is translated into a ScriptVal object on the output.</p> <p></p> <p>vScriptValFromCustomData</p> <p>Create a Fusion ScriptVal object from Custom Data</p> <p>The \"Text\" control is used to specify the key used for the CustomData record. CustomData entries use a dot syntax for the hierarchy. If you define a lower level name it will return the full Lua table structure with multiple preference items at the same time.</p> <p>The \"Context\" control reads the CustomData from either the Fusion scope, or the Comp scope.</p> <p></p> <p>Fusion Scope</p> <p>The Fusion scope CustomData entries are stored on disk at the PathMap location of:</p> <p><code>Profiles:/Default/Fusion.prefs</code></p> <p>In the \"Fusion.pref\" file Lua table, the Fusion scope CustomData entries are found under:</p> <pre><code>Global.Script.GlobalData = {}\n</code></pre> <p>Using Lua you can save a CustomData setting into Fusion:</p> <pre><code>-- Fusion Scope\nfusion:SetData(\"Vonk.Version\", 1)\n</code></pre> <p>Comp Scope</p> <p>When using Comp scope CustomData entries, this is what the Lua table formatted CustomData records look like in a .comp file:</p> <pre><code>Composition {\n    CustomData = {\n        Vonk = {\n            Date = {\n                hour = 18,\n                min = 39,\n                wday = 7,\n                day = 24,\n                month = 9,\n                yday = 267,\n                sec = 44,\n                year = 2022,\n                isdst = true\n            },\n            Version = 1,\n            UUID = \"86cb495e-36ea-43eb-8761-7e27cf7ea947\"\n        }\n    },\n}\n</code></pre> <p>Using Lua you can save a CustomData setting into a comp:</p> <pre><code>-- Comp Scope\ncomp:SetData(\"Vonk.Version\", 1)\n</code></pre> <p>vScriptValToCustomData</p> <p>Save a Fusion ScriptVal object to Custom Data</p> <p>The \"Text\" control is used to specify the key used for the CustomData record. CustomData entries use a dot syntax for the hierarchy. If you define a lower level name it will return the full Lua table structure with multiple preference items at the same time.</p> <p>The \"Context\" control writes the CustomData to either the Fusion scope, or the Comp scope.</p> <p></p> <p>vScriptValFromFile</p> <p>Reads a Fusion ScriptVal object from a file</p> <p>This node reads a text formatted version of a Lua table structure from disk. The result is translated into a ScriptVal object on the output.</p> <p></p> <p>vScriptValToFile</p> <p>Writes a Fusion ScriptVal object to a file</p> <p>This node writes a text formatted version of a Lua table structure to disk.</p> <p></p> <p>vScriptValFromText</p> <p>Convert a Fusion Text object into a ScriptVal</p> <p>This node expects a text formatted version of a Lua table structure as the input. The result is translated into a ScriptVal object on the output.</p> <p></p> <p>vScriptValFromBinaryFile</p> <p>Reads a Fusion ScriptVal blob encoded object from a binary file</p> <p>The binary file data is Base64 encoded and placed in a Lua table structure. A sample output from this encoding process looks like:</p> <pre><code>{\n    Base64 = \"SGVsbG8gV29ybGQh\",\n    Base64Size = 16,\n    BinarySize = 12,\n    Ext = \".txt\",\n    Filename = \"Hello.txt\"\n    Source = \"/Users/vfx/Desktop/Hello.txt\",\n    Type = \"File\",\n}\n</code></pre> <p></p> <p>vScriptValToBinaryFile</p> <p>Writes a Fusion ScriptVal blob encoded object to a binary file</p> <p></p> <p>vScriptValFromJSON</p> <p>Casts JSON text into a ScriptVal object</p> <p>This node takes a Text datatype based JSON as the input which is translated into a ScriptVal datatype based output.</p> <p>The \"Sort List\" checkbox will alphabetically sort the Lua table formatted results generated by the node.</p> <p></p> <p>vScriptValToJSON</p> <p>Casts a ScriptVal object into JSON text</p> <p>This node takes a ScriptVal datatype as the input which is translated into a JSON Text datatype based output.</p> <p>The \"Sort List\" checkbox will alphabetically sort the Lua table formatted results generated by the node.</p> <p></p> <p>vScriptValToText</p> <p>Convert a Fusion ScriptVal object into Text</p> <p>The Text based multi-line output from this node can be displayed in the Inspector view with the vTextViewer node.</p> <p></p> <p>vScriptValGetToText</p> <p>Gets the value of a ScriptVal key</p> <p></p> <p>vScriptValGetElementToText</p> <p>Gets an element from a ScriptVal array</p> <p>An example of array like elements in a Lua table would look like this:</p> <pre><code>{\n    \"1\",\n    \"2\",\n    \"3\",\n    \"4\",\n    \"5\",\n    \"6\",\n    \"7\",\n    \"8\",\n    \"9\",\n    \"10\",\n}\n</code></pre> <p>The \"Index\" control is used to access individual entries from a ScriptVal array like object. The first item is accessed at Index position 1.</p> <p>The output from the vScriptValGetElementToText node is a text based data type. It is possible to translate the text based output from this node into numerical values via the vNumberFromText node.</p> <p></p> <p>vScriptValGetToNumber</p> <p>Gets the value of a ScriptVal key as a Fusion Number</p> <p>The output from the vScriptValGetToNumber node is a Number based data type that can be used to drive number based controls in the Inspector view like transforms, rotations, scale, angle, or other parameters. You can also use the Number based output from the vScriptValGetToNumber node to carry out further node-based math operations with nodes like vNumberAdd, vNumberSubtract, vNumberMultiply, vNumberDivide, etc..</p> <p></p> <p>vScriptValGetToTable</p> <p>Gets the value of a ScriptVal key as a table</p> <p>The output from the vScriptValGetToTable node is a ScriptVal based data type.</p> <p></p> <p>vScriptValGetElementToTable</p> <p>Gets an element from a ScriptVal array as a table</p> <p>The \"Index\" control is used to access individual entries from a ScriptVal array like object. The first item is accessed at Index position 1.</p> <p>The output from the vScriptValGetElementToTable node is a ScriptVal based data type.</p> <p></p> <p>vScriptValKeysToText</p> <p>Returns the keys present in a ScriptVal object</p> <p></p> <p>vScriptValKeysToTable</p> <p>Returns the keys present in a ScriptVal object as a table</p> <p></p> <p>vScriptValToNumber</p> <p>Convert a Fusion ScriptVal object into a Number</p> <p></p> <p>vScriptValFromNumber</p> <p>Convert a Fusion Number object into a ScriptVal</p> <p></p> <p>vScriptValRemoveElement</p> <p>Removes an element from a ScriptVal array using its index position</p> <p></p> <p>vScriptValTrimElement</p> <p>Extract a range of elements from a ScriptVal array as a table</p> <p>This node is useful for creating animated vector graphics that are revealed over time when your 2D point data is encoded into a ScriptVal Lua table structure that represents a polyline shape.</p> <p></p> <p>vScriptValDoFile</p> <p>Return a ScriptVal object from running an external Lua script</p> <p></p> <p>vScriptValDoString</p> <p>Return a ScriptVal object from running a string of Lua code</p> <p>The ScriptVal based input connection on the node can be accessed in the script using a Lua table variable named \"tbl\".</p> <p>The ScriptVal based output connection on the node receives the data that is defined by the \"return\" command.</p> <p>The \"Script Header Wire\" input is used to specify a text datatype connection of code that is appended to the top of the Lua Script field contents when run. The script content connected to the Script Header Wire field is typically sourced from a vTextCreateMultiline or vTextFromFile node.</p> <p>The vScriptValMerge node can be used to combine multiple ScriptVal objects before they are passed into the vScriptValDoString node.</p> <p>In your Lua Script code you can iterate through each record in the Lua table data using:</p> <pre><code>for i, v in ipairs(tbl) do\nend\n</code></pre> <p>If you need to temporarily troubleshoot the internals of what your code is doing in the vScriptValDoString node there are two diagnostic checkbox controls labelled \"Show Code\" and \"Show Dump\". The output from those options is displayed in the Console window. For performance reasons you probably want to leave those options turned off most of the time when rendering long sequences in Fusion to reduce the Console logging overhead.</p> <p></p> <p>vScriptValCreatePolyline</p> <p>Create a polygon line shape from a ScriptVal based Lua table of XY point pairs</p> <p>An example of 2D point like elements in a Lua table would look like this:</p> <pre><code>{\n    {\n        0.382075787528567,\n        0.534720150858805\n    },\n    {\n        0.436349336750095,\n        0.490753326992875\n    },\n    {\n        0.486955559603984,\n        0.440547877640415\n    },\n    {\n        0.531495059415565,\n        0.386469304121596\n    },\n    {\n        0.568050230127849,\n        0.331244047492371\n    },\n    {\n        0.595285357663032,\n        0.277804252649087\n    },\n    {\n        0.612508622697929,\n        0.229116724236359\n    },\n    {\n        0.619692622456641,\n        0.188006456120492\n    }\n}\n</code></pre> <p></p> <p>vScriptValAccumulator</p> <p>Temporally concatenateScriptVal elements into one table</p> <p></p> <p>This node can be thought of as a ScriptVal based merge node that works across a time range. It can be used to create Lua Table based array elements that are built over time from dynamically generated tables of data.</p> <p>The \"Start Frame\" control will often be driven by a vNumberCompRenderStart or vNumberCompGlobalStart node.</p> <p>The \"End Frame\" control will often be driven by a vNumberCompRenderEnd or vNumberCompGlobalEnd node.</p> <p>The \"Step\" control allows for frame skipping to occur.</p> <p>The \"Sort List\" checkbox works on a line-by-line basis to alphabetically sort the results generated by the node.</p> <p>If you want to stop a vScriptValAccumulator node from re-rendering on subsequent frames in the Fusion timeline, you can add a \"vScriptValTimeSpeed\" node right afterwards and set the Speed to 0 and the Delay to 0.</p> <p>The data combined together by a vScriptValAccumulator node can be separated again into individual items using the vScriptValGetElementToTable node.</p> <p>vScriptValTimeSpeed</p> <p>Time based operation on ScriptVal objects</p> <p></p> <p>vScriptValTimeStretch</p> <p>Time based operation on ScriptVal objects</p> <p></p> <p>vScriptValCount</p> <p>Count the number of items in a Fusion ScriptVal object</p> <p>This node returns a number data type that indicates how many array elements exist at this level in a ScriptVal hierarchy. This return value could be used to drive a vTextAccumulator node's EndFrame attribute if you wanted to increment through each of the array elements.</p> <p></p> <p>vScriptValDump</p> <p>Dump the contents of a Fusion ScriptVal object to the Console</p> <p></p> <p>vScriptValMerge</p> <p>Dynamically join ScriptVal elements into one table</p> <p></p> <p>vScriptValFromYAML</p> <p>Casts YAML text into a ScriptVal object</p> <p>Technology Note: YAML is used as part of Film &amp; TV production lens metadata workflows by Cine lenses with sensors and encoders like the Cooke Optics /i Technology metadata system. YAML metadata exchange is also starting to be used by other Cine lens manufacturers, in match-moving and tracking packages like SynthEyes and PFTrack, and as part of data exchange approaches like OpenTimelineIO, too.</p> <p>Blackmagic BRAW media filmed on a BMD URSA Mini Pro 12K camera with a Cooke Optics PL-mount lens is capable of holding this YAML metadata recorded lens information internally. This is useful for supporting better data interchange between VP (Virtual Production) onset ICVFX (In-Camera VFX) departments and subsequent post-production workflows carried out by external vendors.</p> <p></p> <p>vScriptValSwitch</p> <p>Switch between Fusion ScriptVal objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a vScriptValSwitch node's Which input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p> <p>vScriptValWireless</p> <p>Wirelessly link to ScriptVal nodes</p> <p>The vScriptValWireless node allows you to connect to other ScriptVal based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#shape-tree-nodes","title":"Shape Tree Nodes","text":"<p>Shape Tree Nodes</p> <p>vShapeSwitch</p> <p>Switch between Fusion ShapeTree objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a vShapeSwitch node's Which input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p> <p>Note: A Fusion ShapeTree datatype accessibility bug was reported to BMD at the end of July 2022. This bug affects the usability of all ShapeTree based fuses in Fusion v17-v18.0.x. Hopefully a bugfix from BMD will solve an issue where a connected sRender nodes' input is rendered as a transparent canvas if a Fuse is placed upstream in the toolchain.</p> <p>vShapeWireless</p> <p>Create wireless links to Fusion ShapeTree objects</p> <p>The vShapeWireless node allows you to connect to other shape based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p>Note: A Fusion ShapeTree datatype accessibility bug was reported to BMD at the end of July 2022. This bug affects the usability of all ShapeTree based fuses in Fusion v17-v18.0.x. Hopefully a bugfix from BMD will solve an issue where a connected sRender nodes' input is rendered as a transparent canvas if a Fuse is placed upstream in the toolchain.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#json-nodes","title":"JSON Nodes","text":"<p>JSON Nodes</p> <p>vJSONToFile</p> <p>Writes a JSON string into a file</p> <p>The \"File\" text field is used to specify the filename of the JSON document to be written to disk.</p> <p>The JSON file will be saved when the node is viewed/rendered. The contents of the JSON file is sourced from the text based input connection on the node.</p> <p></p> <p>vJSONFromNet</p> <p>Reads a JSON string from a network URL</p> <p>The network-based JSON resource downloading functionality provided by this node makes it possible to drive a composite from an external cloud based datasource.</p> <p>This means IoT (Internet of Things) electronic sensors, sports statistics, financial data, or any other web enabled datasource can be used on-the-fly to supply Text, Number, Matrix, Array, or other values to nodes in the comp.</p> <p></p> <p>vJSONFromFile</p> <p>Reads a JSON string from a file</p> <p>The \"Input\" text field is used to specify the disk-based filename of the JSON document to be read.</p> <p>The JSON file will be loaded when the node is viewed/rendered. The contents of the JSON file is returned via a text based data type output connection on the node.</p> <p></p> <p>vJSONGet</p> <p>Gets the value of a JSON key</p> <p>The \"Key\" text-field is used to select and isolate a specific entry from a JSON file.</p> <p>The output from the vJSONGet node is a text based data type.</p> <p>You can stack several vJSONGet nodes in a row to browse upwards in the hierarchy of a nested JSON structure.</p> <p>It is possible to translate this text based output from this node into numerical values via the vNumberFromText node. This is a useful step if you want to perform math operations downstream of this node, or if you need to connect a numerical value to an Inspector based attribute on another node.</p> <p></p> <p>vJSONGetElement</p> <p>Gets the element of a JSON array</p> <p>The \"Index\" control is used to access individual entries from a JSON array type of object.</p> <p>The node expects a text based JSON array object as the input.</p> <p>The output from the vJSONGetElement node is a text based data type. It is possible to translate the text based output from this node into numerical values via the vNumberFromText node.</p> <p>The first item is accessed at Index position 1.</p> <p></p> <p>vJSONSet</p> <p>Sets a new key value pair in a JSON table</p> <p>The \"Key\" text-field lets you enter the name of the JSON element to be modified/inserted. The 2<sup>nd</sup> text field is used for the \"Value\" field which holds the actual data you want to store.</p> <p>The vJSONSet node makes it possible to create new JSON data structures that can be saved to disk using a vJSONToFile node.</p> <p></p> <p>vJSONCountElement</p> <p>Counts the elements in a JSON array</p> <p>The node expects a text based JSON array object as the input.</p> <p>This node returns a number data type that indicates how many array elements exist at this level in a JSON hierarchy. This return value could be used to drive a vTextAccumulator node's EndFrame attribute if you wanted to increment through each of the array elements.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#text-nodes","title":"Text Nodes","text":"<p>Text Nodes</p> <p>vTextAccumulator</p> <p>Temporally concatenates a text string over a frame range</p> <p>This node can be thought of as a text based merge node that works across a time range. It can be used to create IFL (image file lists) or other types of results that are built over time by dynamically generated strings of text.</p> <p>The \"Start Frame\" control will often be driven by a vNumberCompRenderStart or vNumberCompGlobalStart node.</p> <p>The \"End Frame\" control will often be driven by a vNumberCompRenderEnd or vNumberCompGlobalEnd node.</p> <p>The \"Step\" control allows for frame skipping to occur.</p> <p>The \"Separator\" text field is used to define the character placed between each text element that is concatenated (merged) together. You might want to use a separator like a space, a comma, a semicolon, or a newline (\\n), return (\\r), or a tab (\\t).</p> <p>The \"Sort List\" checkbox works on a line-by-line basis to alphabetically sort the results generated by the node.</p> <p>The \"Remove Duplicates\" checkbox can be used to remove any lines that have an identical output that pre-exists in the results.</p> <p>The counterpoint to the vTextAccumulator node is the vTextReadLine node that can break apart a multi-line text block into single line elements.</p> <p>If you want to stop a vTextAccumulator node from re-rendering on subsequent frames in the Fusion timeline, you can add a \"vTextTimeSpeed\" node right afterwards and set the Speed to 0 and the Delay to 0.</p> <p></p> <p>vTextTimeSpeed</p> <p>Time based operation on text</p> <p></p> <p>vTextTimeStretch</p> <p>Time based operation on text</p> <p></p> <p>vTextOrderShuffle</p> <p>Shuffles the order of a Fusion Text object</p> <p>The \"Text\" field contents will be output with a randomized order. This is done using an approach known as a Fisher--Yates shuffle.</p> <p>If you typed in \"Hello Shuffle World!\" the output would be \"Wdool uhSffod rlHoe!\".</p> <p></p> <p>vTextOrderReverse</p> <p>Reverses the order of a Fusion Text object</p> <p>The \"Text\" field contents will be output letter-by-letter in a right-to-left mirrored fashion that reverses the text's placement.</p> <p>If you typed in \"Hello Shuffle World!\" the output would be \"!dlroW elffuhS olleH\".</p> <p></p> <p>vTextResolvePID</p> <p>Returns the Resolve/Fusion PID (Process ID)</p> <p>A PID value is an integer style number that is used by the operating system to track a running executable.</p> <p>Often PID values are the identifier used to tell an external program to gracefully quit. A PID number can also be used by the \"renice\" terminal utility to help balance the compute load on a system by scaling back the resource hogging level of a single dominant program that is reducing the overall interactivity of the host computer.</p> <p></p> <p>vTextResolveProjectName</p> <p>Returns the current Resolve project name</p> <p>This node outputs a Text based string that holds the name of the current Resolve editing project as listed in the Resolve \"Project Manager\" window.</p> <p></p> <p>vTextToFile</p> <p>Writes a Text string to a file</p> <p>The \"Input\" text-field holds the textual content that is saved to disk.</p> <p>The \"File\" text-field specifies the filename for the document.</p> <p>Both of these controls can be driven externally by enabling the \"Show Input\" checkbox. You would then connect vTextCreate or vTextSubFormat like text based data nodes to the input connections on the vTextToFile node.</p> <p></p> <p>vTextFromZip</p> <p>Reads a Text string from a zip archive</p> <p>This node accesses a plain-text formatted resource that is stored inside a Zip archive using the Fusion v16+/Resolve v15+ based ZipIO library.</p> <p>The \"Zip File\" field is used to define the filename of the zip archive.</p> <p>The \"Extract File\" field is used to define the resource that is stored inside the zip archive.</p> <p>Both attributes can be driven externally by a Text data type connection to the node.</p> <p></p> <p>vTextFromNet</p> <p>Reads a Text string from a network URL</p> <p>The \"Input\" text-field is used to supply the http://, https://, or file:// based URL.</p> <p>The network-based text resource downloading functionality provided by this node makes it possible to drive a composite from an external cloud based datasource like a CSV (Comma Separated Value), TSV (Tab Separated Value), SVG (Scalable Vector Graphics), Fusion Macro .setting, Fusion .comp, etc.</p> <p>This means IoT (Internet of Things) electronic sensors, sports statistics, financial data, or any other web enabled datasource can be used on-the-fly to supply Text, Number, Matrix, Array, or other values to nodes in the comp.</p> <p></p> <p>vTextFromComp</p> <p>Reads text strings from a Fusion .comp file</p> <p>This node tunnels inside of an external Fusion .comp file on disk and extracts string elements. These text strings are typically filepaths.</p> <p>The \"File\" text field specifies which .comp file should be parsed.</p> <p>The \"Match\" text field helps sort the content returned to filter the results.</p> <p>The \"File Exists\" checkbox lets you further filter the results by looking on disk to see if the text string lines up with an actual file that exists.</p> <p>The \"Expand PathMaps\" checkbox will automatically convert any relative filepaths into absolute filepaths on the output.</p> <p>The \"Sort List\" checkbox works on a line-by-line basis to alphabetically sort the results generated by the node.</p> <p>The \"Remove Duplicates\" checkbox is used to remove any line entry that is a duplicate entry, meaning the content is not unique.</p> <p></p> <p>vTextFromFile</p> <p>Reads a Text string from a file</p> <p>This node is used to access a block of text from a plain-text format style of document stored on disk. This is useful for accessing CSV (Comma Separated Value), TSV (Tab Separated Value), IFL (Image File Lists), or other external data resources.</p> <p>The \"Input\" text field is used to specify the disk-based filename of the plain-text document to be read.</p> <p>The \"Remove Non-Printable Characters\" checkbox is used to remove ASCII invisible control characters from the text stream. This allows the node to be used to extract ASCII strings from binary files.</p> <p>The output from this node is a text data type.</p> <p></p> <p>vTextFromClipboard</p> <p>Grabs the current clipboard text</p> <p>The \"Sort List\" checkbox works on a line-by-line basis to alphabetically sort the results generated by the node.</p> <p>The \"Remove Quotes\" checkbox is used to strip out any quote symbols found in the clipboard text. This is useful if you are trying to make an IFL like list and the source text was added to the clipboard buffer using the Windows \"File Explorer\" right-click based \"Copy as path\" contextual menu item.</p> <p>This node works on Windows, macOS, and Linux.</p> <p></p> <p>vTextNotEqual</p> <p>Compares two strings to see if they are not equal</p> <p>The result is a false/true based number result of 0-1.</p> <p></p> <p>vTextEqual</p> <p>Compares two strings to see if they are equal</p> <p>The result is a false/true based number result of 0-1.</p> <p></p> <p>vTextTernary</p> <p>Compare a value and return one of two possible strings as the result</p> <p></p> <p>vTextEncodeUrl</p> <p>URL-encodes a Fusion Text object</p> <p></p> <p>vTextCompName</p> <p>Returns the name of the comp</p> <p>An example output from this node would be the base filename for the currently open .comp file like: \"Demo Text.comp\"</p> <p>If the currently open composite is an unsaved document the node would output a string like:</p> <p>\"Composition1\"</p> <p></p> <p>vTextCompCurrentTime</p> <p>Returns the comp's current time value</p> <p>The current time represents the point where the timeline playhead is positioned regardless of any temporal effects that might be happening.</p> <p></p> <p>vTextCompFilename</p> <p>Returns the full path of a comp</p> <p>An example output from this node would be an absolute filepath based string like:</p> <p>\"C:/ProgramData/Blackmagic Design/Fusion/Reactor/Deploy/Comps/Kartaverse/Vonk Ultra/Demo Text/Demo Text.comp\"</p> <p></p> <p>vTextCompReqTime</p> <p>Returns the comp's request time</p> <p>This is the currently requested frame that is being processed at render time. It supports temporal effects like the vTextAccumulate node that iterates over a frame duration.</p> <p></p> <p>vTextCompAppUUID</p> <p>Returns the Fusion application process UUID</p> <p>A UUID value is formatted like: 11625315-7785-4eb4-8b2f-d6dca235c42</p> <p>This node is powered by the Lua function \"bmd.getappuuid()\".</p> <p></p> <p>vTextDoString</p> <p>Return a Text object from running a string of Lua code</p> <p>The node automatically creates new text input connections as needed.</p> <p>The text based input data can be accessed in the script using a Lua table variable named \"tbl\".</p> <p>The text based output connection on the node receives the data that is defined by the \"return\" command.</p> <p>The \"Script Header Wire\" input is used to specify a text datatype connection of code that is appended to the top of the Lua Script field contents when run. The script content connected to the Script Header Wire field is typically sourced from a vTextCreateMultiline or vTextFromFile node.</p> <p>In your Lua Script code you can iterate through each record in the Lua table data using:</p> <pre><code>for i, v in ipairs(tbl) do\nend\n</code></pre> <p>If you need to temporarily troubleshoot the internals of what your code is doing in the vTextDoString node there are two diagnostic checkbox controls labelled \"Show Code\" and \"Show Dump\". The output from those options is displayed in the Console window. For performance reasons you probably want to leave those options turned off most of the time when rendering long sequences in Fusion to reduce the Console logging overhead.</p> <p></p> <p>vTextRunScript</p> <p>Runs an external Lua script</p> <p>The \"File\" text-field is used to specify an external .lua script file.</p> <p>This node is powered by the Lua \"<code>dofile()</code>\" function.</p> <p>Note: This node is effectively deprecated please use vTextDoString Instead.</p> <p></p> <p>vTextShellBG</p> <p>Launch a command-line shell task in the background via <code>bmd.executebg()</code></p> <p>The \"Wait\" checkbox can be used to make the node act in a blocking fashion that will pause the rendering of this branch of the comp until the launched process has completed and exited.</p> <p></p> <p>Note: Make sure to write in the absolute filepath for the executable program you want to run. You can discover this by typing \"which SomeProgramName\" into the Terminal window on macOS/Linux:</p> <pre><code>which open\n/usr/bin/open\n</code></pre> <p>Also, the vTextShellBG node is used to launch a program with its command line arguments specified. It is not a full terminal environment so shell redirection approaches and expanding environment variable tokens in the command string are not supported. If you need those extended command line scripting features, write out a temporary .bat/.sh/.command file to disk then use vTextShellBG to run the script.</p> <p>vTextSlashCommand</p> <p>Run a Console Fuse SlashCommand as a node</p> <p>A SlashCommand is a type of Lua or Python script in Fusion that is normally launched from the Console window by prefacing a command with a leading \"/\" character.</p> <p></p> <p>SlashCommand Examples:</p> <pre><code>/for (selected|visible|all) [tooltype[,tooltype...]] [where &lt;condition&gt;] &lt;command&gt; [ &amp; &lt;command&gt;...]\nSupported commands:\n    animate &lt;input&gt; [(with &lt;modifier&gt;|remove)] [force]\n    color [tile &lt;color&gt;] [text &lt;color&gt;] [fill &lt;color&gt;]\n    select [(add|remove)]\n    set &lt;input&gt; ([at &lt;time&gt;] to &lt;value&gt;|expression &lt;exp&gt;)\n\n/footage list\n</code></pre> <p>Check out the Vonk Node Cookbook topic \"SlashCommands\" for more details about features and usage.</p> <p>vTextDoAction</p> <p>Executes Fusion actions</p> <p>The \"Action Name\" text field is where the action you want to run is entered.</p> <p>The \"Action Params\" text field contents are placed inside a Lua table like element {}. This information is used to specify any extra attributes you would like to pass along to the action when it is run.</p> <p>The \"Wrap Lines\" checkbox makes it possible to enable/disable line wrapping in the text preview area.</p> <p></p> <p>DoAction is launched via the \"self.Comp:Execute()\" function so it is run asynchronously.</p> <p>The Action Listener script provided by the Reactor Package manager's \"UI Manager Lua &amp; Python Examples\" atom package for Fusion/Resolve is a great way to see actions at work from inside of your compositing application. It's possible to print out a list of the actions present inside of Fusion with the handy \"Action Printout\" script.</p> <p>If you want to peek into the Actions that are connected to the default hotkeys in Fusion take a look at the \"The Ultimate Listicle of Actions and Hotkeys\" post on the WSL forum.</p> <p>The standard actions available in Resolve's Fusion page include:</p> <pre><code>Bin_New_Reel\nBin_New_Folder\nBin_New_Item\nBin_Icon_Size\nBin_Show_Checker\nBin_View_Mode\nEffects_ShowSearch\nEffects_Search\nFlow_Add_Bookmark\nFlow_Go_To_Bookmark\nFlow_Manage_Bookmarks\nGraphView_ZoomToFit\nGraphView_SortMenu\nGraphView_ZoomX\nKeyframeView_ZoomY\nGraphView_ZoomY\nPlayer_Item_Next\nPlayer_Item_Prev\nPlayer_Play\nPlayer_Play_Forward\nPlayer_Play_Reverse\nPlayer_Seek_By\nPlayer_Seek_To\nPlayer_Seek_Start\nPlayer_Seek_End\nPlayer_Seek_Prev\nPlayer_Seek_Next\nPlayer_Set_Loop\nPlayer_Trim_Set_In\nPlayer_Trim_Set_Out\nPlayer_Gamma\nPlayer_Gain\nPlayer_Set_FPS\nPlayer_Set_Time\nPlayer_Guide_Enable\nPlayer_Guide_Select\nPlayer_Channel\nPlayer_Show_Metadata\nPlayer_Sync_Mode\nPlayer_Loop_Set_In\nPlayer_Loop_Set_Out\nPlayer_Loop_Reset\nPlayer_Loop_Set_Shot\nPlayer_Device_DeckLink\nFusion_Screen_Mode\nFusion_View_Show\nFusion_Zone_Expand\nFusion_Time_Set\nFusion_Time_Get\nACTION_GET_TEMPLATES_LIST\nACTION_GET_UI_LAYOUT\nACTION_SET_UI_LAYOUT\nACTION_SHOW_CONSOLE\nACTION_PRINT_CONSOLE\nACTION_CLOSE_COMP\nACTION_INSTALL_FILE\nNo_Action\nViewer_Checker_Enable\nViewer_ROI_Enable\nViewer_ROI_Auto\nViewer_ROI_Lock\nViewer_ROI_Set\nViewer_ROI_Reset\nViewer_DOD_Enable\nViewer_3D_Lighting\nViewer_3D_Wireframe\nViewer_3D_Solid\nViewer_3D_Lights\nViewer_3D_Shadows\nViewer_3D_Transparency\nFrame_Activate_SubWnd\nFrame_Activate_Frame\nFrame_Activate_Next\nFrame_Activate_Prev\nComp_Choose_Tool\nComp_Choose_Action\nExecute\nComp_New\nComp_Open\nComp_Save\nComp_SaveVersion\nAddTool\nAddLUT\nRunScript\nAddSetting\nLayout_Switch\nPrefs_Show\nApp_Exit\nComp_BackgroundRender\nComp_Undo\nComp_Redo\nComp_ShowTimeCode\nComp_TimeCodeFormat\nApp_About\nApp_NewImageView\nComp_NewTabbedFrame\nComp_NewFloatFrame\nApp_Help\nApp_OnlyActiveComp\nApp_ShowUI\nApp_CustomizeToolBars\nApp_CustomizeHotkeys\nApp_Cut\nApp_Copy\nApp_Paste\nApp_Delete\nApp_SelectAll\nApp_DeselectAll\nApp_PasteSettings\nView_Show\nComp_Close\nComp_SaveAs\nComp_SaveCopyAs\nScript_Edit\nLayout_Load\nLayout_Save\nLayout_Reset\nComp_Recent_Open\nComp_Recent_Clear\nUtility_Show\nTool_ViewOn\nTool_ViewClear\nBins_Play\nBins_Stop\nBins_Delete\nBins_Rename\nBins_Refresh\nBins_SelectAll\nTime_Step_Forward\nTime_Step_Back\nTime_Step_NextKey\nTime_Step_PrevKey\nTime_Goto_GlobalStart\nTime_Goto_GlobalEnd\nTime_Goto_RenderStart\nTime_Goto_RenderEnd\nTime_Set\nTool_Settings_Activate\nTool_Settings_Store\nViewer_SubView_Enable\nViewer_Lock\nViewer_QuadView\nViewer_Scale_Rel\nViewer_Scale_Abs\nViewer_Buffer\nViewer_Reset\nViewer_SubView_Swap\nViewer_Tools_Disable\nViewer_Unview_All\nViewer_LUT_Enable\nViewer_Show_GainGamma\nViewer_LUT_Edit\nViewer_Channel\nViewer_Guides_Show\nViewer_Controls_Show\nViewer_3D_CentreSelected\nViewer_3D_FitSelected\nViewer_3D_FitAll\nView_Zoom_In\nView_Zoom_Out\nView_Zoom_Fit\nView_Zoom_Rectangle\nTime_Goto_Key_Next\nTime_Goto_Key_Prev\nPlayback_Mode\nPlayback_Seek\nPlayback_Seek_Start\nPlayback_Seek_End\nNetRender_Allow\nComp_Render_Frame\nComp_Render_End\nComp_Activate_Tool\nComp_Set_Active\nComp_StartRender\nComp_Start_Render\nComp_Render\nComp_Abort\nComp_Opened\nDrag_Drop\nComp_High_Quality\nComp_Motion_Blur\nComp_Proxy\nComp_Auto_Proxy\nComp_Play_Loop\nComp_Play_PingPong\nReel_Delete_Selected\nTarget_Show_Menu\nTarget_Show_Scripts\nConsole_Show\nComp_Reset\nExpose_Tool_Name_Mode\n</code></pre> <p>vTextProcessOpen</p> <p>Launches a command-line process via popen</p> <p>The \"Text\" field is used to define the executable program name and the command-line arguments you want to run from a shell session. The output from the shell session is returned to the node's output connection as a text data type result.</p> <p>Typically a vTextSubFormat node is used to build the executable command line string that is supplied to the Text input on a vTextProcessOpen node. If you need cross-platform support you can use a vTextCreatePlatform or vTextCreatePlatformBrowse node to automatically define the per-OS specific elements like the program name to run.</p> <p>If you need to access more complex automation techniques, or dynamically define custom environment variables, it is possible to use a vTextToFile node to export a dynamically created .bat (Windows), .sh (Linux), .command (macOS) script file to the TEMP folder on disk. Then the vTextProcessOpen node could be used to execute this document by specifying in the \"Text\" field both the shell interpreter to use, like \"/bin/zsh\" or \"/bin/zsh\", and the external script file to run:</p> <p>\"Text\" field contents:</p> <pre><code>\"/bin/zsh\"  \"/tmp/Vonk_Temp_Script.command\"\n</code></pre> <p>\"Vonk_Temp_Script.command\" File Contents:</p> <pre><code>#!/bin/zsh\nsay Hello Vonk World!\n</code></pre> <p></p> <p>vTextRenderComp</p> <p>Launches a command-line Fusion Render Node based .comp or .dfq process via popen</p> <p>This node currently works on macOS and Linux. Windows support is a WIP task that is yet to be completed.</p> <p></p> <p>The Fusion composite specified in the \"Comp File\" field will be batch rendered in the background by the Fusion Render Node executable.</p> <p>The \"Render Mode\" control allows you to adjust how the composite will be rendered.</p> <p></p> <p>If \"Current Frame\" is selected, the parent comp's current frame will be passed to the Fusion Render Node program as the frame to render in the child comp.</p> <p>If \"Comp Frame Range\" is selected, the parent comp's Render Start - Render End frame range will be sent to the Fusion Render Node program as the frame range to render in the child comp.</p> <p>If \"Comp Frame Range\" is selected, the parent comp's Render Start - Render End frame range will be sent to the Fusion Render Node program as the frame range to render in the child comp.</p> <p>If \"Custom Frame Range\" is selected, a set of numerical input controls will be displayed. These controls allow you to manually drive the frame range used by the Fusion Render Node program on the fly.</p> <p></p> <p>The \"Render Node Version\" control allows you to choose the exact Fusion Render Node executable version number you would like to launch when the .comp file is rendered. This allows you the flexibility to target a different Fusion Render node release than you are using to run the GUI session inside of Fusion Studio.</p> <p>vTextExecute</p> <p>Executes code sourced from a Fusion Text object</p> <p>The \"Script Language\" control is used to define if you want to use Lua or Python code in the text input field. This code is executed asynchronously by the Fusion API function \"<code>self.Comp:Execute()</code>\".</p> <p>In the code block you can return a value from the executed script to the node graph with the function \"<code>OutText()</code>\". An example of that would be '<code>OutText(\"Hello World\")</code>'. The output from the vTextExcute node is a text based filepath that holds any results you might have written to disk using the function \"OutText()\".</p> <p></p> <p>vTextMerge</p> <p>Dynamically joins strings into one</p> <p>Merge together several strings that are connected to the node's text based input connections. The combined strings are joined with the addition of a user defined separator character.</p> <p></p> <p>vTextSubReplace</p> <p>Replaces substrings of a string</p> <p>The \"Pattern\" text field uses Lua Patterns to parse the string. Additional information about patterns can be read in the Lua manual.</p> <p>The 2<sup>nd</sup> text field represents the \"Replace\" text that will be substituted.</p> <p></p> <p>vTextSubFormat</p> <p>Formats a template string with input values</p> <p>Each input connection on the vTextSubFormat node can be placed exactly where it is needed using a token approach. A token value is entered using curly braces that surround an integer number like \"<code>{1}</code>\" or \"<code>{2}</code>\" that represent an input connection number on the node.</p> <p></p> <p>vTextSubFormatMultiline</p> <p>Formats a multi-line template string with input values</p> <p>Each input connection on the vTextSubFormat node can be placed exactly where it is needed using a token approach. A token value is entered using curly braces that surround an integer number like \"<code>{1}</code>\" or \"<code>{2}</code>\" that represent an input connection number on the node.</p> <p></p> <p>vTextSubJoin</p> <p>Dynamically joins strings into one</p> <p></p> <p>vTextSubReturn</p> <p>Returns a substring of a string</p> <p>This node is used to shorten a string by using the Start and End numeric fields to define the number of characters to remove.</p> <p>A positive number entered in the number input fields is used to define the removal of characters by starting the counting process at the left side of the input string. A negative number in the number input fields is used to define the removal of characters starting on the right side of the input string.</p> <p>This added complexity makes it easier to remove elements like a 3 letter file extension using the negative number input ability to trim off characters starting from the end (right side) of a variable length text string in a precise fashion.</p> <p></p> <p>vTextSubStripLeft</p> <p>Strips a leading substring of a string</p> <p>The \"Strip\" text field is used to define the text you would like to remove from the (left side) of the input text data that is connected to the node. This type of text editing would sometimes be called removing a leading prefix element from a string.</p> <p></p> <p>vTextSubStripRight</p> <p>Strips a trailing substring of a string</p> <p>The \"Strip\" text field is used to define the text you would like to remove from the (right side) of the input text data that is connected to the node. This type of text editing would sometimes be called removing a trailing postfix element from a string.</p> <p></p> <p>vTextSubSplit</p> <p>Returns a substring of a string</p> <p>The \"Pattern\" text field uses Lua Patterns to parse the string into a JSON like Array object. Additional information about patterns can be read in the Lua manual.</p> <p>The portion of the pattern you want to return should be placed inside a pair of parentheses characters \"(\" and \")\".</p> <p>If you wanted to return all of the characters from the input string you would use a Pattern of: <code>(.*)</code></p> <p>If you had a list of single word objects that were comma separated like: <code>Apple;Orange,Pear,Mango</code></p> <p>Then you could break the text down into individual objects using a Pattern of: <code>(%a+),-</code></p> <p>The output would be formatted as: <code>{\"size\":4,\"array\":[\"Apple\",\"Orange\",\"Pear\",\"Mango\"]}</code></p> <p>If you had a string with an IPv4 style IP address in it like \"192.168.1.1\", you could break the text down into individual digits groupings using a Pattern of: <code>(%d+)</code></p> <p>The output would be formatted as: <code>{\"size\":4,\"array\":[\"192\",\"168\",\"1\",\"1\"]}</code></p> <p></p> <p>vTextDecodeUrl</p> <p>URL-decodes a Fusion Text object</p> <p></p> <p>vTextCaseInvert</p> <p>Inverts the case of a Fusion Text object</p> <p>A Text based input of \"Hello World!\" would be converted to \"hELLO wORLD!\". Every uppercase letter in the output becomes lower case, and every lowercase letter becomes an uppercase letter.</p> <p></p> <p>vTextCaseSentence</p> <p>Converts the case of a Fusion Text object to sentence</p> <p>A Text based input of \"hello world!\" would be converted to \"Hello world!\" with the initial letter in each sentence having a capitalized letter.</p> <p></p> <p>vTextCaseAlternate</p> <p>Alternates the case of a Fusion Text object</p> <p>A Text based input of \"hello world!\" would be converted to \"hElLo wOrLd!\" where every 2<sup>nd</sup> letter is formatted as a capital letter.</p> <p></p> <p>vTextCaseLower</p> <p>Converts the case of a Fusion Text object to lower</p> <p>A Text based input of \"Hello World!\" would be converted to \"hello world!\".</p> <p></p> <p>vTextCaseTitle</p> <p>Converts the case of a Fusion Text object to title</p> <p>A Text based input of \"hello world!\" would be converted to \"Hello World!\".</p> <p></p> <p>vTextCaseRandom</p> <p>Changes the case of a Fusion Text object in a random fashion</p> <p>A Text based input of \"hello world!\" would be converted to an output like \"hellO WoRlD!\".</p> <p></p> <p>vTextCaseUpper</p> <p>Converts the case of a Fusion Text object to upper</p> <p>A Text based input of \"hello world!\" would be converted to \"HELLO WORLD!\".</p> <p></p> <p>vTextFontMetrics</p> <p>Return font measurements as Fusion Number objects</p> <p></p> <p>vTextFromHex</p> <p>Converts a Base16 Hex encoded string to ASCII text</p> <p>The \"Input\" field is used to supply the block of HEX encoded content.</p> <p>The \"Separator\" text field allows you to enter a value like a space, a tab, a dash, a semicolon, or other character that is present between the Base16 encoded number groups. This user supplied separator information is then used to guide the decoding process.</p> <p>The \"Remove Non-Printable Characters\" control will automatically remove any ASCII characters that are control characters. In software like the macOS based BBEdit text editor, a non-printable character in a text file would be described as a \"Gremlin\" and this process would be called \"Zapping Gremlins\".</p> <p>A sample Hex string that says \"Hello World!\" is \"48656C6C6F20576F726C6421\".</p> <p></p> <p>vTextCreate</p> <p>Creates a Fusion Text object</p> <p>This is the standard starting point for generating new Text data type based content.</p> <p></p> <p>vTextCreateBrowse</p> <p>Creates a Fusion Text object with a file browser dialog</p> <p>This node is used to create filepath based Text data type content. The Browse button displays a file picker dialog.</p> <p></p> <p>vTextCreateMultiline</p> <p>Creates a multi-line Fusion Text object</p> <p>The \"Text\" field supports entering multi-line text blocks that can include indentation, tabs, newlines, returns and other plain-text formatting variations.</p> <p>If you need to view this multi-line text based content downstream in the comp, try the vTextViewer node.</p> <p>This node is especially useful if you needed to create the original textual contents used for a shell script that you would save to disk using the vTextToFile node, and then run with a vTextProcessOpen node.</p> <p></p> <p>vTextCreateMultilineCode</p> <p>Create a multi-line Fusion Text object with syntax highlighting</p> <p></p> <p>vTextCreateArch</p> <p>Creates a unique Fusion Text object per CPU architecture</p> <p>This node provides a series of text fields that allow you to enter three different string values. The correct string that matches the current CPU architecture will be returned when the comp is rendered.</p> <p></p> <p>vTextCreatePlatform</p> <p>Creates a unique Fusion Text object per OS platform</p> <p>This node provides a series of text fields that allow you to enter three different string values. The correct string that matches the current operating system platform will be returned when the comp is rendered.</p> <p>This node is a handy way to define the correct parameters to use with a vTextSubFormat or ProcessOpen node.</p> <p></p> <p>vTextCreatePlatformBrowse</p> <p>Creates a unique Fusion Text object per OS platform</p> <p>This node provides a series of Browse buttons and text fields that allow you to enter three different string values. The correct string that matches the current operating system platform will be returned when the comp is rendered.</p> <p>This node is a handy way to define the correct parameters to use with a vTextSubFormat or ProcessOpen node.</p> <p></p> <p>vTextFromASCII</p> <p>Converts an ASCII code number to text</p> <p>The \"Number\" control is used to enter an ASCII code value. The result is a single character placed inside a text data type based output.</p> <p></p> <p>vTextFromCSV</p> <p>Creates a Fusion Text object by extracting a single cell from a CSV formatted block of text</p> <p>The \"Row\" control is used to define the CSV line number to read.</p> <p>The \"Column\" control is used to increment through each set of comma separated entries on a single line of CSV input data.</p> <p>The \"Ignore Header Row\" checkbox will offset the first index position to start at line 2 in the CSV file. This will skip over a labelled header row in the source document to avoid that information being accessed as part of the ingested data.</p> <p></p> <p>vTextDate</p> <p>Creates a date and time based Fusion Text object</p> <p>The \"Text\" field is used to enter the string formatting pattern used to generate a date based output. The default value is \"<code>%Y-%m-%d</code>\" which creates a result like \"2022-05-24\".</p> <p>The Lua documentation on the Date function provides more details about the supported values you can enter into the Text field in this node.</p> <p></p> <p>vTextEnv</p> <p>Creates an environment variable based Fusion Text object</p> <p>This node will read an environment variable and return the result as a string. This is useful if you need to access a value like a SITE, SHOW, or SHOT env variable inside your composite.</p> <p>The \"Text\" field is used to enter the environment variable name like \"PATH\", \"HOME\", \"USER\", etc...</p> <p>If you need to troubleshoot the active environment variables on your Windows system using the Command Prompt you can type in \"set\". In the macOS/Linux terminal program you can type in \"env | sort\" to see an alphabetically sorted list of the active environment variables.</p> <p></p> <p>vTextFromNumber</p> <p>Converts a number to text</p> <p>This node takes a number based input value that is converted automatically into a Text data type on the output. This makes it possible to supply a numerical value to a node like vTextSubFormat that only works with Text based inputs.</p> <p>The \"Number\" field holds the source numerical value.</p> <p>If the \"Show Input\" checkbox is enabled, the Number field based value can come from an external source.</p> <p></p> <p>vTextUUID</p> <p>Creates a UUID Fusion Text object</p> <p>A per-frame (Universally Unique IDentifier) value is generated by this node. This value can be used to help with naming temporary items on disk, or for other tasks where an incrementing index based identifier is not appropriate.</p> <p>A UUID value is formatted like: <code>11625315-7785-4eb4-8b2f-d6dca235c424</code></p> <p></p> <p>vTextToHex</p> <p>Converts a string into Base16 Hex encoded text</p> <p>The \"Separator\" text field allows you to enter a value like a space, a tab, a dash, a semicolon, or other character you want to use between the Base16 encoded output number groups.</p> <p>The \"Remove Non-Printable Characters\" control will automatically remove any ASCII characters that are control characters.</p> <p></p> <p>vTextFromNumberPadded</p> <p>Converts a number to a leading zero padded text</p> <p>This node is excellent for creating fixed length numbers thanks to the built-in \"Padding\" control.</p> <p></p> <p>vTextUUIDStatic</p> <p>Creates a UUID Fusion Text object</p> <p>A static non-animated UUID (Universally Unique IDentifier) value is generated by this node. This value can be used to help with naming temporary items on disk, or for other tasks where an incrementing index based identifier is not appropriate.</p> <p>A UUID value is formatted like: <code>11625315-7785-4eb4-8b2f-d6dca235c424</code></p> <p></p> <p>vTextFromArray</p> <p>Creates Text from an array</p> <p>The \"Index\" control is used to extract an individual element from a JSON based array. The output is a text based data type.</p> <p></p> <p>vTextSortLines</p> <p>Sorts a multi-line block of text</p> <p>The \"Sort List\" checkbox will break apart a multi-line block of text and alphabetically sort the content on a line-by-line basis.</p> <p>The \"Remove Duplicates\" checkbox is used to remove any line entry that is a duplicate entry, meaning the content is not unique.</p> <p></p> <p>vTextNormalizeSlashes</p> <p>Unifies the slash direction on filepaths</p> <p>The \"Slash Direction\" multi-button control allows you to choose if you want Windows (\\) or Linux (/) style slashes for your output text.</p> <p>The \"Remove Duplicate Slashes\" checkbox will replace any occurrence for two adjacent slashes with a single slash. This option is something you might not want to use if UNC file paths are common in filenames used in your pipeline.</p> <p></p> <p>vTextParseFilename</p> <p>Creates a Fusion Text object by parsing a filepath</p> <p>The \"Text\" input field supports a filepath style of string that contains absolute or relative filepaths (including the use of Fusion PathMaps).</p> <p></p> <p>The \"Parse\" ComboControl entries include:</p> <p>\"FullPath\", \"FullPathMap\", \"Path\", \"PathMap\", \"FullName\", \"Name\", \"CleanName\", \"SNum\", \"Number\", \"Extension\", \"Padding\", \"UNC\", and \"Path + Name\".</p> <p></p> <p>vTextParseFilenameOutputs</p> <p>Creates a Fusion Text object by parsing a disk based filepath</p> <p>This node is a multi-output connection based variation on the more commonly used vTextParseFilename node. Each output port exports a separate part of the extracted filename components.</p> <p>The use of this multi-output node is fairly rare but it does a good job of showing that multiple output connections are possible in a fuse node.</p> <p></p> <p>vTextDelay</p> <p>Creates a Delay while passing a Fusion Text object</p> <p>The delay effect is measured in seconds. This node is implemented internally using the \"<code>bmd.wait()</code>\" function.</p> <p>Among several use cases one can find for a tool that can momentarily pause rendering; it can be used to simulate a slow to render comp task when testing a render farm program. It also has applications when running a command line task via the Vonk ProcessOpen node and the system requires a momentary pause.</p> <p></p> <p>vTextDump</p> <p>Dump the contents of a Fusion Text object to the Console window</p> <p>The vTextDump node is handy for printing diagnostic logging information to the Console during a complex workflow. This could include status results, frame counts, or any other information. You can see this output text in the Console view, or for a job that is sent to be processed by Fusion Render Node the terminal/command prompt output will show the log results.</p> <p>If you want to build an elaborate block of text to be output by the \"vTextDump\" node, you can assemble the compound string using the \"vTextSubFormatMultiline\" node where each input connection is able to be sourced from separate data nodes.</p> <p>Vonk number datatype content can be translated into a text format using the \"vTextFromNumber\" node. If you require leading zero based frame padding, look at the \"vTextFromNumberPadded\" node. The \"vTextCompCurrentTime1\" node returns the current timeline frame number in a format that can be used directly with the input connections on a \"vTextSubFormatMultiline\" node.</p> <p></p> <p>The \"Shift + 0\" hotkey is useful if you need to quickly toggle the visibility of the Console window in Resolve or Fusion Studio. Alternatively, clicking on the \"Console\" tab button at the top left of the Fusion Studio user interface will carry out a similar task.</p> <p></p> <p>vTextLength</p> <p>Returns the length of a string</p> <p>The vTextLength node counts the number of characters present in a string. It returns the text length value as an integer based Number data type.</p> <p>If the text \"Hello\" was input to the vTextLength node, the output would be a string length measurement of the number 5.</p> <p></p> <p>vTextViewer</p> <p>Displays the Fusion Text object contents in the Inspector</p> <p>The vTextViewer node is a handy way to view multi-line text based data type content using the Inspector.</p> <p>The \"Display Lines\" control is used to adjust how many visible lines of text are shown in the preview area at once. This number can be lowered if you want to have the vTextViewer node shortened to reduce the amount of vertical screen space used in the Inspector.</p> <p>The \"Wrap Lines\" checkbox makes it possible to enable/disable line wrapping in the text preview area.</p> <p></p> <p>vTextLineCount</p> <p>Returns the line count of a multi-line string</p> <p>This node is especially useful if you are working with IFL (Image File Lists), or CSV (Comma Separated Value) / TSV (Tab Separated Value) text files. It gives you a quick indication of how many rows of text are in the supplied multi-line block of text.</p> <p>The output from the node is a Number data type that indicates the total line count. If the text file had ten lines of text supplied to the input connection, then the output from the node would be the number 10.</p> <p></p> <p>vTextReadLine</p> <p>Creates a Fusion Text object by extracting a single line of text from a multi-line text block</p> <p>The \"Index\" control accepts integer based number input connections. Typically a vNumberCompReqTime or vNumberCompCurrentTime node will be used to scan through the text input contents one frame at a time.</p> <p>If your timeline start frame is not frame 1, you can use a vNumberAdd / vNumberSubtract node to shift the frame incrementing value that is fed into the \"Index\" control. This allows your starting frame of either frame 0, frame 1000, or frame 1001 to be accessed effortlessly as an index value of 1 (meaning line one).</p> <p>The counterpoint to the vTextReadLine node is the vTextAccumulator node that combines single line elements of text into a multi-line text block of text.</p> <p>The \"Display Lines\" control is used to adjust how many visible lines of text are shown in the preview area at once. This number can be lowered if you want to have the vTextViewer node shortened to reduce the amount of vertical screen space used in the Inspector.</p> <p>The \"Wrap Lines\" checkbox makes it possible to enable/disable line wrapping in the Input field preview area.</p> <p></p> <p>vTextWireless</p> <p>The vTextWireless node allows you to connect to other text based nodes in your comp without drawing the connection wirelines visually in the Flow/Nodes view. This can be helpful if you need to reduce clutter.</p> <p></p> <p>vTextSwitch</p> <p>Switches between Fusion Text objects</p> <p>The \"Which\" control uses an integer number that starts at 1 and counts upwards to define the input connection port that is passed through to the output connection.</p> <p>If you are using a logical comparator that works on a false/true based 0-1 number range and want to connect it to a vTextSwitch node's Which input connection, that works on a 1+ number range, simply insert a vNumberAdd node set to increment the number upwards by 1.</p> <p>The \"Show Which Input\" checkbox is used to hide the Number datatype based input connection for the Which parameter in the Nodes view.</p> <p>The \"Show Active Input\" checkbox is used as a visualization and diagnostics mode. When enabled, this control automatically toggles the visibility off for the inactive connection wirelines fed into the switch node. This approach makes it possible to visually see in a quick glance the source comp branch that is selected as the input and used by the Which control. All other inputs will be turned into hidden wireless inputs when not in use.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#vector-nodes","title":"Vector Nodes","text":"<p>Vector Nodes</p> <p>vVectorMultiplyNumber</p> <p>Multiplies a vector by a number</p> <p></p> <p>vVectorNormalize</p> <p>Normalizes a vector</p> <p></p> <p>vVectorDivideNumber</p> <p>Divides a vector by a number</p> <p></p> <p>vVectorSubtract</p> <p>Subtracts two vectors</p> <p></p> <p>vVectorSlice</p> <p>Slices a vector</p> <p></p> <p>vVectorDotProduct</p> <p>Adds two vectors</p> <p></p> <p>vVectorAdd</p> <p>Adds two vectors</p> <p></p> <p>vVectorCrossProduct</p> <p>Adds two vectors</p> <p></p> <p>vVectorFromArray</p> <p>Creates a vector from an array</p> <p></p> <p>vPointToVector</p> <p>Creates a vector from a point</p> <p></p> <p>vVectorToPoint</p> <p>Creates a point from a vector</p> <p></p> <p>vVectorFromPoint</p> <p>Creates a vector from a point</p> <p></p> <p>vVectorCreate</p> <p>Creates a vector from an array</p> <p></p> <p>vVectorLength</p> <p>Calculates the length of a vector</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Node%20Reference%20Guide/#matrix-nodes","title":"Matrix Nodes","text":"<p>Matrix Nodes</p> <p>vMatrixDivide</p> <p>Divides two matrices</p> <p></p> <p>vMatrixInvert</p> <p>Inverts a matrix</p> <p></p> <p>vMatrixDeterminant</p> <p>Calculates the determinant of a matrix</p> <p></p> <p>vMatrixMultiply</p> <p>Multiplies two matrices</p> <p></p> <p>vMatrixDivideNumber</p> <p>Divides a matrix by a number</p> <p></p> <p>vMatrixFromArray</p> <p>Creates a matrix from an array</p> <p></p> <p>vMatrixColorTransform</p> <p>Animatible/Modifiable ColorMatrix</p> <p></p> <p>vCreateMatrix4x4</p> <p>Creates a 4x4 matrix</p> <p></p> <p>vMatrixToTranslation</p> <p>Decomposes translation from a matrix</p> <p></p> <p>vMatrixTranspose</p> <p>Transposes a matrix</p> <p></p> <p>vMatrixToRotation</p> <p>Decomposes a rotation from a matrix in Euler angles</p> <p></p> <p>vMatrixFromRotation</p> <p>Creates a rotation matrix</p> <p></p> <p>vMatrixToScale</p> <p>Decomposes scale from a matrix</p> <p></p> <p>vMatrixFromTranslation</p> <p>Creates a translation matrix</p> <p></p> <p>vEulerFromMatrix</p> <p>Converts a matrix to Euler angles</p> <p></p> <p>vMatrixFromScale</p> <p>Creates a scale matrix</p> <p></p> <p>vMatrixSlice</p> <p>Slices a matrix</p> <p></p> <p>vMatrixConcatenateHorizontal</p> <p>Concatenates two matrices horizontally</p> <p></p> <p>vMatrixConcatenateVertical</p> <p>Concatenates two matrices vertically</p> <p></p> <p>vMatrixLink</p> <p>Links to a matrix</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/","title":"Vonk Scripts","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#comp-scripts","title":"Comp Scripts","text":"<p>Comp Scripts</p> <p>Vonk includes several comp scripts that can be located on disk at:</p> <p><code>Scripts:/Comp/Vonk Ultra/</code></p> <p>Render Selected</p> <p>The \"Render Selected\" script will launch a GUI based rendering of the currently active node in the Nodes view. This will re-cook the upstream node branches that lead into the selected node.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#vonk-open-sub-folder","title":"Vonk Open Sub-Folder","text":"<p>Vonk Open Sub-Folder</p> <p>The \"Open\" folder of scripts are used to quickly access Vonk resources.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-comps-folder","title":"Show Comps Folder","text":"<p>Show Comps Folder</p> <p>The \"Show Comps Folder\" menu item opens up the \"<code>Reactor:/Deploy/Comps/Kartaverse/Vonk Ultra/</code>\" folder in a Finder/Explorer/Nautilus window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-docs-local","title":"Show Docs Local","text":"<p>Show Docs Local</p> <p>The \"Show Docs Local\" menu item opens up the \"<code>Reactor:/Deploy/Docs/Kartaverse/Vonk Ultra/Vonk Ultra Data Nodes.pdf</code>\" documentation in your operating systems' default PDF viewing tool. This is a local on-disk version of the Vonk documentation guide you are currently reading now.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-docs-online","title":"Show Docs Online","text":"<p>Show Docs Online</p> <p>The \"Show Docs Online\" menu item displays a Google Docs based online version of the Vonk documentation guide you are currently reading now.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-fuses-folder","title":"Show Fuses Folder","text":"<p>Show Fuses Folder</p> <p>The \"Show Fuses Folder\" menu item opens up the \"<code>Fuses:/Kartaverse/Vonk Ultra/</code>\" folder in a Finder/Explorer/Nautilus window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-lua-modules-folder","title":"Show Lua Modules Folder","text":"<p>Show Lua Modules Folder</p> <p>The \"Show Lua Modules Folder\" menu item opens up the \"<code>Macros:/Kartaverse/Vonk Ultra/</code>\" folder in a Finder/Explorer/Nautilus window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-macros-folder","title":"Show Macros Folder","text":"<p>Show Macros Folder</p> <p>The \"Show Macros Folder\" menu item opens up the \"<code>Reactor:/Deploy/Modules/Lua/</code>\" folder in a Finder/Explorer/Nautilus window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#show-temp-folder","title":"Show Temp Folder","text":"<p>Show Temp Folder</p> <p>The \"Show Temp Folder\" menu item opens up the \"<code>Temp:/Vonk/</code>\" folder in a Finder/Explorer/Nautilus window.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#vonk-tools-sub-folder","title":"Vonk Tools Sub-Folder","text":"<p>Vonk Tools Sub-Folder</p> <p>The \"Tools\" folder is used to carry out Vonk centric utility tasks.</p> <p>Create All Data Nodes</p> <p>The \"Create All Data Nodes\" menu item adds every single Vonk node to the currently open composite. This is useful if you want to browse visually through the GUIs of the nodes to familiarize yourself with the large collection of fuses.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#tool-scripts","title":"Tool Scripts","text":"<p>Tool Scripts</p> <p>Vonk includes several tool scripts that can be located on disk at:</p> <p><code>Scripts:/Tool/Vonk Ultra/</code></p> <p>These nodes are accessible when you have a node selected in the Nodes view area. Right-clicking on a node will display a pop-up contextual menu. Navigating to the \"Script &gt; Vonk Ultra\" menu entry will provide access to Vonk centric scripts that can be run on the active node selection.</p> <p>You can have one, or more nodes selected when running a Tool script. The Tool script will be launched individually for each item in the selection list. Inside a Tool script a global variable named \"tool\" will exist that provides the name of the active node.</p> <p></p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Scripts/#render-selected","title":"Render Selected","text":"<p>Render Selected</p> <p>The \"Render Selected\" script will launch a GUI based rendering of the currently active node in the Nodes view. This will re-cook the upstream node branches that lead into the selected node.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Ultra/","title":"Vonk Ultra","text":"<p>Vonk Ultra provides a wide range of \"data node\" fuses that allow you to create efficient node graphs in Fusion that directly work with text, numbers, CSV spreadsheets, JSON, XML, YAML, and many other types of data using modifier nodes. Vonk Ultra can be installed via the Reactor package manager. More information can be read in the Vonk Ultra documentation. See also the Vonk Ultra Learning Resources.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Ultra/#introduction","title":"Introduction","text":"<p>Vonk Ultra is a collection of data nodes for Blackmagic Design Resolve/Fusion. Vonk can be thought of as node-based modifiers that live in the flow. These node-based operations provide a no-code alternative to using expressions or custom scripts. Data nodes are tools that allow you to interconnect nodes together by supporting more data types for the input and output connections such as numbers, text, spreadsheets, CSV, JSON, XML, YAML, metadata, arrays, matrices, and more.</p> <p>These data node-based techniques encourage a more seamless interchange of information between DCC tools by reducing the loss of important metadata, removing manual data entry steps that can be error-prone, and keep data flowing through a pipeline in a more organized and consistent way.</p> <p>The long-term hope of Vonk's developers is to help encourage artists and TDs to adopt \"data node\" concepts across a full production pipeline. These approaches are beneficial for teams working on cutting-edge projects in the motion graphics, VFX, XR, computer vision, machine learning, video/photogrammetry, and digital production/VP space.</p> <p>Vonk's wide range of nodes include the newly added \"vFileSystem\" fuses which make it possible for a comp/pipeline TD to port the conceptual ideas found in a typical pipeline shell-script (.bat/.sh) into a fully node-based \"Visual Shell Scripting'' paradigm that can run cross-platform inside of Resolve/Fusion/Fusion Render Node. This is effective if it's late at night, your brain focus is fading fast, and you need to quickly whip up in 15 minutes or less a general purpose data processing tool to solve an immediate production challenge.</p> <p>If you would like to provide feedback on the evolution of the Vonk data nodes, please check out the development thread on the Steakunderwater forum.</p> <p>The Vonk Ultra visual scripting nodes are installed using the Fusion community created Reactor Package Manager. There is a separate Vonk GitLab repository if you need to quickly grab a resource.</p> <p>The Vonk Ultra documentation (you are reading now) is accessible on Google Docs. Local PDF formatted Vonk documentation can be read on disk at the following PathMap location:</p> <pre><code>Reactor:/Deploy/Docs/Kartaverse/Vonk Ultra/Vonk Ultra Data Nodes.pdf\n</code></pre> <p>If you enjoy the Vonk data nodes, you might also like to check out a companion guide that explains how to automate Fusion and Resolve workflows with the help of Houdini's TOPS task operators.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Vonk%20Ultra/Vonk%20Ultra/#original-table-of-contents","title":"Original Table of Contents","text":"<ul> <li>Vonk Ultra</li> <li>Kartaverse/Vonk Ultra/Software Required</li> <li>Acknowledgements</li> <li>Install Vonk</li> <li>Kartaverse/Vonk Ultra/Fusion Render Node Customization</li> <li>Adding Data Nodes to a Composite</li> <li>Vonk Essentials</li> <li>Vonk Scripts</li> <li>Vonk Node Reference Guide</li> <li>Vonk Node Cookbook</li> </ul>","tags":["Kartaverse",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/","title":"Creating ST Maps","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>KartaVR Workflows | Creating ST Maps</p> <p>Created 2021-12-20 Last Updated 2022-01-03 12.06 PM UTC -4</p> <p>By Andrew Hazelden \\&lt;andrew@andrewhazelden.com&gt;</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#overview","title":"Overview","text":"<p>Overview</p> <p>The motivation for writing this content is to illustrate and describe approaches that can be used to perform high-speed panoramic warping with the existing software tools you likely already have access to on your workstation, today.</p> <p>If you need to quickly stitch a lot of high-resolution footage, one way to affordably approach this challenge is to use pre-computed warping templates created using an \"ST Map\" which is also called UV pass warping.</p> <p></p> <p>An ST Map is a high dynamic range image that stores the X/Y coordinate values for a lens distortion calculation in the red and green channels of an RGB image. If you look at the starting image you will see a horizontal and a vertical gradient stored in a linear gamma 1.0 color based image.</p> <p></p> <p>Note: Depending on your coordinate system, you might want to have the horizontal gradient start with black on the left side, and transition to white on the right side of the frame. This can also be achieved with the flip control on the UV Gradient generator.</p> <p>Any warping effects performed on the ST Map gradient starting image can be \"replayed\" quickly and efficiently on any footage you run through this workflow. This can be a time-saver if you need to do on-set 360VR stitching previews using a program like TouchDesigner with an HDMI/SDI/USB/NDI based video capture device.</p> <p>After Effects (with the RE:Vision Effects RE:Map plugin), Resolve/Fusion, NukeX, and many other tools can all work with ST Map based lens distortion images in a way that gives consistent and identical pixel matched results.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#software-required","title":"Software Required","text":"<p>Software Required</p> <p>To carry out an ST Map based 360VR video stitching workflow you need to have at least two of the following programs installed. (KartaVR is an optional item to add if you are using BMD software like Resolve/Fusion.)</p> <ul> <li> KartaVR</li> <li>PTGui Pro v12</li> <li> Derivative TouchDesigner</li> <li>BMD Resolve (Free) / Resolve Studio</li> <li>BMD Fusion Studio</li> <li>Foundry NukeX + Occula</li> <li> Autodesk Flame</li> <li>Adobe Photoshop + The Domemaster Photoshop Actions Pack</li> <li> Adobe After Effects + RE:Vision Effects RE:Map Plugin</li> <li> Blender Compositor (Free)</li> <li>Natron Compositor (Free)</li> <li> Imagemagick (Free) +  FFMpeg (Free) Command-Line Tools</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#ptgui-pro-workflow","title":"PTGui Pro Workflow","text":"<p>PTGui Pro Workflow</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-1-rename-the-ptgui-project-file","title":"Step 1. Rename the PTGui Project File","text":"<p>Step 1. Rename the PTGui Project File</p> <p></p> <p>Start by opening up an existing PTGui Pro v12 .pts project file. Use the \"File &gt; Save Project As...\" menu entry to save a copy of the current stitching project to disk as \"stmap.pts\".</p> <p>Note: If your immersive content production pipeline needs to manage multiple concurrent stitching shots, in parallel, for a full-length VR or fulldome film, you could also add more details to the saved filename with values like \"\\&lt;Project&gt;_\\&lt;Shot&gt;_\\&lt;Version&gt;_stmap.pts\"</p> <p>For the rest of the steps in this tutorial, it is assumed that you have clicked to enable \"Advanced\" GUI mode, at the bottom of the left-hand sidebar region in the PTGui window.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-2-change-the-exposure","title":"Step 2. Change the Exposure","text":"<p>Step 2. Change the Exposure</p> <p>Click on the \"Exposure / HDR\" tab on the left side of the PTGui window.</p> <p></p> <p>An ST Map based warping requires very precise color values. In this type of workflow, each pixel in the rendered ST map template image represents a final pre-computed warping LUT (Look Up Table) X/Y position. This data is used to carry out panoramic image projection transforms or lens distortion corrections.</p> <p>Any of the color matching done per-camera view, vignetting correction, or camera response curve modifications that would typically be desirable in a color panoramic stitching workflow, need to be disabled when generating an ST Map template output.</p> <p>This is due to the ST map source data holding a pure horizontal and vertical gradient, not photographic content.</p> <p>Looking at the \"Vignetting curve\", and the \"Camera response curve\" charts below, we can see they are not linear \"straight lines\" but instead have a graceful, curved shape.</p> <p></p> <p>Change the \"Precision\" setting to \"Float\". This gives 32 bit-per channel processing support.</p> <p>Then click on the \"Automatic exposure and color adjustment\" section's \"Reset\" button. This will flatten out the \"Vignetting curve\" yellow-colored line plot so it is perfectly horizontal.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-3-changing-the-camera-curve","title":"Step 3. Changing the Camera Curve","text":"<p>Step 3. Changing the Camera Curve</p> <p>On the left side of the PTGui user interface is a series of sidebar \"tabs\". Click on the tab labelled \"Image Parameters\".</p> <p></p> <p>The Image Parameters tab displays a list of all the footage loaded in the current PTGui project file in a spreadsheet-like grid layout.</p> <p></p> <p>When viewing the Image Parameters tab, if you scroll horizontally or expand the window's width larger, you will notice a far right-hand column labelled \"Camera Curve\".</p> <p>When using PTGui, most sRGB based color photos have a gamma value of 2.2. This is a typical setting for 8 bit per-channel PNG, JPG, and PSD formatted images.</p> <p>In order to turn the .pts file into an ST Map based warping template we need to set all color options to use a linear color managed workflow. A gamma value of 1.0 needs to be assigned to all OpenEXR .exr formatted images used in ST map warping processes.</p> <p>To do this, select all of the images in the Image Parameters tab by pressing the Ctrl+A (Windows) hotkey on your keyboard.</p> <p></p> <p>Now right-click on the small triangle in the Camera Curve column's first entry labelled \"Global camera curve\". Change this value to \"Linear\". Since all of the images were selected at the same time, this change is applied to multiple images at once. Nice!</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-4-change-the-camera-response-curve","title":"Step 4. Change the Camera Response Curve","text":"<p>Step 4. Change the Camera Response Curve</p> <p>Click on the \"Exposure / HDR\" tab again on the left side of the PTGui window. Then look at the \"Camera response curve\" section on the lower right side of the window.</p> <p></p> <p>Move your cursor over the \"Trash Can\" icon in this toolbar. The tooltip for this button says \"Remove camera response curve\". This option is available since we previously used the \"Image Parameters\" tab to change the Camera curve to \"Linear\".</p> <p></p> <p>Click the \"Trash Can\" button.</p> <p>The \"Exposure / HDR\" tab's \"automatic exposure and color adjustment\" settings should now look like this:</p> <p></p> <p>For good measure, click on the \"automatic exposure and color adjustment\" section's \"Settings\" button. A small dialog window will appear.</p> <p></p> <p>We need to make sure the following options are configured:</p> <p>Optimize Brightness: Disabled</p> <p>Optimize white balance: Disabled</p> <p>Optimize lens flare: Disabled</p> <p>Global &gt; Optimize Vignetting: Disabled</p> <p>Once these customizations are locked in, click the \"OK\" button to close the dialog. When the dialog closes, you may be asked in an additional dialog window if you would like to optimize the panorama using these settings.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-5-open-the-panorama-editor","title":"Step 5. Open the Panorama Editor","text":"<p>Step 5. Open the Panorama Editor</p> <p>Open the Panorama Editor window using the \"Tools &gt; Panorama Editor\" menu entry. The hotkey for quickly displaying the Panorama Editor view is Ctrl+E (Windows).</p> <p></p> <p>The PTGui \"Panorama Editor\" window lets you see a quick preview of the current stitching settings.</p> <p></p> <p>A helpful diagnostic option to enable in the Panorama editor window is the \"Show image numbers\" button found in the toolbar at the top of the view.</p> <p></p> <p>The Panorama Editor has a lot of UI controls hidden under a small \"triangle\" button icon found at the top right corner of the window. It can be easy to miss this feature when you are just getting started with PTGui v12.</p> <p></p> <p>If you hover your cursor over the triangle-shaped button, an entirely new set of UI controls slide into the frame and are visible.</p> <p></p> <p>Expand the \"Blending\" section and un-check the \"Exposure Compensation\" option. It's a good idea to un-check the \"Fill holes\" option too.</p> <p></p> <p>Expand the \"Tone mapping\" section. Un-check the \"Apply tone mapping\" option. This control adjusts the way shadows and highlight regions in a high dynamic range image are compressed to fit inside a low dynamic range output.</p> <p></p> <p>Expand the \"Exposure fusion\" section. Un-check the \"Apply Exposure Fusion\" option. This control is relevant to HDR bracket merging operations, which is not something an ST mapping workflow needs to perform when you are performing warping using an ST Map template.</p> <p></p> <p>Finally, expand the \"Post Process\" section. The \"Toning curve\" graph image shows that a gamma 2.2 style output is generated by default.</p> <p></p> <p>This curve shape would do bad things to the precision of the ST map templates numerical values stored in the LUT (Look Up Table) so we need to disable the effect of the toning curve.</p> <p>Change the \"Shape\" to 0.</p> <p>Change the \"Shift\" to 0.</p> <p>Make sure the \"Saturation\" is at 100%.</p> <p>Once these changes are made, we should see a yellow-colored straight line running diagonally at a 45% angle in the chart, instead of a rolling \"S\" shaped curve with a slope.</p> <p>At this point, the color intensity values for each pixel are mapped in a linear style going from 0 (black) to 1.0 (white) in a floating point-based color range.</p> <p></p> <p>You can now close the Panorama Editor window.</p> <p>Save the revised PTGui project file to disk, using the \"File &gt; Save Project\" menu item, or the Ctrl+S (Windows) hotkey.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-6-open-the-create-panorama-tab","title":"Step 6. Open the Create Panorama tab.","text":"<p>Step 6. Open the Create Panorama tab.</p> <p>The essential settings in the Create Panorama tab include:</p> <p>Output: [x] Individual HDR layers</p> <p>This setting tells PTGui that each source image in the panorama needs to be exported to a separate warped image result, and left un-blended, when the final panoramic output is rendered to disk by the \"Create Panorama\" button.</p> <p>HDR file format: OpenEXR (.exr) (with alpha float)</p> <p>Un-check the [] use default checkbox next to the Output file prefix text field.</p> <p>Output file prefix: \"<code>Render\\stmap</code>\"</p> <p>The \"Output file prefix\" setting specified will create a new \"Render\" sub-folder on disk at the same folder hierarchy level where the PTGui .pts file is located. Also, the rendered images will all have the initial filename of \"stmap\" used before the image view number, and file extension is appended to the filename.</p> <p>Advanced &gt; Interpolator: Nearest Neighbor</p> <p>Advanced &gt; Output color space: Linear sRGB IEC619660-2.1</p> <p>(Optionally) you can enable the \"[x] Use source image color space if possible\" checkbox.</p> <p></p> <p>Once these settings are locked into the Create Panorama tab, it's time to click the \"Settings:\" button to the right of the HDR file format control. The \"Settings:\" button causes PTGui to display a dialog that lets you customize the image format parameters used when the image file is written to disk.</p> <p>In the \"EXR Options\" dialog, you should change the controls to:</p> <p>Alpha Channel (transparency): With alpha channel</p> <p>Bit depth: Float (32 bits per channel)</p> <p>Compression: ZIPS</p> <p>It is super important to avoid using any lossy (destructive) image compression codecs in an ST Map as that choice will result in PTGui \"shredding\" the quality of the final output which gives unexpected artifacts.</p> <p></p> <p>Step 7. Swap out the photos for an ST Map gradient image.</p> <p>Switch to the \"Source Images\" tab.</p> <p></p> <p>The \"Source Images\" view provides a quick way to see each of the photos that are loaded into the PTGui project file. A thumbnail preview image is shown along with the image file name, and the width / height of the photo.</p> <p></p> <p>If you right-click on a photo, in the contextual pop-up menu there is a \"Replace...\" option that lets you swap the current image out for another document you can select from your hard disk.</p> <p></p> <p>We need to replace the photos with a common red/green colored ST Map \"initial\" gradient image using the right-click \"Replace...\" contextual menu item several times.</p> <p></p> <p>Save the PTGui Project file to disk.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#editing-ptgui-json-project-files","title":"Editing PTGui JSON Project Files","text":"<p>Editing PTGui JSON Project Files</p> <p>It is worth noting that it is fully possible to use a programmer's text editor like Notepad++ for Fusion (Windows) or BBEdit (macOS) to open up an existing PTGui .pts file and manually use a regular expression based \"Find &amp; Replace\" approach to swap out the images. A PTGui v11 and v12 .pts file is saved as a JSON format document. This makes it pretty easy to edit since JSON is a standard format that many editing tools are familiar with.</p> <p></p> <p>This screenshot shows the \"Notepad++ for Fusion\" atom package in Reactor being used to edit and relink the photos in a .pts file. By combining a JSON based syntax highlighting mode in your text editor, along with file differencing based comparisons, and a JSON hierarchy browser, you'll have assembled something that approximates a fancy PTGui project based text editing IDE.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-8-render-the-ptgui-project","title":"Step 8. Render the PTGui Project","text":"<p>Step 8. Render the PTGui Project</p> <p>Now that we've got a PTGui .pts file that is fully tuned for ST Map based template generation, we can render the individual warped views to disk.</p> <p>Switch to the \"Create Panorama\" tab.</p> <p></p> <p>Click the \"Create Panorama\" button.</p> <p></p> <p>After a few seconds, you will see the PTGui progress bar complete the rendering stage.</p> <p></p> <p>Take a moment to look in the Explorer (Windows) or Finder (macOS) desktop folder browsing view, and navigate inside the folder where the .pts file is saved on disk.</p> <p>There should be a new \"Render\" sub-folder that holds each of the warped ST map template images we just created.</p> <p>The images are currently named:</p> <p>stmap_layer_0.exr</p> <p>stmap_layer_1.exr</p> <p>stmap_layer_2.exr</p> <p>stmap_layer_3.exr</p> <p>stmap_layer_4.exr</p> <p>stmap_layer_5.exr</p> <p>...</p> <p>As a pro-tip, it's very handy to rename the final ST Map template images to a simpler \"sequentially named\" format like:</p> <p>stmap01.0000.exr</p> <p>stmap02.0000.exr</p> <p>stmap03.0000.exr</p> <p>stmap04.0000.exr</p> <p>stmap05.0000.exr</p> <p>...</p> <p>Note: You really do want to add the \"dummy\" frame numbers, in a 4-digit leading zero-padded nature, to the end of each image's file name so you've got a \"name.####.ext\" formatted \"image sequence\" based filename.</p> <p>If we do this step, we avoid having the set of multi-view ST Map images automatically loaded as one single unified animated ST Map sequence. This is not how we want to use the maps as we want to have each ST Map loaded in as a separate composite branch, alongside the source footage.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-10-creating-an-st-map-gradient","title":"Step 10. Creating an ST Map Gradient","text":"<p>Step 10. Creating an ST Map Gradient</p> <p>In this part of the workflow guide several different approaches for tackling the ST Map \"initial\" gradient creation task will be explored.</p> <p>The goal is to try and keep this step as software-agnostic as possible since the starting point ST Map image is made up of a horizontal and vertical gradient, which is hopefully, not too complex of a task to ask a professional imaging tool to carry out.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#blackmagic-resolvefusion","title":"Blackmagic Resolve/Fusion","text":"<p>Blackmagic Resolve/Fusion</p> <p>KartaVR UVGradientMap Macro</p> <p>If you have access to a copy of the Fusion compositing environment provided by Resolve's Fusion page, or from Fusion Studio, you can take advantage of KartaVR's provided \"UVGradientMap\" macro.</p> <p></p> <p>The \"UVGradientMap\" macro allows you to quickly specify the width, height, and bit-depth for your new ST Map initial gradient template image.</p> <p>If needed, you can also set options for flipping the image horizontally or vertically.</p> <p></p> <p>In the Fusion \"Nodes\" view, you would wire the image output from the KartaVR provided \"UVGradientMap\" macro into a Saver node. The Saver node needs to be configured to use an EXR image format, with ZIPS compression, and a \"float32\" 32 bit floating-point image bitdepth.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#fusion-customtool-node","title":"Fusion CustomTool Node","text":"<p>Fusion CustomTool Node</p> <p>If you are a compositing TD (Technical Director) who is comfortable with expressions and formulas, you could also explore the Fusion built-in CustomTool node as a way to generate an ST Map in a super precise fashion.</p> <p>To use this workflow, connect a Background node to the CustomTool node. The Background node generates the canvas size by defining the image width, image height, and initial bit depth. Then the CustomTool creates the vertical and horizontal direction based red/green gradient effect needed for the starting point of an STMap template.</p> <p></p> <p>Since the CustomTool works with normalized coordinates, running from 0 - 1 for the frame size, which are inherently resolution independent, you can make a new ST Map simply by typing in the values \"X\" and \"Y\" for the Red and Green channels.</p> <p></p> <p>As a small tip, if you need to flip the ST Map gradient horizontally, you can start with a value of one in the field, then subtract the current X axis value, using a CustomTool expression like \"1 - X\". Nice!</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#adobe-photoshop","title":"Adobe Photoshop","text":"<p>Adobe Photoshop</p> <p>If you are a die-hard Adobe Photoshop fan, the (free) Domemaster Photoshop Actions Pack toolset includes handy parametric UV pass (ST Map) creation actions.</p> <p>With this toolset, the red-green colored horizontal/vertical ST Map gradient pattern is created as a smart object so it maintains its re-editable nature and vector-like resizability.</p> <p>One step you need to do is to resize the Photoshop document to match your original \"source\" photo's image width/height. This is done immediately after you use the Domemaster Photoshop Actions Pack to add the new ST Map gradient to the photoshop layer stack.</p> <p>UV Pass Actions</p> <ul> <li>UV Rectangle Gradient Landscape Layout</li> <li>UV Rectangle Gradient Portrait Layout</li> <li>UV Equirectangular to Angular Gradient</li> <li>UV Equirectangular to Domemaster Gradient</li> <li>Horizontal Offset 960px</li> <li>Vertical Offset 960px</li> <li>Rotate 90 Degrees</li> <li>Rotate 180 Degrees</li> <li>Rotate 270 Degrees</li> <li>Flip Vertical</li> <li>Flop Horizontal</li> <li>Gamma 2.2 to 1.0 Repair</li> <li>Gamma 1.0 to 2.2 Repair</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#the-interconnected-nature-of-framebuffer-bit-depths-and-st-map-resolution","title":"The Interconnected Nature of Framebuffer Bit-depths and ST Map Resolution","text":"<p>The Interconnected Nature of Framebuffer Bit-depths and ST Map Resolution</p> <p>ST Map gradient images need to be stored in a high dynamic range image format to function correctly, and the image should be at the exact frame size (width and height) as the original photo, too.</p> <p>If you save an ST Map as an 8 bit per-channel JPEG or PNG format image, the maximum size of the output resolution you can have from the process is only 256px width by 256px height. This is due to the way an ST map uses the color range (of an 8 bit, 10 bit, 12 bit, 16 bit, or 32 bit per channel image) as the driver of the X and Y pixel plotting location for the warping process.</p> <p>An 8 bit per-channel image provides a color range of 0-255, which can be described as 256 unique values that can be used for the warping LUT (Look Up Table). The 256 color values are calculated as 2^8 if you are a math geek.</p> <p></p> <p>By comparison, an unsigned 16 bit per channel integer image supports a color range of 0-65535 which can be calculated as 2^16.</p> <p></p> <p>This gives a lot more resolution to work with. In this case the ST map warping precision could potentially exceed the capability of a 32K x 32K resolution image on the output side of things, which is great.</p> <p>General speaking, for most ST map generation needs, a 32-bit per-channel floating-point image in many ways is better to use than a 16 bit half-float or 16 bit integer image, due to the standardization of that floating-point format's use as the best / highest specification option available in photo editors, composting packages, game engines, and in OpenCL/CUDA/Metal based GPU framebuffers.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#step-11-stitching-immersive-media-with-st-maps","title":"Step 11. Stitching Immersive Media with ST Maps","text":"<p>Step 11. Stitching Immersive Media with ST Maps</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#after-effects-st-map-based-360vr-video-stitching","title":"After Effects ST Map Based 360VR Video Stitching","text":"<p>After Effects ST Map Based 360VR Video Stitching</p> <p>RE:Vision Effects has a \"RE:Map\" plugin that is available for many compositing software packages including After Effects. If you buy one RE:Map license it will run with the same license, on the same host workstation, in just about every comp tool made.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#fusion-st-map-based-360vr-video-stitching","title":"Fusion ST Map Based 360VR Video Stitching","text":"<p>Fusion ST Map Based 360VR Video Stitching</p> <p>In Fusion you have several nodes you can use to perform ST map based stitching:</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#fusion-texture-node","title":"Fusion Texture Node","text":"<p>Fusion Texture Node</p> <p>There is a built-in \"Texture\" node in Fusion. The main downside is that it cannot pass an alpha channel through the warping process.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#remap-plugin","title":"RE:Map Plugin","text":"<p>RE:Map Plugin</p> <p>RE:Vision Effects has a \"RE:Map\" plugin that is available for many compositing software packages including Resolve/Fusion. If you buy one RE:Map license it will run with the same license, on the same host workstation, in just about every comp tool made.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#fusion-stmapper-fuse","title":"Fusion STMapper Fuse","text":"<p>Fusion STMapper Fuse</p> <p>Jacob Dannell from Emberlight released a very fast and high-quality \"ST Mapper\" DCTL fuse that can be added to Resolve/Fusion v16-17.4.3+ via the Steakunderwater forum's Reactor package manager. It is quick and supports alpha channels.</p> <p>After I add an ST Mapper node to my comp, the first thing I tend to change in the Inspector window is the \"Crop: STMap Frame\" combo box menu item, and I enable the \"[x] Flip V\" checkbox. One could right-click in the nodes view, and save those options as a default setting for the node if they wanted to.</p> <p></p> <p>There is a KartaVR provided variation of the STMapper fuse called \"STMapper Inline\". It is unique in that it is capable of running in the Resolve Edit page timeline environment via a technique called an Effects Template macro.</p> <p></p> <p>Pro Tip: Instance Your Fusion Nodes</p> <p>When adding several ST map based warping nodes to a Fusion comp, you can manage the setting more efficiently through the use of \"instanced nodes\". This will keep the ST Map warping settings in the Inspector window synced up across each of the camera views you process.</p> <p>Instanced nodes can be added to a Fusion comp by copying the first node into your clipboard copy/paste buffer. Then you right-click in the Nodes views, and from the contextual menu select the \"Paste Instance\" menu item, or use the Ctrl+Shift+V (Windows) hotkey.</p> <p></p> <p>This will add the extra warping nodes in a way that all controls are linked back to the first node. When two nodes are instanced together in the Nodes view, there is a thin green line that connects them together visually so you can see the instanced relationship.</p> <p></p> <p>If you later need to customize a few individual UI controls on instanced nodes, you can right-click in the Inspector window on a specific attribute and then select the \"Deinstance\" item from the contextual menu.</p> <p></p> <p>This instancing of nodes approach is useful for cases where you need to perform subtle per-view changes on multi-view 360VR camera rig based compositing operations.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#fusion-lens-distort-node","title":"Fusion Lens Distort Node","text":"<p>Fusion Lens Distort Node</p> <p>If you want to use ST Maps to correct for lens distortion in live-action plate footage used in VFX workflows, Resolve/Fusion includes a LensDistort node that can be used to manually calibrate and process checkerboard lens alignment grids.</p> <p></p> <p>The LensDistort node supports several camera lens models including the output from the PFTrack, and 3D Equalizer match-moving software.</p> <p>Interestingly, the 3D Equalizer options include a fisheye lens model called \"3DE4 Radial - Fisheye, Degree 8\" which is a perfect fit for fulldome, VR180, and 360VR video stitching needs if you have to un-distort and linearize the f-theta warping present in footage shot on a circular fisheye lens based camera array.</p> <p>The output from the LensDistort node can be either a lens corrected RGBA image, or an ST Map which is produced by turning on the \"[x] Output Distortion Map\" checkbox at the top of the Inspector view.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#nukex-st-map-workflows","title":"NukeX ST Map Workflows","text":"<p>NukeX ST Map Workflows</p> <p>The Foundry NukeX documentation includes a guide on STMap template creation using an Expressions node.</p> <p>Once you have generated the required ST Map template image, it can be used to distort the footage in your NukeX composite with the aptly named STMap node. To help artists get started, there is a Working With STMaps guide.</p> <p>NukeX ships with a LensDistort node that can be used to process checkerboard lens alignment grids where the output is typically an ST Map style image. More details about lens distortion techniques in NukeX are covered in the Working with Lens Distortion guide.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#blender-compositor-st-map-workflows","title":"Blender Compositor ST Map Workflows","text":"<p>Blender Compositor ST Map Workflows</p> <p>Blender's built-in compositing environment includes a MapUV node. This node, while very minimal in the controls presented to the end user, allows artists to perform ST Map (UV pass retexturing) techniques.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#touchdesigner-st-map-based-real-time-360vr-video-stitching","title":"TouchDesigner ST Map Based Real-Time 360VR Video Stitching","text":"<p>TouchDesigner ST Map Based Real-Time 360VR Video Stitching</p> <p>More information to be added shortly. \ud83d\ude00</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20ST%20Maps/#closing-notes","title":"Closing Notes","text":"<p>Closing Notes</p> <p>Thanks for reading this workflow guide on ST Map-based techniques. I'm sure it took a long time to slog through this lengthy technical content. I hope this guide will help cement new ideas in your mind on lens distortion correction techniques.</p> <p>The motivation for writing this new content was to illustrate and describe approaches that can be used to perform high-speed panoramic warping with the existing software tools you likely already have access to on your workstation, today.</p> <p>After writing this ST Map guide, and chatting with a stereo panoramic photographer friend, Antonio... I'd like to boldly and seriously put forward a term to be used for describing the color shading of ST Map initial templates in a colloquial sense: An immersive content creator uses a \"Mango Map\" to perform \"Mango Warping\".</p> <p></p> <p>Essentially, if you look at the specific shading of a freshly made red/green channel-based ST Map \"initial lens distortion\" template, it looks a heck of a lot like the outside color of a peeled mango.\ud83e\udd6d</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/","title":"Creating Volumetric NeRFs","text":"<p>The motivation for writing this content is to illustrate and describe approaches that can be used to create volumetric NeRF representations of environments. NeRF stands for a neural radiance field which is an alternative way to describe a scene compared to datatypes like meshes, point clouds, voxels, lightfields, or MultiSphere/MultiPlane media.</p> <p>This year NVIDIA released a project called Instant NGP (Neural Graphics Primitives). Among other achievements it dramatically speeds up the process of training a NeRF scene by several orders of magnitude compared to prior techniques developed between 2020-2021.</p> <p>Previously this NeRF performance bottleneck issue was a significant blockage for the further adoption and refinements of NeRF concepts from both a technical and creative perspective.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#nerf-video-snapshots","title":"NeRF Video Snapshots","text":"<p>Here are several short video clips that give an impression of what it's like to explore a NeRF scene using the Instant NGP repository's TestBed program.</p> <p>This video shows an orbit of the camera around a lion sculpture.</p> NeRF Instant NGP | TestBed | Lion OrbitNeRF Instant NGP | TestBed | Lion Orbit <p>This video shows the effect of the \"Crop aabb\" control. It allows you to perform 3D bounding box region cropping operations of the NeRF scene.</p> NeRF Instant NGP | TestBed | 3D CroppingNeRF Instant NGP | TestBed | 3D Cropping <p>When you zoom out to the edge boundary zone of a NeRF scene you start to see floaty blobs that look a bit like fluffy/cloudy artifacts. Although it's not an officially used NeRF term, as far as I know, I like to call these glitches \"Neural Foam\" artifacts.</p> NeRF Instant NGP | TestBed | Cloudy Neural Foam Artifacts on Scene BoundaryNeRF Instant NGP | TestBed | Cloudy Neural Foam Artifacts on Scene Boundary <p>The NVIDIA Instant NGP library is very fast at performing NeRF model training and refinement. This clip captures the viewport from the moment the TestBed program is launched until the lion sample scene is refined to a point that is enjoyable to explore interactively in 3D.</p> NeRF Instant NGP | TestBed | Model TrainingNeRF Instant NGP | TestBed | Model Training","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#equipment-needed-to-explore-instant-ngp","title":"Equipment Needed to Explore Instant NGP","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#hardware-required","title":"Hardware Required","text":"<ul> <li>Windows or Linux based PC</li> <li>64 GB+ System RAM</li> <li>NVIDIA RTX 2000 or 3000 Series GPU</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#software-required","title":"Software Required","text":"<p>To run NeRF based workflows on your system you will need the following tools:</p> <ul> <li> Python 3.10.4</li> <li> Microsoft Visual Studio 2019 Community Edition</li> <li> Git Client</li> <li> NVIDIA GPU Driver</li> <li> NVIDIA CUDA Toolkit 11.6</li> <li> NVIDA OptiX 7.3</li> <li> NVIDIA Instant NGP</li> <li> CMake v3.23.1</li> <li>Colmap 3.7</li> <li>openCV-Python</li> <li>Numpy</li> <li> OpenEXR</li> <li>NotePad++</li> <li> FFMpeg</li> </ul> <p>Use of Conda, Rez, whatever...</p> <p>I'm avoiding discussing the topic of virtual environments like Conda in this guide in an effort to keep things focused primarily on the NeRF centric steps required. If you are comfortable with Conda or other virtual environments like Rez, feel free to bring that knowledge to play when you follow along at home. \ud83d\ude00</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#example-nerf-instant-ngp-dataset","title":"Example NeRF Instant NGP Dataset","text":"<p>Lion Sculpture @ Sir Sandford Fleming Park, Nova Scotia aka. \"The Dingle\" Park</p> <p> &gt; Nerf_instant_ngp_lion.zip (118 MB / 36 images)</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#build-instant-ngp","title":"Build Instant NGP","text":"<p>The following sections decribe how to setup an environment to build Instant NGP</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-1-install-python","title":"Step 1. Install Python","text":"<p>Download and install the 64-bit version of Python 3.10.4 by clicking on the \"Windows Installer (64-bit) link on the Python Release page.</p> <p></p> <p>To make things simpler for command prompt usage, in the Python installer, enable the checkbox to add Python to the system PATH.</p> <p></p> <p>We also want to override the install folder so Python is installed to C:\\Python310\\. This is achieved by changing the \"Customize install location\" text field contents to \"C:\\Python310\\\".</p> <p>Click the \"Install\" button to complete the Python install process.</p> <p></p> <p>After Python 3.10.4 is installed, open a new Windows Command Prompt in administrator mode.</p> <p>This is done by clicking on the start menu. Then start typing in the word \"command\" and autocomplete should filter the list of programs down to Command Prompt. Select the \"Run as administrator\" entry on the right side of this view.</p> <p></p> <p>In the command prompt window run the Python 3 version of the pip installer to add Numpy and OpenCV support.</p> <p>Numpy is installed using the command prompt window by typing in:</p> <pre><code>pip3 install numpy\n</code></pre> <p></p> <p>Then OpenCV is installed using the command prompt window by typing in:</p> <pre><code>pip3 install opencv-python\n</code></pre> <p></p> <p>Wrong Screenshot</p> <p>This is not an opencv-python install, but the numpy screenshot. Double checke: It has already been in the (Scrvener) source file.</p> <p>Command Prompt Tip: If you have copied a line of text you want to run into your clipboard copy buffer, in Windows 10, you can paste that text directly into the Command Prompt window by right-clicking in that view.</p> <p>Press enter to run the recently pasted in shell command.</p> <p>In order to use OpenEXR formatted images with Python and the testbed program we need to add the OpenEXR library.</p> <p>Download and install the OpenEXR supporting libraries for Python from:</p> <p>https://www.lfd.uci.edu/~gohlke/pythonlibs/#openexr</p> <p>Since we are using Python 3.10.4 we want to select the OpenEXR library that has \"CP310\" in the filename: \"OpenEXR-1.3.2-cp310-cp310-win_amd64.whl\".</p> <p>We can cut down the amount of time needed to scroll through that long webpage by copying the text \"OpenEXR-1.3.2-cp310-cp310-win_amd64\" into your clipboard.</p> <p>Then hit the Control+F shortcut to open your web-browser's \"Find\" dialog.</p> <p>Paste in the text from your clipboard and the webpage view will be paged down directly to that line. Click on that highlighted .whl file to download it.</p> <p></p> <p>Python PIP Tip: A .whl file is known as a Python \"Wheel\" package. This format is a convenient way to install extra Python libraries.</p> <p>The .whl file can be installed by changing the Command Prompt's current working directory to your user account's \"Downloads\" folder.</p> <p>Then we run the pip installer command with the filename of the local .whl package file specified:</p> <p>cd %HOMEPATH%\\Downloads</p> <p>pip3 install OpenEXR-1.3.2-cp310-cp310-win_amd64.whl</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-2-install-visual-studio-cmake","title":"Step 2. Install Visual Studio + CMake","text":"<p>Download Microsoft Visual Studio 2019 Community Edition. This is a C++ development environment that lets us compile programs. The community edition release is free to download and use at home.</p> <p>To access the 2019 release of Visual Studio, expand the \"2019\" heading on the left side of the webpage. Then click the \"Download\" button.</p> <p></p> <p>Because Visual Studio is made by Microsoft, you will need to login to the site with a Microsoft/Skype ID credential to access this download. This page will likely want to use 2-factor authentication if you aren't already logged in beforehand.</p> <p></p> <p>The exact version of the download is currently listed as \"Visual Studio Community 2019 (version 16.11)\" as of 2022-05-12. We are going for an x64 (64-bit) .exe download of a Multi Language release.</p> <p>Clicking the \"Download\" button will download a 1.4 MB sized web-installer program that is named \"vs_Community.exe\".</p> <p></p> <p>When the vs_Community installer launches you will be presented with a dialog that lists Microsoft's license terms. Click the \"Continue\" button to proceed.</p> <p></p> <p>The installer will then download a list of available Visual Studio packages you can add to your system. This takes a few moments to complete on a fast internet connection.</p> <p></p> <p>We only need to choose one option in this screen for our project today. In the main part of the view click on the large tile on the lower right area that is labelled \"Desktop development with C++\". The default installation entries that are pre-selected are fine for our needs. Click the \"Install\" button to continue.</p> <p></p> <p>This Visual Studio Community 2019 install is estimated to use about 8 GB of disk space. It will take a while to finish. At this point in the tutorial you can take a short break while the progress bar is working its way across the screen towards 100% completion.</p> <p></p> <p>When this dialog appears on your screen you'll know that Visual Studio 2019 is fully installed.</p> <p></p> <p>A Microsoft login prompt window will appear which allows you to launch Visual Studio and keep it up-to-date. This dialog is asking for your Microsoft / Skype login credentials to go to the next step.</p> <p></p> <p>After you click the \"Sign In\" button a 2-factor login dialog will appear. Click the \"Send code\" button to have a numerical 2-factor code sent automatically to your registered email address.</p> <p></p> <p>The single-use code should arrive in your email inbox in a few seconds.</p> <p></p> <p>With all of that taken care of we are now brought to the Visual Studio 2019 landing page view for the program. Click on the top-right corner of the window's \"X\" icon to close the view. This should quit Visual Studio and let us carry on further with the next step.</p> <p></p> <p>With Visual Studio installed, the next stage of the compiling software puzzle is to add a free utility called CMake.The CMake tool helps create \"makefiles\" which are used to prepare the computer-specific parameters for each of the supporting resources and libraries that a compiler requires to convert source code into executable software.</p> <p>Go to the CMake website and download v3.212.1 (or the current newest release). The CMake installer we want to use for a 64-bit version of Windows comes in an .msi format which is a self-running installer package format.</p> <p>To access this file, scroll down on the CMake Download page to the heading \"Latest Release\". Click to download the Binary distribution of the Windows x64 installer.</p> <p>The current file (as of 2022-05-12) is named \"cmake-3.23.1-windows-x86_64.msi\". The installer file is 27.9 MB in size.</p> <p></p> <p>Run the CMake installer. On the first screen click the \"Next\" button to continue.</p> <p></p> <p>On the \"End-User License Agreement\" screen you need to enable the \"[x] I accept the terms in the License Agreement\" checkbox. Click the \"Next\" button to continue.</p> <p></p> <p>On the \"Install Options\" screen if your computer is used by a single user, then you likely want to select the \"(x) Add CMake to the system PATH for the current user\" entry. Click the \"Next\" button to continue.</p> <p></p> <p>On the \"Ready to install CMake\" screen, click the \"Install\" button.</p> <p></p> <p>When the installer finishes we can exit it by clicking the \"Finish\" button.</p> <p></p> <p>The CMake installer provides a command line program, along with a visual user interface that can be launched from the start menu called \"CMake (cmake-gui)\".</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-3-install-nvidia-cuda-toolkit-and-optix","title":"Step 3. Install NVIDIA CUDA Toolkit and OptiX","text":"<p>Next we need to download the NVIDIA CUDA Toolkit 11.6 and NVIDA OptiX 7.3 installers. You will need to register for a free NVIDIA Developer Program account to download the Optix library.</p> <p>The CUDA Toolkit is used to create compiled software that is able to take advantage of NVIDIA CUDA based GPU acceleration.</p> <p>On the CUDA Toolkit 11.7 Downloads page, set the \"Operating System\" to \"Windows\". Then pick the default \"x86-64\" architecture. The \"Version\" control relates to your Windows OS version which in my case is Windows 10 so I would select \"10\". The \"Installer Type\" should be \"exe (local)\" for most users needs.</p> <p>Finally in the \"Download Installer for Windows 10 x86-64\" section of the page, scroll down to the \"Base Installer\" heading and click on the \"Download (2.5 GB)\" button.</p> <p>The file I downloaded was named \"cuda_11.7.0_516.01_windows.exe\". The specific version number will change over time. The installer download might take a few minutes to complete since it is 2.5 GB in size.</p> <p></p> <p>When you run the NVIDIA CUDA Toolkit installer you need to agree to the license terms to continue.</p> <p></p> <p>For most users the \"Express (Recommended)\" install option is the best choice. Click \"Next\" to continue.</p> <p>Note: The \"Express (Recommended)\" setting will also change the current NVIDIA display driver version. If you need to preserve your current display driver version then you might want to explore the \"Custom (Advanced)\" install option.</p> <p></p> <p>The NVIDIA CUDA Toolkit installation will start after a few moments.</p> <p></p> <p>A NVIDIA Nsight Visual Studio Edition Summary screen will appear. Clicking the \"Next\" button will advance the installer to the final screen.</p> <p></p> <p>At this point the NVIDIA CUDA Toolkit installer is finished and you can exit the program by clicking the \"Close\" button.</p> <p></p> <p>The OptiX library is used to allow the Visual Studio compiler to support building source code that relies on NVIDIA RTX GPU driven raytracing and interactive image denoising.</p> <p>On the \"NVIDIA OptiX Downloads\" page, scroll down to the \"Optix SDK 7.4.0 - (Windows, Linux, and ARM)\" section. Click on the green \"Windows 10, 64-bit Accept &amp; Download\" button to continue.</p> <p></p> <p>As mentioned previously, you will need to register for a free NVIDIA Developer Program account to download the Optix library. This takes only a few moments to complete.</p> <p></p> <p>If you need to register for a new account click the \"Join Now\" button. Otherwise, if you have an existing account click the \"Login\" button to continue. NVIDIA uses a 2-factor login system for this site so you will have to check your email for the login code and click the \"Verify Email Address\" button to proceed.</p> <p>The OptiX installer file \"NVIDIA-OptiX-SDK-7.4.0-win64.exe\" was a 53.5 MB download.</p> <p>On the first screen of the installer you need to click the \"Next\" button to continue.</p> <p></p> <p>On the \"License Agreement\" screen you need to click \"I Agree\" to continue.</p> <p></p> <p>The next few screens just require you to keep on clicking \"Next\" unless you feel the need to customize the settings.</p> <p></p> <p>To start the installation process click the \"Install\" button.</p> <p></p> <p>When the OptiX SDK installation process completes you can exit the installer by clicking on the \"Finish\" button.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-4-clone-the-instant-ngp-repository","title":"Step 4. Clone the Instant NGP Repository","text":"<p>Git is a technology that is frequently used to interface with online source code repositories like GitHub and GitLab. Git based software tools help with essential version control tasks during software development which is something that allows a team of programmers to work together effectively on the same project.</p> <p>This step in the tutorial assumes you don't already have a favourite git client like Git-Tower, or GitKraken, etc. installed on your system.</p> <p>We are now going to install a free open-source, command prompt based, git program by downloading and installing the Git Client tools. On the Git-SCM website's Download page, select the \"Windows\" option.</p> <p></p> <p>We are interested in downloading the Standalone Installer called \"64-bit Git for Windows Setup\". The installer is 47.3 MB in size and currently has the filename of \"Git-2.36.1-64-bit.exe\".</p> <p></p> <p>On the Git installer's \"Information\" screen you have to accept the GNU GPL license terms by hitting the \"Next\" button.</p> <p></p> <p>Most of the subsequent screens in the git installer can be navigated through without too much attention by leaving things pretty much at their default values and clicking the \"Next\" button each time.</p> <p></p> <p>You have the option of customizing the installed components.</p> <p></p> <p>You are able to configure the default text editor that is used by git. There are several options you can choose from the list.</p> <p></p> <p>As previously mentioned the default settings that are pre-selected for most of these screens are fine for the average user just getting started with git.</p> <p></p> <p>Since we want to be able to use the command line git utility from the Command Prompt window it is a good idea to select either the 2<sup>nd</sup> or 3<sup>rd</sup> options in the \"Adjusting your PATH environment\" screen.</p> <p>Personally, I think the 2<sup>nd</sup> option of \"(x) Git from the command line and also from 3<sup>rd</sup> party software\" is the most balanced and flexible choice for new users.</p> <p></p> <p>You can click the \"Next\" button on all remaining git installer screens to complete the process.</p> <p>Let's try out the git program for the first time! We are now ready to launch a Windows \"Command Prompt\" window with administrative permissions using the start menu.</p> <p></p> <p>With the command prompt window open, lets type in: <pre><code>cd \\\\\ngit clone --recursive https://github.com/nvlabs/instant-ngp\ncd instant-ngp\ndir /w\n</code></pre></p> <p>These commands will launch the git utility and it should automatically download the current version of the NVIDIA Instant NGP (Neural graphics primitives) source code from the GitHub website and save it to the root folder on the C:\\ drive at the folder path of \"C:\\instant-ngp\\\".</p> <p></p> <p></p> <p>Git Usage Note: You have the freedom to customize this git cloning download path but for convenience the shorter the filepath, the easier it is to access from a command prompt session when you go to run the testbed program later on. Also keep in mind that there is a limit to the length of a typical folder path on a default Windows system so if you download the files into a custom location of your own choosing and it happens to be a deeply nested hierarchy, you might be causing yourself trouble later on.</p> <p>Git Troubleshooting Tip: If you see an error message about git not being found in your system's PATH variable, you can double check things by typing the following text into the command prompt window. This will list the current contents of the PATH environment variable:</p> <p><pre><code>echo %PATH%\n</code></pre> Hopefully in this long list of folders that is separated by semi-colon characters you will spot an entry for \"C:\\Program Files\\Git\\cmd\"</p> <p>Git Troubleshooting Tip: We needed to use the Command Prompt with Administrative permissions in order to be able to download the Instant NGP files into the root folder on the C:\\ drive. If you do not have administrator permissions you could still follow this tutorial but instead would have to download the files to a location like a folder inside your user account's home folder.</p> <p>With the git downloading phase complete you should be able to navigate using the Windows Explore folder browsing view to open up the instant-npg folder. The path we installed the files to by default was \"C:\\instant-ngp\\\".</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-5-building-instant-ngp","title":"Step 5. Building Instant NGP","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#install-colmap","title":"Install COLMAP","text":"<p>COLMAP is a free cross-platform open-source camera alignment and photogrammetry (image based modelling) toolset. COLMAP is used by the Instant NGP python scripts to prepare the NeRF camera data before the training task is started.</p> <p></p> <p>Download Colmap 3.7 from the GitHub releases page as a pre-compiled Windows binary that has NVIDIA CUDA GPU acceleration enabled. This download is currently named \"COLMAP-3.7-windows-cuda.zip\" and is 129 MB in size.</p> <p></p> <p>Expand the zip archive and copy the expanded COLMAP folder to the root of your hard disk. Let's rename the COLMAP folder at the same time for easier command line usage. Change the folder name from \"C:\\COLMAP-3.7-windows-cuda\\\" to a shorter and simpler version by reducing the folder name down to merely \"C:\\COLMAP-3.7\\\".</p> <p></p> <p>Make sure to avoid installing COLMAP to a folder that has a space in the filepath or the Colmap unit tests will fail. This will occur if you placed COLMAP inside your home folder and your user account name has spaces between your first and last name. I repeat, spaces in the path will cause you headaches if you ignore this suggestion!</p> <p>Next we are going to add COLMAP's \"bin\" and \"lib\" folders to the system PATH environment variable using the Windows based System Control Panel.</p> <p>Power User Tip: It is worth mentioning now that if your Windows computer has complex dependencies caused by having several different versions of large DCC programs / development tools installed at the same time, along with several different Python versions installed concurrently too, and you use virtual environments as well, please feel free to customize this process to meet your needs.</p> <p>Click on the Windows Start menu. Then begin typing in the words \"View advanced system settings\" in the search dialog's text input area. By the time you've typed in the 2<sup>nd</sup> word the Start menu will likely have finished auto-completing the full text.</p> <p>Click the \"Open\" text based link on the right-side of the view to launch this Control Panel.</p> <p></p> <p>In the System Properties window click on the \"Environment Variables...\" button. This dialog is where custom environment variables like the system PATH are configured.</p> <p></p> <p>In the \"Environment Variables\" window click on the \"System Variables &gt; Path\" entry. Then click the \"Edit\" button. This will allow us to customize a version of the PATH variable that is used for all user accounts and background system processes, too.</p> <p></p> <p>In the \"Edit environment variable\" window click the \"New\" button to add an additional entry. Type in \"C:\\COLMAP-3.7\\bin\\\".</p> <p>Click the \"New\" button again and add a \"C:\\COLMAP-3.7\\lib\\\" entry as well. This will add the COLMAP .dll library files to the system PATH as well.</p> <p>This process will make the executables and libraries used by the COLMAP program easier to run from the command prompt without having to type in the full absolute path to each .exe file each time.</p> <p>If you wanted to get fancy one could spend more time down the road and customize other parameters like a QT_PLUGIN_PATH environment variable, too... but for our needs right now it is not required.</p> <p>Click the \"OK\" button to close this window. Then close the subsequent other Control Panel windows by clicking their \"OK\" buttons as well.</p> <p></p> <p>Environment Variables Tip 1: The \"PATH\" variable, which is written as %PATH% when accessed from the command prompt window, is used for several purposes. One of those use cases is to define which executable programs on your computer (.exe, .bat, etc files) can be run from a terminal session simply by typing in the program's base filename name without having to always write in the full folder path to the program. This saves a lot of time when a user frequently navigates a filesystem hierarchy in a text based command prompt/terminal window and runs a series of command line tools.</p> <p>Environment Variables Tip 2: An environment variable can be thought of as a system wide preference that any program that is started is able to read. An environment variable is a technique that system administrators will often use to customize the operating environment that software runs inside of on a workstation or render node. This concept of customizing environment variables allows you to pass a common set of preferences to multiple executable programs in a consistent way. It helps inform software of the custom values you might want to define system wide and avoids using hard-coded fixed settings in each application. It is possible to read environment variables inside of just about every general purpose programming language or scripting language like C, C++, C#, Python, Lua, Perl, PHP, Batch, and BASH/ZSH, etc.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#build-the-testbed-program","title":"Build the TestBed Program","text":"<p>Instant NGP uses a visual interface called TestBed to allow you to create scenes using NeRF (neural radiance field) rendering techniques. We need to compile thisTestBed program and at the same time adjust the CUDA parameters used at compile time to match the capabilities of our currently installed NVIDIA CUDA based GPU.</p> <p>Step 1. Start by opening a Visual Studio \"Developer Command Prompt\". This window will have the compiler specific environment variables tuned for using Visual Studio 2019's development tools.</p> <p>We do this step by clicking on the Start menu. Begin typing in the words \"Developer Command Prompt for VS 2019\". The rest of the text will be auto-completed for you.</p> <p>Click on the \"Run as administrator\" link.</p> <p></p> <p>Step 2. It is important to define the CUDA architecture before you build the testbed program. This will affect the maximum \"aabb_scale\" number you will be able to run in your transform.json file. For an RTX Series 3000 GPU the environment variable can be defined in the \"Command Prompt\" window using:</p> <p><pre><code>set TCNN_CUDA_ARCHITECTURES=86\n</code></pre> The result of setting this environment variable value can be verified by typing in:</p> <pre><code>echo %TCNN_CUDA_ARCHITECTURES%\n</code></pre> <p></p> <p>The echo command prints out the currently defined value for the environment variable you specify inside a pair of percent signs \"%\" which in the case of my screenshot is a value of \"86\".</p> <p>Further information on how to find the best \"TCNN_CUDA_ARCHITECTURES\" setting for your GPU can be read on the Instant NGP GitHub issues page here and by following that text's suggestion along to land on the Wikipedia link from that specific GitHub issue post.</p> <p>Step 3. When compiling software you can adjust how many CPU cores are used for the task. Set the \"-j 64\" entry below to match the number of CPU cores you want used during the compiling process. The number 64 in this case refers to 64 cores which works well for AMD Threadripper systems. If you have an Intel PC with 8 CPU cores you would use a value of \"-j 8\".</p> <p>The code below uses the CMake utility to create a new makefile for Instant NGP. This will add in the computer specific settings in the makefile so they match the file paths for the supporting resources and libraries you've already installed. After the makefile is created the source code is compiled.</p> <p><pre><code>cd C:\\instant-ngp\ncmake . -B build\ncmake --build build --config RelWithDebInfo -j 64\n</code></pre> If this task is completed successfully, you should now have a ready-to-run copy of the NeRF testbed program after a few minutes of compiling.\ud83e\udd73\ud83c\udf89\ud83c\udf81</p> <p></p> <p></p> <p></p> <p></p> <p>Congratulations if by some miracle you have managed to make it this far in the tutorial in a single reading session. Bonus points if you followed along with all the steps in your first run through of this document. Needless to say, I'm impressed!</p> <p>If the fates have smiled favourably on your freshly prepared compiler toolchain you should be able to peek inside the folder \"C:\\instant-ngp\\build\". If things worked out well you will see the new executable that you just compiled on your own home computer/workstation system. The exe file is named \"testbed.exe\". Yay.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#using-instant-ngp","title":"Using Instant NGP","text":"<p>Instant NGP is launched from the command line. It is possible to see a list of the available parameters by running the program with the \"help\" flag added from the command prompt which is done with the addition of \"-h\":</p> <p><pre><code>C:\\instant-ngp\\build\\testbed.exe -h\n</code></pre> </p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#testbed-command-line-syntax","title":"TestBed Command-Line Syntax","text":"<pre><code>C:\\instant-ngp\\build\\testbed {OPTIONS}\n\n    neural graphics primitives\n    version 1.0dev\n\n  OPTIONS:\n\n    -h, --help                      Display this help menu.\n    -m[MODE], --mode=[MODE]         Mode can be 'nerf', 'sdf', or 'image' or\n                                        'volume'. Inferred from the scene if\n                                        unspecified.\n    -n[CONFIG], -c[CONFIG],\n    --network=[CONFIG],\n    --config=[CONFIG]               Path to the network config. Uses the\n                                        scene's default if unspecified.\n    --no-gui                        Disables the GUI and instead reports\n                                        training progress on the command line.\n    --no-train                      Disables training on startup.\n    -s[SCENE], --scene=[SCENE]      The scene to load. Can be NeRF dataset,\n                                        a *.obj mesh for training a SDF, an\n                                        image, or a *.nvdb volume.\n    --snapshot=[SNAPSHOT]           Optional snapshot to load upon startup.\n    --width=[WIDTH]                 Resolution width of the GUI.\n    --height=[HEIGHT]               Resolution height of the GUI.\n    -v, --version                   Display the version of neural graphics\n                                        primitives.\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#explore-the-built-in-demo-scenes","title":"Explore the Built-in Demo Scenes","text":"<p><pre><code>cd C:\\instant-ngp\\\n</code></pre> The first scene that every new Instant NGP user needs to try out if this is their first time exploring realtime NeRF rendered visuals has to be the \"fox demo\".</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#fox-scene","title":"Fox Scene","text":"<p>A scene of an old taxidermy style stuffed fox can be viewed as a NeRF using:</p> <p>C:\\instant-ngp\\build\\testbed --scene data/nerf/fox</p> <p>In only a few moments the testbed program will launch.</p> <p></p> <p>A visual IMGUI based immediate mode user interface will appear and you can start panning the view to explore the 3D scene while the training process is carried out.</p> <p></p> <p>If you want to peek inside the fox scene's \"images\" folder to see the individual camera views that were used to train the testbed player in only a few moments, navigate using the Windows Explorer folder browsing view to:</p> <p><pre><code>C:\\instant-ngp\\data\\nerf\\fox\\images\n</code></pre> You will find 50 JPEG format photos that were photographed in a vertical portrait mode at 1080 x 1920 px resolution.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#armadillo-model","title":"Armadillo Model","text":"<p>A Wavefront OBJ format polygon model of an armadillo character is calculated as an SDF (Signed Distance Function) that can be viewed as a NeRF using:</p> <pre><code>C:\\instant-ngp\\build\\testbed --scene data/sdf/armadillo.obj\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#uprezzed-photo","title":"Uprezzed Photo","text":"<p>An uprezzed version of an old black and white Albert Einstein photo can be viewed as a NeRF using:</p> <pre><code>C:\\instant-ngp\\build\\testbed --scene data/image/albert.exr\n</code></pre> <p>When you pan in and then zoom around in the NeRF rendered photo, the testbed window will display a view that looks like this:</p> <p></p> <p>This example uses an EXR format image as the source media so you had to install the Python centric OpenEXR library files in the earlier steps to be able to load this image successfully.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#prepare-your-first-instant-ngp-scene","title":"Prepare your first Instant NGP Scene","text":"<p>Troubleshooting Image Filenames: A handy tip when creating your own NeRF scenes is to use simple filenames for your imagery. It is best to avoid complex long filenames as it will reduce the occurrence of frustrating issues later on.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-1-download-the-nerf_instant_ngp_lionzip-example-project","title":"Step 1. Download the \"Nerf_instant_ngp_lion.zip\" example project","text":"<p>Download the \"Nerf_instant_ngp_lion.zip\" example project near the top of this guide.</p> <p>Extract the \"lion\" folder from this zip archive and copy it to \"C:\\instant-ngp\\data\\nerf\\lion\\\".</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-2-run-colmap-using-the-included-colmap2nerfpy-script","title":"Step 2. Run COLMAP using the included \"colmap2nerf.py\" script.","text":"<p>Run COLMAP using the included \"colmap2nerf.py\" script. After a few minutes this script will generate a ready to use camera alignment JSON file.</p> <p><pre><code>cd C:\\instant-ngp\\\npython C:\\instant-ngp\\scripts\\colmap2nerf.py --colmap_matcher exhaustive --run_colmap --aabb_scale 16 --images data\\\\nerf\\\\lion\\\\images\n</code></pre> You will be asked a yes/no question when the COLMAP script starts. Press the letter \"Y\" to continue: <pre><code>warning! folders 'colmap_sparse' and 'colmap_text' will be deleted/replaced. continue? (Y/n) Y\n</code></pre></p> <p></p> <p>You will see screens and screens of progress text scroll continuously in the Command Prompt window as each image is aligned and registered by the COLMAP program:</p> <p></p> <p></p> <p>If everything worked out you should see a final line in the command prompt window that mentions \"writing transforms.json\". This means success was had.</p> <p>Troubleshooting Tip 1: If you skipped adding COLMAP's bin and lib folders to your system's PATH environment variable in the earlier steps, you will see the following error message when launching COLMAP:</p> <p>Colmap.exe - System Error dialog:</p> <p>The code execution cannot proceed because</p> <p>boost_filesystem-vc143-mt-x64-1_77.dll was not found. Reinstalling this program may fix this problem.</p> <p>If the COLMAP lib folder was not added to the PATH environment variable, you would also likely see subsequent messages about \"glew32.dll was not found\" and \"glog.dll was not found\".</p> <p>Troubleshooting Tip 2: If the Python OpenCV library was not installed you will see the following error message:</p> <p>Traceback (most recent call last):</p> <p>File \"C:\\instant-ngp\\scripts\\colmap2nerf.py\", line 19, in \\&lt;module&gt;</p> <p>import cv2</p> <p>ModuleNotFoundError: No module named 'cv2'</p> <p>Troubleshooting Tip 3: If the Python Numpy library was not installed you will see the following error message:</p> <p>Traceback (most recent call last):</p> <p>File \"C:\\instant-ngp\\scripts\\colmap2nerf.py\", line 15, in \\&lt;module&gt;</p> <p>import numpy as np</p> <p>ModuleNotFoundError: No module named 'numpy'</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-3-copy-the-colmap-generated-transformjson-file","title":"Step 3. Copy the COLMAP generated \"Transform.json\" file","text":"<p>Copy the COLMAP generated \"Transform.json\" file from inside the \"C:\\instant-ngp\\\" folder into \"C:\\instant-ngp\\data\\nerf\\lion\\\" folder.</p> <p></p> <p>This places the json document side-by-side in the current project, next to the individual NeRF scene's \"images\" folder.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#step-4-open-the-document-in-a-programmers-text-editing-tool","title":"Step 4. Open the document in a programmer's text editing tool","text":"<p>Open the document in a programmer's text editing tool like NotePad++.</p> <p>We need to edit the \"Transform.json\" text file to remove any filepath prefixes that might have been entered in the JSON document for each image resource. This edit can be carried out using a plain old-fashion \"Find &amp; Replace\" text substitution approach.</p> <p></p> <p>Open the Find &amp; Replace dialog using the Control+F hotkey.</p> <p>Switch at the top of the dialog to the \"Replace\" tab. Make sure to set the Notepad++ \"Search Mode\" setting to \"Normal\" to avoid having to worry about escaping the slash characters.</p> <p>Using the Find &amp; Replace dialog, set the \"Find what:\" field to:</p> <p>./data\\\\nerf\\\\lion\\\\</p> <p>Then in the \"Replace with:\" text field, clear it out so it contains nothing (\"\") at all and is blank. This setting will allow us to delete the extra folder paths from the start of each image entry in the JSON file.</p> <p>Press the \"Replace All\" button to carry out this editing task.</p> <p></p> <p>The final relative filepath, after editing, should look like this for an individual image in the JSON file:</p> <p>\"file_path\": \"images/lion.0001.jpg\",</p> <p></p> <p>COLMAP JSON Troubleshooting: If you forget to edit the Transforms.json file to make the image path relative you will likely see the following error when you carry on down to the next step and run the lion test scene in the testbed program:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#really-you-should-get-notepad-installed-asap","title":"Really, you should get Notepad++ Installed ASAP!","text":"<p>If you only have Microsoft's Notepad or Wordpad text editing programs installed on your Windows based PC, it is seriously worth mentioning that the free Notepad++ program does a great job at this type of JSON editing task.</p> <p>Don't hesitate to go and install NotePad++ now. Few other programmer centric text editors are as lean, simple, fast, and minimalist to use. I tend to think of Notepad++ as \"the Firefox\" of text editors.</p> <p>If you want to experience a really nicely optimized &amp; very refined version of Notepad++... and you happen to already use the Blackmagic Resolve/Fusion software, I'd encourage you to check out the Reactor Package Manager's \"Bin\" category. This version of \"Notepad++ for Fusion\" has all of the nice little thoughtful improvements you didn't know you were living without and missing in your life:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#check-your-camera-transforms-for-nans","title":"Check Your Camera Transforms for NaNs","text":"<p>When you are looking at the JSON file, do take a moment to page down visually through the transform matrix entries in the text file. You want to see if any floating point \"NaN\" values are present.</p> <p>In this situation a NaN number represents an invalid value similar to infinity being stored in the camera placement fields. If this exists in the JSON document it typically means the camera alignment task carried out in COLMAP generated invalid data on the output.</p> <p>You will likely have to remove source images that are causing issues, or re-photograph the scene again if the images are all fully planar without sufficient parallax between the camera views to be accurately aligned.</p> <p>Assuming there are no NaN values present in the JSON file, carry on to the next step.</p> <p>Step 5. The COLMAP camera locator based lion NeRF scene can be viewed using the testbed executable with the following command prompt based entries:</p> <pre><code>cd C:\\instant-ngp\\\nC:\\instant-ngp\\build\\testbed --scene data/nerf/lion --mode=nerf\n</code></pre> <p></p> <p>At this point you should be experiencing a lion sculpture in NeRF like style! After several seconds of training and refinement the view will become clearer. You can rotate the camera view around in the scene within limits and see the different angles on the sculpture.</p> <p></p> <p>TestBed Troubleshooting Tip</p> <p>If you get an error message when launching the TestBed program that says:</p> <p><pre><code>Could not free memory: C:\\\\instant-ngp\\\\dependencies\\\\tiny-cuda-nn\\\\include\\\\tiny-cuda-nn/gpu_memory.h:454 cudaDeviceSynchronize() failed with error operation not permitted when stream is capturing\n</code></pre> This error typically indicates that you needed to adjust the \"TCNN_CUDA_ARCHITECTURES\" environment variable back in the earlier \"Step 5.2 Building Instant NGP\" step of this guide.</p> <p>If you've done this process already and still get the error you can open the \"Transform.json\" document up in your text editor and lower the \"aabb_scale\" value which acts like a NeRF scene resolution parameter.</p> <p>Valid settings for the \"aabb_scale\" parameter are base 2 numbers such as 16, 8, 4, or 2. In this situation 16 is the best quality you can define at this time, and 2 is a much lower detail representation of the scene that might work on your GPU if you have less GPU VRAM available.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#using-the-testbed-program","title":"Using the TestBed Program","text":"<p>The TestBed UI is an immediate mode GUI that allows interactive control over the NeRF scene training and rendering process.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#camera-path","title":"Camera Path","text":"<p>The camera path controls allow you to keyframe animate a motion path through the scene. This data can be saved to disk and used to create a high quality command-line rendered animation of the NeRF scene.</p> <p></p> <p>After you click the \"Add from Cam\" button you can start to make an animated camera.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#training","title":"Training","text":"<p>The training section allows you to keep an eye on the scene's training progress.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#rendering","title":"Rendering","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#render-mode","title":"Render Mode","text":"<p>The \"Render Mode\" control allows you to toggle the type of render element you are viewing.</p> <p>The \"Shade\" control gives a regular RGB color rendered version of the scene that is photorealistic.</p> <p></p> <p>The \"AO\" control gives an ambient occlusion pass rendered version of the scene. AO is used to approximate the effects of indirect lighting in a CG scene. This is conceptually similar to the lighting conditions of an overcast day that has no direct lighting from the sun, which would otherwise cast hard shadows.</p> <p></p> <p>The \"Depth\" control gives a z-depth pass rendered version of the scene. The near-clipping plane distance is shaded as black (0 distance from the camera), and the far-clipping plane distance is shaded as while.</p> <p></p> <p>The \"Tonemap curve\" allows you to perform HDRI like image range remapping. This can allow you to compress the highlights and shadows in the scene.</p> <p>The \"Exposure\" control allows you to adjust the overall scene brightness.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#crop-aabb","title":"Crop aabb","text":"<p>The Crop controls allow you to define a 3D scene bounding-box that is used to clip off outside data. This can be used to isolate a cubic region around a model and remove all distracting data outside this region.</p> <p></p> <p>This is what it looks like if you crop the scene down to just a single object using a combination of the crop size and crop aabb controls:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#camera","title":"Camera","text":"<p>The \"Depth of field\" control is used to simulate lens defocus blur. This out of focus region effect is also called \"bokeh blur\" in photographic terms.</p> <p>The \"Field of view\" control is used to adjust the angle of view of the camera lens model.</p> <p>The \"Zoom\" control defaults to a value of 1.0. If you change this control it feels just like you are using a zoom lens attached to the camera.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#snapshot","title":"Snapshot","text":"<p>The snapshot controls allow you to export to disk the fully trained scene in its current state. You can also re-import training data from a prior session.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#marching-cubes-mesh-output","title":"Marching Cubes Mesh Output","text":"<p>This section of controls allows you to create a polygon mesh representation of the NeRF scene density.</p> <p></p> <p>The polygon formatted model output quality is not quite refined yet from the testbed NeRF program to satisfy the most demanding of users with a professional VFX/animation/games background. In many ways the meshing algorithms used at the moment are still lacking in refinements compared to traditional high-quality photogrammetry generated meshes.</p> <p>On the flip side though, pure NeRF display mode rendered visuals like plant vegetation already have the capacity to look a lot better than most photogrammetry captured vegetation like dense leaves on a tree, or grass. So there is some balance between the two techniques already.</p> <p></p> <p></p> <p>Meshing Tip: If you increase the \"Res\" setting to a value higher than your GPU's VRAM can support then the current testbed session will likely exit abruptly. You will then be returned back to the Command Prompt session with the following error message:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#history-of-trainable-encoding-parameters","title":"History of trainable encoding parameters","text":"<p>This control is a diagnostic element you can learn more about as you go deeper into exploring the testbed utility on more scenes.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Creating%20Volumetric%20NeRFs/#instant-ngp-web-resources","title":"Instant NGP Web Resources","text":"<p>The following web pages were of great help as I prepared this guide.</p> <p>TBH, if you get stuck on anything shown in this tutorial, you will likely find the answers you need to solve the problem branched off from the content on the following webpages:</p> <ul> <li>YouTube | NVIDIA Instant NeRF: NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI</li> <li>NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI</li> <li>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</li> <li>Instant Neural Graphics Primitives</li> <li>Got cutlass error: Error Internal at: 346\u00a0#455</li> <li>https://github.com/NVlabs/instant-ngp/issues/219#issuecomment-1055141789</li> <li>https://github.com/bycloudai/instant-ngp-Windows</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20Building%20an%20Effective%20nVP%20%28Neural%20Virtual%20Production%29%20Sound%20Stage/","title":"DEV Building an Effective nVP (Neural Virtual Production) Sound Stage","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Kartaverse Workflows | Building an Effective nVP (Neural Virtual Production) Sound Stage</p> <p>Kartaverse | nVP On-set Solutions</p> <p>First Draft</p> <p>Created: 2022-12-07 Last Updated 2022-12-10 07:30 AM UTC -4</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20Building%20an%20Effective%20nVP%20%28Neural%20Virtual%20Production%29%20Sound%20Stage/#ref12","title":"Overview","text":"<p>Overview</p> <p>This guide is a companion resource for the OpenDisplayXR VDD (Virtual Device Driver) and Kartaverse \"KartaVP\" open-source immersive content production pipeline projects. This draft document explains how to approach driving large-scale nVP (Neural Virtual Production) workflows in an efficient and performant fashion.</p> <p>Included with the guide is a high-level discussion of the back-end hardware systems integration considerations a new nVP sound stage operator needs to consider when switching away from traditional \"machinima\" style OpenGL/DirectX based LED panel rendering workflows.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20Building%20an%20Effective%20nVP%20%28Neural%20Virtual%20Production%29%20Sound%20Stage/#opengl-rasterization-rendering","title":"OpenGL Rasterization Rendering","text":"<p>OpenGL Rasterization Rendering</p> <p>OpenGL real-time rendering is still quite common, as of December 2022. OpenGL started out as IrisGL on SGI IRIX systems, and the descendant of that API is pretty much the number one option used in (legacy) rectilinear lens based rasterizer VP pipeline architectures.</p> <p>The fact that OpenGL rasterization techniques have endured for decades is impressive. Many of the essential OpenGL API developer documentation resources pre-date the 1997 release of the Nintendo64 GoldenEye 007 game. The N64 hardware performed photo-realistic rendering via OpenGL running on SGI (Silicon Graphics) derived graphics chips. It's a stunning technical and engineering accomplishment to keep the OpenGL API going in such a consistent fashion for so long, really! \ud83d\udc4d</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20Building%20an%20Effective%20nVP%20%28Neural%20Virtual%20Production%29%20Sound%20Stage/#neural-vp-rendering","title":"Neural VP Rendering","text":"<p>Neural VP Rendering</p> <p>KartaVP and the OpenDisplayXR VDD provided \"NeuralFoam Engine\" renderer are developed as cross-platform compatible, free open-source tools. This is an intentional choice to help move forward the objective of modernizing existing VP workflows with ML driven neural rendering techniques.</p> <p>With NeRF approaches, content creators can embrace recent advances in the state of the art technology used in volumetric video capture/playback.</p> <p>In 2023 the emergence of off-the-shelf nVP stage solutions will hopefully provide feature film-level DOPs (Director of Photography) with the chance to unlock exciting new potential for 100% real-time rendered digital environments. NeRF has already demonstrated its potential to deliver levels of photorealism (and rendering features) never witnessed in conventionalrasterized-based on-set virtual production systems deployed between 2015-2022.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20Building%20an%20Effective%20nVP%20%28Neural%20Virtual%20Production%29%20Sound%20Stage/#distributed-nerf-rendering-for-live-action-virtual-production-background-environments","title":"Distributed NeRF Rendering for Live-Action Virtual Production Background Environments","text":"<p>Distributed NeRF Rendering for Live-Action Virtual Production Background Environments</p> <p>If you review the OpenXR-VR Virtual Device Driver Google Docs file, you will see a \"Demo Apps\" section that has notes that cover a novel \"distributed NeRF rendering\" pipeline, and how that can be achieved in a modular fashion, (with relatively low design complexity), to power near-infinite LED video wall size, for an nVP stage setup that supports an arbitrary geometric screen surface shape.</p> <p></p> <p>This approach empowers the construction of highly-scalable virtual production workflows that use NeRF techniques on large-scale LED display panel based cylindrical VP sound stages.</p> <p>The core aspect is the use of a conventional 10 Gb Ethernet networked client/server method. This drives a genlock synced, GPU-powered, rack-mounted NeRF-based distributed rendering appliance.</p> <p>The key aspect is that the individual NeRF \"worker nodes'' are used as multi-view tile generators. Of special importance in the system design is to avoid the need of OpenGL quad buffer rendering support in the worker node's GPUs.</p> <p>One worker node is configured to direct-drive high-resolution 24Hz - 120 Hz output. The generated frame-buffer data is routed via an NewTek NDI IP video stream or a fibre-encoded SDI cable and either an ATEM switcher or SmartVideo Hub connection to either individual LED display panel's LED video processor unit.</p> <pre><code>    ![img/image5__fix10.png](&lt;../../img/image5__fix10.png&gt;)AJA NDI to SDI Encoder         ![img/image4__fix10.png](&lt;../../img/image4__fix10.png&gt;)BMD Smart Video Hub SDI Video Routing\n</code></pre> <p>Brompton Tessera S8 LED Processor           Roe Visual LED panel</p> <p>I feel this NeRF distributed rendering workflow best mirrors the concepts that Disguise, Unreal + nDisplay, Assimilate LiveFX, Notch, and TouchDesigner TouchEngine all support for OpenGL/DirectX rendered real-time \"Machinima\" content today.</p> <p>All NVIDIA InstantNGP API based NeRF rendering implementations support a cropped 3D DoD (Domain of Definition) bounding box.To fully optimize the render pipeline, and efficiently extract all usable VRAM on the NVLink bridge connected GPUs pairs; one needs to bind the active GPU worker node's \"nCam tracked\" camera view frustum to the precise DoD region cropping control in NVIDIA's InstantNGP testbed program.</p> <p>This DoD usage allows a VP production setup, that features an arbitrarily shaped LED panel based video wall, to handle voxel scene scales an order of magnitude larger than most people could ever conceivably imagine.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/","title":"DEV The Ultimate Guide to OpenUSD Pipeline Development","text":"<p>Overview</p> <p>This guide is a companion resource for the OpenDisplayXR VDD and Kartaverse \"KartaVP\" open-source immersive content production pipeline projects.</p> <p>This document explains how to approach Pixar OpenUSD asset-based best practices, and how to use those concepts to help drive large-scale nVP (Neural Virtual Production) workflows in an efficient and performant fashion.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#part-1-compiling-your-own-openusd-plugins","title":"Part 1 - Compiling your own OpenUSD Plugins","text":"<p>Note</p> <p>For this post, CentOS 7.x and the YUM package manager are going to be used for all the BASH CLI (command-line) shell examples.</p> <p>Compiling USD from source is the first step a TD needs to start with on the long journey towards being able to use the Fusion SDK C++ files to try and create USDC (Binary Crate)/USDA (ASCII) centric USDMesh3D and USDExporter nodes that would run inside of Fusion v16.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#its-usd-compile-time","title":"It's USD Compile Time!","text":"<p>Before we do any compiling we need to clone a copy of the PIXAR OpenUSD GitHub repo and save it in our <code>$HOME/usd/</code> folder.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-1-gnome-desktop-based-group-install-to-compile-openusd","title":"Step 1. \"Gnome Desktop\" based group install to compile OpenUSD","text":"<p>It helps to have a full \"Gnome Desktop\" based group install present on the system used to compile OpenUSD if you want to get going faster.</p> <p>YumGroupInstall.bsh <pre><code>sudo yum -y groupinstall \"GNOME Desktop\"\n</code></pre></p> <p>Note</p> <p>Compiling USD on a headless computer, and running with a CentOS minimal install can be frustrating to set up as it is initially missing a lot of libraries needed to compile a functioning copy of usdview.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-2-add-supporting-libs-to-your-redhatcentos","title":"Step 2. Add supporting libs to your RedHat/CentOS","text":"<p>Add the required supporting libraries to your Redhat/CentOS distro using Yum:</p> <p>YumInstallPackages.bsh <pre><code># YUM with devel files\nsudo yum install -y \\\n  alembic alembic-devel \\\n  boost boost-devel boost-filesystem boost-system boost-thread \\\n  bzip2 bzip2-devel \\\n  cmake \\\n  curl \\\n  glew glew-devel \\\n  glfw glfw-devel \\\n  hdf5 hdf5-devel \\\n  jemalloc jemalloc-devel \\\n  libpng libpng-devel libtiff libtiff-devel \\\n  OpenColorIO OpenColorIO-devel \\\n  OpenEXR OpenEXR-devel \\\n  OpenImageIO OpenImageIO-devel \\\n  PyOpenGL \\\n  python-devel python-jinja2 python-pip \\\n  qt-devel \\\n  tbb tbb-devel \\\n  gcc \\\n  doxygen graphviz\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-3-use-pip-to-add-pyside-for-the-pixar-usdviews-ui","title":"Step 3. Use PIP to add PySide for the PIXAR usdview's UI","text":"<p>Upgrade your copy of Python PIP. Then use PIP to add PySide which is required by the PIXAR usdview program's UI.</p> <p>PIPupgrade.bsh <pre><code># PIP\nsudo pip install --upgrade pip\nsudo pip install pyside\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-4-environment-variables-for-the-supporting-libs","title":"Step 4. Environment variables for the supporting libs","text":"<p>To help simplify the OpenUSD compiling process, let's define a set of environment variables that tell the compiler where to find the supporting libraries needed.</p> <p>This BASH shell example assumes you also want to compile a build of the OpenUSD plugins for Maya 2019, Katana v3.2, and RenderMan 22 on your system, and that you have the shipping version of Houdini installed.</p> <p>AddEnvVars.bsh <pre><code># Add these as temporary env vars\n{\n    export ALEMBIC_INCLUDE_DIR=/usr/include\n    export ALEMBIC_LIBRARIES=/usr/lib64/libAlembic.so\n    export ALEMBIC_LIBRARY_DIR=/usr/lib64\n    export BOOST_LIBRARYDIR=/usr/lib64\n    export DOXYGEN_EXECUTABLE=/usr/bin/doxygen\n    export DOT_EXECUTABLE=/usr/bin/dot\n    export EMBREE_LIBRARY=/usr/lib64\n    export EMBREE_INCLUDE_DIR=/usr/include\n    export OIIO_INCLUDE_DIR=/usr/include\n    export OIIO_LIBRARIES=/usr/lib64/libOpenImageIO.so\n    export OPENEXR_Half_LIBRARY=/usr/lib64/libHalf.so\n    export OPENEXR_INCLUDE_DIR=/usr/include\n    export OPENEXR_LIB=/usr/lib/\n    export OPENEXR_LIBRARY_DIR=/usr/lib\n    export OPENSUBDIV_INCLUDE_DIR=/usr/include\n    export PXR_BUILD_ALEMBIC_PLUGIN=TRUE\n    export PXR_ENABLE_PTEX_SUPPORT=FALSE\n    export PXR_MALLOC_LIBRARY=/usr/lib64/libjemalloc.so\n    export TBB_ROOT_DIR=/usr/include/\n    export DEVKIT_LOCATION=$HOME/devkitBase\n    export MAYA_LOCATION=/usr/autodesk/maya2019\n    export HOUDINI_ROOT=/opt/hfs17.5.229\n    export HOUDINI_BASE_DIR=/opt/hfs17.5.229\n    export HOUDINI_INCLUDE_DIRS=/opt/hfs17.5.229/toolkit/include\n    export HOUDINI_LIB_DIRS=/opt/hfs17.5.229/dsolib\n    export HOUDINI_VERSION=17.5.229\n    export KATANA_API_LOCATION=/opt/Katana3.2v1\n    export KATANA_API_INCLUDE_DIR=/opt/Katana3.2v1/plugin_apis/include\n    export KATANA_API_SOURCE_DIR=/opt/Katana3.2v1/plugin_apis/src\n    #export RENDERMAN_LOCATION=/opt/pixar/RenderManProServer-22.6\n    export RENDERMAN_LOCATION=$RMANTREE\n    export PXR_ENABLE_OSL_SUPPORT=FALSE\n    }\n</code></pre></p> <p>This snippet is handy if you want to print the active envrionment variables in your terminal session, and sort them alphabetically at the same time when you display the results:</p> <p>ListEnvVars.bsh <pre><code>env | sort\n</code></pre></p> <p>Note: We will leave the Houdini OpenUSD compiling process up to the makefiles that ship alongside of Houdini v17.5 or v18.</p> <p>This is due to \"Hython\" dependency hell that can occur when you naively intermix an OpenUSD library compile (or add to the <code>$PATH</code> env variable) parts of Hython and your operating system's version of Python.</p> <p>Below is a snippet of BASH terminal session output that documents what happens if you compiled and then added the PIXAR OpenUSD public repository's \"raw\" library files to your Houdini.env entry and started up Houdini.</p> <p>Short Summary: You do need to use the Hython modified/custom patched version of the OpenUSD makefiles that come with Houdini's installer to avoid making Houdini unhappy...</p> <p>Houdini.env <pre><code># USD for Houdini\nHOUDINI_PATH=/opt/r_usd/third_party/houdini:&amp;\nHOUDINI_DSO_ERROR=1\n\n#HOUDINI_DSO_PATH=@/plugin:/opt/r_usd/plugin:&amp;\nHOUDINI_DSO_PATH=@/plugin:&amp;\nHOUDINI_SCRIPT_PATH=@/scripts:/opt/r_usd/lib:&amp;\nHOUDINI_PYTHON_LIB=/usr/lib64/libpython2.7.so\n\u00a0\n[vfx@R01 ~]$ houdini\n------------------------ 'houdini-bin' is dying\n------------------------\nhoudini-bin crashed. FATAL ERROR: [TF_DEBUG_ENVIRONMENT_SYMBOL] multiple symbol definitions. \u00a0This is usually due to software misconfiguration. \u00a0Contact the build team for assistance. (duplicate 'TF_SCRIPT_MODULE_LOADER')\nin _Add at line 96 of /home/prisms/builder-new/WeeklyDevToolsHEAD/dev_tools/src/usd/usd-19.01/USD/pxr/base/lib/tf/debug.cpp\n\u00a0\nThe stack can be found in R01:/var/tmp/st_houdini-bin.12529\ndone.\n\n------------------------------------------------------------------\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-5-install-cmake-v322-to-allow-enabling-osl-support","title":"Step 5. Install CMake v3.2.2+ to allow enabling OSL support","text":"<p>If you want to enable OSL support you need to have CMake v3.2.2+. By default, my copy of CentOS had CMake v2.8.12.2.</p> <p>You can download CMake from: https://cmake.org/download/</p> <p>After you install CMake v3.2.2+, you need to override the standard built-in version of CMake. There are several ways you could handle this. I was lazy and did a CMake local install in my home folder and then added CMake to my <code>$PATH</code> environment variable via an edit to the <code>$HOME/.bash_profile/$HOME/.profile</code>.</p> <p>CMakePATH.bsh <pre><code># Add CMake v3 to the $PATH\nexport PATH=$HOME/cmake-3.15.3-Linux-x86_64/bin:$PATH:$HOME/.local/bin:$HOME/bin\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-6-compile-osl","title":"Step 6. Compile OSL.","text":"<p>Once you have the right version of CMake present, you can then compile OSL.</p> <p>Using OSL in your USDC and USDA files is exciting since you can see the results inside of usdview if you compiled in support for the PIXAR PRman renderer, too.</p> <p>AddOSL.bsh <pre><code># OSL for PRman in USDView\n# OSL requires OpenEXR v2.0 but CentOS has OpenEXR v1.6.1 by default\ncd $HOME/\ngit clone https://github.com/imageworks/OpenShadingLanguage.git osl\ncd $HOME/osl\nmake\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-7-clear-out-any-old-usd-builds","title":"Step 7. Clear out any old USD builds","text":"<p>Clear out any of your old USD builds if you've done this process before, then re-create the build folder:</p> <p>ClearOldBuilds.bsh <pre><code># Clear the old build\nsudo rm -rf /opt/r_usd/\n\n# Create the output folder and make it writable during development\nsudo mkdir -p /opt/r_usd/\nsudo chmod 777 /opt/r_usd/\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-8-run-openusd-build-script","title":"Step 8. Run OpenUSD build script","text":"<p>Run the PIXAR OpenUSD build script to create the exact deliverables you want:</p> <p>RunBuildScript1.bsh <pre><code># Run the USD build script\ncd $HOME/usd/build_scripts\n\u00a0\n# Create an initial USDView only build of OpenUSD\n# (--prman enables RenderMan support)\npython build_usd.py \\\n  --no-tests \\\n  --alembic \\\n  --opencolorio \\\n  --openimageio \\\n  --python \\\n  --usdview \\\n  --prman \\\n  /opt/r_usd/\n</code></pre></p> <p>RunBuildScript2.bsh <pre><code># Run the USD build script\ncd $HOME/usd/build_scripts\n\n# Then create the Maya and Katana OpenUSD compiled plugins\npython build_usd.py \\\n  --no-tests \\\n  --alembic \\\n  --opencolorio \\\n  --openimageio \\\n  --python \\\n  --maya \\\n  --katana \\\n  --usdview \\\n  /opt/r_usd/\n</code></pre></p> <p>RunBuildScript3.bsh <pre><code># Run the USD build script\ncd $HOME/usd/build_scripts\n\u00a0\n# Optional create just the Katana OpenUSD compiled plugin:\npython build_usd.py \\\n  --katana \\\n  --katana-api-location /opt/Katana3.2v1 \\\n  /opt/r_usd/\n</code></pre></p> <p>RunBuildScript4.bsh <pre><code># Run the USD build script\ncd $HOME/usd/build_scripts\n\n# Optional (but you don't want to do this yourself\n# with the \"raw\" original makefiles found on the\n# PIXAR OpenUSD Repo..) create the Houdini OpenUSD\n# Compiled plugin\npython build_usd.py \\\n  --no-tests \\\n  --alembic \\\n  --opencolorio \\\n  --openimageio \\\n  --python \\\n  --houdini \\\n  --usdview \\\n  /opt/r_usd/\n</code></pre></p> <p>Note: We are skipping the OpenUSD compile options for the following <code>build_usd.py</code> CLI (command-line) flag entries:</p> <p>ExcludedBuildUSDFlags.bsh <pre><code>  1  --houdini\n  2  --docs\n  3  --embree\n  4  --ptex\n  5  --hdf5\n</code></pre></p> <p>(hdf5 is the legacy Alembic format that was superseded by Alembic Ogawa.)</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-9-use-openusd-plugins-in-single-environments","title":"Step 9. Use OpenUSD plugins in single environments","text":"<p>If you plan to use your compiled copy of the OpenUSD plugins in a single-user artist/TD environment you could edit your <code>$HOME/.bash_profile</code> to add entries like the example below.</p> <p>An OpenUSD Centric .bash_profile Example:</p> <p></p> <p>.bash_profile <pre><code># .bash_profile\n\u00a0\n# Get the aliases and functions\nif [ -f ~/.bashrc ]; then\n    \u00a0 \u00a0 \u00a0 \u00a0 . ~/.bashrc\nfi\n    \u00a0\n# User specific environment and startup programs\nexport PATH=$PATH:$HOME/.local/bin:$HOME/bin\n    \u00a0\n# RenderMan 22.6\n# export PATH=\"/opt/pixar/RenderManProServer-22.6/bin/:$PATH\"\nexport RMANTREE=\"/opt/pixar/RenderManProServer-22.6/\"\nexport RMSTREE=\"/opt/pixar/RenderManForMaya-22.6/\"\nexport PIXAR_LICENSE_FILE=9010@localhost\n\n# RenderMan 22.6 for Katana 3.2\nexport DEFAULT_RENDERER=prman\nexport KATANA_RESOURCES=\"/opt/pixar/RenderManForKatana-22.6-katana3.2/plugins/Resources/PRMan22/\"\nexport PATH=\"/opt/Katana3.2v1/:$PATH\"\n\u00a0\n# USD\nexport PATH=$PATH:/opt/r_usd/bin\nexport PYTHONPATH=/opt/r_usd/lib/python\n\n# USD for Katana\nexport PYTHONPATH=$PYTHONPATH:/opt/r_usd/lib/python\nexport KATANA_RESOURCES=$KATANA_RESOURCES:/opt/r_usd/third_party/katana/plugin\nexport KATANA_POST_PYTHONPATH=$KATANA_RESOURCES:/opt/r_usd/third_party/katana/lib\n\n# Houdini 17.5.229\n#cd /opt/hfs17.5\n#source houdini_setup\n#cd $HOME\n</code></pre></p> <p>If you are working in a multi-user environment you might want to consider switching over to a REZ based configuration, build, and deployment system.</p> <p>And humorously, by random coincidence, REZ's official slogan is \"Resolve it with rez\" which seems in line with a WSL user's goal of eventually running OpenUSD inside of Resolve (and Fusion Standalone). </p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-10-download-the-kitchen_set-example-usd-scene","title":"Step 10. Download the \"Kitchen_set\" example USD scene","text":"<p>Next, you need to download the PIXAR \"Kitchen_set\" example USD scene.</p> <p>PIXAR USD &gt; Assets &gt; Download Kitchen Set</p> <p></p> <p>After you expand the ZIP archive for the Kitchen_set.zip\" example, you can then browse the very efficiently nested hierarchy of USD composed models:</p> <p>Exploring the Kitchen_set Example Assets</p> <p></p> <p>The USD scene is composed using the \"Kitchen_set.usd\" file.</p> <p></p> <p>The \"<code>Kitchen_set.usd</code>\" file is a USDA (ASCII) file that can be viewed in a programmer's plain text editor. References to the placed OpenSubdiv based polygon model assets are visible in each of the \"<code>add references = @./assets/Blah/Blah.usd@</code>\" like sections in the USDA file.</p> <p></p> <p>If you open up the \"assets\" folder, then open up the \"Cheerio\" folder you can inspect one of the OpenSubdiv based models in usdview to get an idea of the individual elements that are used in the scene.</p> <p></p> <p>The \"<code>Cheerio.usd</code>\" file is a USDA (ASCII) document that can be viewed in a programer's plain text editor. The \"<code>Cheerio.usd</code>\" file lists two model variants named \"CheerioA\" and \"CheerioB\". These variants are alternated between randomly when the bowl on the table in the full kitchen scene is filled via USD instancing of the cheerio model.</p> <p></p> <p>After the Cheerio model is loaded in \"usdview\", you can enable the \"View &gt; Shading Mode &gt; WireframeOnShaded\" menu item based rendering method to see a preview of the finished model. It helps if you also enable the OpenSubdiv based realtime mesh smoothing feature using the \"View &gt; Complexity &gt; Very High\" menu item, too.</p> <p></p> <p>Finally, we can view the \"<code>Kitchen_set/Kitchen_set.usd</code>\" file in our freshly compiled copy of usdview:</p> <p>KitchenSetInUSDView.bsh <pre><code>usdview '$HOME/Downloads/Kitchen_set/Kitchen_set.usd'\n</code></pre></p> <p>This results in usdview launching and the OpenSubdiv based example scene being loaded:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-11-setup-openusd-plugin-in-mayaenv","title":"Step 11. Setup OpenUSD plugin in Maya.env","text":"<p>Setup the OpenUSD plugin in your Maya 2019 Maya.env file:</p> <p>Maya.env <pre><code># Suppress Arnold not found error message\nMAYA_NO_WARNING_FOR_MISSING_DEFAULT_RENDERER=1\n\n# Set the CIP disable flag\nMAYA_DISABLE_CIP=1\n\n# USD for Maya\nMAYA_PLUG_IN_PATH=$MAYA_PLUG_IN_PATH:/opt/r_usd/third_party/maya/plugin\n\nXBMLANGPATH=$XBMLANGPATH/%B:/opt/r_usd/third_party/maya/lib/usd/usdMaya/resources/%B\n\nMAYA_SCRIPT_PATH=$MAYA_SCRIPT_PATH:/opt/r_usd/third_party/maya/lib/usd/usdMaya/resources/:/opt/r_usd/third_party/maya/plugin/pxrUsdPreviewSurface/resources\n\u00a0\nPYTHONPATH=$PYTHONPATH:/opt/r_usd/lib/python\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-12-double-check-katana-environment-variables","title":"Step 12. Double-check Katana environment variables","text":"<p>Double-check your Katana environment variables to make sure they exist for your active session:</p> <p>.profile <pre><code>export PYTHONPATH=$PYTHONPATH:/opt/r_usd/lib/python\n\nexport KATANA_RESOURCES=$KATANA_RESOURCES:/opt/r_usd/third_party/katana/plugin\n\nexport KATANA_POST_PYTHONPATH=$KATANA_RESOURCES:/opt/r_usd/third_party/katana/lib\n</code></pre></p> <p>When you start using OpenUSD inside of RenderMan for Katana, you will typically interact with the PxrUsdIn node in the Katana Node graph as the primary way to load all models, textures, and lights.</p> <p>Here are two screenshots that show Katana running with the PIXAR \"Kitchen_set\" example scene:</p> <p></p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-13-links-for-the-main-extra-libraries","title":"Step 13. Links for the main \"extra\" libraries","text":"<p>If you need them, here are the GitHub repo/webpage links for the main \"extra\" libraries you can compile when building your own full-featured PIXAR OpenUSD plugins.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#openusd","title":"OpenUSD","text":"<ul> <li>https://graphics.pixar.com/usd/docs/index.html</li> <li>https://github.com/PixarAnimationStudios/USD</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#houdini-openusd","title":"Houdini OpenUSD","text":"<ul> <li>Houdini-USD-Plugins</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#katana-openusd","title":"Katana OpenUSD","text":"<ul> <li>http://openusd.org/docs/Katana-USD-Plugins.html</li> <li>Local Resource: <code>/opt/Katana3.2v1/docs/dev_guide/</code></li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#maya-devkit","title":"Maya DevKit","text":"<ul> <li>http://openusd.org/docs/Maya-USD-Plugins.html</li> <li>Where is the Maya 2016 devkit Note: Install the Maya devkit in the <code>$HOME</code> folder then set the two env vars \"<code>DEVKIT_LOCATION</code>\" and \"<code>MAYA_LOCATION</code>\".</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#opensubdiv","title":"OpenSubdiv","text":"<ul> <li>https://github.com/PixarAnimationStudios/OpenSubdiv</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#ptex","title":"PTEX","text":"<ul> <li>https://github.com/wdas/ptex/</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#alembic","title":"Alembic","text":"<ul> <li>https://github.com/alembic/alembic</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#jemalloc","title":"jemalloc","text":"<ul> <li>https://github.com/jemalloc/jemalloc</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#flex","title":"Flex","text":"<ul> <li>https://github.com/westes/flex</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#bison","title":"Bison","text":"<ul> <li>https://www.gnu.org/software/bison/</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#jinja2","title":"Jinja2","text":"<ul> <li>http://jinja.pocoo.org/docs/dev/</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#argparse","title":"Argparse","text":"<ul> <li>https://docs.python.org/3/library/argparse.html</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#find-rpms","title":"Find RPMs","text":"<ul> <li>https://pkgs.org/</li> <li>https://www.rpmfind.net/linux/RPM/index.html</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-14-cmake-examples-to-build-the-common-libraries","title":"Step 14. CMake examples to build the common libraries","text":"<p>Here are cmake CLI (command-line) BASH examples that can be used to build the common libraries you might add to OpenUSD:</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#pixar-opensubdiv","title":"Pixar OpenSubdiv","text":"<p>OpenSubdiv.bsh <pre><code># OpenSubdiv\nmkdir -p $HOME/OpenSubdiv/build\ncd $HOME/\ngit clone https://github.com/PixarAnimationStudios/OpenSubdiv\ncd $HOME/OpenSubdiv/build\ncmake -D NO_PTEX=1 -D NO_DOC=1 \\\n\u00a0 \u00a0 \u00a0 -D NO_OMP=1 -D NO_TBB=1 -D NO_CUDA=1 -D NO_OPENCL=1 -D NO_CLEW=1 \\\n\u00a0 \u00a0 \u00a0 -D GLEW_LOCATION=\"/usr/include/GL\" \\\n\u00a0 \u00a0 \u00a0 -D GLFW_LOCATION=\"/usr/include/GLFW\" \\\n\u00a0 \u00a0 \u00a0 ..\nsudo cmake --build . --target install -- -j 63\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#walt-disney-animation-studios-ptex","title":"Walt Disney Animation Studios PTEX","text":"<p>PTEX.bsh <pre><code>#PTEX\ngit clone https://github.com/wdas/ptex/\ncd $HOME/ptex\n# ...\n# ...\n# ...\n</code></pre></p> <p>Note: If you don't have X11 installed you will likely get errors from: Q_WS_X11 LibXml2 LibXslt</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#intel-embree","title":"Intel Embree","text":"<p>Embree.bsh <pre><code># Embree\ncd $HOME\nwget https://github.com/embree/embree/releases/download/v3.5.2/embree-3.5.2.x86_64.rpm.tar.gz\ntar xzf embree-3.5.2.x86_64.rpm.tar.gz\nsudo rpm --install embree3-*.rpm\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-15-flags-for-the-build_usdpy-based-compile","title":"Step 15. Flags for the <code>build_usd.py</code> based compile","text":"<p>It's a good idea to have a clear idea of the available flags you can specify in the CLI (command-line) when running the PIXAR OpenUSD build_usd.py compiling process on your own.</p> <p>Code: [Select all]\u00a0[Expand/Collapse]\u00a0[Download] (build_usd.bsh)</p> <p><pre><code>vfx@R01 build_scripts]$ python build_usd.py\n</code></pre> <pre><code>usage: build_usd.py [-h]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [-n]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [-v | -q]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [-j JOBS]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--build BUILD]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--build-args [BUILD_ARGS [BUILD_ARGS ...]]]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--force FORCE_BUILD]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--force-all]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--generator GENERATOR]\n    \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--src SRC]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--inst INST]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--build-shared | --build-monolithic] [--debug]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--tests | --no-tests]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--docs | --no-docs]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--python | --no-python]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--imaging | --usd-imaging | --no-imaging]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--ptex | --no-ptex]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0 \u00a0 [--usdview | --no-usdview]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--embree | --no-embree]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--embree-location EMBREE_LOCATION]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--openimageio | --no-openimageio]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--opencolorio | --no-opencolorio]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--alembic | --no-alembic]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [--hdf5 | --no-hdf5]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [--materialx | --no-materialx]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [--maya | --no-maya]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--maya-location MAYA_LOCATION]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--katana | --no-katana]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [--katana-api-location KATANA_API_LOCATION]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [--houdini | --no-houdini]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [--houdini-location HOUDINI_LOCATION]\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  install_dir\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-16-build-process-terminal-output","title":"Step 16. Build process terminal output","text":"<p>After the build_usd.py script has been used to create usdview and the 3<sup>rd</sup> party OpenUSD plugins are compiled successfully, you will see output like this in the terminal:</p> <p>BuildResults.bsh* <pre><code>vfx@R01 build_scripts]$ python build_usd.py /opt/r_usd/\n</code></pre> <pre><code>Building with settings:\n\u00a0 USD source directory \u00a0 \u00a0 \u00a0 \u00a0 \u00a0/home/vfx/USD\n\u00a0 USD install directory \u00a0 \u00a0 \u00a0 \u00a0 /opt/r_usd/\n\u00a0 3rd-party source directory \u00a0 \u00a0/opt/r_usd/src\n\u00a0 3rd-party install directory \u00a0 /opt/r_usd/USD\n\u00a0 Build directory \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 /opt/r_usd/build\n\u00a0 CMake generator \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Default\n\u00a0 Downloader \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0curl\n\u00a0\n\u00a0 Building \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Shared libraries\n\u00a0 \u00a0 Config \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Release\n\u00a0 \u00a0 Imaging \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 On\n\u00a0 \u00a0 Ptex support: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n\u00a0 \u00a0 OpenImageIO support: \u00a0 \u00a0 \u00a0Off\n \u00a0 \u00a0OpenColorIO support: \u00a0 \u00a0 \u00a0Off\n \u00a0UsdImaging \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0On\n \u00a0 \u00a0usdview: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0On\n\u00a0 Python support \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0On\n\u00a0 Documentation \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n\u00a0 Tests \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n \u00a0Alembic Plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Off\n \u00a0\u00a0 HDF5 support: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n  MaterialX Plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Off\n  Maya Plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n  Katana Plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Off\n  Houdini Plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Off\n\n\u00a0 Dependencies \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0boost, TBB, OpenEXR, GLEW, OpenSubdiv\nSTATUS: Installing boost...\nSTATUS: Installing TBB...\nSTATUS: Installing OpenEXR...\nSTATUS: Installing GLEW...\nSTATUS: Installing OpenSubdiv...\nSTATUS: Installing USD...\n\nSuccess! To use USD, please ensure that you have:\n\nThe following in your PYTHONPATH environment variable:\n/opt/r_usd/lib/python\n\nThe following in your PATH environment variable:\n/opt/r_usd/bin\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#step-17-usd-tools-you-can-run-from-the-cli","title":"Step 17. USD tools you can run from the CLI","text":"<p>With OpenUSD installed on your system the <code>/opt/r_usd/USD/bin/</code> folder will have the following USD tools you can run from the CLI (command-line):</p> <p></p> <ul> <li>cjpeg</li> <li>djpeg</li> <li>exrenvmap</li> <li>exrheader</li> <li>exrmakepreview</li> <li>exrmaketiled</li> <li>exrmultipart</li> <li>exrmultiview</li> <li>exrstdattr</li> <li>jpegtran</li> <li>libpng16-config</li> <li>libpng-config</li> <li>pngfix</li> <li>png-fix-itxt</li> <li>rdjpgcom</li> <li>sdfdump</li> <li>sdffilter</li> <li>stringify</li> <li>testusdview</li> <li>usdcat</li> <li>usdchecker</li> <li>usddiff</li> <li>usddumpcrate</li> <li>usdedit</li> <li>usdGenSchema</li> <li>usdresolve</li> <li>usdstitch</li> <li>usdstitchclips</li> <li>usdtree</li> <li>usdview</li> <li>usdzip</li> <li>wrjpgcom</li> </ul> <p>You will also have the following Alembic tools you can use from the CLI (command-line), too:</p> <ul> <li>abcconvert</li> <li>abcdiff</li> <li>abcecho</li> <li>abcechobounds</li> <li>abcls</li> <li>abcstitcher</li> <li>Abctree</li> </ul> <p>Stay tuned for part 2. More to follow. </p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#part-2-houdini-18","title":"Part 2 - Houdini 18","text":"<p>Houdini v18 Released</p> <p>Houdini v18 shipped today with support for Windows/Linux/macOS systems. Now anyone can download Houdini Apprentice for free from SideFX and try out the Solaris integration.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#screenshots","title":"Screenshots","text":"<p>Here's a quick screenshot of the PIXAR \"Kitchen_set.usd\" scene loaded up using a stock Houdini \"File\" node from inside a Geo node.</p> <p></p> <p>And here's a quick view of the Houdini Solaris \"Stage\" environment:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#houdini-bundled-usd-cli-tools","title":"Houdini Bundled USD CLI Tools","text":"<p>Houdini 18 ships with Hython compiled CLI (command-line) copies of the following core USD tools:</p> <ul> <li>usdcat</li> <li>usddiff</li> <li>usdedit</li> <li>usdresolve</li> <li>usdstitchclips</li> <li>usdview</li> <li>usdchecker</li> <li>usddumpcrate</li> <li>usdrecord</li> <li>usdstitch</li> <li>usdtree</li> <li>usdzip</li> </ul> <p>On a macOS system running Houdini v18.0.287 these USD CLI tools are located in the folder: <pre><code>/Applications/Houdini/Houdini18.0.287/Frameworks/Houdini.framework/Versions/Current/Resources/bin/\n</code></pre></p> <p>On a Windows 10 system running Houdini v18.0.287 these USD CLI tools are located in the folder: <pre><code>C:\\Program Files\\Side Effects Software\\Houdini 18.0.287\\bin\\\n</code></pre></p> <p>On a CentOS 7.x system running Houdini v18.0.287 these USD CLI tools are located in the folder: <pre><code>/opt/hfs18.0.287/bin/\n</code></pre></p> <p>You can source Houdini on Linux's environment variables using: <pre><code>cd /opt/hfs18.0.287/\nsource houdini_setup\n</code></pre></p> <p>You can source Houdini on macOS's environment variables using: <pre><code>cd /Applications/Houdini/Houdini18.0.287/Frameworks/Houdini.framework/Versions/Current/Resources\nsource houdini_setup\n</code></pre></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#running-houdinis-provided-copy-of-usdview","title":"Running Houdini's Provided Copy of USDVIEW","text":"<p>Houdini v18 provides a <code>usdview.bat</code> launching script on Windows 10 in the Houdini \"<code>bin</code>\" folder. Inside the bat file the script runs the code: <pre><code>hython %HFS%/bin/usdview %*\n</code></pre></p> <p>If you haven't loaded Houdini 18's bin folder into your <code>%PATH%</code> environment variable, from a fresh Command Prompt session you could launch usdview using: <pre><code>\"C:\\Program Files\\Side Effects Software\\Houdini 18.0.287\\bin\\hython2.7.exe\" \"C:\\Program Files\\Side Effects Software\\Houdini 18.0.287\\bin\\usdview\" Kitchen_set.usd\n</code></pre></p> <p></p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#part-3-fusion-studio","title":"Part 3 - Fusion Studio","text":"<p>The KartaVR \"Export Point Cloud\" script now supports Fusion PointCloud3D node data export to XYZ ASCII (.xyz), PLY ASCII (.ply), Maya ASCII (.ma), and PIXAR USDA ASCII (.usda) formats from Fusion.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#translating-fusion-3d-system-nodes-into-the-usd-ascii-format","title":"Translating Fusion 3D System Nodes into the USD ASCII Format","text":"<p>The current version of the \"Export Point Cloud\" script that is in Reactor's \"KartaVR/Scripts\" category in the \"KartaVR Scripts | Virtual Production\" atom package can now do PointCloud3D node based exports to a lot of formats, and also a whole lot more, too.</p> <p></p> <p>I'm excited about building out a more complete set of KartaVR based camera/point cloud/volumetric video/mesh sequence tools to help production artists start to embracing what PIXAR's USD technology can do for allowing seamless data interchange of both 3D scene graph information and volumetric assets.</p> <p>As a side bonus some of these tool creation efforts, things like the \"Export Point Cloud\" script might just become an essential addon for Fusion compositors that want to take on matchmoving, point cloud workflows, or push their matte painting and texture projection workflows further.</p> <p>The most recent thing I've been exploring is how to support animated USD ASCII exporting of Fusion Camera3D node based cameras from the Fusion 3D system into a .usda file export.</p> <p>Here's a sample output from the \"Export Point Cloud\" script that is saves out a animated Camera3D node as USD formatted data using the timeSamples option to store per-frame keyframe data on the rotateXYZ and translate elements in the USDA file:</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#camera3dusda","title":"Camera3D.usda","text":"<pre><code>#usda 1.0\n(\n    defaultPrim = \"AnimatedCamera3D\"\n    doc = \"\"\"Generated from Composed Stage of root layer /Users/andrew/Downloads/FusionAnimatedCamera/AnimatedCamera.comp\"\"\"\n    metersPerUnit = 0.01\n    upAxis = \"Y\"\n)\n\ndef Xform \"AnimatedCamera3D\" (\n    kind = \"assembly\"\n)\n{\n    float3 xformOp:rotateXYZ.timeSamples = {\n        0: (-37, -16.200000762939, 0),\n        1: (-36.618713450292, -16.415570938378, 0),\n        2: (-36.237426900585, -16.631141113817, 0),\n        3: (-35.856140350877, -16.846711289255, 0),\n        4: (-35.47485380117, -17.062281464694, 0),\n        5: (-35.093567251462, -17.277851640132, 0),\n        6: (-34.712280701754, -17.493421815571, 0),\n        7: (-34.330994152047, -17.70899199101, 0),\n        8: (-33.949707602339, -17.924562166448, 0),\n        9: (-33.568421052632, -18.140132341887, 0),\n        10: (-33.187134502924, -18.355702517325, 0),\n        11: (-32.805847953216, -18.571272692764, 0),\n        12: (-32.424561403509, -18.786842868203, 0),\n        13: (-32.043274853801, -19.002413043641, 0),\n        14: (-31.661988304094, -19.21798321908, 0),\n        15: (-31.280701754386, -19.433553394518, 0),\n        16: (-30.899415204678, -19.649123569957, 0),\n        17: (-30.518128654971, -19.864693745396, 0),\n        18: (-30.136842105263, -20.080263920834, 0),\n        19: (-29.755555555556, -20.295834096273, 0),\n        20: (-29.374269005848, -20.511404271711, 0),\n        21: (-28.99298245614, -20.72697444715, 0),\n        22: (-28.611695906433, -20.942544622589, 0),\n        23: (-28.230409356725, -21.158114798027, 0),\n        24: (-27.849122807018, -21.373684973466, 0),\n        25: (-27.46783625731, -21.589255148904, 0),\n        26: (-27.086549707602, -21.804825324343, 0),\n        27: (-26.705263157895, -22.020395499782, 0),\n        28: (-26.323976608187, -22.23596567522, 0),\n        29: (-25.94269005848, -22.451535850659, 0),\n        30: (-25.561403508772, -22.667106026097, 0),\n        31: (-25.180116959064, -22.882676201536, 0),\n        32: (-24.798830409357, -23.098246376975, 0),\n        33: (-24.417543859649, -23.313816552413, 0),\n        34: (-24.036257309942, -23.529386727852, 0),\n        35: (-23.654970760234, -23.74495690329, 0),\n        36: (-23.273684210526, -23.960527078729, 0),\n        37: (-22.892397660819, -24.176097254168, 0),\n        38: (-22.511111111111, -24.391667429606, 0),\n        39: (-22.129824561404, -24.607237605045, 0),\n        40: (-21.748538011696, -24.822807780483, 0),\n        41: (-21.367251461988, -25.038377955922, 0),\n        42: (-20.985964912281, -25.253948131361, 0),\n        43: (-20.604678362573, -25.469518306799, 0),\n        44: (-20.223391812866, -25.685088482238, 0),\n        45: (-19.842105263158, -25.900658657676, 0),\n        46: (-19.46081871345, -26.116228833115, 0),\n        47: (-19.079532163743, -26.331799008554, 0),\n        48: (-18.698245614035, -26.547369183992, 0),\n        49: (-18.316959064328, -26.762939359431, 0),\n        50: (-17.93567251462, -26.978509534869, 0),\n        51: (-17.554385964912, -27.194079710308, 0),\n        52: (-17.173099415205, -27.409649885747, 0),\n        53: (-16.791812865497, -27.625220061185, 0),\n        54: (-16.41052631579, -27.840790236624, 0),\n        55: (-16.029239766082, -28.056360412062, 0),\n        56: (-15.647953216374, -28.271930587501, 0),\n        57: (-15.266666666667, -28.48750076294, 0),\n        58: (-15.261757105943, -27.989408675262, 0),\n        59: (-15.25684754522, -27.491316587585, 0),\n        60: (-15.251937984496, -26.993224499908, 0),\n        61: (-15.247028423773, -26.495132412231, 0),\n        62: (-15.242118863049, -25.997040324554, 0),\n        63: (-15.237209302326, -25.498948236877, 0),\n        64: (-15.232299741602, -25.0008561492, 0),\n        65: (-15.227390180879, -24.502764061523, 0),\n        66: (-15.222480620155, -24.004671973846, 0),\n        67: (-15.217571059432, -23.506579886169, 0),\n        68: (-15.212661498708, -23.008487798491, 0),\n        69: (-15.207751937985, -22.510395710814, 0),\n        70: (-15.202842377261, -22.012303623137, 0),\n        71: (-15.197932816537, -21.51421153546, 0),\n        72: (-15.193023255814, -21.016119447783, 0),\n        73: (-15.18811369509, -20.518027360106, 0),\n        74: (-15.183204134367, -20.019935272429, 0),\n        75: (-15.178294573643, -19.521843184752, 0),\n        76: (-15.17338501292, -19.023751097075, 0),\n        77: (-15.168475452196, -18.525659009398, 0),\n        78: (-15.163565891473, -18.027566921721, 0),\n        79: (-15.158656330749, -17.529474834043, 0),\n        80: (-15.153746770026, -17.031382746366, 0),\n        81: (-15.148837209302, -16.533290658689, 0),\n        82: (-15.143927648579, -16.035198571012, 0),\n        83: (-15.139018087855, -15.537106483335, 0),\n        84: (-15.134108527132, -15.039014395658, 0),\n        85: (-15.129198966408, -14.540922307981, 0),\n        86: (-15.124289405685, -14.042830220304, 0),\n        87: (-15.119379844961, -13.544738132627, 0),\n        88: (-15.114470284238, -13.04664604495, 0),\n        89: (-15.109560723514, -12.548553957273, 0),\n        90: (-15.104651162791, -12.050461869595, 0),\n        91: (-15.099741602067, -11.552369781918, 0),\n        92: (-15.094832041344, -11.054277694241, 0),\n        93: (-15.08992248062, -10.556185606564, 0),\n        94: (-15.085012919897, -10.058093518887, 0),\n        95: (-15.080103359173, -9.56000143121, 0),\n        96: (-15.07519379845, -9.0619093435329, 0),\n        97: (-15.070284237726, -8.5638172558558, 0),\n        98: (-15.065374677003, -8.0657251681787, 0),\n        99: (-15.060465116279, -7.5676330805016, 0),\n        100: (-15.055555555556, -7.0695409928245, 0),\n        101: (-15.050645994832, -6.5714489051475, 0),\n        102: (-15.045736434109, -6.0733568174704, 0),\n        103: (-15.040826873385, -5.5752647297933, 0),\n        104: (-15.035917312661, -5.0771726421162, 0),\n        105: (-15.031007751938, -4.5790805544391, 0),\n        106: (-15.026098191214, -4.080988466762, 0),\n        107: (-15.021188630491, -3.5828963790849, 0),\n        108: (-15.016279069767, -3.0848042914078, 0),\n        109: (-15.011369509044, -2.5867122037307, 0),\n        110: (-15.00645994832, -2.0886201160536, 0),\n        111: (-15.001550387597, -1.5905280283765, 0),\n        112: (-14.996640826873, -1.0924359406994, 0),\n        113: (-14.99\n</code></pre> <p>Cut off file!?!</p> <p>Seems that (maybe due to all the document imports and exports) the file <code>Camera3D.usda</code> got cut off at the end!?!</p> <p>The script has the ability to translate AlembicMesh3D node-based elements from your Fusion comp into Maya ASCII (.ma) \"Reference Editor\" based alembic references, and USDA formatted Xform assembly references which instance externally stored Alembic meshes in the USD scene:</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#alembicmesh3dusda","title":"AlembicMesh3D.usda","text":"<pre><code>#usda 1.0\n(\n\u00a0 \u00a0 defaultPrim = \"SoccerAlembicMesh3D\"\n\u00a0 \u00a0 doc = \"\"\"Generated from Composed Stage of root layer /Users/andrew/Downloads/FusionAnimatedCamera/AnimatedCamera.comp\"\"\"\n\u00a0 \u00a0 metersPerUnit = 0.01\n\u00a0 \u00a0 upAxis = \"Y\"\n)\n\u00a0\ndef Xform \"SoccerAlembicMesh3D\" (\nkind = \"assembly\"\n)\n{\n \u00a0 def Xform \"SoccerAlembicMesh3DReferenceAssembly\" (\n \u00a0 \u00a0 \u00a0 kind = \"assembly\"\n\u00a0 \u00a0 \u00a0 prepend references = @/Users/andrew/Downloads/FusionAnimatedCamera/Media/soccer_HDF5.abc@\n \u00a0 )\n \u00a0 {\n \u00a0 \u00a0 \u00a0 float3 xformOp:rotateXYZ = (0, 0, 0)\n\u00a0 \u00a0 \u00a0  double3 xformOp:translate = (0, 0, 0)\n \u00a0 \u00a0 \u00a0 uniform token[] xformOpOrder = [\"xformOp:translate\", \"xformOp:rotateXYZ\"]\n\u00a0 }\n}\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#example-fusion-comp-project","title":"Example Fusion Comp Project","text":"<p>Here's a small Fusion example project you can use to explore the new PIXAR USD ASCII and Maya ASCII output options that are in the Reactor delivered \"Export Point Cloud\" script:</p> <p>AnimatedCamera.comp</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#fusion-export-stage","title":"Fusion Export Stage","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#maya-import-stage","title":"Maya Import Stage","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#part-4-compx","title":"Part 4 - CompX","text":"<p>I'm working on a slightly expanded scope for an OpenUSD integration effort for the Fusion Studio/Resolve Studio's Fusion page... It's a bit like going down a rabbit hole but the end result could help to radically improve data interchange of compositing node graphs for things like USD shots publishes that could be delivered to artists with an accompanying slap comp attached.</p> <p>GitHub | CompX https://github.com/AndrewHazelden/CompX</p> <p>An OpenUSD schema for representing nodal compositing operators. Optimized for VFX and virtual production workflows. The goal is to create an OpenUSD based CompX schema, alongside a reference implementation that ships with the essential DCC plugins, command-line utilities, and libraries to support compositing data interchange.</p> <p>An OpenUSD schema for representing nodal compositing operators. Optimized for VFX and virtual production workflows.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/DEV%20The%20Ultimate%20Guide%20to%20OpenUSD%20Pipeline%20Development/#project-status","title":"Project Status:","text":"<p>A new working group of VFX/animation/post-production/virtual production/game industry professionals is being assembled.</p> <p>The goal is to create an OpenUSD based CompX schema, alongside a reference implementation that ships with the essential DCC plugins, command-line utilities, and libraries to support compositing data interchange.</p> <p>Two (legacy) OpenUSD ASCII exporter scripts were added to the CompX repository recently to help with R&amp;D tests as ongoing research is done during 2022 to move CompX from an idea, into a production-usable toolset.</p> <p>Open Source License: - Apache 2.0 License</p> <p>OpenUSD Reference Information: - OpenUSD Glossary | API Schema - OpenUSD | Generating New Schema Classes</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/","title":"Domemaster Photoshop Actions Pack","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Domemaster Photoshop Actions Pack</p> <p>Version 2.5 - Released March 16, 2017\\ by Andrew Hazelden</p> <p>Email: andrew@andrewhazelden.com\\ Blog: http://www.andrewhazelden.com</p> <p>GitHub Page:</p> <ul> <li>https://github.com/AndrewHazelden/Domemaster-Photoshop-Actions-Pack</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#about-the-software","title":"About the Software","text":"<p>About the Software</p> <p>The Domemaster Photoshop Actions Pack is a collection of custom Adobe Photoshop actions that were designed to speed up the fulldome content creation workflow.</p> <p>The actions provide tools for converting images from several common panoramic formats such as angular fisheye, equirectangular, and cube map panoramas, and general utilities for fulldome production.</p> <p></p> <p>The Domemaster Photoshop Actions Pack is distributed under the GPL v3 license.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#version-history","title":"Version History","text":"<p>Version History</p> <p>Version 2.5 - 2017-03-16</p> <ul> <li>Fixed a Photoshop CS6 compatibility issue with the \"2:1 Equirectangular to Domemaster 180\u00b0\" action.</li> </ul> <p>Version 2.4 - 2017-01-21</p> <ul> <li> <p>Added support for the new Autodesk Revit Vertical Strip and Horizontal Strip panoramic image projections.</p> </li> <li> <p>Added a new experimental set of \"UV Pass\" actions allow you to prepare UV pass maps that are used for pre-computed panoramic image transforms. This approach is commonly used in compositing to correct for lens distortion.</p> <p>Another term for a UV pass map if you are a Foundry NukeX user is an \"ST map\". A UV pass image template is made using a 16 bit integer red/green gradient image that is then distorted using a program like PTGui Pro and the Domemaster Fusion Macros.</p> <p>Note: It is very important that you load and save a UV pass map using an sRGB linear gamma 1.0 color space in Photoshop or you will have distortions in your image template from the non-linear shading of the generated gradients.</p> </li> </ul> <p>Version 2.3 - 2015-12-18</p> <ul> <li>Added more sample panoramic images examples to illustrate the different image projection formats.</li> </ul> <p>Version 2.2 - 2015-11-23</p> <ul> <li>Added a \"Cube Map to Gear VR Mono\" and \"Gear VR Mono to Cube Map\" set of actions. The \"Cube Map to Gear VR Mono\" action creates a 6:1 aspect ratio horizontal strip cubemap and the other action can extract that imagery back into a set of 6 cube map layers.</li> <li>Added a \"Stereo Side by Side Extract\" and a \"Stereo Over Under Extract\" macro for processing stereo imagery.</li> <li>Updated the \"Cube Map to X\" actions to fix an error that would happen if the File &gt; New... dialog had a transparent background selected, and there was no background layer present in the new document.</li> </ul> <p>Version 2.1 - 2015-11-21</p> <ul> <li>Improved the Photoshop compatibility of the \"2:1 Equirectangular to 180\u00b0 Domemaster\" action.</li> </ul> <p>Version 2 - 2015-11-20</p> <ul> <li>Expanded the General Utilities section to include \"1x1 Guide Grid\", \"1x2 Guide Grid\", \"2x1 Guide Grid\", \"6x2 Guide Grid\", and \"12x1 Guide Grid\".</li> <li>Expanded the Transforms section to include \"200% Vertical Canvas Expand\", and \"200% Horizontal Canvas Expand\".</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#action-list","title":"Action List","text":"<p>Action List</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#transforms","title":"Transforms:","text":"<p>Transforms:</p> <p>1:1 to 2:1 Aspect Ratio Expand\\ 2:1 to 1:1 Aspect Ratio Reduce\\ 50% Scale\\ 200% Scale\\ 200% Vertical Canvas Expand\\ 200% Horizontal Canvas Expand\\ Rotate 90 Degrees\\ Rotate 180 Degrees\\ Rotate 270 Degrees\\ Flip Vertical\\ Flop Horizontal\\ Horizontal Offset 1024 pixels\\ Vertical Offset 1024 pixels\\ Horizontal and Vertical Offset 1024 pixels</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#conversions","title":"Conversions","text":"<p>Conversions</p> <p>Inverse Angular Fisheye\\ Angular Fisheye to Equirectangular\\ Angular Fisheye to 2:1 Equirectangular\\ 180\u00b0 Domemaster to 2:1 Equirectangular\\ Equirectangular to Angular Fisheye\\ 2:1 Equirectangular to Angular Fisheye\\ 2:1 Equirectangular to 180\u00b0 Domemaster\\ 3x2 Cube Map to Cube Map\\ Vertical Cross to Cube Map\\ Horizontal Cross to Cube Map\\ Vertical Tee to Cube Map\\ Horizontal Tee to Cube Map\\ Vertical Strip to Cube Map\\ Horizontal Strip to Cube Map\\ Mental Ray Horizontal Strip to Cube Map\\ Gear VR Mono to Cube Map\\ Revit Horizontal Strip to Cube Map\\ Revit Horizontal Strip Stereo to Cube Map Stereo\\ Revit Vertical Strip to Cube Map\\ Cube Map to 3x2 Cube Map\\ Cube Map to Vertical Cross\\ Cube Map to Horizontal Cross\\ Cube Map to Vertical Tee\\ Cube Map to Horizontal Tee\\ Cube Map to Vertical Strip\\ Cube Map to Horizontal Strip\\ Cube Map to Mental Ray Horizontal Strip\\ Cube Map to Revit Horizontal Strip\\ Cube Map to Revit Vertical Strip\\ Cube Map to Gear VR Mono\\ Cube Map to New Cube Map\\ Cube Map Rotate X:+90 Degrees\\ Cube Map Rotate Y:+90 Degrees\\ Cube Map Rotate Z:+90 Degrees\\ Stereo Side by Side Extract\\ Stereo Over Under Extract</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#masking-and-selection","title":"Masking and Selection:","text":"<p>Masking and Selection:</p> <p>Crop to Selection\\ Select All\\ Save Selection\\ Load Selection\\ Color Range Selection\\ Inside Circular 50% Mask\\ Outside Circular 50% Mask\\ Fisheye Alpha Channel\\ Fisheye Layer Mask\\ Layer Mask from Selection\\ Layer Mask from Inverse Selection\\ Enable Layer Mask\\ Disable Layer Mask\\ Delete Layer Mask\\ Black Matting BG</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#general-utilities","title":"General Utilities:","text":"<p>General Utilities:</p> <p>1x1 Guide Grid\\ 1x2 Guide Grid\\ 1x6 Guide Grid\\ 2x1 Guide Grid\\ 2x2 Guide Grid\\ 3x2 Guide Grid\\ 3x4 Guide Grid\\ 4x3 Guide Grid\\ 4x4 Guide Grid\\ 6x1 Guide Grid\\ 6x2 Guide Grid\\ 12x1 Guide Grid\\ Clear Guides\\ Invert Colors\\ Background to Layer\\ Merge Visible\\ Flatten Image</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#uv-pass","title":"UV Pass","text":"<p>UV Pass</p> <p>UV Rectangle Gradient Landscape Layout\\ UV Rectangle Gradient Portrait Layout\\ UV Equirectangular to Angular Gradient\\ UV Equirectangular to Domemaster Gradient\\ Horizontal Offset 960px\\ Vertical Offset 960px\\ Rotate 90 Degrees\\ Rotate 180 Degrees\\ Rotate 270 Degrees\\ Flip Vertical\\ Flop Horizontal\\ Gamma 2.2 to 1.0 Repair\\ Gamma 1.0 to 2.2 Repair</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#installation-instructions","title":"Installation Instructions","text":"<p>Installation Instructions</p> <p>The Domemaster Photoshop Actions Pack is compatible with Photoshop CS3 to CC on both macOS and Windows.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#step-1-open-the-actions-tab","title":"Step 1. Open the Actions Tab","text":"<p>Step 1. Open the Actions Tab</p> <p>Start by opening Adobe Photoshop. Navigate to the \"Window\" menu, and select the \"Actions\" menu item.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#step-2-load-the-actions","title":"Step 2. Load the actions.","text":"<p>Step 2. Load the actions.</p> <p>Click on the Actions tab pop-up menu located at the top right of the actions tab.</p> <p>Select the \"Load Actions\" menu item.</p> <p></p> <p>In the Load dialogue window select the action files \"Conversions.atn\", \"General Utilties.atn\", \"Masking and Selection.atn\", \"Transforms.atn\", and \"UV Pass.atn\".</p> <p>Click the Load button to open the action files.</p> <p></p> <p>The Domemaster Photoshop Actions Pack files will be loaded into the Actions Tab.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#step-3-switch-to-button-mode","title":"Step 3. Switch to Button Mode","text":"<p>Step 3. Switch to Button Mode</p> <p>If you want to make it easier to run the actions you can switch the Actions tab to \"Button Mode\". This will make each action item a clickable button.</p> <p>Click on the Actions tab pop-up menu located at the top right of the actions tab.</p> <p>Select the first item in the menu labeled \"Button Mode\". Your view will switch from a long list into a colorful grid of labeled buttons.</p> <p></p> <p>To make it easier to find things, the actions groups are color coded:</p> <p>The \"Conversions\" actions are blue.</p> <p>The \"General Utilities\" actions are violet.</p> <p>The \"Masking and Selection\" actions are green.</p> <p>The \"Transforms\" actions are yellow.</p> <p>The \"UV Pass\" actions are red.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#tool-descriptions","title":"Tool Descriptions","text":"<p>Tool Descriptions</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#transforms_1","title":"Transforms","text":"<p>Transforms</p> <p>1:1 to 2:1 Aspect Ratio Expand</p> <p>This action will convert a 1:1 square aspect ratio image into a 2:1 aspect ratio image by scaling the document 200% larger horizontally.</p> <p>2:1 to 1:1 Aspect Ratio Reduce</p> <p>This action will convert a 2:1 square aspect ratio image into a 1:1 aspect ratio image by scaling the document 50% smaller horizontally.</p> <p>50% Scale</p> <p>This action will scale the image 50% smaller using bicubic interpolation.</p> <p>200% Scale</p> <p>This action will scale the image 200% larger using bicubic interpolation.</p> <p>200% Vertical Canvas Expand</p> <p>This action will double the height of the image which is helpful for preparing over under format stereo images. A guide line is added at the edge of the expanded area which makes snapping easier.</p> <p>200% Horizontal Canvas Expand</p> <p>This action will double the width of the image which is helpful for preparing side by side format stereo images. A guide line is added at the edge of the expanded area which makes snapping easier.</p> <p>Rotate 90 Degrees</p> <p>This action will rotate the Photoshop document by 90 degrees. This is useful for changing the orientation of the angular fisheye and equirectangular images prior to the conversion.</p> <p></p> <p></p> <p>Rotate 180 Degrees</p> <p>This action will rotate the Photoshop document by 180 degrees. This is useful for changing the up orientation of the angular fisheye and equirectangular images prior to the conversion.</p> <p></p> <p></p> <p>Rotate 270 Degrees</p> <p>This action will rotate the Photoshop document by 270 degrees. This is useful for changing the up orientation of the angular fisheye and equirectangular images prior to the conversion.</p> <p>Flip Vertical</p> <p>This flips the image upside down.</p> <p>Flop Horizontal</p> <p>This flops the image left and right.</p> <p>Horizontal Offset 1024 Pixels</p> <p>This action slides the image 1024 pixels to the right and wraps the right side of the image around to the left side.</p> <p>This is useful for changing the content in the center of an equirectangular image. This is also useful for fixing image seams and preparing tiling textures</p> <p></p> <p></p> <p>Vertical Offset 1024 Pixels</p> <p>This action slides the image upwards by 1024 pixels and wraps the top side of the image around to the bottom side. This is useful for fixing image seams and preparing tiling textures.</p> <p></p> <p></p> <p>Horizontal and Vertical Offset 1024 Pixels</p> <p>This action slides the image upwards and to the right by 1024 pixels and wraps the top and right side of the image around to the bottom side. This is useful for fixing image seams and preparing tiling textures.</p> <p>If you are running this action on a 2K square resolution image it will shift the seams on an image's border to the center of the document. After you have finished your cloning or touch-up work you can run the action a 2<sup>nd</sup> time so the image border will be reset to its original position.</p> <p>On a 4K square or 8K square resolution image you will need to run the action multiple time until the seam is shifted into the center of the document.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#ref9","title":"Conversions","text":"<p>Conversions</p> <p>Inverse Angular Fisheye</p> <p>This action will allow you to inverse an angular fisheye image. This is the effect \"rolling\" the inside of the fisheye image to the outside of the frame. This effect works best with a 360\u00b0 degree fisheye image.</p> <p>The action can be used to quickly turn a regular angular fisheye image into a \"tiny planet\" style image.</p> <p>The inverted fisheye effect is achieved by taking your angular fisheye image and doing a polar to rectangular conversion. Then the action rotates the image 180 degrees. The final step is to convert the image from rectangular coordinates back into polar coordinates.</p> <p>The latest version of Photoshop CC (14.2.1+) has added support for 16-bit per channel and 32-bit per channel imagery in the Polar Coordinates filter. If you are using an older version of Photoshop, the action will not work on 16-bit per channel and 32-bit per channel images due to limitations in Photoshop's \"Polar to Rectangular\" image filter.</p> <p>Note: It is also possible to use the \"Inverse Angular Fisheye\" action a 2<sup>nd</sup> time to convert a \"tiny planet\" image back into a normal fisheye image.</p> <p></p> <p>Angular Fisheye to Equirectangular</p> <p>This action converts a full frame fisheye image into a 360\u00b0 x 180\u00b0 spherical panorama with a ratio of 1:1. This means a fulldome image with a 2048x2048 resolution will be converted to a 2048x2048 resolution lat/long image. This is done with the help of the Photoshop polar to rectangular coordinates filter.</p> <p>This action can also be used on individual alpha channels by selecting the alpha channel in the Channels tab and then clicking the button for the action.</p> <p>The latest version of Photoshop CC (14.2.1+) has added support for 16-bit per channel and 32-bit per channel imagery in the Polar Coordinates filter. If you are using an older version of Photoshop, the action will not work on 16-bit per channel and 32-bit per channel images due to limitations in Photoshop's \"Polar to Rectangular\" image filter.</p> <p>Tip: If you see a visible seam artifact at the 0\u00b0 mark after converting to/from an angular fisheye format you can try flattening the image before performing the conversions.</p> <p></p> <p>Angular Fisheye to 2:1 Equirectangular</p> <p>This action converts a full frame fisheye image into a 360\u00b0 x 180\u00b0 spherical panorama with a ratio of 2:1. This means a fulldome image with a 2048x2048 resolution will be converted to a 4096x2048 resolution lat/long image. This is done with the help of the Photoshop polar to rectangular coordinates filter.</p> <p>This action can also be used on individual alpha channels by selecting the alpha channel in the Channels tab and then clicking the button for the action.</p> <p>The latest version of Photoshop CC (14.2.1+) has added support for 16-bit per channel and 32-bit per channel imagery in the Polar Coordinates filter. If you are using an older version of Photoshop, the action will not work on 16-bit per channel and 32-bit per channel images due to limitations in Photoshop's \"Polar to Rectangular\" image filter.</p> <p>Tip: If you see a visible seam artifact at the 0\u00b0 mark after converting to/from an angular fisheye format you can try flattening the image before performing the conversions.</p> <p></p> <p>180\u00b0 Domemaster to 2:1 Equirectangular</p> <p>This action converts a 180\u00b0 Domemaster angular fisheye image into a 360\u00b0 x 180\u00b0 spherical panorama with a ratio of 2:1.</p> <p>Since a domemaster frame only has a vertical coverage area of 90 degrees when converted into a spherical format, this image will have the bottom / empty half of the spherical frame filled with a black background color.</p> <p></p> <p>Equirectangular to Angular Fisheye</p> <p>This action converts a 360\u00b0 x 180\u00b0 spherical panorama into a full frame fisheye image. This means a lat/long image with a 1:1 aspect ratio like 2048x2048 pixels will be converted to a 2048x2048 angular fisheye image. This is done with the help of the Photoshop rectangular to polar coordinates filter.</p> <p>This action can also be used on individual alpha channels by selecting the alpha channel in the Channels tab and then clicking the button for the action.</p> <p>The latest version of Photoshop CC (14.2.1+) has added support for 16-bit per channel and 32-bit per channel imagery in the Polar Coordinates filter. If you are using an older version of Photoshop, the action will not work on 16-bit per channel and 32-bit per channel images due to limitations in Photoshop's \"Polar to Rectangular\" image filter.</p> <p>Tip: If you see a visible seam artifact at the 0\u00b0 mark after converting to/from an angular fisheye format you can try flattening the image before performing the conversions.</p> <p></p> <p>2:1 Equirectangular to Angular Fisheye</p> <p>This action converts a 360\u00b0 x 180\u00b0 spherical panorama into a full frame fisheye image. This means a lat/long image with a 2:1 aspect ratio like 4096x2048 pixels will be converted to a 2048x2048 angular fisheye image. This is done with the help of the Photoshop rectangular to polar coordinates filter.</p> <p>This action can also be used on individual alpha channels by selecting the alpha channel in the Channels tab and then clicking the button for the action.</p> <p>The latest version of Photoshop CC (14.2.1+) has added support for 16-bit per channel and 32-bit per channel imagery in the Polar Coordinates filter. If you are using an older version of Photoshop, the action will not work on 16-bit per channel and 32-bit per channel images due to limitations in Photoshop's \"Polar to Rectangular\" image filter.</p> <p>Tip: If you see a visible seam artifact at the 0\u00b0 mark after converting to/from an angular fisheye format you can try flattening the image before performing the conversions.</p> <p></p> <p>2:1 Equirectangular to 180\u00b0 Domemaster</p> <p>This action converts a 360\u00b0 x 180\u00b0 spherical panorama into a 180\u00b0 domemaster formatted angular fisheye image. This means a lat/long image with a 2:1 aspect ratio will be converted to a domemaster formatted image with a black circular fisheye mask applied around the frame.</p> <p>This is done with the help of the Photoshop rectangular to polar coordinates filter.</p> <p></p> <p>3x2 Cube Map to Cube Map</p> <p>This converts a 3x2 cube map format image into the cubic layer map panorama format.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Vertical Cross to Cube Map</p> <p>This converts a vertical cross format panorama into the cubic map panorama format.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Horizontal Cross to Cube Map</p> <p>This converts a horizontal cross format panorama into the cubic map panorama format.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Vertical Tee to Cube Map</p> <p>This converts a vertical tee format panorama into the cubic map panorama format.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Horizontal Tee to Cube Map</p> <p>This converts a horizontal tee format panorama into the cubic map panorama format.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Vertical Strip to Cube Map</p> <p>This converts a vertical strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 1:6 ratio. If the input image is 1024x6,144 pixel image the output will be a 1024x1024 pixel layered Photoshop image.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Horizontal Strip to Cube Map</p> <p>This converts a horizontal strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 6:1 ratio. If the input image is 6,144x1024 pixel image the output will be a 1024x1024 pixel layered Photoshop image.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Mental Ray Horizontal Strip to Cube Map</p> <p>This converts a mental ray mib_lookup_cube1 horizontal strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 6:1 ratio in the mental ray cubic frame layout. If the input image is 6,144x1024 pixel image the output will be a 1024x1024 pixel layered Photoshop image.</p> <p>The input image is in the mental ray mib_lookup_cube1 horizontal strip image format:</p> <p>left</p> <p>right   bottom   top (flipped vertically)   back   front</p> <p>The output from this action is a layered Photoshop document with cubic faces named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Gear VR Mono to Cube Map</p> <p>This converts a Gear VR / Octange Render monoscopic horizontal strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 6:1 ratio. If the input image is 6,144x1024 pixel image the output will be a 1024x1024 pixel layered Photoshop image.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Revit Vertical Strip to Cube Map</p> <p>This converts an Autodesk Revit cloud rendered vertical strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 1:6 ratio. If the input image is 1536x9216 pixel image the output will be a 1536x1536 pixel layered Photoshop image.</p> <p>The converted cubic map faces are named:</p> <p>right</p> <p>left   top   bottom   back   front</p> <p>Revit Horizontal Strip to Cube Map</p> <p>This converts an Autodesk Revit cloud rendered horizontal strip format panorama into the cubic map panorama format.</p> <p>The input image is expected to be in a aspect 6:1 ratio. If the input image is 9216x1536 pixel image the output will be a 1536x1536 pixel layered Photoshop image.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   bottom (rotate 90\u00b0\u00a0CCW)   top (rotate -90\u00b0\u00a0CW)</p> <p>Revit Horizontal Strip Stereo to Cube Map Stereo</p> <p>This converts an Autodesk Revit cloud rendered stereoscopic 3D horizontal strip format panorama into a pair of left and right view cubic map panoramas.</p> <p>The input image is expected to be in an over/under stereo Revit Horizontal Strip panoramic format. For the over/under stereo image layout the right view is placed ontop of the left view.</p> <p>If the input image is 9216x3072 pixel image the output will be two 1536x1536 pixel layered Photoshop images.</p> <p>Note: If you want to apply an additional image editing panoramic transform like a \"Cube Map to Horizontal Cross\" action to the left and right camera cube map documents, you need to drag the active image's filename tab in Photoshop to the farthest to the right side of the open document tabs.</p> <p>The converted cubic map faces are named:</p> <p>front</p> <p>right   back   left   bottom (rotate 90\u00b0\u00a0CCW)   top (rotate -90\u00b0\u00a0CW)</p> <p>Cube Map to 3x2 Cube Map</p> <p>This converts a cube map format image into the 3x2 panorama format.</p> <p></p> <p>Cube Map to Vertical Cross</p> <p>This converts a cube map format image into the vertical cross panorama format.</p> <p>The converted vertical cross faces are located in the format:</p> <p>blank   top                   blank</p> <p>left    front                 right   blank   bottom                blank   blank   back (rotated 180\u00b0)   blank</p> <p></p> <p>Cube Map to Horizontal Cross</p> <p>This converts a cube map format image into the horizontal cross panorama format.</p> <p>The converted horizontal cross faces are located in the format:</p> <p>blank   top      blank   blank</p> <p>left    front    right   back   blank   bottom   blank   blank</p> <p></p> <p>Cube Map to Vertical Tee</p> <p>This converts a cube map format image into the vertical tee panorama format.</p> <p>The converted vertical tee faces are located in the format:</p> <p>left    front                 right</p> <p>blank   bottom                blank   blank   back (rotated 180\u00b0)   blank   blank   top                   blank</p> <p></p> <p>Cube Map to Horizontal Tee</p> <p>This converts a cube map format image into the horizontal tee panorama format.</p> <p>The converted horizontal tee faces are located in the format:</p> <p>blank   top      blank   blank</p> <p>front   right    back    left   blank   bottom   blank   blank</p> <p></p> <p>Cube Map to Vertical Strip</p> <p>This converts a cube map format image into a single column panorama format.</p> <p>The vertical strip faces are located in the format:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p></p> <p>Cube Map to Horizontal Strip</p> <p>This converts a cube map format image into a single row panorama format.</p> <p>The horizontal strip faces are located in the format:</p> <p>| :----- | :----- | :----- | :----- | :----- | :----- | | front | right | back | left | top | bottom |</p> <p></p> <p>Cube Map to Revit Horizontal Strip</p> <p>This converts a cube map format image into a single row panorama format that is used by Autodesk Revit's cloud rendering VR Panorama products.</p> <p>The Revit horizontal strip faces are located in the format:</p> <p>| :----- | :----- | :----- | :----- | :----- | :----- | | front | right | back | left | bottom (rotate 90\u00b0 CCW) | top (rotate -90\u00b0 CW) |</p> <p>Cube Map to Revit Vertical Strip</p> <p>This converts a cube map format image into a single column vertical panorama format that is used by Autodesk Revit's cloud rendering VR Panorama products.</p> <p>The Revit vertical strip faces are located in the format:</p> <p>right</p> <p>left   top   bottom   back   front</p> <p>Cube Map to Mental Ray Horizontal Strip</p> <p>This converts a cube map format image into a single row panorama format.</p> <p>This converts a layered cubic map Photoshop document into a mental ray <code>mib_lookup_cube1</code> horizontal strip format panorama.</p> <p>The input image is expected to be in a 1:1 aspect ratio. If the input image is a layered 1024x1024 pixel image the output will be a 6,144x1024 pixel image with a 6:1 aspect ratio.</p> <p>The input for this action is a layered Photoshop document with cubic faces named:</p> <p>front</p> <p>right   back   left   top   bottom</p> <p>The output image is in the mental ray <code>mib_lookup_cube1</code> horizontal strip image layout with the following cubic map face order:</p> <p>left</p> <p>right   bottom   top (flipped vertically)   back   front</p> <p></p> <p>Cube Map to Gear VR Mono</p> <p>This converts a cube map format image into the Gear VR / Octane Render ORBX 6:1 aspect ratio horizontal strip cubic panorama format.</p> <p>The converted horizontal strip faces are located in the format:</p> <p>| :----- | :----- | :----- | :----- | :----- | :----- | | Left | Right | Top (rotated 180) | Bottom (rotated 180) | Back | Front |</p> <p></p> <p>Cube Map to New Cube Map</p> <p>This action will copy the cube map \"front\", \"right\", \"back\", \"left\", \"top\", and \"bottom\" layers from your current Photoshop document into a new Photoshop document.</p> <p>Cube Map Rotate X:+90 Degrees</p> <p>This action will rotate the cube map panorama by 90 degrees on the X-axis. This has the effect of turning the front \"view\" upwards towards the sky.</p> <p>Tip: If you want to rotate a cross style, tee style, 3x2 cubic map, or strip style pano you need to convert them to the layered \"cube map\" format first using the actions in the Conversions Actions tab group.</p> <p></p> <p></p> <p>Cube Map Rotate Y:+90 Degrees</p> <p>This action will rotate the cube map panorama by 90 degrees on the Y-axis. The has the effect of turning the front \"view\" towards the left.</p> <p>Tip: If you want to rotate a cross style, tee style, 3x2 cubic map, or strip style pano you need to convert them to the layered \"cube map\" format first using the actions in the Conversions Actions tab group.</p> <p></p> <p></p> <p>Cube Map Rotate Z:+90 Degrees</p> <p>This action will rotate the cube map panorama by 90 degrees on the Z-axis. This has the effect of rotating the front \"view\" 90 degrees clockwise to the right.</p> <p>Tip: If you want to rotate a cross style, tee style, 3x2 cubic map, or strip style pano you need to convert them to the layered \"cube map\" format first using the actions in the Conversions Actions tab group.</p> <p></p> <p></p> <p>Stereo Side by Side Extract</p> <p>This action will copy the left and right stereo views out of a side by side stereo format image.</p> <p>A new image will be created and then two layers will be added with the layer names of \"left\" and \"right\".</p> <p>The source image should have the stereo image layout of:</p> <p>| :----- | :----- | | left | right |</p> <p>Stereo Over Under Extract</p> <p>This action will copy the left and right stereo views out of an over under stereo format image.</p> <p>A new image will be created and then two layers will be added with the layer names of \"left\" and \"right\".</p> <p>The source image should have the stereo image layout of:</p> <p>left</p> <p>right</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#masking-and-selection_1","title":"Masking and Selection","text":"<p>Masking and Selection</p> <p>Crop to Selection</p> <p>This action will crop the Photoshop document smaller based upon the currently selected area. The crop command will reduce the image size based upon a square cropping rectangle drawn around the current selection shape.</p> <p>Select All</p> <p>This action will select all of the pixels on the current image layer.</p> <p></p> <p>Save Selection</p> <p>This action will save the current selection to a new alpha channel.</p> <p>Load Selection</p> <p>This action will open the \"Load Selection\" dialogue. You can choose to load either a layer mask, transparency channel, or an alpha channel into the current selection region.</p> <p>There are several advanced options in the the \"Load Selection\" dialogue that will let you do differencing operations ( new, add, subtract, intersect, or invert) your current selection.</p> <p>For example of you were painting a layer mask you could change your current selection region by subtracting the shape of a mask or alpha channel from another layer or image.</p> <p>Color Range Selection</p> <p>This action will load the \"Color Range\" dialogue. This dialogue is useful for using a color / luma keying approach to generate a new selection region.</p> <p>You can preview the effects of the selection region in the dialogue or use the \"Selection Preview\" pop-up menu to view the results in the main Photoshop window.</p> <p>Inside Circular 50% Mask</p> <p>This action creates a circular layer mask that hides the area inside a circular region in the center of the current layer.</p> <p></p> <p>Outside Circular 50% Mask</p> <p>This action creates a circular layer mask that hides the area outside a circular region in the center of the current layer.</p> <p></p> <p>Fisheye Alpha Channel</p> <p>This action creates a full frame circular alpha channel.</p> <p>A common use is to create a single circular alpha channel and then use the \"load selection\" action to repetitively make circular domemaster shaped boundary selections.</p> <p></p> <p>Fisheye Layer Mask</p> <p>This action creates a full frame circular layer mask on the currently select layer.</p> <p>To use this action you must convert all flattened background layers into floating layers. You can do this using the \"Background to Layer\" action.</p> <p></p> <p>Layer Mask From Selection</p> <p>This action applies a new raster layer mask based upon the current selection. To use this action you must remove any existing \"raster\" layer masks from the current layer.</p> <p>Layer masks are a quick and easy way to temporarily hide content on an image layer.</p> <p></p> <p></p> <p>After you create a new layer mask you can edit the layer mask by opening the layers tab and clicking on the mask icon to the right of the layer icon. When the layer mask is selected you can paint the mask using the brush tool.</p> <p>Layer Mask Editing Tips</p> <p>When editing a layer mask you can paint regions of the layer visible or invisible by changing the brush color to either white or black.</p> <p>You can create transparent areas on the layer by using a shade of gray as the brush color when painting the layer mask.</p> <p>If you adjust the brush hardness to 100% you can paint a crisp hard-edged matte. For a nice soft matte edge set the brush hardness to a value between 0 to 80%.</p> <p>You can view the contents of a single layer mask full-screen by holding down the option key on Mac OS X or the alt key on Windows, and clicking on a layer mask thumbnail image in the Layers Tab.</p> <p>To exit the full-screen layer mask view you need to click back on the layer's color thumbnail image in the Layers Tab.</p> <p>You can invert a layer mask by selecting the layer mask thumbnail icon and clicking the \"Invert Colors\" action button. This will reverse the visible and hidden areas in the layer mask.</p> <p>Layer Mask From Inverse Selection</p> <p>This action creates a new layer mask based upon inverting the current selection. To use this action you must remove any existing \"raster\" layer masks from the current layer.</p> <p></p> <p></p> <p>Enable Layer Mask</p> <p>This action will enable the layer mask on the current layer. This is useful for comparing the effects of transparency on the current layer.</p> <p></p> <p>Disable Layer Mask</p> <p>This action temporarily disables the layer mask on the current layer. This is useful for comparing the effects of transparency on the current layer.</p> <p></p> <p>Delete Layer Mask</p> <p>This action deletes the layer mask on the current layer.</p> <p></p> <p>Black Matting BG</p> <p>This action creates a new shape layer with a black background color.</p> <p>If the current image layer is a floating layer, the black BG shape layer will be placed behind it. If the current image layer is a flattened background layer, the Black BG shape layer will be placed on top of it.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#general-utilities_1","title":"General Utilities","text":"<p>General Utilities</p> <p>1x1 Guide Grid</p> <p>This creates a guide layout that forms a basic outline of the image frame. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>1x2 Guide Grid</p> <p>This creates an over under stereo format guide grid. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>1x6 Guide Grid</p> <p>This creates a vertical strip style 1x6 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>2x1 Guide Grid</p> <p>This creates a side by side stereo format guide grid. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>2x2 Guide Grid</p> <p>This creates a 2x2 guide grid that divides the image into quarters. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>3x2 Guide Grid</p> <p>This creates a 3x2 cube map style alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>3x4 Guide Grid</p> <p>This creates a vertical cross or vertical tee style 3x4 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>4x3 Guide Grid</p> <p>This creates a horizontal cross or horizontal tee style 4x3 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>4x4 Grid Guide</p> <p>This action creates a 4x4 style alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on. You can use the grid to make sure the nadir point in the fulldome image is perfect centered.</p> <p></p> <p></p> <p>6x1 Guide Grid</p> <p>This creates a horizontal strip style 6x1 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>6x2 Guide Grid</p> <p>This creates a 2 image high, over under stereo format, horizontal strip style 6x1 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>12x1 Guide Grid</p> <p>This creates a side by side stereo format horizontal strip style 6x1 alignment guide layout. This grid is extremely useful for making accurate selections in the image when the \"Snap to Guides\" command is turned on.</p> <p>Clear Guides</p> <p>This action will remove all of the guides from the current Photoshop document.</p> <p></p> <p>Invert Colors</p> <p>This action will invert the image colors of the currently selected layer. This action can be used on color images, layer masks, and alpha channels.</p> <p></p> <p>My favorite use of this filter is to invert a grayscale layer mask. This will reverse the visible and hidden parts of the layer mask.</p> <p>This action can be used on individual alpha channels by selecting the alpha channel in the Channels tab and then clicking the button for the action. The action can also used on a layer mask by selecting the layer mask's thumbnail icon in the layers tab and then clicking the button for the action.</p> <p>Background to Layer</p> <p>This action will convert a flattened image from the background layer mode into a floating layer that supports features like layer masks.</p> <p>The most common use for this action is to prepare an imported picture like a flat JPEG .jpg or Targa .tga file for custom layer masks.</p> <p></p> <p>Merge Visible</p> <p>This action will merge all of the visible layers into a single layer.</p> <p>This action is different than the flatten image command in that it will ignore any hidden layers. You can use the merge visible command to selectively flatten layers by hiding the other layers, elements, and groups you want to keep.</p> <p>This version of Merge Visible can merge a single layer and bake the layer mask and layer style effects into the final image.</p> <p>Flatten Image</p> <p>This action will merge all of the layers in the current Photoshop document. This is useful for removing transparency from an image, merging layer style effects, vector shapes, and editable text layers into a single raster image.</p> <p>When an image is flattened, all of the transparent background areas in the image will be filled with a solid color.</p> <p>Note: You really want to have saved a backup of your Photoshop document before you flatten the image because all of your layers are permanently merged into a single element!</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Domemaster%20Photoshop%20Actions%20Pack/#ref10","title":"UV Pass","text":"<p>UV Pass</p> <p>The \"UV Pass\" actions allow you to prepare UV pass maps that are used for pre-computed panoramic image transforms. This approach is commonly used in compositing to correct for lens distortion. Another term for a UV pass map if you are a Foundry NukeX user is an \"ST map\".</p> <p>A UV pass image template is made using a 16 bit integer red/green gradient image that is then distorted using a program like PTGui Pro and KartaVR.</p> <p>Note: It is very important that you load and save a UV pass map using an sRGB linear gamma 1.0 color space in Photoshop or you will have distortions in your image template from the non-linear shading of the generated gradients.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/","title":"Jupyter Notebook for Resolve/Fusion","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Created 2022-09-14 Last Updated 2022-09-14 09.11 PM UTC -4</p> <p>By Andrew Hazelden \\&lt;andrew@andrewhazelden.com&gt;</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#ref8","title":"Overview","text":"<p>Overview</p> <p>This guide is designed to help you set up a virtual environment to run Jupyter Notebook + Resolve/Fusion.</p> <p>This combination can be used to take post-production workflow automation to the next level, and allows computer vision, machine learning, data science, and other tasks to be done as part of a video creation process.</p> <p>It is expected that you have Resolve Studio or Fusion Studio v18 installed, along with a 64-bit version of Python ranging from v3.6 - v3.10. On Windows, when you install Python3 x64, you need to enable the option to add Python to your System PATH environment variable.</p> <p></p> <p>For this WIP experiment we are importing and using the Python \"<code>imp</code>\" module to access the \"<code>Fusionscript.dll</code>\" library. In Python v3.12+ we will eventually need to switch over to using \"<code>importlib</code>\" instead of \"<code>imp</code>\" for compatibility.</p> <p>As a troubleshooting step, make sure you've temporarily quit the Fusion Render Node program on your workstation. Also you need to ensure you have either Resolve Studio or Fusion Studio open but not both of them at the same time.</p> <p>An important detail that you need to avoid glossing over when reading this guide is that external scripting via Python is a \"paid feature\" in the BMD ecosystem that requires Resolve Studio or Fusion Studio. This means you won't be able to follow along with this guide if you only have Resolve (Free) installed.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#install-python3s-virtual-environment-library","title":"Install Python3's virtual environment library","text":"<p>Install Python3's virtual environment library</p> <p>Let's add the Python virtualenv module to our systems.</p> <p>In a Terminal/Command Prompt session run:</p> <pre><code>pip3 install virtualenv\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#create-the-jupyterfusion-environment","title":"Create the JupyterFusion environment","text":"<p>Create the JupyterFusion environment</p> <p>A virtual environment lets you tinker with libraries and content without affecting the rest of your computer's settings. This is a handy feature to have access to when installing Python based modules and other resources.</p> <p>We are going to create a new virtual environment called \"JupyterFusion\" that is placed at the root of our user account folder.</p> <p>From a macOS / Linux Terminal session run:</p> <pre><code>cd $HOME/\nvirtualenv JupyterFusion\n</code></pre> <p>From a Windows Command Prompt session run:</p> <pre><code>cd %USERPROFILE%\\\nvirtualenv JupyterFusion\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#activate-the-environment","title":"Activate the Environment","text":"<p>Activate the Environment</p> <p>The next step in using virtual environments is to navigate to the new folder and to activate it. This will modify the currently active environment variables.</p> <p>From a macOS / Linux Terminal session run:</p> <pre><code>cd $HOME/JupyterFusion/\nsource bin/activate\n</code></pre> <p>From a Windows Command Prompt session run:</p> <pre><code>cd %USERPROFILE%\\JupyterFusion\\\nScripts\\activate.bat\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#install-jupyter","title":"Install Jupyter","text":"<p>Install Jupyter</p> <p>Now we are ready to install Jupyter Notebook in our new virtual environment.</p> <p>In a Terminal/Command Prompt session run:</p> <pre><code>pip3 install jupyter\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#start-jupyter-notebook","title":"Start Jupyter Notebook","text":"<p>Start Jupyter Notebook</p> <p>Let's start up Jupyter for the first time. Jupyter has a web-based GUI that works by running a small webserver on your local system at port 8888.</p> <p>From a macOS / Linux Terminal session run:</p> <pre><code>mkdir -p $HOME/JupyterFusion/notebooks\ncd $HOME/JupyterFusion/notebooks\njupyter notebook\n</code></pre> <p>From a Windows Command Prompt session run:</p> <pre><code>mkdir %USERPROFILE%\\JupyterFusion\\notebooks\ncd %USERPROFILE%\\JupyterFusion\\notebooks\njupyter notebook\n</code></pre> <p>Open your local web browser to:</p> <p>http://localhost:8888/notebooks/</p> <p>To run Jupyter Notebook again:</p> <p>The next time you want to access Jupyter you can type in the following syntax:</p> <p>From a macOS / Linux Terminal session run:</p> <pre><code>source $HOME/JupyterFusion/bin/activate\ncd $HOME/JupyterFusion/notebooks\njupyter notebook\n</code></pre> <p>From a Windows Command Prompt session run:</p> <pre><code>%USERPROFILE%\\JupyterFusion\\Scripts\\activate.bat\ncd %USERPROFILE%\\JupyterFusion\\notebooks\njupyter notebook\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#lets-create-a-new-notebook","title":"Let's create a new notebook","text":"<p>Let's create a new notebook</p> <p>In Jupyter Notebook's web based interface, click on the \"New\" button and select \"Python 3 (ipykernel)\". This will add a notebook we can use for Python3 scripting in Resolve/Fusion v18.</p> <p></p> <p>Click on the heading at the top left of the webpage labelled \"Untitled\".</p> <p></p> <p>This will display a Rename Notebook dialog that will allow us to rename the Jupyter notebook to \"JupyterFusion\".</p> <p></p> <p>Note: The toolbar pop-up menu item labelled \"Code\" can be changed to other options like \"Markdown\" to allow you to customize what can be added to the individual blocks of code.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Jupyter%20Notebook%20for%20Resolve_Fusion/#add-the-python-code","title":"Add the Python Code","text":"<p>Add the Python Code</p> <p>Let's paste the following content below into the individual Jupyter Notebook cells we create.</p> <p>Click in the first cell. Change the cell type from \"Code\" to \"Markdown\". Markdown is a documentation formatting system for making notes that have styled text.</p> <p></p> <p>Markdown Cell Content:</p> <pre><code># Jupyter Fusion v0.1 2022-09-12\n\nA WIP example that shows how to connect a Jupyter Notebook session to Resolve Studio 18 or Fusion Studio 18.\n\n**Tip:** If you are running Resolve Studio, make sure to quit the \"Fusion Studio\" and \"Fusion Render Node\" processes on this workstation to avoid binding to those external applications.\n</code></pre> <p>Now we are going to use the \"Insert &gt; Insert Cell Below\" menu item each time we add another block of Python code.</p> <p></p> <p>The remaining cells of text are all \"code\" type content.</p> <p></p> <p>Code Cell Content:</p> <pre><code>import sys, os\nfrom pprint import pprint\n\ntry:\n    import imp\nexcept DeprecationWarning:\n    # Python 3.12+ requires the use of importlib instead of imp\n    ;\n\ndef FuScriptLib():\n    lib_path = \"\"\n    if sys.platform.startswith(\"darwin\"):\n        lib_path = \"/Applications/DaVinci Resolve/DaVinci Resolve.app/Contents/Libraries/Fusion/fusionscript.so\"\n        #lib_path = \"/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/fusionscript.so\"\n        #lib_path = /Applications/Blackmagic Fusion 18 Render Node/Fusion Render Node.app/Contents/MacOS/fusionscript.so\n    elif sys.platform.startswith(\"win\"):\n        lib_path = \"C:\\\\Program Files\\\\Blackmagic Design\\\\DaVinci Resolve\\\\fusionscript.dll\"\n        #lib_path = \"C:\\\\Program Files\\\\Blackmagic Design\\\\Fusion 18\\\\fusionscript.dll\"\n        #lib_path = \"C:\\\\Program Files\\\\Blackmagic Design\\\\Fusion Render Node 18\\\\fusionscript.dll\"\n    elif sys.platform.startswith(\"linux\"):\n        lib_path = \"/opt/resolve/libs/Fusion/fusionscript.so\"\n        #lib_path = \"/opt/BlackmagicDesign/Fusion18/fusionscript.so\"\n        #lib_path = \"/opt/BlackmagicDesign/FusionRenderNode18/fusionscript.so\"\n\n    if not os.path.isfile(lib_path):\n        print(\"[Fusion] [Library Does Not Exist on Disk]\", lib_path)\n\n    try:\n        bmd = imp.load_dynamic(\"fusionscript\", lib_path)\n    except DeprecationWarning:\n        # Python 3.12+ requires the use of importlib instead of imp\n        ;\n\n    if bmd:\n        sys.modules[__name__] = bmd\n    else:\n        raise ImportError(\"[Fusion] Could not locate module dependencies\")\n\n    return bmd\n\ndef Resolve():\n    app = FuScriptLib().scriptapp(\"Resolve\")\n    return app\n\ndef Fusion():\n    app = FuScriptLib().scriptapp(\"Fusion\")\n    return app\n\n# Get the Resolve and Fusion objects\n# res = Resolve()\nfu = Fusion()\nbmd = FuScriptLib()\n\nif fu is not None:\n    # Get the current comp object\n    comp = fu.GetCurrentComp()\nelse:\n    print(\"[Fusion] Please open a comp and then run this script again.\")\n</code></pre> <p>Code Cell Content:</p> <pre><code># Display the fusion and comp object info\nprint(\"\\n\\n[FusionScript]\")\npprint(bmd)\n\nprint(\"\\n\\n[Fusion]\")\nif fu is not None:\n    pprint(fu.GetAttrs())\n\nprint(\"\\n\\n[Current Comp]\")\nif comp is not None:\n    pprint(comp.GetAttrs())\nelse:\n    print(\"[Fusion] Please open a comp and then run this script again.\")\n</code></pre> <p>Code Cell Content:</p> <pre><code>if comp is not None:\n    # Stop Loader/Saver node file dialogs from showing\n    comp.Lock()\n\n    # Add a node to the comp\n    ldr = comp.AddTool(\"Loader\")\n    ldr.Clip[1] = \"Fusion:/Brushes/smile.tga\"\n\n    # Allow Loader/Saver node file dialogs to show up again\n    comp.Unlock()\n</code></pre> <p>Code Cell Content:</p> <pre><code>if comp is not None:\n    # Display the Loader node details\n    print(ldr.Name, \"=\", ldr.Clip[1])\n\n    # Display the Loader node contents in the left viewer window\n    comp.GetPreviewList()[\"LeftView\"].ViewOn(ldr, 1)\n</code></pre> <p>Let's press the \"Save\" button on the far left side of the Jupyter Notebook toolbar.</p> <p></p> <p>After pasting the code into the individual Jupyter Notebook cells, you will be able to run it by pressing the \"Run\" button in the toolbar. Each time you press the \"Run\" button a new block of code is highlighted and then executed. The console output results are listed below the cell.</p> <p>This is the output result I see on my macOS system:</p> <pre><code>[FusionScript]\n&lt;module 'fusionscript' (/Applications/Blackmagic Fusion 18/Fusion.app/Contents/MacOS/fusionscript.so)&gt;\n\n\n[Fusion]\n{'FUSIONB_IsManager': False,\n 'FUSIONB_IsRenderNode': False,\n 'FUSIONB_IsResolve': False,\n 'FUSIONH_CurrentComp': &lt;BlackmagicFusion.PyRemoteObject object at 0x111af3990&gt;,\n 'FUSIONI_NumProcessors': 8,\n 'FUSIONI_PhysicalRAMFreeMB': 5867,\n 'FUSIONI_PhysicalRAMTotalMB': 16384,\n 'FUSIONI_SerialHi': &lt;snip&gt;,\n 'FUSIONI_SerialLo': 0,\n 'FUSIONI_VersionHi': 1179648,\n 'FUSIONI_VersionLo': 65543,\n 'FUSIONI_VirtualRAMTotalMB': 16839,\n 'FUSIONI_VirtualRAMUsedMB': 10971,\n 'FUSIONS_FileName': '/Applications/Blackmagic Fusion '\n                     '18/Fusion.app/Contents/MacOS/Fusion',\n 'FUSIONS_GLDevice': 'AMD Radeon R9 M370X OpenGL Engine',\n 'FUSIONS_GLVendor': 'ATI Technologies Inc.',\n 'FUSIONS_GLVersion': '2.1 ATI-4.8.101',\n 'FUSIONS_MachineType': 'IA32',\n 'FUSIONS_Version': '18.0.1'}\n\n\n[Current Comp]\n{'COMPB_HiQ': True,\n 'COMPB_Locked': False,\n 'COMPB_LoopPlay': True,\n 'COMPB_Modified': True,\n 'COMPB_MotionBlur': True,\n 'COMPB_Proxy': False,\n 'COMPB_Rendering': False,\n 'COMPH_ActiveTool': None,\n 'COMPI_RenderFlags': 131072,\n 'COMPI_RenderStep': 1,\n 'COMPN_AudioOffset': 0.0,\n 'COMPN_AverageFrameTime': 0.0,\n 'COMPN_CurrentTime': 0.0,\n 'COMPN_ElapsedTime': 0.0,\n 'COMPN_GlobalEnd': 1000.0,\n 'COMPN_GlobalStart': 0.0,\n 'COMPN_LastFrameRendered': -2000000000.0,\n 'COMPN_LastFrameTime': 0.0,\n 'COMPN_RenderEnd': 1000.0,\n 'COMPN_RenderEndTime': 1000.0,\n 'COMPN_RenderStart': 0.0,\n 'COMPN_RenderStartTime': 0.0,\n 'COMPN_TimeRemaining': 0.0,\n 'COMPS_FileName': '',\n 'COMPS_LoopMode': 'loop',\n 'COMPS_Name': 'Composition1'}\n\n\nLoader1 = Fusion:/Brushes/smile.tga\n</code></pre> <p>After running the Notebook, your Fusion compositing session should now look like this:</p> <p></p> <p>At this point you will be able to start modifying the Python code in the Notebook and customizing Jupyter to run your own scripts.</p> <p>Feel free to customize the \"lib_path\" variable at the top of the Python code to point to the actual installed location of the fusionscript library on your computer, if required. This would be relevant if you modified the installation path for Resolve Studio or Fusion Studio.</p> <p>Good Luck and Happy Coding!</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/","title":"KickAss ShaderZ for Fusion","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>KickAss ShaderZ for Fusion</p> <p>Overview</p> <p>\"KickAss ShaderZ\" is a community supported repository of material shaders for the Fusion community by the Fusion community. Curated by Andromeda_Girl and developed for Reactor by Andrew Hazelden.</p> <p>WSL members can submit shaders to be added and watch the library grow.</p> <p></p> <p>For More Information</p> <p>If you'd like to explore how the KickAss Shaders were created, simply expand the group to peek inside the shader.</p> <p>KickAss ShaderZ is a project that is hosted on the WeSuckLess Fusion community forum. You can check out the Reactor GitLab Repository if you need direct access to the individual files via your web browser.</p> <p>Project Created by</p> <ul> <li>andromeda_girl (WSL Profile)</li> <li>Andrew Hazelden (WSL Profile)</li> <li>WSL Community</li> </ul> <p>Requirements</p> <ul> <li>Blackmagic Fusion Studio or Resolve</li> <li>WSL Reactor Package Manager</li> </ul> <p>Installation</p> <p>The KickAss ShaderZ is installed using the Reactor package manager. Look for KickAss ShaderZ in the \"Shaders\" category on the left side of the Reactor window.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#import-pbr-metal-roughness-textures-script","title":"Import PBR Metal Roughness Textures Script","text":"<p>Import PBR Metal Roughness Textures Script</p> <p>KickAss ShaderZ includes a handy \"Substance PBR Import\" script that reads the image from the selected Loader node and expands it to import the full set of related Substance PBR texture maps.</p> <p>The idea for this PBR texture map \"splitter\" script was directly inspired by the concept of how the \"hos_SplitEXR_Ultra.lua\" script works at breaking apart EXR channels. </p> <p>Nodes View Screenshot</p> <p>This is what a typical PBR material import looks like in the Nodes view area:</p> <p></p> <p>File Import Menu Usage</p> <p>Step 1. If you have KickAss ShaderZ menus installed, then you have access in Fusion Studio to a \"File &gt; Import &gt; PBR Textures...\" menu item.</p> <p></p> <p>As a fallback option, there is a KickAss ShaderZ menu entry for this script as well. It can be accessed using the \"KickAss Shaders &gt; Tools &gt; Substance PBR Import\" menu item.</p> <p></p> <p>Step 2. A file browsing dialog is shown when either of the menu items are selected. In the file browsing dialog choose a PBR Metal Roughness texture map on disk.</p> <p></p> <p>An example KAS bundled PBR Metal Roughness set of texture maps you can try out can be found on-disk at the PathMap location of:</p> <pre><code>Reactor:/Deploy/Macros/KickAss ShaderZ/Assets/PreviewSphere_Sphere_BaseColor.png\n</code></pre> <p>A PBR Import dialog will appear with import options. Clicking the \"Create PBR Material\" button will auto-create a PBR material shading network in the Fusion comp by matching the corresponding texture filenames and PBR channel names.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#tool-script-usage","title":"Tool Script Usage","text":"<p>Tool Script Usage</p> <p>Step 1. Select a Loader node in the Flow view.</p> <p></p> <p>Step 2. Right-click in the flow view and from the contextual menu select the \"Script &gt; KickAss ShaderZ &gt; Substance PBR Import\" menu item to launch the script.</p> <p></p> <p>Step 3. Customize the settings in the dialog, then click the \"Create PBR Material\" button.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#gui-controls","title":"GUI Controls","text":"<p>GUI Controls</p> <p>PBR Surface Material</p> <p>The \"PBR Surface Material\" ComboBox allows you to choose either a \"Cook Torrance/Reflect\", or a \"CustomShader3D (Alpha)\" based material workflow.</p> <p></p> <p>Note: You need to have the 3<sup>rd</sup> party \"CustomShader3D\" plugin installed in Fusion Studio v9 for Windows in order to use this option.</p> <p>Add Environment Map</p> <p>The \"Add Environment Map\" checkbox allows you to have an HDRI panoramic image added to the node graph automatically.</p> <p></p> <p>Add Shader Ball</p> <p>The \"Add Shader Ball\" checkbox allows you to have a polygon mesh added to the node graph automatically for use as preview geometry for your surface materials.</p> <p></p> <p>This is a preview of the KickAss ShaderZ \"kas_ShaderBall\" node with PBR Materials applied to it.</p> <p></p> <p>Add Note</p> <p>The \"Add Note\" checkbox inserts a note node into the composite which summarizes the texture maps and settings used when the PBR materials were imported.</p> <p></p> <p>This is a preview of the type of information that is automatically added to the Node node when the PBR Materials are imported.</p> <p></p> <p>Reset to Defaults</p> <p>The \"Reset to Defaults\" checkbox reverts the settings in the dialog back to their initial factory default values.</p> <p></p> <p>? / Help</p> <p>The \"?\" help button shows the built-in help documentation (which you are currently viewing now).</p> <p></p> <p>Create PBR Material</p> <p>The \"Create PBR Material\" button will process the current Loader node selection in the flow view to generate a full set of imported PBR maps connected to a Fusion surface material.</p> <p></p> <p>Image Channels</p> <p>A Substance \"PBR Metal Rough\" export workflow is expected by this script. That means you will have a set of texture maps with the following PBR map channels:</p> <p>BaseColor</p> <p>Roughness</p> <p>Normal</p> <p>Metallic</p> <p>Height</p> <p>Emissive</p> <p>These maps will be named with a filename formatted like:</p> <pre><code>image_&lt;map&gt;.ext\n</code></pre> <p>Note: It would be possible to add PBR texture import support for additional naming conventions such as importing maps and building the shading network for the LearnNowFX AccuShader plugin, or loading in footage based upon the naming patterns of Disney Principal texture maps, or Pixar Surface texture maps if there was user interest.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#substance-material-export","title":"Substance Material Export","text":"<p>Substance Material Export</p> <p>In Substance Painter select the \"File &gt;Export Textures...\" menu item to prepare your final baked and flattened texture maps.</p> <p></p> <p>In the \"Export document...\" dialog set the export location using the button at the top of the dialog. Then set the \"Config\" attribute to use the \"PBR MetalRough\" option to generate the correct texture maps.</p> <p>Finally, click the \"Export\" button to save out the textures.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#content-browser","title":"Content Browser","text":"<p>Content Browser</p> <p></p> <p>The \"Content Browser\" window allows you to effortlessly navigate through the \"Industrial\", \"Natural\", \"Utility\", and \"HDRI\" categories of macros included in the KAS shader collection. This view is accessed using the \"KickAss ShaderZ &gt; Content Browser...\" menu item.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#kickass-shaderz-descriptions","title":"KickAss ShaderZ Descriptions","text":"<p>KickAss ShaderZ Descriptions</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#industrial","title":"Industrial","text":"<p>Industrial</p> <p>kas_Atomic</p> <p>\"kas_Atomic\" creates an irradiated material that is self-illuminated with an orange shade.</p> <p></p> <p>kas_Chrome</p> <p>\"kas_Chrome\" creates a super shiny metallic surface.</p> <p></p> <p>kas_CobaltBlueCarbonFibre</p> <p>\"kas_CobaltBlueCarbonFibre\" is great for futuristic hard surface modelled objects where you might want a procedurally textured lightly scuffed surface for added photorealism.</p> <p></p> <p>kas_GlassDeepBlue</p> <p>\"kas_GlassDeepBlue\" is a semi-transparent glass material. A primitive attempt has been taken to simulate a faked blue color absorption effect on the material using a Falloff node.</p> <p></p> <p>kas_GlassDeepRuby</p> <p>\"kas_GlassRuby\" is a semi-transparent glass material. A primitive attempt has been taken to simulate a faked red color absorption effect on the material using a Falloff node.</p> <p></p> <p>kas_GlassDirty</p> <p>\"kas_GlassDirty\" creates a semi-transparent glass with a layer of grime coating the surface.</p> <p></p> <p>kas_GlassQuartzScratched</p> <p>\"kas_GlassQuartzScratched\" is a semi-transparent glass material. A primitive attempt has been taken to simulate a faked purple color absorption effect on the material using a Falloff node.</p> <p></p> <p>kas_Gold</p> <p>\"kas_Gold\" creates a stylized NPR metallic surface material that could be used for logos and titles. The lustre of the gold is highly dependent on the lighting angle. Make sure to enable the Fusion 3D workspace \"3D Options &gt; Lighting\" mode so you see an accurate preview of the material in the realtime viewport.</p> <p></p> <p>kas_HeatShield</p> <p>\"kas_HeatShield\" generates a super-heated plasma-like fresnel shading effect that can be used to create earth atmosphere re-entry shading effects for spacecraft or meteorites. The material can also be modified to augment the look of tracer bullets, incendiary rounds, or futuristic ballistic weaponry that need a plasma like heat bubble that wraps around the projectile.</p> <p>When you render the \"kas_HeatShield\" surface material, don't forget to explore adding an exponential glow effect to the final frame to increase the incandescent luminoous feel of the material. The \"TextureMap\" input connection on the node supports images with alpha channels which can punch holes through the final material for a patch-work shading effect.</p> <p>If you want to see the kas_HeatShield material with the same look as the thumbnail has, open the provided kas_HeatShield.comp file located at \"Reactor:/Deploy/Comps/KickAss ShaderZ/kas_HeatShield.comp\".</p> <p>This composite has a customized Light Rotate XYZ value on the kas_ShaderBall node.</p> <p></p> <p>kas_MetalGalvanized</p> <p>\"kas_MetalGalvanized\" creates an industrial sheet metal material.</p> <p></p> <p>kas_MetalScuzzy</p> <p>\"kas_MetalScuzzy\" is a metallic material that has become dulled by a thick layer of dirt and grime.</p> <p></p> <p>kas_Radioactive</p> <p>\"kas_Radioactive\" creates an irradiated material that is self-illuminated with a strong violet shade.</p> <p></p> <p>kas_RustyNail</p> <p>\"kas_RustyNail\" creates a worn, oxidized steel material.</p> <p></p> <p>kas_Xray</p> <p>\"kas_Xray\" creates a stylized and colourful NPR rendering effect of a medical X-ray material.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#natural","title":"Natural","text":"<p>Natural</p> <p>kas_DarkBlueIceShard</p> <p>\"kas_DarkBlueIceShard\" creates a frosted blue icy material.</p> <p></p> <p>kas_GreenEctoplasm</p> <p>\"kas_GreenEctoplasm\" is perfect for organic effects like semi-transparent gloopy liquids, or otherworldly paranormal objects.</p> <p></p> <p>kas_IridescentBlue</p> <p>\"kas_IridescentBlue\" creates a luminous material with a saturated blue sheen, and a fresnel edge shading effect.</p> <p></p> <p>kas_MarbleStone</p> <p>\"kas_MarbleStone\" creates a glossy tiled floor material. You can choose to render this stone with a full surface displacement effect on the mesh.</p> <p>To get the displacement effect out of this material you need to add a Displace3D node and connect its \"SceneInput\" input to a 3D model's \"3DData\" output connection. Then connect the \"kas_MarbleStoneDisplace\" node's \"DisplacementTextureOutput\" connection to the Displace3D node's \"Input\"connection.</p> <p>The strength of the displacement effect is controlled on the Displace3D node's scale attribute with a good starting value of approximately 0.02.</p> <p></p> <p>kas_MarbleStone Asset Licenses:</p> <p>Freeware:\\ kas_MarbleStone PBR Textures</p> <p>By:\\ https://www.textures.com</p> <p>Is licensed under:\\ CG Textures Freeware</p> <p>Creative Commons:\\ St.\u00a0Nicholaus Church Interior HDRI</p> <p>By:\\ https://hdrmaps.com</p> <p>Is licensed under:\\ CC BY 2.0</p> <p>kas_OrganicMote</p> <p>\"kas_OrganicMote\" is perfect for stylized NPR rendering needs such as bio-medical visualization. If you are assigning this material to animated elements that are floating around and drifting slowly in your scene, make sure to enable motion blur and DoF bokeh blur in your renderings for added realism.</p> <p></p> <p>kas_Ocean</p> <p>\"kas_Ocean\" macro creates a multi-spectral ocean material that combines an HDRI environment map with a simulated sub-surface translucent like shading layer.</p> <p></p> <p>kas_Ocean Asset Licenses:</p> <p>Simon's Town Rocks, Cape Town, South Africa IBL</p> <p>Creative Commons:\\ Simon's Town Rocks</p> <p>By:\\ https://hdrihaven.com/</p> <p>Is licensed under:\\ CC0 (Public Domain)</p> <p>Anonymous Water Template</p> <p>The Anonymous Water Template is the actual Fusion 3D water setup as it was used on Roland Emmerich's Anonymous (2011) film, courtesy of Uncharted Territory.</p> <p>SIGGRAPH 2012 Presentation on Anonymous:\\ https://www.youtube.com/watch?v=mOpN6C3ZrjY</p> <p>kas_RedBloodCell</p> <p>\"kas_RedBloodCell\" is perfect for stylized NPR rendering needs such as bio-medical visualization of high detail blood cells flowing in a bloodstream.</p> <p>If you are assigning this material to animated blood cells that are floating around and drifting slowly in your scene, make sure to enable motion blur and DoF bokeh blur in your renderings for added realism.</p> <p></p> <p>kas_StoneWall</p> <p>\"kas_StoneWall\" creates a rough wall from fieldstone and mortar. You can choose to render this stone with a bump map, or with a full surface displacement effect on the mesh.</p> <p>To get the displacement effect out of this material you need to add a Displace3D node and connect its \"SceneInput\" input to a 3D model' s \"3DData\" output connection. Then connect the \"kas_StoneWall\" material' s \"DisplacementTextureOutput\" connection to the Displace3D node' s \"Input\" connection.</p> <p>The strength of the displacement effect is controlled on the Displace3D node's scale attribute with a good starting value of approximately 0.2.</p> <p></p> <p>kas_MarbleStone Asset Licenses:</p> <p>Freeware:\\ kas_StoneWall PBR Textures (Castle Stone Wall)</p> <p>By:\\ https://quixel.com/megascans</p> <p>Is licensed under:\\ Quixel Megascans Freeware</p> <p>kas_VelvetyMoss</p> <p>\"kas_VelvetyMoss\" is perfect for stylized NPR rendering organic elements such as bio-medical visualization.</p> <p></p> <p>kas_VolcanicMagma</p> <p>\"kas_VolcanicMagma\" creates a super hot molten rock material. When you render this material, consider attaching a 2D glow effect to highlight the surface cracks that are luminous.</p> <p>To get the displacement effect out of this material you need to add a Displace3D node and connect its \"SceneInput\" input to a 3D model' s \"3DData\" output connection. Then connect the \"kas_VolcanicMagma\" material' s \"DisplacementTextureOutput\" connection to the Displace3D node' s \"Input\" connection.</p> <p>The strength of the displacement effect is controlled on the Displace3D node's scale attribute with a good starting value of approximately 0.2.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#utility","title":"Utility","text":"<p>Utility</p> <p>kas_IconSaver</p> <p>\"kas_IconSaver\" renders a Fusion v9 Bin window 130x100 px BMP format icon to the Comp PathMap folder. If you have HiQ enabled simply viewing this node will write you new bin icon to disk.</p> <p>This node is supposed to be connected directly to the \"kas_ShaderBall.Output\" node's output connection.</p> <p>The kas_IconSaver node includes an integrated copy of the GreyCheckerboard macro. GreyCheckerboard is based upon the \"Checkerboard\" macro from the Muse Tools Library by Joe Laude.</p> <p></p> <p>kas_GreyCheckerboard</p> <p>\"kas_GreyCheckerboard\" renders a preview shader swatch with a baked in grey checker background.</p> <p>GreyCheckerboard is based upon the \"Checkerboard\" macro from the Muse Tools Library by Joe Laude.</p> <p></p> <p>kas_ShaderBall</p> <p>\"kas_ShaderBall\" adds a shader ball model to your Fusion 3D system scene. It is used to apply and preview the look of surface materials. Make sure to enable the Fusion 3D workspace \"3D Options &gt; Lighting\" mode so you see an accurate preview of the material in the realtime viewport.</p> <p>This node's output is supposed to be connected directly to the \"kas_ShaderPreview\" nodes input connection so you can see a high-quality preview of your surface material.</p> <p></p> <p>kas_ShaderBallDragon</p> <p>\"kas_ShaderBallDragon\" adds a Stanford Dragon model shader ball to your Fusion 3D system scene. It is used to apply and preview the look of surface materials. Make sure to enable the Fusion 3D workspace \"3D Options &gt; Lighting\" mode so you see an accurate preview of the material in the realtime viewport.</p> <p>This node's output is supposed to be connected directly to the \"kas_ShaderPreview\" nodes input connection so you can see a high-quality preview of your surface material.</p> <p>The \"DragonUVMap3D\" node inside the GroupOperator allows you to adjust the UV layout on the model and its perfect for tweaking how the texture map is placed on the mode.</p> <p></p> <p>kas_ShaderBallDragon Asset License:</p> <p>By:\\ The Stanford 3D Scanning Repository</p> <p>Is licensed under:\\ Public Domain</p> <p>kas_ShaderPreview</p> <p>\"kas_ShaderPreview\" is has a Renderer3D node inside is that renders a preview shader swatch with a baked-in grey checker background.</p> <p>This node is supposed to be connected directly to the \"kas_ShaderBall.Output\" node's output connection.</p> <p>The kas_ShaderPreview node includes an integrated copy of the GreyCheckerboard macro. GreyCheckerboard is based upon the \"Checkerboard\" macro from the Muse Tools Library by Joe Laude.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#hdri","title":"HDRI","text":"<p>HDRI</p> <p>kas_Parkland</p> <p>\"kas_Parkland\" is an HDRI image of Egg mountain in Gory Sowie, Poland. The foreground of the image has a grassy field with smooth rolling mountains stretching upwards in the distance.</p> <p></p> <p>kas_SimonsTownRocks</p> <p>\"kas_SimonsTownRocks\" is an HDRI image of a rocky coastal shoreline in Simon's Town, Cape Town, South Africa.</p> <p></p> <p>kas_StNicholasChurch</p> <p>\"kas_StNicholasChurch\" is an HDRI image of the interior of the Dominican order's St.\u00a0Nicholas Church in Gda\u0144sk, Poland. The church was originally erected in 1227. The interior of the church currently features a baroque altar design with a black and golden colored theme.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#copyright-credits","title":"Copyright Credits","text":"","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#copyright-credits_1","title":"Copyright Credits","text":"<p>kas_Parkland</p> <p>Creative Commons:\\ Egg mountain at afternoon</p> <p>By:\\ https://hdrmaps.com</p> <p>Is licensed under:\\ CC BY 2.0</p> <p>Simon's Town Rocks, Cape Town, South Africa IBL</p> <p>Creative Commons:\\ Simon's Town Rocks</p> <p>By:\\ https://hdrihaven.com/</p> <p>Is licensed under:\\ CC0 (Public Domain)</p> <p>St.\u00a0Nicholas Church, Gdansk, Poland IBL</p> <p>Creative Commons:\\ St.\u00a0Nicolaus Church Interior HDRI</p> <p>By:\\ https://hdrmaps.com</p> <p>Is licensed under:\\ CC BY 2.0</p> <p>kas_StoneWall</p> <p>Freeware:\\ kas_StoneWall PBR Textures (Castle Stone Wall)</p> <p>By:\\ https://quixel.com/megascans</p> <p>Is licensed under:\\ Quixel Megascans Freeware</p> <p>kas_MarbleStone</p> <p>Freeware:\\ kas_MarbleStone PBR Textures</p> <p>By:\\ https://www.textures.com</p> <p>Is licensed under:\\ CG Textures Freeware</p> <p>Anonymous Water Template</p> <p>The Anonymous Water Template is the actual Fusion 3D water setup as it was used on Roland Emmerich's Anonymous (2011) film, courtesy of Uncharted Territory.</p> <p>SIGGRAPH 2012 Presentation on Anonymous:\\ https://www.youtube.com/watch?v=mOpN6C3ZrjY</p> <p>GreyCheckerboard</p> <p>GreyCheckerboard is based upon the \"Checkerboard\" macro from the Muse Tools Library by Joe Laude.</p> <p>kas_ShaderBallDragon Asset License:</p> <p>By:\\ The Stanford 3D Scanning Repository</p> <p>Is licensed under:\\ Public Domain</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#shaderz-texture-inputs","title":"ShaderZ Texture Inputs","text":"<p>ShaderZ Texture Inputs</p> <p>There are two image input connections on most of the ShaderZ material nodes named \"TextureMap\" and \"EnvironmentMap\".</p> <p>The \"TextureMap\" input connection allows you to supply your own imagery that will be applied as the base texture map. The \"EnvironmentMap\" input connection allows you to supply your own spherical environment image that will be visible as the reflected environment for the material.</p> <p></p> <p>Note: When imagery is connected to these inputs they are automatically activated and used inside the material via a pair of SwitchElse.fuse nodes that are packed inside the shader. The second you disconnect your imagery from the input connections the surface material defaults back to the internal default texture maps.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#fusion-effects-tab","title":"Fusion Effects Tab","text":"<p>Fusion Effects Tab</p> <p>In Fusion Studio Standalone you can access the KickAss ShaderZ by open up the \"Effects\" Tab. Then expand the \"Templates &gt; KickAss ShaderZ &gt; Native ShaderZ &gt;\" section. You can now select between a \"Industrial\", \"Natural\", and \"Utility\" set of surface materials.</p> <p>You can drag/drop any of the items in this Templates list into your Nodes view and they will be instantly added to your composite.</p> <p></p> <p>Note: Try to make sure to drag the nodes to an open space in the Nodes view so the new material's node-based content doesn't co-mingle with your existing node graph and cause the content to pile up in an unsightly \"heap of nodes\". If this issue ever happens to you, all you have to do to rectify the situation is to hit the \"Edit &gt; Undo &gt;\" menu item to remove the most recently added nodes from the comp.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#fusion-select-tool","title":"Fusion Select Tool","text":"<p>Fusion Select Tool</p> <p>Pressing the \"Shift + Spacebar\" hotkey when Fusion's Nodes view is in focus will display a \"Select Tool\" dialog. Typing in \"kas_\" is a quick way to filter the list of available nodes down to the content provided by the \"KickAss ShaderZ\" collection.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#kickass-shaderz-menu","title":"KickAss ShaderZ Menu","text":"<p>KickAss ShaderZ Menu</p> <p>The \"KickAss ShaderZ\" root level menu system in Fusion Studio provides a quick way to access the full shader collection and the shader tools.</p> <p></p> <p>The KAS menu layout consists of the following entries:</p> <p>KickAss ShaderZ &gt;</p> <ul> <li>Native ShaderZ &gt;<ul> <li>HDRI &gt;<ul> <li>kas_Parkland</li> <li>kas_SimonsTownRocks</li> <li>kas_StNicholasChurch</li> </ul> </li> <li>Natural &gt;<ul> <li>kas_DarkBlueIceShard</li> <li>kas_GreenEctoplasm</li> <li>kas_IridescentBlue</li> <li>kas_MarbleStone</li> <li>kas_OrganicMote</li> <li>kas_Ocean</li> <li>kas_RedBloodCell</li> <li>kas_StoneWall</li> <li>kas_VelvetyMoss</li> <li>kas_VolcanicMagma</li> </ul> </li> <li>Industrial &gt;<ul> <li>kas_Atomic</li> <li>kas_Chrome</li> <li>kas_CobaltBlueCarbonFibre</li> <li>kas_GlassDeepBlue</li> <li>kas_GlassDeepRuby</li> <li>kas_GlassDirty</li> <li>kas_GlassQuartzScratched</li> <li>kas_Gold</li> <li>kas_HeatShield</li> <li>kas_MetalGalvanized</li> <li>kas_MetalScuzzy</li> <li>kas_Radioactive</li> <li>kas_RustyNail</li> <li>kas_Xray</li> </ul> </li> <li>Production<ul> <li>...</li> </ul> </li> <li>Utilty &gt;<ul> <li>kas_IconSaver</li> <li>kas_GreyCheckerboard</li> <li>kas_ShaderBall</li> <li>kas_ShaderBallDragon</li> <li>kas_ShaderPreview</li> </ul> </li> </ul> </li> <li>CustomShader3D ShaderZ &gt;<ul> <li>Install the CustomShader3D Plugin</li> <li>...</li> </ul> </li> <li>PBR ShaderZ &gt;<ul> <li>...</li> </ul> </li> <li>Tools &gt;<ul> <li>Show KAS Docs</li> <li>Show KAS Macros Folder</li> <li>Show KAS Comps Folder</li> <li>Show KAS Config Folder</li> <li>Save Selection to Macro</li> <li>Package ShaderZ for Reactor...</li> </ul> </li> <li>Resources &gt;<ul> <li>KAS Documentation</li> <li>KAS WSL Discussion</li> </ul> </li> <li>Content Browser...</li> <li>About KickAss ShaderZ...</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#kas-tools","title":"KAS Tools","text":"<p>KAS Tools</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/KickAss%20ShaderZ%20for%20Fusion/#save-selection-to-macro","title":"Save Selection to Macro","text":"<p>Save Selection to Macro</p> <p>The \"KickAss ShaderZ &gt; Tools &gt; Save Selection to Macro\" menu item exports the active Nodes view selection to a new Fusion \"Macros\" PathMap based \".setting\" file on disk. This makes it a lot easier for comp artists to create and save out their own macros with less effort.</p> <p></p> <p>When you run the \"Save Selection to Macro\" menu item, a file save dialog appears. You can then type in a name for your new macro \".setting\" file and choose a folder location where you want the macro saved to.</p> <p></p> <p>Whatever nodes are selected in the Nodes view are then instantly exported and pushed out to this new macro .setting file. Your newly saved macro is then opened up in the external script editor that is defined in the Fusion Preferences \"Global and Default Settings &gt; Script &gt; Editor Path\" section.</p> <p>By opening up the macro file in an external text editor like Notepad++ (Windows) / BBEdit (macOS) / gedit (Linux) it is possible to add the final polish like adding a CustomData HelpPage entry, or renaming the input and output connections.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/","title":"OpenDisplayXR/VDD","text":"<p>OpenDisplayXR/VDD (Virtual Device Driver) \"A Simulated OpenVR/OpenXR-Based Virtual Hardware Device\" Document source on docs.google.com Project workspace https://github.com/OpenDisplayXR</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#project-objectives","title":"Project Objectives","text":"<p>Create a working group to develop a cross-platform compatible, hybrid OpenVR/OpenXR API-based virtual display driver solution for arbitrary multi-view display, and video projection hardware.</p> <p>When completed, the \"OpenDisplayXR VDD (Virtual Device Driver)\" toolset works as a simulated OpenVR/OpenXR-based virtual hardware device.</p> <p>The VDD software powers the visual output that is sent in real-time to multiple displays in parallel. The VDD SDK allows you to transform-VR optimised graphics rendering API calls into a pipeline for arbitrary multi-view stereo media creation.</p> <p>The final-frame pixels can be rendered on any number of local-region hosted Amazon AWS EC2 instances, or the full process can run 100% locally on-prem with a GPU-equipped laptop, desktop, workstation, rack-mounted server, or a virtualized VIRSH/QEMU compute instance with hardware accelerated PCIe passthrough support.</p> <p>The modular codebase that the OpenDisplayXR project is creating, right now, is covered by a 100% free, open-source \"license mix\" based Apache/NVIDIA source code license terms, based upon the individual VDD microservices you install.</p> <p>A virtual device driver rendering approach allows existing DCC (Digital Content Creation) software, that supports conventional VR HMDs (Head Mounted Displays), to automatically work interactively with arbitrary 3<sup>rd</sup> party immersive display systems used for stereoscopic, 360VR, 180VR, iDome, SfM, lightfield, and multi-view applications.</p> <p>This user-programmable image generation bridge layer offers more flexibility, that enables use cases like the ability to drive in real-time passive 3D stereo-monitor display solutions, immersive caves, fulldome theatres, projection mapping, virtual production LED stages with composting-created live-action stitched 360VR cylindrical video and 2D/2.5D/3D digital matte paintings.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#modular-vdd-microservices","title":"Modular VDD Microservices","text":"<p>A foundational, key design aspect of the \"OpenDisplayXR VDD (Virtual Device Driver)\" SDK rollout, is the consistent use of a microservices architecture. The use of microservices is applied equally to internal core operators and external user-added microservice features. All microservice plugins get bare-metal direct access to the rendering hardware and VDD-API-provided functions.</p> <p>The OpenDisplayXR VDD operator nodes are designed to be chained together in novel ways by the end user. This process is streamlined, with the help of a powerful preset system, visual macro-building tools, and support for deeply nested, externally referenced flowcharts.</p> <p>When the node graph is evaluated (cooked) during real-time playback, a node-based concatenation approach is used by the VDD node's chosen JIT (Just in Time) compiler that is designed to optimize the rendering performance. Memory management is improved by the JIT compiler's ability to dynamically flatten a series of \"chained operations\" at render time if the nodes have matching class types.</p> <p>Background: The VDD API design choice to rely on node-based microservices comes from experiences learned during the development of the open-source Vonk Data Node project. Vonk includes 329 fuses.</p> <p>A fuse is created as a plain-text-based LuaJIT plugin. Data nodes are interconnected in a DAG (Directed Acyclic Graph) like nodal environment, through the use of a wide range of node-based input and output connection data types that can be converted (and typecasted on the fly) as needed.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#nodal-operator-types","title":"Nodal Operator Types","text":"<p>The node-based content that defines a specific VDD setup, is exported to disk via a DOM (Document Object Model) approach into either a plain-text encoded JSON file, or a CompX-flavored OpenUSD ASCII (.usda) file.</p> <p>End users can extend any of the operators available inside the micro-services architecture via the installation of plain-text-based JIT-evaluated plugins, or compiled C++ based plugins.</p> <p>Full source-code access is provided for all internal VDD micro-service operators, which allows the core features to be customized and extended by the end user on an as-needed basis.</p> <p>The core operator types used in a typical multi-view OpenXR-OpenVR driven VDD project include:</p> <ul> <li>HID Input</li> <li>Output Driver</li> <li>Fragment Shaders</li> <li>Data Nodes</li> <li>Scripting</li> <li>Network Transport</li> </ul> <p>End users are free to implement support for new class types in their own microservice plugins. Through the use of a JIT architecture, VDD supports the creation and use of arbitrary \"data node\" based input and output data types on-the-fly.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#microservices-package-manager","title":"Microservices Package Manager","text":"<p>OpenDisplayXR has a custom LuaJIT-based package manager that is under development.</p> <p>To streamline deployments, the package manager will allow administrators to perform \"network broadcast based\" syncing of custom microservice plugins across a local subnet of GPU-based worker nodes.</p> <p>Newly added microservices that are code-signed, and approved for use by a sysadmin, will be re-initialized in only a few moments by the VDD controller process. This allows deployments to occur in a transparent \"system wide\" fashion that works seamlessly across a large GPU clutter that runs across several different operating systems and CPU/GPU architectures.</p> <p>Microservice updates happen in a low-friction fashion, without requiring the end-user to quit a VDD integration plugin's host process, or requiring someone to re-launch a CLI worker's executable or needing a reboot of the system. This feature dramatically minimizes downtime and keeps the real-time distributed rendering system online, and ready for use in a high-availability state.</p> <p>The design concepts of the VDD package manager implementation are inspired by the success of the Steakunderwater forum hosted Blackmagic Resolve/Fusion community project called the \"Reactor Package Manager\".</p> <p>Reactor uses a modular .atom formatted Lua table structure to define installation bundles that are sourced from any number of user-configured, public or private GitLab/GitHub repos, or local/NAS based disk storage location.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#build-a-6dof-rt-previsualization-station","title":"Build a 6DoF RT Previsualization Station","text":"<p>Previsualization supervisors will enjoy the way VDD assists workstation-based previsualization tasks, like time-consuming \"techviz\". The Viz operational steps are accelerated by an order of magnitude by OpenDisplayXR. This efficiency is achieved, in-part through the removal of disk-based intermediate video/image files, media transcoding, which has the added bonus of reducing file server I/O operations, and significantly cuts down on unnecessary network bandwidth consumption.</p> <p>The VDD interface has a unique capability to dramatically simplify the process of connecting a HDR \"video texture\" pixel stream output, from a best-in-class NLE video timeline, or a colourist suite, directly to an external real-time 3D engine based visualisation tool. By doing this process, OpenDisplayXR supports 6DoF room-scale previsualization approaches of arbitrary image projection based media with assistance provided by a system's native OpenVR and OpenXR APIs.</p> <p>For in-office design review tasks, it is very effective to let OpenDisplayXR manage the visual image generating pipeline. A VDD can send multi-view media in a transparent fashion to large format passive stereo 3D monitoring solutions, like a 3D PluraView monitor. This class of passive display hardware makes it possible for 3 co-workers to wear light-weight polarizer glasses, at the same time, to collaborate and provide direct feedback on creative design or engineering tasks.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#plain-text-json-based-settings","title":"Plain-Text JSON-Based Settings","text":"<p>A single .json-based configuration file automatically configures all relevant parameters required to define a new hardware display product DCC integration. This makes it possible to rapidly test and iterate on new hardware setups without requiring the end user/integrator to maintain a complex build toolchain.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#user-input","title":"User Input","text":"<p>Optionally, any of the connected HID (Human Interface Devices) could be activated in the virtual device driver preferences so they are passed through the virtual VR/XR bridge interface to the host DCC package. This makes it possible for the HID hardware to appear as an emulated VR controller style of input device.</p> <p>When the alternative input device is configured as a simulated VR controller, input remapping techniques can change the nature of the input data stream, to establish constraints and range of motion limits, or to perform 3D coordinate system-based transforms for planar 2D motion-based input devices like graphics tablets or mice.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#output-driver","title":"Output Driver","text":"<p>An extensible \"output driver\" based plugin system allows live-rendered framebuffer data to pass with ultra-low latency from the virtual device driver interface into a post-processing stack that supports external libraries, and fragment shaders.</p> <p>The Output Driver is GPU accelerated via common cross-platform compatible rendering APIs (CUDA, DirectX DXR, OpenCL, Metal, OpenGL). The VRAM based framebuffer in the output driver supports layering ML (Machine Learning) neural style transfer effects, deep dream effects, and Hugging Face transformer models.</p> <p>When running at a reduced frame rate, deferred rendering of Stable Diffusion 2.0 \"img2img\" generators are possible with latent space support, including the use of multiple rasteror vector-shape based alpha masks for effects like ML-driven content-aware fill, seamless blending, and in/out painting.</p> <p>An \"output driver\" concept enables a wide range of customer-created solutions to be achieved such as; Applying WarpMesh techniques for iDome projection, using RTSP/HLS streaming video encoders, passing media to NDI-based IP video streaming connections, working with a frame server solution such as Syphon or Spout FFGL that utilise shared video memory techniques for VJing applications.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#temporal-feedback-loop-buffer","title":"Temporal Feedback Loop Buffer","text":"<p>Customizable in-memory visual feedback loops can be used inside the VDD output driver module. This is a wonderful feature if you need to create MVS compatible \"onion-skinning\" animation overlays, or to generate temporally delayed fadeable motion trail \"visual echos\" effects with a subtractive luminance decay. A feedback loop is also interesting when used with highly-stylized audio-reactive multi-pass image distortion effects used in immersive VJing.</p> <p>The feedback system has a FIFO 4D frame buffer duration parameter to support time-offsets.</p> <p>The multi-view VRAM stored FIFO frame buffer is also helpful when animating or retraining ML transformer models to build up the visual appearance of ML synthesized \"emergent design behaviours\".</p> <p>A good starting point is to try the visual feedback loop feature out, with a ShaderToy sourced fragment shader (like pixel sorting) applied in the VDD output driver stack.</p> <p>This combination of ML and fragment shader effects will very often result in the creation of artistically unique evolving 4D pipe-dream-esque imagery.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#live-360vr-media-reframing","title":"Live 360VR Media Reframing","text":"<p>For in-context immersive media review tasks, such as LED fulldome show QA checks, it is helpful to pass the raw multi-view media directly to the external process via shared memory, or with the use of pixel streaming to an external 360VR immersive media playback tool.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#virtual-environment-simulation","title":"Virtual Environment Simulation","text":"<p>Complex \"nested-visual simulation\" workflows can be satisfied using the generated pixel-streaming framebuffer content as a 2D texture map that is reapplied to a mesh within a game-engine centric virtual production LED stage techviz toolset. The 3<sup>rd</sup> party previz/techviz tools would apply the generated pixel-streamed data on the fly to a textured \"screen surface\" that is part of a 1:1 3D scale model of a simulated sound stage/ LED dome theatre environment.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#scripted-actions-callback-events","title":"Scripted Actions &amp; Callback Events","text":"<p>Lua scripting could be used in the virtual device driver HID settings to configure and apply scripted actions or replay pre-recorded \"input motion\" clips that are passed through as simulated HID control input data with absolute coordinates or relative coordinate system offsets. The scripted action system could be triggered by any of the mappable Aux (Auxiliary) input controls on HID devices, or via OSC (Open Sound Control) based protocol signals via tools like TouchOSC or MIDI hardware.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#initial-rd-team","title":"Initial R&amp;D Team","text":"<p>Developers</p> <ul> <li>Andrew Hazelden (Dover Studios and Kartaverse), Canada, Principal Researcher</li> <li>Paul Bourke, Australia, Digital capture and processing for immersive displays</li> </ul> <p>Creative</p> <ul> <li>Antonio Victor Garcia-Serrano (Zakato360), Spain, Creative Advisor</li> <li>Alexandre Regeffe, France, Creative Advisor</li> <li>Frederic Fermon (CST - Commission Sup\u00e9rieure Technique), France, Creative Advisor</li> <li>Hogan Burrows (Untitled Project), Singapore, Creative Advisor</li> <li>Jared Sandrew, USA, Creative Advisor</li> <li>Joergen Geerds (KonceptVR), USA, Creative Advisor</li> </ul> <p>Technical</p> <ul> <li>Alexis Haggar(LexhagVFX), UK, Technical Advisor</li> <li>Alexey Bogomolov, Technical Advisor</li> <li>Marc-Antoine Desjardins, Canada, Technical Advisor</li> <li>Peregrine Mc Cafferty, UK, Technical Advisor</li> </ul> <p>Fulldome</p> <ul> <li>Allen Rose, USA, Technical Advisor</li> <li>Dario Tiveron (FDDB), Italy, Creative Advisor</li> <li>Greg Downing (Hyperacuity), USA, Creative Advisor</li> <li>Matthew Dougherty (NOAA), USA, Lead Technical Advisor</li> <li>Paul Mowbray (NSC Creative), UK, Creative Advisor</li> <li>Peter Morse, Tasmania, Creative Advisor</li> </ul> <p>Virtual Production</p> <ul> <li>Aurore de Blois (Drengr Bilder), UK, Creative Advisor</li> <li>Tobias Falk (Cinegrace), Sweden, Technical Advisor</li> <li>Tomas Wall (Cinegrace), Sweden, Technical Advisor</li> <li>Kino Gil (Kino Digital), USA, Creative Advisor</li> </ul> <p>Industry Partners</p> <ul> <li>Josef J. Schneider, (Schneider Digital), Germany, Display Hardware Vendor</li> <li>Lutz Moehr, (Schneider Digital and 3D-CC / DNS Consult), Germany, Consultant / Networker / Event organizer</li> </ul>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#software-interface","title":"Software Interface","text":"<p>The virtual device driver is bound to the external DCC package using the conventional OpenVR/OpenXR support in the host toolset.</p> <p>The following screenshot shows Blackmagic Design's Fusion Studio compositing software. The \"VR Headset\" preference is used to define \"OpenVR\" as the active API. This single control is the only setting required to allow a 3<sup>rd</sup> party OpenVR/OpenXR virtual device driver to be enabled on the DCC package side of things.</p> <p>Blackmagic Design's DaVinci Resolve Studio video editing and color correction software uses the same style of HMD connectivity settings as are present in the Fusion page.</p> <p></p> <p>Node Based Workflows</p> <p></p> <p>This Blackmagic Design DaVinci Resolve v18.1 Fusion page node graph shows an initial proof-of-concept \"OpenDisplayXR VDD\" workflow. The comp imports Kartaverse Z360 (Color + depth) equirectangular image projection media as a Fusion 3D system processed content via the Renderer3D node. The WIP logic for the OpenDisplayXR VDD node was implemented via Vonk Data Nodes, and a custom Fuse that is capable of rendering DCTL fragment shaders, and returns the output to a C++ bridge shared library implemented with LuaJIT's FFI feature.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#demo-apps","title":"Demo Apps","text":"","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#neuralfoam-for-syntheyes-pro","title":"NeuralFoam for SynthEyes Pro","text":"<p>Andersson Technologies production-proven \"SynthEyes Pro\" matchmoving software is now able to export directly to a NeuralFoam flavoured OpenUSD ASCII (.usda) format for faster, more precise, and reliable, NeRF camera 4x4 transform matrix alignment.</p> <p>This unique, SynthEyes powered, multi-view camera tracking and neural rendering based workflow allows NVIDIA InstantNGP based NeRF scenes to be created more efficiently.</p> <p>SynthEyes already has an efficient UI that provides access to manual and supervised trackers, fine-grained editing of camera paths via spline editing controls, and the ability to intuitively control the scene origin, scale, and world Up-axis coordinate system.</p> <p></p> <p>SynthEyes is able to export a non-NeRF based output for use in all common DCC programs, as well as in NLE packages like Resolve.</p> <p>The following YouTube video, by Russ Andersson, explores what is possible with SynthEyes Pro's USD (Universal Scene Description) format capabilities.</p> <p>Exporting a NeuralFoam ready camera transform matrix from SynthEyes Pro is as easy as selecting the \"File &gt; Export &gt; Virtual Production &gt; NeuralFoam nVP Calibrated OpenUSD\" menu item. A Universal Scene Description ASCII encoded file is exported to disk with a unique \"CompX\" schema embedded that makes multi-view and volumetric content creation workflows friendlier.</p> <p>Having both NeRF and conventional match moving/photogrammetry export paths in SynthEyes Pro allows the creation of a hybrid volumetric scene with point clouds, meshes, multi-view 3D camera locators, stand-in geometry, and 3D locators.</p> <p>A pre-existing SynthEyes + Resolve based workflow tutorial, by one of the VDD developers, is available. The video shows how quickly an aerial scene shot on a drone can be camera tracked, and then loaded directly as a node-based 3D composite in the Fusion page.</p> <p>The OpenDisplayXR SDK provided sizzle scripts are installed to:</p> macOS <pre><code>/Applications/SynthEyes/scripts/Virtual Production/neuralfoam.szl\n</code></pre> Windows <pre><code>C:\\Program Files\\Andersson Technologies LLC\\SynthEyes\\scripts\\Virtual Production\\neuralfoam.szl\n</code></pre>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#neuralfoam-ofx-plugin","title":"NeuralFoam OFX Plugin","text":"<p>A C++ based OFX plugin named \"NeuralFoam Engine for Resolve\" will be included with the finished OpenXR/OpenVR compatible Virtual Device Driver SDK.</p> <p></p> <p>The OpenFX node is a port of the NVIDIA InstantNGP TestBed executable with OpenXR SDK supportincluded for direct 6DoF HMD connectivity.</p> <p>Check out the guide \"Kartaverse Workflows | Creating Volumetric NeRFs\" for more information about live-action based NeRF capture workflows, and how to build InstantNGP from source. A next-gen nVP workflow guide is available that acts as a semi-official overview of nVP concepts for LED volume creation. The document is titled \"Kartaverse Workflows | Building an Effective nVP (Neural Virtual Production) Sound Stage\".</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#neuralfoam-worker-cli","title":"NeuralFoam Worker CLI","text":"<p>Additionally, a standalone CLI launched \"NeuralFoam Worker Node\" will be included with the OpenDisplayXR VDD SDK when it is released.</p> <p>This neural rendering client is a direct adaptation of Thomas M\u00fcller &amp; Alex Evans' NeRF testbed executable. The testbed code is available publicly from NVIDIA's GitHub page for InstantNGP under an NVIDIA Source Code License.</p> <p>The ported open-source code was redesigned by the VDD developers to better handle HPC workloads, with load balancing, task scheduling, and XML-RPC socket support. The worker supports dynamic GPU performance tuning with support for temperature sensing, and automatic GPU fan speed control. When extreme performance is required, user-controlled tweaks can be defined for GPU parameters like core voltage (mV), core clock (MHz), memory clock (MHz), power limits, and temperature limits.</p> <p>The NeuralFoam worker runs its rendering process in a 100% real-time fashion with an immediate mode UX overlay for advanced cluster rendering diagnostics. Pixel streaming techniques are used to either pass image tiles back to the \"NeuralFoam Engine\" controller host software package (like Resolve) where the buckets are re-assembled into a unified image, or the tiles can be batched together into larger regions, recombined, and then routed via Ethernet, NDI, or SDI, so the image data arrives at a predefined LED processor device that is connected to a specific LED panel on the LED sound stage video wall.</p> <p>The NeRF generated render bucket tasks are distributed across a GPU cluster using a form of tile-based distributed rendering acceleration. The buckets are responsive and intelligent in that each render thread controls a dynamically sized multi-channel HDRI framebuffer. The pixel data is tunnelled over a conventional network using a parallel I/O approach that passes data through a series of high-speed low-latency pixel streaming connections.</p> <p>The NeuralFoam Worker executable is capable of running affordably with a rack-mounted NVIDIA RTX GPU enabled server that hosts an NVLink bridge connected pair of 3090/3090 TI graphics cards.</p> <p>A local cluster of GPU powered worker nodes are synced to a line-level accurate genlock unit. The active Workers perform the real-time distributed rendering of large NeRF scenes with the assistance of camera Frustum-defined DoD (Domain of Definition) 3D region cropping.</p> <p>An OpenDisplayXR VDD hardware certified NeRF render node is useful in virtual production LED stage environments where large-scale neural radiance fields provide a compelling alternative to traditional \"machinima\" style OpenGL/DirectX based graphics.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#nerf-ntb-neural-texture-baker","title":"NeRF NTB (Neural Texture Baker)","text":"<p>A sample NeRF-based NTB (Neural Texture Baker) tool is planned for release with the official Open DisplayXR SDK.</p> <p>NeRF scene graphs are interesting for immersive media content creators, and nVP (Neural Virtual Production) usage, as they allow a neural encoded representation of photorealistic lighting, shading, transparency, reflections, refractions, Beer's law colour-absorption, polarized lighting, and SSS(Subsurface Scattering).</p> <p>The NeRF NTB executable generates temporally stable animated texture maps that can be used on mesh sequence and point cloud sequence outputs. This is an excellent choice for workflows that need both NeRF flythrough renders, while also creating mobile-friendly AR .usdz-based assets that work efficiently on iPhones and iPad tablets as well as desktop systems for use in AAA quality USDZ encoded AR/MR/XR experiences.</p> <p>The provided source code and project files for NTB performs a unique MVS(multi-view stereo) centric version of geometry-defined texture baking operations. The supported output data formats are OpenUSD Clips, and e57 sequence-based dense point clouds.</p> <p>The final baked texture maps are exported as a multi-view encoded multi-part EXR image sequence with an anisotropic filtered, MIP-Mapped tiled encoding, using either None, ZIPS, or DWAA image compression.</p> <p>The NTB executable connects to an OpenDisplayXR .json preference file to access the transform matrix data for each of the multi-view definitions. These locator positions drive the positional values used for transferring NeRF shading information in a view-dependent fashion into a PTEX or UDIM-based UV layout on the polygon model.</p> <p>Creased Sub-D (Catmull-Clark subdivision surfaces) meshes with full-character rig skeletons are supported correctly with the texture transfer operation, however interactive performance is reduced.</p> <p>OpenUSD variants allow for the use of multi-resolution LOD (Level-of-Detail) sets on the imported models. The NTB texture transfer operation is effectively repeated for each LOD level present in a model and is accessed typically via USD VariantSet.</p> <p>OpenUSD .usdc (binary encoded) or .usda (ASCII encoded) scenes that use USD compositionfeatures often take advantage of reference layers and point instances. These scene-graph hierarchies are correctly evaluated when the texture baking occurs. Pixar's OpenUSD team provides additional information on OpenUSD terminology which can be handy for new users.</p> <p>A powerful token-based approach is offered to control the texture map output file naming syntax, and the EXR multi-part/multi-channel layer names. Per-frame-based OpenDisplayXR VDD metadata records can be encoded into each model and texture map if desired. This metadata system is compatible with node-based tools that support powerful \"data node\" workflows during post-production.</p> <p>The content production pipeline-friendly metadata passthrough feature includes support for retaining the original VDD-captured HID input data, a DOM-encoded version of the current VDD .json settings and external side-car file metadata that holds values like YAML-encoded lens information from protocols likeCooke /i Technology lenses, or camera tracking information.</p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/OpenDisplayXR%20VDD/#json-config-file","title":"JSON Config File","text":"<p>A JSON-based configuration file is used to define the display parameters for the connected output video streams.</p> <p>This is an early proof-of-concept JSON file to express the display device/input device centric syntax needed for a passive stereo 3D display that has three frame buffers: a left view, a centre view (monoscopic 2D), and a right eye view.</p> <p></p>","tags":["Kartaverse","Workflow","Project",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/","title":"Render Fusion Comps in Houdini TOPs","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p> <p>Created 2021-11-12 Last Updated 2022-08-01 10.47 PM UTC -4</p> <p>By Andrew Hazelden \\&lt;andrew@andrewhazelden.com&gt;</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#ref1","title":"Overview","text":"<p>Overview</p> <p>The following guide lists the essential steps required to set up a new Houdini TOPs \"Task\" that renders a folder of Fusion .comp files. This rendering process is done using command-line approaches that rely on Blackmagic Design's Fusion Studio and the included Fusion Render Node executable.</p> <p>Houdini TOPs based node graphs provide an exciting new way to tame complex workflows that require multiple linked dependent tasks. This approach has the potential to be the ultimate workflow automation \"glue\" to unify post-production tasks for processes running across artist workstations, local render farms, cloud computing systems, and even for assisting with general purpose task scheduling.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#ref2","title":"Software Required","text":"<p>Software Required</p> <p>To follow along with this workflow you need to have the following programs installed:</p> <ul> <li> <p>SideFX Houdini (Apprentice/Indie/Core/FX)</p> </li> <li> <p>BMD Fusion Studio/Fusion Render Node</p> </li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#tops-workflow","title":"TOPs Workflow","text":"<p>TOPs Workflow</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#part-1","title":"Part 1","text":"<p>Part 2</p> <p>Overview</p> <p>Part 2 will expand on the initial concepts presented, and explain at an overview level, how it is possible to create several more TOPs nodes that will remotely control a Fusion Studio compositing session using FuScript and the \"fusion:DoAction()\" and \"comp:DoAction()\" functions. This is an interesting concept as it allows you to run Fusion actions external to the app.</p> <p></p> <p>The TOP nodes in this example use a Fusion Studio GUI session to create a new Fusion comp, add a NyanCat macro (provided by the Reactor package manager), add a Saver node and define the Clip Filename, then the .comp file is saved to disk.</p> <p>Next the composite is rendered in the background using the Fusion Render Node executable from the command-line via a Generic Generator TOPs node.</p> <p></p> <p>Nodes, Connections, and Attributes</p> <p>To make this process happen, first a Comp_New action is run to create the new empty Fusion composite session.</p> <p>This was created like all of the other \"DoAction\" TOPs described below via a custom subnet. The subnet exposes two elements in the GUI that an artist/TD can interact with called \"Action Name\" and \"Action Parameters\".</p> <p>This specific subnet was customized to use \"fusion:DoAction()\" so it ran the Comp_New command in the Fusion wide scope, instead of targeting a comp specific scope like the other action based subnets do below.</p> <p></p> <p>To run an action inside of Fusion Studio the following custom TOPs subnet was created using a combination of an \"Attribute Create\" node to define our own set of ActionName and ActionParams attributes, along with a \"Generic Generator\" node that makes use of these attributes when talking with Fusion Studio:</p> <p></p> <p>The \"Generic Generator\" node is used to pass the previously defined `@ActionName` and `@ActionParams` attributes into the command-line based FuScript executable session.</p> <p>FuScript allows you to bind locally, or over a LAN network connection to BMD tools like Fusion Studio, Fusion Render Node, Fusion Render Manager, Resolve, and Generation.</p> <p></p> <p>The AddSetting action was used to specify the name of a Fusion Macro .setting file that will be added to the current Fusion Studio session. PathMaps can be used in the Filename attribute here and they will be expanded by Fusion automatically to the full filepath required.</p> <p></p> <p>\ud83d\udcddNote: Using Pathmaps, where possible, makes Fusion scripting tasks cross-platform compatible with low effort.</p> <p>\ud83d\udcddNote: Enter the following text into the Generic Generator node's Command text-field:</p> <p>Command (for Windows):</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\fuscript.exe\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>Command (for macOS):</p> <pre><code>\"/Applications/Blackmagic Fusion 17 Render Node/Fusion Render Node.app/Contents/MacOS/fuscript\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>Command (for Linux):</p> <pre><code>\"/opt/BlackmagicDesign/FusionRenderNode17/fuscript\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>In the next step, the selected node is loaded into Fusion Studio's Viewer 1 context using the Tool_ViewOn action.</p> <p>In this case the NyanCat macro will be shown on screen.</p> <p></p> <p>Next the Execute action will be used to lock the comp viewer session so file dialogs won't be shown by running a snippet of Lua code inside of Fusion Studio. One small detail is that you need to grab the current comp context when using the Execute action or you will otherwise see an error printed out in the results.</p> <p></p> <p>The AddTool action is used to add a Saver node to the comp. The previous step locked the viewer window so the Saver node's empty Filename field won't spawn a file dialog that would need direct user interaction to occur.</p> <p></p> <p>Now the viewer window is unlocked with another Execute action. This allows Fusion's file dialogs to work as expected during the rest of the compositing session. This will make the Fusion GUI session easier to use when testing and debugging code you are running.</p> <p></p> <p>Finally an Execute action is used to rename the Filename attribute for the currently selected node, which in this case is the Saver node.</p> <p>\ud83d\udcddNote: With the Create Attribute node it's possible to use Houdini environment variables and have them expanded automatically when they are evaluated and passed over to Fusion Studio via FuScript.</p> <p>In this case the `$HIP` token dynamically gives us the base Houdini project folder path on disk, which can be combined as a string with the \"render\" folder name, where Fusion will save the comp's rendered imagery too.</p> <p></p> <p>We are using the `$HIP` environment variable again to tell Fusion Studio where the current foreground Fusion .comp file should be saved to.</p> <p>This composite saving task is done using the Comp_Save action along with manually defining the name parameter.</p> <p></p> <p>In this next step, we are reusing the FusionRenderNode based command-line TOPs rendering approach that was first shown in Part 1 of the \"Render Fusion Comps in Houdini TOPs\" guide.</p> <p>The only major difference here from what was shown in Part 1, is that these nodes were put into a subnet, and the File Pattern node's \"Value\" parameter was exposed in the Houdini UI.</p> <p>These exposed controls make it easier to interact with the FusionRenderNode subnet in a more modular fashion.</p> <p></p> <p>A final \"Wait for All\" TOPs node was used at the end of the TOPs node graph to keep the ordering of the work unit tasks tidy.</p> <p></p> <p>This is a cropped view of what the final TOPs node graph looks like after it is cooked (rendered). If the process was successful, then green check-marks are shown next to each stage.</p> <p></p> <p>Well, that was something of an interesting, yet geeky, ride through the world of TOPs network creation and interconnecting Fusion into the mix.</p> <p>Resolve Studio FuScript Linking Tips</p> <p>\ud83d\udcddNote: The same base concepts presented here to control Fusion Studio centric workflows can also be used to automate Resolve Studio workflows from Houdini TOPs via FuScript too.</p> <p>This can be done by specifying the Resolve SubType when connecting to the app using FuScript, which also provides a way to have direct access to the built-in Resolve API functions via Lua or Python scripting.</p> <p>\ud83d\udcddNote: If you want to configure a \"Generic Generator\" TOP node so it connects to a Resolve Studio instance to access Resolve API functions, while being able to send \"DoAction\" tasks to the Resolve Fusion page, then the following text should be used as a starting point for your learning efforts. Enter one of the strings below into the Generic Generator node's Command text-field:</p> <p>Command (for Windows):</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\DaVinci Resolve\\fuscript.exe\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>Command (for macOS):</p> <pre><code>\"/Applications/DaVinci Resolve/DaVinci Resolve.app/Contents/Libraries/Fusion/fuscript\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>Command (for Linux):</p> <pre><code>\"/opt/BlackmagicDesign/FusionRenderNode17/fuscript\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>*If you explore this approach IRL, at some point you may have to peek into the \"Fusion Comp Link\" Lua script for more FuScript SubType parameter insight for an Interactive vs Fusion vs Resolve session. You can also specify a timeout value, a unique UUID value for the copy of Resolve/Fusion that is running, and even a remote host's IP address to connect to, if the other Resolve/Fusion system is connected on your local LAN network, too.</p> <p>\ud83d\udcddNote: You also have to make sure that you are running a copy of Resolve Studio, as a copy of Resolve Free doesn't provide command-line access to FuScript and the Resolve process. The next step is to verify that you adjusted the \"Resolve Preferences &gt; System &gt; General &gt; External scripting using\" preference so it is set to the \"Network\" option.</p> <p>(By default external scripting access is disabled on a fresh Resolve install... which typically results in a lot of wasted time spent troubleshooting issues when you first start to explore command-line based Resolve automation techniques.)</p> <p></p> <p>Fusion Action/Event Scripting Resources</p> <p>\ud83d\udcddNote: The Action Listener script provided by the Reactor Package manager's \"UI Manager Lua &amp; Python Examples\" atom package for Fusion/Resolve is a great way to see actions at work from inside of your compositing application.</p> <p>It's possible to print out a list of the actions present inside of Fusion with the handy \"Action Printout\" script.</p> <p>You can also learn a lot about the Fusion API from the \"Fusion Script Help Browser\" example. Additionally, Roger Magnusson's \"Class Browser\" is another essential scripting tool for Fusion/Resolve.</p> <p>\ud83d\udcddNote: If you want to peek into the Actions that are connected to the default hotkeys in Fusion take a look at the \"The Ultimate Listicle of Actions and Hotkeys\" post on the WSL forum.</p> <p>\ud83d\udcddNote: A general introduction to Actions and Events can be found on the following WSL forum scripting posts:</p> <ul> <li>Events/Callbacks in Python</li> <li>Running Python Code in an Event</li> <li>Common Variables Found in a .fu Event Execute Scope</li> <li>Using AddNotify() in Fusion to Respond to Actions</li> <li>FusionCompEvents.fu</li> <li>RandomizeNodeColors.fu Event Example</li> <li>Automatically Display the Selected Node in the Viewer Window</li> <li>.fu Based Contextual Menus - Python Print Attributes</li> <li>Using a Script to Add Macros to a Comp</li> <li>Resolve Scripting Essentials</li> <li>Python Script Snippets for Fusion TDs</li> <li>Running Python Scripts in FuScript</li> <li>Running UI Manager GUIs from a Terminal FuScript Session</li> <li>Menu configuration in Fusion 8.1</li> <li>FuScript Subtype Essentials</li> <li>Fusion Comp Link Atom</li> <li>Hypertext Compositor - An Interactive Documentation &amp; Walkthrough Tool for Compers</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-1","title":"Step 1.","text":"<p>Step 1.</p> <p>Create a new Houdini project folder.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-2","title":"Step 2.","text":"<p>Step 2.</p> <p>Place several Fusion .comp files inside the Houdini project folder's \"comp\" sub-folder. For this example I've created two comp files in Fusion Studio that are named \"Fusion1.comp\" and \"Fusion2.comp\".</p> <p></p> <p>\ud83d\udcddNote: Don't forget to customize your Fusion .comp files so the Saver nodes will render the media into the current Houdini project folder's \"render\" sub-folder.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-3","title":"Step 3.","text":"<p>Step 3.</p> <p>Create a new Houdini .hip/.hiplc/.hipnc file for this exercise.</p> <p>Use the Houdini desktop manager menu item (found at the top of the Houdini UI next to the menu bar) to change the desktop mode to \"TOPs\". This will modify the view layout for a TOPs optimized working environment.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-4","title":"Step 4.","text":"<p>Step 4.</p> <p>Press the Tab key in the Tasks context, and start typing the node name. A list of the TOP nodes that are available will be displayed.</p> <p></p> <p>For this project you will need to individually create each of the following TOP nodes listed below. The required parameters that have to be customized are also listed below, too.</p> <p>After you add the nodes, you will need to connect each node to the subsequent node that follows immediately after it. Doing this will create a single vertical branch of nodes. This node graph represents your first Fusion-centric Houdini TOP network.</p> <p></p> <p>Add the Node: File Pattern (Rename it to: ListComps)</p> <p></p> <p>File Types:</p> <p>Files Only</p> <p>Pattern:</p> <p>$HIP/comp/*.comp</p> <p>Work Item:</p> <p>[ ] Include Extension in Filename Attribute</p> <p>[x] Split Files into separate items</p> <p>[x] Output File Tag:</p> <p>filename</p> <p>\ud83d\udcddNote: The \"filename\" tag we defined here can be accessed in downstream nodes by adding the parameter name `@filename` to any text field.</p> <p>\ud83d\udcddNote: We unchecked the \"Include Extension in Filename Attribute\" so the individual .comp files would be listed without the file extension. This made it easier to write out a per-task render log file with a customized filename in the Generic Generator node.</p> <p>Add the Node: Environment Edit (Rename it to: NoPy)</p> <p></p> <p>[x] Variable Name:</p> <p>PYTHONHOME</p> <p>Variable Type:</p> <p>String</p> <p>Existing Name:</p> <p>Replace Existing Variable</p> <p>Value:</p> <p>(Leave this field blank with nothing typed in the text field.)</p> <p>[x] Variable Name:</p> <p>PYTHONPATH</p> <p>Variable Type:</p> <p>String</p> <p>Existing Name:</p> <p>Replace Existing Variable</p> <p>Value:</p> <p>(Leave this field blank with nothing typed in the text field.)</p> <p>\ud83d\udcddNote: The EnvironmentEdit node is useful for clearing out the pre-existing Python 2.7 based Hython shell env variables so the FusionRenderNode process will be happy.</p> <p>If you don't add an EnvironmentEdit node before the Generic Generator, you would need to prefix the Fusion Render Node launching Generic Generator command string with: set PYTHONHOME= &amp; set PYTHONHOME= &amp;</p> <p>Add the Node: Generic Generator (Rename it to: FusionRenderNode)</p> <p></p> <p>[x] Sequential</p> <p>Item Count:</p> <p>1</p> <p>Specify Using:</p> <p>Custom String</p> <p>Command (for Windows):</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\FusionRenderNode.exe\" \"$HIP/comp/`@filename`.comp\" /render /log \"$HIP/comp/`@filename`_log.txt\" /cleanlog /verbose /status /quit\n</code></pre> <p>Command (for macOS):</p> <pre><code>\"/Applications/Blackmagic Fusion 17 Render Node/Fusion Render Node.app/Contents/MacOS/Fusion Render Node\" \"$HIP/comp/`@filename`.comp\" -render -log \"$HIP/comp/`@filename`_log.txt\" -cleanlog -verbose -status -quit\n</code></pre> <p>Command (for Linux):</p> <pre><code>\"/opt/BlackmagicDesign/FusionRenderNode17/FusionRenderNode\" \"$HIP/comp/`@filename`.comp\" -render -log \"$HIP/comp/`@filename`_log.txt\" -cleanlog -verbose -status -quit\n</code></pre> <p>[x] Run Command in System Shell</p> <p>\ud83d\udcddNote: It looks like the \"Run Command in System Shell\" checkbox needs to be enabled if you want the \"@filename\" parameter to be parsed correctly inside the Command string.</p> <p>\ud83d\udcddNote: You can limit a render to a specific frame range using \"start\" and \"end\" flags when launching the Fusion Render Node executable. This is done by appending this text to the middle of your Command string:</p> <p>Render a single frame:</p> <p>/render /start 0 /end 0</p> <p>Render a 144 frame long sequence:</p> <p>/render /start 1 /end 144</p> <p>\ud83d\udcddNote: Fusion Render Node supports the following command line flags:</p> <p>(On Windows the flags are defined with slashes, while on Linux and macOS you can use dashes in place of the slashes for each flag you specify.)</p> <p></p> <p>Add the Node: Environment Edit (Rename it to: ResetPy)</p> <p></p> <p>[x] Reset Environment</p> <p>\ud83d\udcddNote: This node is used to restore the default environment variable settings.</p> <p>In the previous step, we had overridden the PYTHONHOME and PYTHONHOME entries to blank them out. This node will help us revert the values of those modified environment variables back to their standard setting.</p> <p>Add the Node: Wait For All</p> <p></p> <p>\ud83d\udcddNote: This node is useful as it will pause any additional downstream tasks until all of the Fusion comps are rendered to disk.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-5","title":"Step 5.","text":"<p>Step 5.</p> <p>Enable the orange colored \"Output\" parameter which is on the right side of the \"Wait For All\" node shape. The \"Output\" parameter makes this node the final output stage for the current Tasks rendering process.</p> <p></p> <p>At the top of the tasks view, there is a triangle-shaped \"play\" button with a little orange colored block next to it. Press that button to cook (render) the current TOPs node graph. This will batch render the node tree you have created.</p> <p></p> <p>Alternatively, you can right-click on a node and select the \"Dirty and Cook This Node\" menu item to re-process it. This action has a keyboard shortcut of Shift+V.</p> <p></p> <p>Once the TOPs network has been generated and cooked, the Task Graph Table will show diagnostics information about the whole rendering process. The Task Graph Table is visible at the bottom right of the TOPs view layout.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#step-6","title":"Step 6.","text":"<p>Step 6.</p> <p>In the Task Graph Table you can double-click on the \"Cooked\" heading entry in the tree list to see debugging information about each node's output. This can help you diagnose issues and see the individual pieces of information, like the Generic Generator node's command-line feedback results in the log section.</p> <p></p> <p>Also, if you click the small green circles shown on any TOPs node in the topnet graph, it will filter the results displayed in the Task Graph Table to show you the output for a specific work unit.</p> <p></p> <p>Step 7.</p> <p>Since we have cooked the TOPs graph, and each of the specified Fusion comps have been rendered to disk, we can now review the Fusion Render Node verbose logging information saved for each comp file.</p> <p></p> <p>This information was exported to disk because the Generic Generator node had the following flags present as part of the Command string:</p> <pre><code>/log \"$HIP/comp/`@filename`_log.txt\" /cleanlog /verbose\n</code></pre> <p>This logging flag results in two text files being created for our Fusion comps:</p> <p><code>$HIP/comp/Fusion1_log.txt</code></p> <p><code>$HIP/comp/Fusion2_log.txt</code></p> <p>An example copy of the log file output is included below. This logging information can help you spot issues like Fusion plugins not loading, GPU rendering headaches, or other error states which could cause a render to fail.</p> <pre><code>---------------------------------------------------\nStarting Fusion Render Node 17.4.1 at 12/Nov/21 13:53:02\nC:/Program Files/Blackmagic Design/Fusion Render Node 17\\FusionRenderNode.exe\n---------------------------------------------------\nLoading Plugins\nCreating GPU context on CUDA device: GeForce RTX 3090\nCreating GPU context on CUDA device: GeForce RTX 3090\nCreating GPU context on CUDA device: GeForce RTX 3090\nCreating GPU context on CUDA device: GeForce RTX 3090\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\fusionoperators.dll\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\fusionformats.dll\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\CinemaRaw\\cinemaraw.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\alembic.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\directshow.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\dimension.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\dds.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\bins.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\3d.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\fbx.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\mxf.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\fuses.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\paint.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\opencolorio.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\openfx.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\particles.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\quicktime.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\text.plugin\nLoading plugin C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\Plugins\\Blackmagic\\utilities.plugin\nChecking for licenses...\nAdding Global App Events\nInitialising all geometry caches\nInitialising GLTools\nInitialising Texture Manager\nStarting GraphicsThread\nLoading Comp at E:\\Projects\\Houdini_TOP\\comp\\Fusion1.comp\nRendering Comp, frames 0, step 1\nShowing Status\n\nRender started at Fri 1:53PM  (Range: 0.0 to 0.0)\nRendered frame 0 (1 of 1), took 0.270316 secs\nRender completed successfully at Fri 1:53PM - Total Time: 0h 0m 0.27s, Average: 3.70 frames/second\nAuto-exiting with errcode 0\nCleanup licenses\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#process-complete","title":"Process Complete","text":"<p>Process Complete</p> <p>Congrats for making it this far into the tutorial! This topic can be intimidating for artists new to Houdini TOPs usage but with a little practice you can come up with novel use cases for a hybrid Houdini + Fusion centric workflow.</p> <p>Example workflows you could explore with TOPs approaches might include using Houdini to automatically slice and render a voxel based VDB volumetric dataset into a \"contact sheet\" like tiled grid image layout which can then be used inside Fusion's VolumeFog node.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#part-2","title":"Part 2","text":"<p>Part 2</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#ref3","title":"Overview","text":"<p>Overview</p> <p>Part 2 will expand on the initial concepts presented, and explain at an overview level, how it is possible to create several more TOPs nodes that will remotely control a Fusion Studio compositing session using FuScript and the \"<code>fusion:DoAction()</code>\" and \"<code>comp:DoAction()</code>\" functions. This is an interesting concept as it allows you to run Fusion actions external to the app.</p> <p></p> <p>The TOP nodes in this example use a Fusion Studio GUI session to create a new Fusion comp, add a NyanCat macro (provided by the Reactor package manager), add a Saver node and define the Clip Filename, then the .comp file is saved to disk.</p> <p>Next the composite is rendered in the background using the Fusion Render Node executable from the command-line via a Generic Generator TOPs node.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#nodes-connections-and-attributes","title":"Nodes, Connections, and Attributes","text":"<p>Nodes, Connections, and Attributes</p> <p>To make this process happen, first a Comp_New action is run to create the new empty Fusion composite session.</p> <p>This was created like all of the other \"DoAction\" TOPs described below via a custom subnet. The subnet exposes two elements in the GUI that an artist/TD can interact with called \"Action Name\" and \"Action Parameters\".</p> <p>This specific subnet was customized to use \"<code>fusion:DoAction()</code>\" so it ran the <code>Comp_New</code> command in the Fusion wide scope, instead of targeting a comp specific scope like the other action based subnets do below.</p> <p></p> <p>To run an action inside of Fusion Studio the following custom TOPs subnet was created using a combination of an \"Attribute Create\" node to define our own set of ActionName and ActionParams attributes, along with a \"Generic Generator\" node that makes use of these attributes when talking with Fusion Studio:</p> <p></p> <p>The \"Generic Generator\" node is used to pass the previously defined `@ActionName` and `@ActionParams` attributes into the command-line based FuScript executable session.</p> <p>FuScript allows you to bind locally, or over a LAN network connection to BMD tools like Fusion Studio, Fusion Render Node, Fusion Render Manager, Resolve, and Generation.</p> <p></p> <p>The AddSetting action was used to specify the name of a Fusion Macro .setting file that will be added to the current Fusion Studio session. PathMaps can be used in the Filename attribute here and they will be expanded by Fusion automatically to the full filepath required.</p> <p></p> <p>\ud83d\udcddNote: Using Pathmaps, where possible, makes Fusion scripting tasks cross-platform compatible with low effort.</p> <p>\ud83d\udcddNote: Enter the following text into the Generic Generator node's Command text-field:</p> <p>Command (for Windows):</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\Fusion Render Node 17\\fuscript.exe\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>Command (for macOS):</p> <pre><code>\"/Applications/Blackmagic Fusion 17 Render Node/Fusion Render Node.app/Contents/MacOS/fuscript\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>Command (for Linux):</p> <pre><code>\"/opt/BlackmagicDesign/FusionRenderNode17/fuscript\" -x \"fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Fusion Studio GUI before cooking this node.') end\"\n</code></pre> <p>In the next step, the selected node is loaded into Fusion Studio's Viewer 1 context using the Tool_ViewOn action.</p> <p>In this case the NyanCat macro will be shown on screen.</p> <p></p> <p>Next the Execute action will be used to lock the comp viewer session so file dialogs won't be shown by running a snippet of Lua code inside of Fusion Studio. One small detail is that you need to grab the current comp context when using the Execute action or you will otherwise see an error printed out in the results.</p> <p></p> <p>The AddTool action is used to add a Saver node to the comp. The previous step locked the viewer window so the Saver node's empty Filename field won't spawn a file dialog that would need direct user interaction to occur.</p> <p></p> <p>Now the viewer window is unlocked with another Execute action. This allows Fusion's file dialogs to work as expected during the rest of the compositing session. This will make the Fusion GUI session easier to use when testing and debugging code you are running.</p> <p></p> <p>Finally an Execute action is used to rename the Filename attribute for the currently selected node, which in this case is the Saver node.</p> <p>\ud83d\udcddNote: With the Create Attribute node it's possible to use Houdini environment variables and have them expanded automatically when they are evaluated and passed over to Fusion Studio via FuScript.</p> <p>In this case the `$HIP` token dynamically gives us the base Houdini project folder path on disk, which can be combined as a string with the \"render\" folder name, where Fusion will save the comp's rendered imagery too.</p> <p></p> <p>We are using the `$HIP` environment variable again to tell Fusion Studio where the current foreground Fusion .comp file should be saved to.</p> <p>This composite saving task is done using the Comp_Save action along with manually defining the name parameter.</p> <p></p> <p>In this next step, we are reusing the FusionRenderNode based command-line TOPs rendering approach that was first shown in Part 1 of the \"Render Fusion Comps in Houdini TOPs\" guide.</p> <p>The only major difference here from what was shown in Part 1, is that these nodes were put into a subnet, and the File Pattern node's \"Value\" parameter was exposed in the Houdini UI.</p> <p>These exposed controls make it easier to interact with the FusionRenderNode subnet in a more modular fashion.</p> <p></p> <p>A final \"Wait for All\" TOPs node was used at the end of the TOPs node graph to keep the ordering of the work unit tasks tidy.</p> <p></p> <p>This is a cropped view of what the final TOPs node graph looks like after it is cooked (rendered). If the process was successful, then green check-marks are shown next to each stage.</p> <p></p> <p>Well, that was something of an interesting, yet geeky, ride through the world of TOPs network creation and interconnecting Fusion into the mix.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#resolve-studio-fuscript-linking-tips","title":"Resolve Studio FuScript Linking Tips","text":"<p>Resolve Studio FuScript Linking Tips</p> <p>\ud83d\udcddNote: The same base concepts presented here to control Fusion Studio centric workflows can also be used to automate Resolve Studio workflows from Houdini TOPs via FuScript too.</p> <p>This can be done by specifying the Resolve SubType when connecting to the app using FuScript, which also provides a way to have direct access to the built-in Resolve API functions via Lua or Python scripting.</p> <p>\ud83d\udcddNote: If you want to configure a \"Generic Generator\" TOP node so it connects to a Resolve Studio instance to access Resolve API functions, while being able to send \"DoAction\" tasks to the Resolve Fusion page, then the following text should be used as a starting point for your learning efforts. Enter one of the strings below into the Generic Generator node's Command text-field:</p> <p>Command (for Windows):</p> <pre><code>\"C:\\Program Files\\Blackmagic Design\\DaVinci Resolve\\fuscript.exe\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>Command (for macOS):</p> <pre><code>\"/Applications/DaVinci Resolve/DaVinci Resolve.app/Contents/Libraries/Fusion/fuscript\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>Command (for Linux):</p> <pre><code>\"/opt/BlackmagicDesign/FusionRenderNode17/fuscript\" -x \"resolve = bmd.scriptapp([[Resolve]], [[localhost]]);if resolve ~= nil then res = resolve;else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;fusion = bmd.scriptapp([Fusion](&lt;../../Fusion/Fusion.md&gt;), [[localhost]], 0.0, 0, [[Resolve]]);if fusion ~= nil then fu = fusion;app = fu;composition = fu.CurrentComp;comp = composition;SetActiveComp(comp);comp:DoAction([[`@ActionName`]], {`@ActionParams`}) else print('[FuScript Error] Please open up the Resolve Studio GUI before cooking this node.') end;\"\n</code></pre> <p>*If you explore this approach IRL, at some point you may have to peek into the \"Fusion Comp Link\" Lua script for more FuScript SubType parameter insight for an Interactive vs Fusion vs Resolve session. You can also specify a timeout value, a unique UUID value for the copy of Resolve/Fusion that is running, and even a remote host's IP address to connect to, if the other Resolve/Fusion system is connected on your local LAN network, too.</p> <p>\ud83d\udcddNote: You also have to make sure that you are running a copy of Resolve Studio, as a copy of Resolve Free doesn't provide command-line access to FuScript and the Resolve process. The next step is to verify that you adjusted the \"Resolve Preferences &gt; System &gt; General &gt; External scripting using\" preference so it is set to the \"Network\" option.</p> <p>(By default external scripting access is disabled on a fresh Resolve install... which typically results in a lot of wasted time spent troubleshooting issues when you first start to explore command-line based Resolve automation techniques.)</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Render%20Fusion%20Comps%20in%20Houdini%20TOPs/#fusion-actionevent-scripting-resources","title":"Fusion Action/Event Scripting Resources","text":"<p>Fusion Action/Event Scripting Resources</p> <p>\ud83d\udcddNote: The Action Listener script provided by the Reactor Package manager's \"UI Manager Lua &amp; Python Examples\" atom package for Fusion/Resolve is a great way to see actions at work from inside of your compositing application.</p> <p>It's possible to print out a list of the actions present inside of Fusion with the handy \"Action Printout\" script.</p> <p>You can also learn a lot about the Fusion API from the \"Fusion Script Help Browser\" example. Additionally, Roger Magnusson's \"Class Browser\" is another essential scripting tool for Fusion/Resolve.</p> <p>\ud83d\udcddNote: If you want to peek into the Actions that are connected to the default hotkeys in Fusion take a look at the \"The Ultimate Listicle of Actions and Hotkeys\" post on the WSL forum.</p> <p>\ud83d\udcddNote: A general introduction to Actions and Events can be found on the following WSL forum scripting posts:</p> <ul> <li>Events/Callbacks in Python</li> <li>Running Python Code in an Event</li> <li>Common Variables Found in a .fu Event Execute Scope</li> <li>Using AddNotify() in Fusion to Respond to Actions</li> <li>FusionCompEvents.fu</li> <li>RandomizeNodeColors.fu Event Example</li> <li>Automatically Display the Selected Node in the Viewer Window</li> <li>.fu Based Contextual Menus - Python Print Attributes</li> <li>Using a Script to Add Macros to a Comp</li> <li>Resolve Scripting Essentials</li> <li>Python Script Snippets for Fusion TDs</li> <li>Running Python Scripts in FuScript</li> <li>Running UI Manager GUIs from a Terminal FuScript Session</li> <li>Menu configuration in Fusion 8.1</li> <li>FuScript Subtype Essentials</li> <li>Fusion Comp Link Atom</li> <li>Hypertext Compositor - An Interactive Documentation &amp; Walkthrough Tool for Compers</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/","title":"SketchFab in VR Via QuestLink","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#sketchfab-in-vr-via-questlink","title":"SketchFab in VR Via QuestLink","text":"<p>If you have a SketchFab 3D scene you want to explore in VR, you might need to use your PC to do the actual rendering. In this case, the free Oculus Link drivers for Windows 10/11 allows you to connect your PC to a Meta Quest HMD via WiFi or a long USB-C cable.</p> <p>YouTube | Explore the Cave-verse via QuestLink</p> <p>https://youtu.be/QI9f_PrWK_A</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#install-the-oculus-drivers-for-windows","title":"Install the Oculus Drivers for Windows","text":"<p>Install the Oculus Drivers for Windows</p> <p>Start by going to the Meta2 Website. Click the blue \"Download Software\" button part way down the webpage.</p> <p></p> <p>After you download the \"<code>OculusSetup.exe</code>\" program, run the installer.</p> <p></p> <p>You can use either a Facebook or Instagram account for signing into your Oculus account on Windows. I went with my existing Facebook account.</p> <p></p> <p>The Facebook website then offers to set up a \"Meta\" account.</p> <p></p> <p>After the Meta account was configured the webpage offers to pass those credentials over to the Oculus application running on your PC.</p> <p></p> <p>The rest of the Quest install process is done by clicking continue a few more times.</p> <p></p> <p>You need to select the model of Meta/Oclus HMD you are using. This will typically be a Quest 2 HMD or a Quest 1 HMD.</p> <p></p> <p>Then you can choose to connect from the PC via a long USB-C Cable \"Link\" or via WIFI v6 connection using \"AirLink (Wireless)\".</p> <p></p> <p>The setup program will now exit.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#configure-openxr-on-windows","title":"Configure OpenXR on Windows","text":"<p>Configure OpenXR on Windows</p> <p>You now need to enable the OpenXR runtime which allows desktop PC programs to use the VR HMD. This can be done by clicking on the header bar at the top of the window.</p> <p></p> <p>Next to the heading \"OpenXR Runtime\" click \"Set Oculus as active\".</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#pair-your-quest-hmd","title":"Pair your Quest HMD","text":"<p>Pair your Quest HMD</p> <p>Now you can start pairing the HMD to your PC.</p> <p></p> <p>On the Meta Quest HMD open the \"Settings\" button. You can toggle between AirLink (Wifi) and a USB-C cable connection if you need to in the \"Experimental\" tab.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#enabling-airlink-on-the-quest","title":"Enabling AirLink on the Quest","text":"<p>Enabling AirLink on the Quest</p> <p>The Quest's control panel view has a handy \"AirLink\" button on the right side of the window.</p> <p></p> <p>With AirLink you can connect via a fast WiFi v6 link to Windows PCs on your local network that are running the Oculus Link software.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#connect-in-vr-to-your-desktop-pc","title":"Connect in VR to your Desktop PC","text":"<p>Connect in VR to your Desktop PC</p> <p>On the HMD you can press the \"Desktop\" icon in the toolbar to see a live screenshot of your PC monitor. This makes it easier to load the SketchFab website in Google Chrome using your Quest hand controllers to click the buttons.</p> <p></p> <p>With Google Chrome open, you can now press the \"VR\" button on a 3D model and beam that content directly to your Quest HMD. This is possible due to the magic of OpenXR running in a web browser session.</p> <p></p> <p>The first time you view a webpage in VR with the HMD connected, you may be asked to allow VR devices to work with Chrome. Click \"Allow\" to continue.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/SketchFab%20in%20VR%20Via%20QuestLink/#wander-around-in-your-vr-scenes","title":"Wander Around in your VR Scenes","text":"<p>Wander Around in your VR Scenes</p> <p>Now you can roam around in SketchFab 3D scenes using VR on your Quest. The native Quest head tracking feature still works in \"Room-scale\" 6DoF VR with AirLink, and it even supports the use of your hand-controllers as an input device to teleport your character controller around the environment.</p> <p>Since you are using your desktop PC to render the 3D content when AirLink is active, you can load far larger scenes using your PC's GPU and its many gigabytes of onboard VRAM to do the heavy lifting.</p> <p></p> <p>I hope this guide allows you to have fun exploring vast virtual worlds that are streamed from the web.</p> <p>SketchFab | Las Cabras Cave 3D Scene</p> <p>https://sketchfab.com/3d-models/las-cabras-cave-mobile-edition-d15457a4df734093953eb470259d640c</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/","title":"Troubleshooting Guide for Fusion Studio Freeze Ups","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#troubleshooting-guide-for-fusion-studio-freeze-ups","title":"Troubleshooting Guide for Fusion Studio Freeze Ups","text":"<p>What follows is a handy set of tips that can be used by a comp TD to find the root cause of issues when a Fusion Studio .comp file crashes all the time. It can also help you track down if a GPU glitch is responsible for your Fusion freezes, etc...</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#adding-the-custom-hidden-environment-variable","title":"Adding the Custom Hidden Environment Variable","text":"<p>Adding the Custom Hidden Environment Variable</p> <p>If Fusion is crashing unexpectedly, you can add a custom environment variable to your Windows system called \"<code>FUSION_EXCEPTION_HANDLER=true</code>\".</p> <p>When this undocumented environment variable is active, if Fusion crashes, it automatically produces a diagnostic report listing the source of the problem.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-1-environment-variables-are-added-to-your-windows-pc-using-the-system-control-panel","title":"Step 1. Environment variables are added to your Windows PC using the \"System\" Control Panel.","text":"<p>Step 1. Environment variables are added to your Windows PC using the \"System\" Control Panel.</p> <p></p> <p>With the System Control Panel visible, on the top left of the window is the clickable text \"Advanced system settings\".</p> <p>In the Advanced System settings window, you can click the \"Environment Variables\" button on the lower right of the window to show the \"Environment Variables\" dialog.</p> <p>At the bottom of the \"Environment Variable\" window is a \"System Variables\" section. Clicking the \"New...\" button will display a \"New System Variable\" dialog.</p> <p>(FYI The next image shows the new environment variable in the Systems Variable section. This only exists after you add it, manually, by yourself to the environment variable window...)</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-2-in-the-new-system-variable-dialog-enter-the-variable-name-as-fusion_exception_handler-then-enter-the-variable-value-as-true-click-the-ok-button-to-save-this-new-environment-variable-entry","title":"Step 2. In the \"New System Variable\" dialog enter the \"Variable name:\" as \"FUSION_EXCEPTION_HANDLER\". Then enter the \"Variable value:\" as \"true\". Click the \"OK\" button to save this new environment variable entry.","text":"<p>Step 2. In the \"New System Variable\" dialog enter the \"Variable name:\" as \"<code>FUSION_EXCEPTION_HANDLER</code>\". Then enter the \"Variable value:\" as \"<code>true</code>\". Click the \"OK\" button to save this new environment variable entry.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-3-its-now-time-to-restart-your-windows-system-for-the-newly-added-environment-variable-to-be-active","title":"Step 3. It's now time to restart your Windows system for the newly added environment variable to be active.","text":"<p>Step 3. It's now time to restart your Windows system for the newly added environment variable to be active.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-4-after-rebooting-your-system-you-can-check-if-the-fusion_exception_handler-environment-variable-is-present-and-active-by-opening-the-command-prompt-and-entering","title":"Step 4. After rebooting your system, you can check if the \"FUSION_EXCEPTION_HANDLER\" environment variable is present and active by opening the Command Prompt and entering:","text":"<p>Step 4. After rebooting your system, you can check if the \"<code>FUSION_EXCEPTION_HANDLER</code>\" environment variable is present and active by opening the Command Prompt and entering:</p> <pre><code>echo %FUSION_EXCEPTION_HANDLER%\n</code></pre> <p>The result should be:</p> <pre><code>true\n</code></pre> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-5-now-when-you-start-up-fusion-studio-if-the-program-crashes-a-crash-dump-report-is-generated-on-the-windows-platform-and-is-written-automatically-to-the-temp-folder-this-path-is-represented-on-disk-as","title":"Step 5 Now when you start up Fusion Studio, if the program crashes a crash dump report is generated on the Windows platform, and is written automatically to the %temp% folder. This path is represented on disk as:","text":"<p>Step 5 Now when you start up Fusion Studio, if the program crashes a crash dump report is generated on the Windows platform, and is written automatically to the <code>%temp%</code> folder. This path is represented on disk as:</p> <pre><code>C:\\Users\\&lt;User Account&gt;\\AppData\\Local\\Temp\n</code></pre> <p>The following Fusion crash dump report files are written to disk each time:</p> <p>\"<code>crash.dmp</code>\"</p> <p>\"<code>crash.log</code>\"</p> <p>\"<code>crashdump_x64_YYYY-MM-DD_HH-MM-SS.zip</code>\"</p> <p>The last crash log has the date and time code is expanded as a filename like this:</p> <p>\"<code>crashdump_x64_2020-07-11_18-45-10.zip</code>\"</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#step-6-do-not-submit-these-undocumented-fusion-api-based-crash-reports-to-bmd-they-would-arrive-at-a-currently-unmonitored-development-email-address","title":"Step 6. Do NOT submit these undocumented Fusion API based crash reports to BMD. They would arrive at a currently-unmonitored development email address.","text":"<p>Step 6. Do ***NOT*** submit these undocumented Fusion API based crash reports to BMD. They would arrive at a currently-unmonitored development email address.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#generating-a-crash-state-in-fusion","title":"Generating a Crash State in Fusion","text":"<p>Generating a Crash State in Fusion</p> <p>When a crash state happens in Fusion, with the undocumented environment variable active, a crash dump log is saved to disk.</p> <p>These log files are special in that it saves all of the required debugging information, from the current Fusion artists session to disk, along with a full memory dump that allows a programmer to find out the source cause of the Fusion program freeze up.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#forcing-a-crash-log-from-fusion-console","title":"Forcing a crash log from Fusion Console:","text":"<p>Forcing a crash log from Fusion Console:</p> <p>Step 7. You can also use the Fusion Console window and run the following Lua command if the Fusion left or right viewer windows fail to update your 3D or 2D view contexts... but the rest of the Fusion program still functions:</p> <p>fu:Crash()</p> <p></p> <p>Step 8. In the crash dialog ALWAYS select the \"No\" option. Never EVER select the \"Yes\" option or your crash log will end up in a Fusion developer's email inbox.... \ud83d\ude44</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Troubleshooting%20Guide%20for%20Fusion%20Studio%20Freeze%20Ups/#forcing-a-crash-log-from-the-command-prompt-window","title":"Forcing a crash log from the Command Prompt Window:","text":"<p>Forcing a crash log from the Command Prompt Window:</p> <p>Step 9. If the Fusion UI is locked and unresponsive it is also possible to use Fusion's CLI (command-line) interface to force a crash state and a log file to be written to disk.</p> <p>First navigate in the command prompt window into the Fusion Studio folder using this folder:</p> <pre><code>cd \"C:\\Program Files\\Blackmagic Design\\Fusion 18\\\"\n</code></pre> <p>Step 10. Then look in the Task Manager to find the Fusion Studio Process ID(PID) aka \"Process number\" code.</p> <p>Finally, using FuScript, (the Fusion scripting API that runs inside the Command Prompt window), you can dump the active Fusion GUI process state using:</p> <pre><code>FuScript.exe -d &lt;process num&gt;\n</code></pre>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Workflows/","title":"Kartaverse Workflows","text":"<p>This is an export from Scrivener that should be revised!</p> <p>In this folder you will find an export generated from a Scrivener source. Scrivener being an authoring software for writing book type content, the different files will come originally meant to be read in some linear order. Please help to re-organize and re-write them into separate articles, each working kind of independently from the others.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/Workflows/#original-table-of-contents","title":"Original Table of Contents","text":"<ul> <li>Kartaverse Workflows (this page)</li> <li>Creating Volumetric NeRFs</li> <li>Creating ST Maps</li> <li>Render Fusion Comps in Houdini TOPs</li> <li>SketchFab in VR Via QuestLink</li> <li>Troubleshooting Guide for Fusion Studio Freeze Ups</li> <li>YouTube 360 to Equirectangular Conversions</li> <li>Jupyter Notebook for Resolve/Fusion</li> <li>Domemaster Photoshop Actions Pack</li> <li>DEV OpenDisplayXR/VDD (Virtual Device Driver)</li> <li>DEV The Ultimate Guide to OpenUSD Pipeline Development</li> <li>DEV Building an Effective nVP (Neural Virtual Production) Sound Stage</li> <li>KickAss ShaderZ for Fusion</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/","title":"YouTube 360 to Equirectangular Conversions","text":"Scrivener Export - Reformatting Needed! <p>This article is an export of a Scrivener document. It will definitely need at least some reformatting to work in Obsidian and MkDocs. Delete this note once the article's formatting  has been fixed to some extent.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#youtube-360-to-equirectangular-conversions","title":"YouTube 360 to Equirectangular Conversions","text":"<p>KartaVR has several different workflow paths that can be used to convert panoramic image projections. This guide will cover a technique called a \"MeshUV\" based conversion that relies on a Wavefront \".obj\" based polygon mesh and UV layout to define the image projection transform.</p> <p>Optionally you could use a YouTube 360 monoscopic 2D centric \"direct\" image projection conversion macro called \"YouTubeCubemap3x22Equirectangular\" if you want to avoid using a MeshUV approach.</p> <p>Also, it's worth mentioning that KartaVR supports \"MacroLUTs\" that can be loaded into the Fusion Standalone \"LUTs\" viewer window control. These specialized LUTs provide an interactive preview of the image projection conversion on any media loaded into that viewer window context on-the-fly. For more information about LUT based approaches, check out the KartaVR MacroLUTs documentation.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#youtube-360-image-projections","title":"YouTube 360 Image Projections","text":"<p>YouTube 360 Image Projections</p> <p>When you use a video downloading tool to save a local copy of a YouTube 360 video, you will likely come across a video file that is stored in one of the following \"cubic view\" based image projection layouts. KartaVR can be used to translate these cubic image projections back into an equirectangular format.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#youtube-3x2-cubic-face-layout-monoscopic-2d","title":"YouTube 3x2 Cubic Face Layout - Monoscopic 2D","text":"<p>YouTube 3x2 Cubic Face Layout - Monoscopic 2D</p> <p>(Macros:/KartaVR/Images/youtube_cubemap3x2.jpg)</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#youtube-2x3-cubic-face-layout-stereo-3d-side-by-side","title":"YouTube 2x3 Cubic Face Layout - Stereo 3D Side By Side","text":"<p>YouTube 2x3 Cubic Face Layout - Stereo 3D Side By Side</p> <p>(Macros:/KartaVR/Images/youtube_cubemap2x3.jpg)</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#kartavr-conversion-obj-meshes","title":"KartaVR Conversion OBJ Meshes","text":"<p>KartaVR Conversion OBJ Meshes</p> <p>KartaVR includes two MeshUV centric conversion meshes. These polygon models can be loaded into your Fusion composite using the \"FBX File\" control on the \"MeshUV2Equirectangular\" and \"MeshUV2EquirectangularStereo\" macros.</p> <p>The OBJ meshes are located on disk using the following Fusion based PathMap:</p> <ul> <li>Macros:/KartaVR/Images/youtube_cubemap2x3.obj</li> <li>Macros:/KartaVR/Images/youtube_cubemap3x2.obj</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#kartavr-built-in-example-comps","title":"KartaVR Built-In Example Comps","text":"<p>KartaVR Built-In Example Comps</p> <p>The following three example comps show a few different ways to rework panoramic imagery. These comps are located inside the \"Reactor:\\Deploy\\Comps\\KartaVR\" PathMap based folder:</p> <ul> <li>MeshUV Conversions.comp</li> <li>YouTube Cubemap3x2.comp</li> <li>YouTube180 Conversions.comp</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#macro-documentation","title":"Macro Documentation","text":"<p>Macro Documentation</p> <ul> <li>MeshUV2Equirectangular</li> <li>MeshUV2EquirectangularStereo</li> <li>YouTubeCubemap3x22CubicFaces</li> <li>YouTubeCubemap3x22Equirectangular</li> </ul>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#meshuv2equirectangular-macro-usage","title":"MeshUV2Equirectangular Macro Usage","text":"<p>MeshUV2Equirectangular Macro Usage</p> <p>Note: This macro node expects you to link in an OBJ or FBX formatted polygon mesh using the \"FBX File\" control in the Inspector view.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-1-create-a-new-fusion-composite","title":"Step 1. Create a new Fusion composite.","text":"<p>Step 1. Create a new Fusion composite.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-2-add-a-youtube-360-downloaded-video-file-to-your-fusion-composite-using-either-a-loader-node-in-fusion-studio-or-a-mediain-node-in-resolves-fusion-page","title":"Step 2. Add a YouTube 360 downloaded video file to your Fusion composite using either a Loader Node (in Fusion Studio), or a MediaIn node (in Resolve's Fusion Page).","text":"<p>Step 2. Add a YouTube 360 downloaded video file to your Fusion composite using either a Loader Node (in Fusion Studio), or a MediaIn node (in Resolve's Fusion Page).</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#sample-media","title":"Sample Media","text":"<p>Sample Media</p> <p>KartaVR provides a YouTube 360 \"Monoscopic 2D\" based still image that you can use to test the image projection conversion process out. You can paste in the following KartaVR PathMap based file path into a Loader node's Filename control:</p> <pre><code>Macros:/KartaVR/Images/youtube_cubemap3x2.jpg\n</code></pre> <p></p> <p>When you view this node's output in the left viewer window you will see the following output that has an arrangement of 3 horizontal cubemap faces by two vertical cubemap faces. This is often shortened down to being called a 3x2 (three by two) cubic face layout. The cubic faces are laid out in the order of Left, Front, Right, Bottom, Back, Top.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-3-with-the-fusion-nodes-view-active-in-the-foreground-press-the-shift-space-hotkey-on-your-keyboard","title":"Step 3. With the Fusion Nodes view active in the foreground, press the \"Shift + Space\" hotkey on your keyboard.","text":"<p>Step 3. With the Fusion Nodes view active in the foreground, press the \"Shift + Space\" hotkey on your keyboard.</p> <p></p> <p>This hotkey will display the \"Select Tool\" dialog that is used to quickly add nodes to your composite. Start typing the words \"MeshUV2Equirectangular\" into the Select Tool dialog until the macro is selected in the list. Then press the \"Add\" button.</p> <p>At this point, a new node has been added to the Fusion composite.</p> <p>A file browsing window will appear automatically as soon as a new \"MeshUV2Equirectangular\" node is placed in the comp. This dialog is used to select the mesh that will be used for the conversion. The OBJ or FBX formatted polygon model you select will then be entered in the \"FBX File\" control in the Inspector view.</p> <p>Let's select the \"<code>youtube_cubemap3x2.obj</code>\" mesh file in this folder. This mesh is used for monoscopic 2D footage saved from YouTube 360.</p> <p></p> <p>You can manually browse to the folder that holds the KartaVR sample images and MeshUV models by navigating to the following Pathmap folder:</p> <pre><code>Macros:/KartaVR/Images/\n</code></pre> <p>That PathMap folder location translates automatically into the following absolute filepath based locations on your system:</p> <p>(Note: The <code>C:\\ProgramData\\</code> folder might be set to be invisible on a default Windows OS install. That setting can be adjusted in the Explorer window's properties in the ribbon toolbar.)</p> <p>Fusion Standalone Paths</p> <p>Windows Reactor Path:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\Deploy\\Macros\\KartaVR\\Images\\\n</code></pre> <p>Mac Reactor Path:</p> <pre><code>/Library/Application Support/Blackmagic Design/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Linux Reactor Path:</p> <pre><code>/var/BlackmagicDesign/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Resolve Paths</p> <p>Windows Reactor Path:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Fusion\\Reactor\\Deploy\\Macros\\KartaVR\\Images\\\n</code></pre> <p>Mac Reactor Path:</p> <pre><code>/Library/Application Support/Blackmagic Design/DaVinci Resolve/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Linux Reactor Path:</p> <pre><code>/var/BlackmagicDesign/DaVinci Resolve/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>If you click on the \"MeshUV2Equirectangular\" node and load its controls in the Inspector view the controls should look like this:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-4-in-the-fusion-nodes-view-you-need-to-connect-your-youtube-360-footages-mediainloader-node-output-connection-to-the-meshuv2equirectangular-nodes-input-connection","title":"Step 4. In the Fusion Nodes view you need to connect your YouTube 360 footage's MediaIn/Loader node output connection to the \"MeshUV2Equirectangular\" node's input connection.","text":"<p>Step 4. In the Fusion Nodes view you need to connect your YouTube 360 footage's MediaIn/Loader node output connection to the \"MeshUV2Equirectangular\" node's input connection.</p> <p></p> <p>This node connection allows the RGBA image data from the MediaIn/Loader node to flow into the \"MeshUV2Equirectangular\" node.</p> <p>Now we can view the output from the \"MeshUV2Equirectangular\" node on the right viewer window.</p> <p>Looking at the screenshot below we can see how the YouTube 3x2 cubic face media was loaded into Fusion, the media was then reformatted into an Equirectangular format, and the result was then displayed on the right viewer window.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-5-you-can-render-this-footage-back-to-an-image-sequence-or-movie-file-on-disk-using-either-a-mediaout-node-in-resolve-or-a-saver-node-in-fusion-standalone","title":"Step 5. You can render this footage back to an image sequence or movie file on disk using either a MediaOut node (in Resolve), or a Saver node (in Fusion Standalone).","text":"<p>Step 5. You can render this footage back to an image sequence or movie file on disk using either a MediaOut node (in Resolve), or a Saver node (in Fusion Standalone).</p> <p></p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#meshuv2equirectangularstereo-macro-usage","title":"MeshUV2EquirectangularStereo Macro Usage","text":"<p>MeshUV2EquirectangularStereo Macro Usage</p> <p>A stereoscopic 3D based MeshUV conversion node is available in KartaVR and it is called MeshUV2EquirectangularStereo. The macro node can be used to convert YouTube 360 footage that is stereoscopic 3D into an Equirectangular Over-Under or Side-By-Side Stereoscopic 3D format.</p> <p>This node also uses an FBX or OBJ formatted mesh to control the panoramic image conversion via the \"FBX File\" control in the inspector window just like the previous \"MeshUV2Equirectangular\" node.</p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#ref4","title":"Step 1. Create a new Fusion composite.","text":"<p>Step 1. Create a new Fusion composite.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-2-add-a-youtube-360-stereoscopic-3d-downloaded-video-file-to-your-fusion-composite-using-either-a-loader-node-in-fusion-studio-or-a-mediain-node-in-resolves-fusion-page","title":"Step 2. Add a YouTube 360 Stereoscopic 3D downloaded video file to your Fusion composite using either a Loader Node (in Fusion Studio), or a MediaIn node (in Resolve's Fusion Page).","text":"<p>Step 2. Add a YouTube 360 Stereoscopic 3D downloaded video file to your Fusion composite using either a Loader Node (in Fusion Studio), or a MediaIn node (in Resolve's Fusion Page).</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#ref5","title":"Sample Media","text":"<p>Sample Media</p> <p>KartaVR provides a YouTube 360 \"Stereoscopic 3D\" based still image that you can use to test the image projection conversion process out. You can paste in the following KartaVR PathMap based file path into a Loader node's Filename control:</p> <pre><code>Macros:/KartaVR/Images/KartaVR/Images/youtube_cubemap2x3_stereo.jpg\n</code></pre> <p></p> <p>When you view this node's output in the left viewer window you will see the following output that has a Side-By-Side stereoscopic 3D frame arrangement of 2 horizontal cubemap faces by three vertical cubemap faces (per eye view).</p> <p>This view layout is often shortened down to being called a 2x3 stereo SBS (two by three stereo side-by-side) cubic face layout. The cubic faces are laid out in the order of Right, Top, Front, Back, Left, Bottom.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#ref6","title":"Step 3. With the Fusion Nodes view active in the foreground, press the \"Shift + Space\" hotkey on your keyboard.","text":"<p>Step 3. With the Fusion Nodes view active in the foreground, press the \"Shift + Space\" hotkey on your keyboard.</p> <p></p> <p>This hotkey will display the \"Select Tool\" dialog that is used to quickly add nodes to your composite. Start typing the words \"MeshUV2EquirectangularStereo\" into the Select Tool dialog until the macro is selected in the list. Then press the \"Add\" button.</p> <p>At this point, a new node has been added to the Fusion composite.</p> <p>A file browsing window will appear automatically as soon as a new \"MeshUV2EquirectangularStereo\" node is placed in the comp. This dialog is used to select the mesh that will be used for the conversion. The OBJ or FBX formatted polygon model you select will then be entered in the \"FBX File\" control in the Inspector view.</p> <p>Let's select the \"<code>youtube_cubemap2x3.obj</code>\" mesh file in this folder. This mesh is used for stereoscopic footage saved from YouTube 360.</p> <p></p> <p>You can manually browse to the folder that holds the KartaVR sample images and MeshUV models by navigating to the following Pathmap folder:</p> <pre><code>Macros:/KartaVR/Images/\n</code></pre> <p>That PathMap folder location translates automatically into the following absolute filepath based locations on your system:</p> <p>(Note: The <code>C:\\ProgramData\\</code> folder might be set to be invisible on a default Windows OS install. That setting can be adjusted in the Explorer window's properties in the ribbon toolbar.)</p> <p>Fusion Standalone Paths</p> <p>Windows Reactor Path:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\Deploy\\Macros\\KartaVR\\Images\\\n</code></pre> <p>Mac Reactor Path:</p> <pre><code>/Library/Application Support/Blackmagic Design/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Linux Reactor Path:</p> <pre><code>/var/BlackmagicDesign/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Resolve Paths</p> <p>Windows Reactor Path:</p> <pre><code>C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Fusion\\Reactor\\Deploy\\Macros\\KartaVR\\Images\\\n</code></pre> <p>Mac Reactor Path:</p> <pre><code>/Library/Application Support/Blackmagic Design/DaVinci Resolve/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>Linux Reactor Path:</p> <pre><code>/var/BlackmagicDesign/DaVinci Resolve/Fusion/Reactor/Deploy/Macros/KartaVR/Images/\n</code></pre> <p>If you click on the \"MeshUV2EquirectangularStereo\" node and load its controls in the Inspector view the controls should look like this:</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#step-4-in-the-fusion-nodes-view-you-need-to-connect-your-youtube-360-footages-mediainloader-node-output-connection-to-the-meshuv2equirectangularstereo-nodes-input-connection","title":"Step 4. In the Fusion Nodes view you need to connect your YouTube 360 footage's MediaIn/Loader node output connection to the \"MeshUV2EquirectangularStereo\" node's input connection.","text":"<p>Step 4. In the Fusion Nodes view you need to connect your YouTube 360 footage's MediaIn/Loader node output connection to the \"MeshUV2EquirectangularStereo\" node's input connection.</p> <p></p> <p>This node connection allows the RGBA image data from the MediaIn/Loader node to flow into the \"MeshUV2EquirectangularStereo\" node.</p> <p>Now we can view the output from the \"MeshUV2EquirectangularStereo\" node on the right viewer window.</p> <p>Looking at the screenshot below we can see how the YouTube 3x2 cubic face media was loaded into Fusion, the media was then reformatted into an Equirectangular format, and the result was then displayed on the right viewer window.</p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kartaverse/Workflows/YouTube%20360%20to%20Equirectangular%20Conversions/#ref7","title":"Step 5. You can render this footage back to an image sequence or movie file on disk using either a MediaOut node (in Resolve), or a Saver node (in Fusion Standalone).","text":"<p>Step 5. You can render this footage back to an image sequence or movie file on disk using either a MediaOut node (in Resolve), or a Saver node (in Fusion Standalone).</p> <p></p> <p></p>","tags":["Kartaverse","Workflow",".scrivener-export"]},{"location":"Kernfusion/","title":"Fuses, Macros &amp; Compositions","text":"<p>Not much in here yet. Meant to collect and cleanup code experiments - for example from the WSL Forum (if permission by the respective author is granted). As a kind of incubator / pre-release area for Reactor for code not yet mature enough for publication; or for Fuses just intended as code examples to learn from, or to provide code fragments to be utilized in your own solutions. But a 'centralized' repository most probably makes very little sense in this regard - however, having some examples may help to shape some schema to link between different such repositories?!?</p>"},{"location":"Kernfusion/#overview","title":"Overview","text":""},{"location":"Kernfusion/#fuses","title":"Fuses","text":"<ul> <li>AudioWaveform by JiPi</li> <li>Bokeh by TiDa</li> <li>FastGlow by Danell</li> <li>CubeMapLoader by nmbr73</li> <li>CubeMapUnfold by nmbr73</li> <li>CubeMapColorizer by nmbr73</li> <li>CubeMapEquirectangular by nmbr73</li> <li>SDF Font Example by nmbr73</li> </ul>"},{"location":"Kernfusion/#comps","title":"Comps","text":"<ul> <li>AudioWaveform by JiPi</li> <li>TitleBurnEffect by TiDa</li> </ul>"},{"location":"Kernfusion/#macros","title":"Macros","text":"<ul> <li>Bokeh_Image by TiDa</li> <li>Bokeh_AChroma by TiDa</li> </ul>"},{"location":"Kernfusion/#setup","title":"Setup","text":"<p>Link Fuses into Fusion</p>"},{"location":"Kernfusion/#on-macos","title":"on macOS","text":"<p>Set PROJECTS to whatever folder you want to clone the project into:</p> <pre><code>PROJECTS=\"/Users/$(whoami)/Projects/\"\nFUSION=\"/Users/$(whoami)/Library/Application Support/Blackmagic Design/Fusion\"\n\ncd $PROJECTS\ngit clone \"https://github.com/$(whoami)/Kernfusion\"\n\ncd \"$FUSION/Fuses\"\nln -s \"$PROJECTS/Kernfusion/Fusion/Fuses\" Kernfusion\n\ncd \"$FUSION/Macros\"\nln -s \"$PROJECTS/Kernfusion/Fusion/Macros\" Kernfusion\n</code></pre>"},{"location":"Kernfusion/#on-windows","title":"on Windows","text":"<p>No idea. Did that once for the Shadertoys setup script, but I don't have a Windows PC and soft links seem to me pretty weird on Windows.</p>"},{"location":"Kernfusion/#on-linux","title":"on Linux","text":"<p>Should be pretty much the same as on macOS ... kind of ... despite the paths ... but if you are on Linux I guess you know what you are doing.</p>"},{"location":"Kernfusion/#in-fusion","title":"in Fusion","text":"<p>Not a must, but if you want to avoid the need to manually fix paths in comps and such, then you may want to set a 'Kernfusion:' path map to the folder you checked out the repository to.</p>"},{"location":"Kernfusion/#in-resolve","title":"in Resolve","text":"<p>I don't know; just use Fusion.</p>"},{"location":"Kernfusion/Comp/","title":"Comps","text":"<ul> <li>JiPi/</li> <li>TiDa/</li> <li>nmbr73/</li> </ul>"},{"location":"Kernfusion/Comp/jipi/","title":"Compositions by JiPi","text":"<ul> <li>AudioWaveform</li> </ul>"},{"location":"Kernfusion/Comp/jipi/#see-also","title":"See also:","text":"<ul> <li>Fuses by JiPi</li> <li>Comps by others</li> </ul>"},{"location":"Kernfusion/Comp/jipi/AudioWaveform/","title":"Audio Waveform Composition","text":"<p>...</p>"},{"location":"Kernfusion/Comp/jipi/AudioWaveform/#youtube-videos","title":"YouTube Videos","text":"<ul> <li>How To Make An Audio Spectrum Visualizer In Davinci Resolve/Fusion(Free Versions) by David 'Learn Now FX' Kohen</li> <li>Audio Waveforms in Davinci Resolve 16 by Jake Wipp</li> <li>Audio Spectrum Waveform Effect in Resolve 16 (Tutorial)</li> <li>Audio Spectrum Visualizer DaVinci Resolve</li> <li>AudioWaveform in Davinci Resolve Fusion by JiPi (German)</li> </ul>"},{"location":"Kernfusion/Comp/jipi/AudioWaveform/#alternative-approaches","title":"Alternative approaches","text":"<ul> <li>How to Create an Audio Visualiser in Davinci Resolve by Video Editor Studio</li> <li>Create Audio Visualizer Effect using Fusion Modifier in DaVinci Resolve 17 by Essential Video Editing</li> <li>Audio Wave Line Visualizer Effect in DaVinci Resolve - Fusion Tutorial by Essential Video Editing</li> </ul>"},{"location":"Kernfusion/Comp/jipi/AudioWaveform/#see-also","title":"See also:","text":"<ul> <li>Fuses by JiPi</li> <li>Comps by JiPi</li> </ul>"},{"location":"Kernfusion/Comp/nmbr73/","title":"Compositions by nmbr73","text":"<ul> <li>CubeMapColorizer.comp</li> <li>CubeMapLoader.comp</li> <li>CubeMapUnfold.comp</li> <li>SDF_Font_Example.comp</li> </ul>"},{"location":"Kernfusion/Comp/nmbr73/#see-also","title":"See also:","text":"<ul> <li>Fuses by nmbr73</li> <li>Comps by others</li> </ul>"},{"location":"Kernfusion/Comp/tida/","title":"Compositions by TiDa","text":"<ul> <li>TitleBurnEffect</li> </ul>"},{"location":"Kernfusion/Comp/tida/#see-also","title":"See also:","text":"<ul> <li>Fuses by TiDa</li> <li>Comps by others</li> <li>Macros by TiDa</li> </ul>"},{"location":"Kernfusion/Comp/tida/TitleBurnEffect/","title":"Title Burn Effect","text":"<p>Source: \"[DEV] DCTL Convolve Bokeh Fuse\" #48 on WSL.</p> <p>A comp using TiDa's Bokeh Fuse to create a title burn effect.</p> <p></p> <p>This is a Comp to demonstrate how easy it is to get a title burn effect (see the video below). A Fast Noise is attached to the Mask Input. It's size, detail and contrast is adjusted that a displacement looks natural. Erosion is also driven by the Mask and subsequent size (white point), black point, contrast and pivot adjustment let one control the fire detail.</p> <p></p>"},{"location":"Kernfusion/Fuses/","title":"Fuses","text":"<ul> <li>JiPi/</li> <li>danell/</li> <li>TiDa/</li> <li>nmbr73/</li> </ul>"},{"location":"Kernfusion/Fuses/danell/","title":"Fuses by Jacob Danell","text":"<ul> <li>FastGlow</li> </ul>"},{"location":"Kernfusion/Fuses/danell/FastGlow/","title":"FastGlow","text":"<ul> <li>[FastGlow.fuse](FastGlow.fuse</li> </ul> <p>In my Glow fuse I'm using a way to quickly create a gaussian blur using 3 box blurs and doing 9 different sizes of blurs. In total this becomes 54 calls to the DCTL kernel (+ some more for other calculations).</p> <p>When the kernel is done running the image moves from the GPU to CPU/RAM. In my tests this is the biggest bottle neck, making the fuse waaay slower than if everything would be done in one kernel (6fps vs 24fps)</p> <p>FastGlow runs at about 4 frames / sec for Danell; 2.1 secs/frame on nmbr73's 2019 MBP (Core i9, Radeon 560X, see discord post); said to be slow on M1 too.</p> <p>If any DCTL guru knows a way to leave the created image in the GPUs memory to be accessed again, this would be a game changer for fuses with many kernel calls. I tried to call <code>_tex2DVec4Write</code> 27 times in one kernel and the FPS only went down from 24fps to 22fps.</p> <p>Going thought the Rays.fuse I'm seeing a couple of functions I haven't seen really anywhere else: - Inside the DCTL I see <code>make_intensity(float4, compOrder)</code>. I also found it being used in LearnNowFX's fuse Long Shadow. Do you know what it does? - Next I see in the processing: <code>node:SetGlobalSize(math.ceil(numRays / 128) * 128)</code> and <code>node:SetWorkSize(128)</code>. Does anyone know what these do?</p> <p>Here you can find the source code :) https://www.steakunderwater.com/wesuckless/viewtopic.php?t=5485</p>"},{"location":"Kernfusion/Fuses/jipi/","title":"Fuses by JiPi","text":"<ul> <li>AudioWaveform</li> </ul>"},{"location":"Kernfusion/Fuses/jipi/#see-also","title":"See also:","text":"<ul> <li>Fuses by others</li> <li>Comps by JiPi</li> </ul>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/","title":"Audio Waveform Fuse by JiPi","text":"<p>The AudioWaveform.fuse is intended for visualizing audio data in Fusion. There are three functions: 1) Waveform of a wav file 2) Spectrum of a Wav file 3) Spectrum output via an additional output for shader fuses</p> <p>For the first two functions there is still the possibility to generate one or three value(s) (elongation), which can be used via \"Connect to\" for parameters in other nodes.</p> <p>By default, the fuse works in function 1 (waveform display) To switch to 2, you have to switch to the Spectrum Page and select the Spectrum check mark there (this will lock some parameters on the Control page). Function 3 is switched on via the \"Shadertoy Audio\" checkbox in the Control page, which automatically switches to the spectrum calculation. If you switch off the spectrum checkbox, the shadertoy audio is also switched off.</p> <p>First, an audio file must be loaded in the Control page via Wave File. Wave files (RIFF WAVE) PCM 16-bit with 44100 Hz and 48000 Hz, mono and stereo are processed. These can easily be generated in Davinci Resolve. After loading, either the waveform of the loaded file appears at the position of the current frame or an error message. The following errors are detected and reported: 1) Special characters in the file name (or folder, e.g. \u00e4,\u00f6,\u00fc) 2) File too large (larger than 50 Mb) 3) Unsupported format 4) Unsupported bit depth (e.g. 24 bit)</p>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/#function1-waveform-display","title":"Function1: waveform display","text":"<p>The parameters for this are in the Control page.</p> <p>The play point is set in the middle of the picture. There are three parameters for setting the waveform's timing: Proxy, Zoom and Resolution</p> <p>1) Proxy: This multiplies the sample pool without increasing the number of pixels shown 2) Zoom: This also multiplies the sample pool, but all values \u200b\u200bare also displayed (as far as can be displayed) 3) Resolution: Acts as a divisor for the displayable pixels -&gt; Resolution = 2 with HD -&gt; 1920/2</p> <p>The stereo signal (Both) is generated by maximum formation of the two channels.</p> <p>There is a setting for the amplitude and 4 different ways to display the envelope. A crosshair can be displayed and the signal can be filtered before it is displayed. There are three filter ranges, low pass (20-300Hz) band pass (300-3kHz) and high pass 3-20kHz)</p> <p>The waveform/spectrum and crosshair colors can be customized in the Layout page. A background image can also be displayed via the iChannel0 input.</p>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/#function2-spectrum","title":"Function2: Spectrum","text":"<p>The number of values to be used can be set with the FFT setting, but it should be noted that large values also require high performance. The smooth factor indicates by how much falling values are delayed in the display. Scale is just a multiplier for the values. With LogK you can influence the calculation of the logarithm. There are 5 different settings available for display - Rough (raw display, the values are directly connected) - Bars (value is kept at the value until the next) - Smoth (A rounding takes place) - Smooth filling (The area under the curve is filled) - Needles (there is no connection of the values in the X-direction)</p> <p>In the representation with equidistant sections, the values are converted evenly to the X-axis. Steps is taken as the power of two for the divider of the FFT values. With Limitation you can limit the values, whereby the type of limitation can be influenced with Compression. With the Decompress setting, the DC component can be lowered or raised. With Slope, an increase can be achieved via a corner frequency.</p> <p>When FrequencyVisualization is switched on, a shaderfuse is used for display. There are other parameters for this.</p>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/#function3-audiodata-for-shader-fuses","title":"Function3: AudioData for shader fuses","text":"<p>Setting the \"Shadertoy Audio\" checkbox switches to spectrum mode and packs the values into an image ( 512*2 pixels ). This image is available at output2 of the AudioWaveform.fuse and can then be used with shader fuses.</p>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/#elongation-connect-to-function","title":"Elongation (connect to function)","text":"<p>1) If function1: waveform representation</p> <p></p> <p>The operator for calculating the elongation value can be selected between Max, Average or Median. Amplify and offset are adjustable. The current value of the elongation is represented graphically by a red block and displayed as a value under the checkbox</p> <p>2) If Function2: Spectrum representation</p> <p></p> <p>The parameters mentioned above also exist for the spectrum display, but three different elongation values can be defined here (e.g. one for bass, one for medium frequencies and one for high tones) Here, too, the ranges used are shown graphically and the values are displayed.</p> <p></p> <p>A so-called Schmidt trigger can be defined via the page elongation. An output value can be set using the switch-on and switch-off threshold. The current value is displayed. The min/max values displayed are calculated continuously, i.e. if a smaller or larger value is detected in a frame, the min/max is reset. Resetting is done by switching the hysteresis on/off.</p>"},{"location":"Kernfusion/Fuses/jipi/AudioWaveform/#see-also","title":"See also:","text":"<ul> <li>Fuses by JiPi</li> <li>Comps by JiPi</li> </ul>"},{"location":"Kernfusion/Fuses/nmbr73/","title":"Fuses by nmbr73","text":"<p>Not meant to provide any 'production ready' functionality or to be even used in Fusion. It's about getting some ideas and having a basis for your own experiments. Being myself a noob when it comes to Fusion, Lua, Python and even Git, these Fuses are actually just my personal playground to persist and (hopefully) evolve some of my findings.</p> <p>All of this is in a very early stage. So far I started working on ...</p> <ul> <li>CubeMapLoader to load a sequence of 6 images as a single texture</li> <li>CubeMapUnfold DCTL non-sense (was just to develop and debug the shader access to a cube map texture)</li> <li>CubeMapColorizer colorize the faces of a cube by different colors (via DCTL)</li> <li>CubeMapEquirectangular DCTL based projection of a cubemap to a 2D image</li> <li>SDF Font Example could help to debug DCTL Fuses</li> <li>Garbage/MultiButtonControls example for the different MultiButtonControl types</li> </ul>"},{"location":"Kernfusion/Fuses/nmbr73/#see-also","title":"See also:","text":"<ul> <li>Fuses by others</li> <li>Comps by nmbr73</li> </ul>"},{"location":"Kernfusion/Fuses/nmbr73/CubeMapColorizer/","title":"CubeMap Colorizer","text":"<ul> <li>CubeMapColorizer.fuse ... can be downloaded and copied manually into your fuses folder if needed</li> <li>CubeMapColorizer.comp ... needs the repository to be checked out as described in the README</li> </ul> <p>Fuse to colorize horizontal cross image that is meant to be used as a cube map.</p> <p><sup>1</sup></p> <p>What you can do with it: - Connect a CubeMapLoader to it ... and you see the cube's faces colorized by different colors - Connect any tool that accepts a horizontal cross texture as a cube map to see where the cube's faces end up</p> <p>Things to discover in its source code: - Creating a simple, fully Lua based tool for Fusion - This Fuse is a very lightweight example of how one can implement a fragment shader via DCTL</p> <ol> <li> <p>The picture you see being used as in input in the screenshot is the work of Emil Persson, aka Humus.\u00a0\u21a9</p> </li> </ol>"},{"location":"Kernfusion/Fuses/nmbr73/CubeMapEquirectangular/","title":"Equirectangular Projection for CubeMaps","text":"<ul> <li>CubeMapEquirectangular.fuse<sup>2</sup> ... can be downloaded and copied manually into your fuses folder if needed</li> <li>CubeMapEquirectangular.comp ... needs the repository to be checked out as described in the README</li> </ul> <p><sup>1</sup></p> <p>What you can do with it: - Connect a CubeMapLoader to it ... and you see the cube's faces projected to a 2D image</p> <ol> <li> <p>The picture you see being used as in input in the screenshot is the work of Emil Persson, aka Humus.\u00a0\u21a9</p> </li> <li> <p>The DCTL code is based on the awesome work of Madsy who was so kind to release his implementation to the public domain\u00a0\u21a9</p> </li> </ol>"},{"location":"Kernfusion/Fuses/nmbr73/CubeMapLoader/","title":"CubeMap Loader","text":"<ul> <li>CubeMapLoader.fuse ... can be downloaded and copied manually into your fuses folder if needed</li> <li>CubeMapLoader.comp ... needs the repository to be checked out as described in the README</li> </ul> <p>Fuse to create a 2D representation of a cube map.</p> <p><sup>1</sup></p> <p>What you can do with it: - Use it as an input for Fusion's CubeMap (3Cu) tool ... but I have no idea what this 3Cu tool is good for. - Use it as an input for DCTL fragment shaders that work with a cube map texture (see CubeMapUnfold) ... but that's a very special use case. - No idea if it is even needed - most probably there are already built-in tools that do all of this and a lot more?!? - Or maybe it can be done with some images and transform nodes as a simple composition / macro / whatsoever?</p> <p>Todo: - Find out when and why <code>REG_Source_GlobalCtrls=false</code> shreds Fusion!?!</p> <p>Things to discover in its source code: - Simple but often forgotten things like setting tooltips on buttons and status texts - Loading a sequence of pictures as a clip - Creating a single image copying the clip pictures into a single texture - Copy, translate, rotate images into a target texture (i.e. the vertical cross)</p> <ol> <li> <p>The picture you see being used as in input in the screenshot is the work of Emil Persson, aka Humus.\u00a0\u21a9</p> </li> </ol>"},{"location":"Kernfusion/Fuses/nmbr73/CubeMapUnfold/","title":"CubeMapUnfold","text":"<p>The CubeMapUnfold.fuse converts a horizontal cross input into a horizontal cross output - this means: it is of no practical use.</p> <p>It helps to test the <code>cubemap</code> function in the <code>CompatibilityCode</code> which is used to mimic Shadertoy cube maps by using a horizontal cross 2D texture. To do so it can be used to try out CubeMapLoader as an input for a DCTL Fuse.</p> <p>The <code>cubemap</code> function in the <code>CompatibilityCode</code> takes a normalized 3D vector meant to point into a cube map and converts it to the respective pixel on a 2D horizontal cross texture. This way we can use such horizontal crosses as an input for those fragment shaders that work on a cube map. Now the CubeMapUnfold's kernel is a fragment shader that displays a cube map as a horizontal cross - so it kind of does what the <code>cubemap</code> code does, but the other way around; maybe so to say it undoes it. However: you put a 2D horizontal cross texture into that fuse and the result is a 2D horizontal cross texture. A functionality that is pretty useless as such. But on the one hand seeing both directions of the calculations might help someone not used to that stuff (like me when I wrote this Fuse) to understand the formulas; and on the other hand it is good to have to doublecheck if the <code>cubemap</code> function does the right thing.</p> <p>Tries to get the DCTL as close as possible to \"normal\" OpenGL ES. Actually the fragment shader code (content of the <code>KernelCode</code> variable) can just be copied and pasted into shadertoy.com). Quite some DCTL specifics enclosed in <code>#ifdef</code> and the resulting code is not very readably, but still this might be an approach to consider to minimize the changes done for WebGL to DCTL conversions?!?</p> <ul> <li>Can be used to test and understand the <code>float4 cubemap(__TEXTURE2D__, float3)</code> function accessing a 2D horizontal cross texture.</li> <li>Shows on the DCTL side some transformations from different vector formats to others (normalized or not, 2D and 3D).</li> <li>Can be used as a basis by just replacing the <code>KernelCode</code> for your own DCTL code that requires accessing a cube map.</li> <li>Is an example of how close we can get between DCTL and WebGL.</li> </ul>"},{"location":"Kernfusion/Fuses/nmbr73/SDF_Font_Example/","title":"SDF Font Example","text":"<ul> <li>SDF_Font_Example.fuse ... can be downloaded and copied manually into your fuses folder if needed</li> <li>SDF_Font_Example.comp ... needs the repository to be checked out as described in the README</li> <li>Uses shader_fontgen/shadertoy.png as its input texture</li> </ul> <p>With Otavio Good's shader_fontgen one can create a SDF (signed distance function) based font texture. For a good introduction into SDF Fonts based on the technique proposed by Chris Green of Valve at SIGGRAPH 2007 see SDFont, a Signed Distance Font Generator and Runtime Utility by Shoichiro Yamanishi. See About SDF fonts in the Unity manual to quickly get the idea.</p> <p></p> <p>Examples of how to render the SDF font into text: - SDF font 0 by IFHEo - SDF Font Texture Adventures  ... uses the font texture and adds some effects</p> <p>Shadertoys using the SDF font texture: - GPU and OS detector v2 by archee - iResolution, iMouse, iDate, etc by FabriceNeyret2 - [SH17C] Physically Based Shading by knarkowicz</p> <p>Other Shadertoys that display text: - Pangram ... just \"paints\" the letters - no texture needed - 96-bit 8x12 Font ... a pixel font - no texture needed</p>"},{"location":"Kernfusion/Fuses/nmbr73/Garbage%20Collection/MultiButtonControl/","title":"MultiButtonControl","text":"<ul> <li>MultiButtonControl.fuse</li> </ul> <p>... just some garbage trying out the Multi Button</p>"},{"location":"Kernfusion/Fuses/tida/","title":"Fuses by TiDa","text":"<ul> <li>Bokeh is a convolutional filter to achieve a bokeh effect</li> </ul>"},{"location":"Kernfusion/Fuses/tida/#see-also","title":"See also:","text":"<ul> <li>Fuses by others</li> <li>Comps by TiDa</li> <li>Macros by TiDa</li> </ul>"},{"location":"Kernfusion/Fuses/tida/Bokeh/","title":"Bokeh Fuse","text":"<p>Source: \"[DEV] DCTL Convolve Bokeh Fuse\" #48 on WSL.</p>"},{"location":"Kernfusion/Fuses/tida/Bokeh/#summary","title":"Summary","text":"<ul> <li>Bokeh.fuse source code</li> </ul> <p>This is a simple convolutional filter, where you can achieve a bokeh from a self-drawn image.</p> <p></p> <p>See DCTL Convolve Bokeh Fuse thread on WSL for further information and full revision history.</p> <p>See it in action: - TitleBurnEffect example Comp</p> <p>See also: - Bokeh_Image Macro - Bokeh_AChroma Macro for Chromatic Aberration</p>"},{"location":"Kernfusion/Fuses/tida/Bokeh/#description","title":"Description","text":"<p>These are just some text fragments copied and pasted from the WSL discussion thread. This needs to be sorted out, complemented and reworded to make it a usable description for the current version.</p> <p>Bokeh image is limited to 100x100 pixels. Image is multiplied and added to the Video in a typical convolutional way. But 50% grey is set to zero influence. Hence below 50% it will darken, above 50% it will brighten. But the Fuse is set on default to use normal B&amp;W bokeh images.</p> <ul> <li>Amplify: does pronounce Bokeh at contrasty zones.</li> <li>Luma Balance: might be used if Luma does change too much compared to the original.</li> <li>Neutral Grey: raise it, if you like to build up a sharpen filter</li> <li>Anam Desqueeze: will change the bokeh aspect ratio. Multiply by 4/3 to calculate the aspect ratio of an anamorphic image. (1.8 * 4/3 = 2.40)</li> <li>CA: Chromatic Abberation (you can change strength and angle)</li> </ul> <p>You are still able to add a depth map to Channel2 (purple input).</p> <p>Make your bokeh image really small like 10x10 pixels. Increase Bokeh size by 10 or whatever. Even if you increase the Amplify slider you should not see any pattern formation. The speed is not the best but for convolving it should be OK by now. It strongly depends on Bokeh input size but you can use now much smaller sizes to get similar results. In addition, if you set Amplify to zero you should see an increase in speed as mentioned power function is disabled.</p> <p>Example - convolve for  100x100 pixel bokeh: - Before: 100x100  (convolve) = 10.000 times to calculate full image in cycle \u2192 very expensive - Now: 10x 10 (convolve) + 10x3x2 (Gaussian with 3sigma) = 160 times to calculate full image in cycle \u2192 much cheaper</p> <p>To receive Bokeh without any pattern formation, you need to put the Size slider of this fuse to a whole number (not a fractional number). Did not make it as an integer as should be also used for smooth transitions.</p> <p>Implemented Chromatic Aberration functionality. Furthermore, you have an additional option to switch to the Bokeh Image.</p> <p>With a bokeh texture of 500x500 and a touch of Amplify, it will take some time to calculate only one frame. That's because 500x500x1024x1024 = 262.144.000.000 pixel (find/add/multiply etc.) calculations. And this is, why the size has been limited.</p> <p>BokehFuse:</p> <p></p> <p>Bokeh and Depth: </p> <p>Bokeh and DepthToFocus Fuse: </p> <p>Implemented micro-dithering to prevent some pattern formation when changing the size of bokeh. It will give an anti-aliasing effect while processing time is not influenced too much. Midgardsormr comments during his VariDilate Fuse development about solving rounding issues helped a lot.</p> <p></p> <p>Scaled Bokeh Image 100x100 pixel - left original - right convolve with micro dithering (without blur mix)</p> <p></p>"},{"location":"Kernfusion/Macros/","title":"Macros","text":"<ul> <li>TiDa/</li> </ul>"},{"location":"Kernfusion/Macros/tida/","title":"Macros by TiDa","text":"<ul> <li>Bokeh_Image</li> <li>Bokeh_AChroma</li> </ul>"},{"location":"Kernfusion/Macros/tida/#see-also","title":"See also:","text":"<ul> <li>Fuses by TiDa</li> <li>Comps by TiDa</li> <li>Macros by others</li> </ul>"},{"location":"Kernfusion/Macros/tida/Bokeh_AChroma/","title":"Bokeh AChroma","text":"<p>Source: \"[DEV] DCTL Convolve Bokeh Fuse\" #46 on WSL.</p> <p>A Macro developed in the context of TiDa's Bokeh Fuse to quickly add Chromatic Aberration to the final Image. All RGB shifts take place symmetrically. It also imparts a Blend Slider to have the possibility to animate changes when changing bokeh blur size.</p> <p></p>"},{"location":"Kernfusion/Macros/tida/Bokeh_Image/","title":"Bokeh Image","text":"<p>Source: \"[DEV] DCTL Convolve Bokeh Fuse\" #45 on WSL.</p> <p>Macro to build up bokeh images - provided in the context of TiDa's Bokeh Fuse. You can change the size of RGB/CMY areas individually to mimic symmetric chromatic aberration or other color effects. To receive a neutral color output without color tint it is helpful to use the LineScope fuse as well.</p> <p>Dependencies: This macro requires the <code>KomkomDoorn.KD_ShapeRender</code>, <code>KomkomDoorn.KD_ShapeMerge</code>, and <code>KomkomDoorn.KD_ShapePrimitiveCreate</code> tools. Install \"Korokodove for Fusion/Resolve Studion 17\" from the Reactor's \"Tools/Plugins\" section to make them available in your Fusion instance.</p>"},{"location":"Kernfusion/Macros/tida/Bokeh_Image/#bokeh-with-color-tint","title":"Bokeh with Color Tint","text":"<p>left image, LineScope with 4x zoom shows averaged G&gt;R&gt;B</p> <p></p>"},{"location":"Kernfusion/Macros/tida/Bokeh_Image/#neutral-bokeh","title":"Neutral Bokeh","text":"<p>left image, LineScope with 4x zoom shows averaged R=G=B</p> <p></p>"},{"location":"Kernfusion/Macros/tida/Bokeh_Image/#final","title":"Final","text":""},{"location":"Lab/Conversion/","title":"Conversion","text":"<p>Scrivener's compile supports Multimarkdown and Pandoc output. Obsidian uses Markdown. MkDocs renders Markdown into a static HTML site. Pandoc renders Markdown into MediaWiki.</p> <p>Sounds simple and perfect to build a documentation workflow ... ... but turns out to be a rabbit hole that I'm not sure I want to jump into.</p>"},{"location":"Lab/Conversion/#imagetest","title":"Imagetest","text":"<pre><code>flowchart TB\n    Scrivener -- MarkDown --&gt; Obsidian\n    Obsidian -- MarkDown --&gt; MkDocs\n    MkDocs -- HTML --&gt; GitHub_Pages\n    Obsidian -- MarkDown --&gt; Pandoc\n    Pandoc -- WikiMarkup --&gt; MediaWiki</code></pre> <ul> <li>Test: Internal link to an \"index\" file WebGL to DCTL</li> <li>Test: Internal link to a file Fuse-Settings</li> </ul>"},{"location":"Lab/Conversion/#issues","title":"Issues","text":"<p>Kartaverse Workflows / Creating Volumetric NeRFs /Equipment Needed to Explore Instant NGP: The \"Git Client\" image is 'image35'</p> <p>Kataverse Workflows / KickAss ShaderZ for Fusion / Natural: The \"kas_DarkBlueIceShard\" image is 'image35'</p>"},{"location":"Lab/Conversion/#todo-docconv","title":"TODO: docconv","text":"<p>https://pkg.go.dev/code.sajari.com/docconv</p>"},{"location":"Lab/Conversion/#misc","title":"Misc","text":"<p>To maybe try some other directions: https://stackoverflow.com/questions/41183642/how-to-convert-github-wiki-into-github-pages ... but not so easy</p> <p>Embed Video: https://pypi.org/project/python-markdown-oembed/ https://gist.github.com/dmitric/6266559</p> <p>Auch ein paar nette dabei: https://chrieke.medium.com/the-best-mkdocs-plugins-and-customizations-fc820eb19759</p> <p>Grundlagen: https://www.mkdocs.org/dev-guide/plugins/ https://python-markdown.github.io/extensions/api/</p> <p>Die kaputten Links: https://github.com/Jackiexiao/mkdocs-roamlinks-plugin Lab/Folder Zero/index</p> <p>Und Bildgr\u00f6\u00dfen m\u00fcsste ich noch gucken - die aber vielleicht einfach als Extension?!?</p> <p>Okay, MultiMarkdown still seems to be the best option. With and <code>.opml</code> (Titles only) I can restore the articles' order - format is simple and straight forward. Have to check what exacly happens</p> <p>https://www.youtube.com/watch?v=yTMo9WkOphE und hier ist was erkl\u00e4rt, das helfen k\u00f6nnte</p> <p>https://www.youtube.com/watch?v=xisfLmWGXqA und vielleicht hier</p> <p>https://medium.com/@TKalippke/all-you-have-to-do-is-type-yourself-494a2c0b2fd6</p> <p>mit docker verbasteln - als beispiel https://hub.docker.com/r/silentstorm/pandoc-mkdocs/</p> <p>Another test is Fusion</p> <p>\\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\), \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\).</p> <p>This is Lua's <code>#!lua if x ~= 42 then -- ...</code> inlined in text.</p> <p>And some Cmd+Option+Q, Ctrl+Alt+Del keystrokes,</p> <p>Config/</p>"},{"location":"Lab/Conversion/#scrivener","title":"Scrivener","text":"<p>\"Compile for: MultiMarkdown\" and then \"Duplicate &amp; Edit Format...\" the \"Basic Pandoc\".</p> <p>Named the new format \"Pandoc (nmbr73)\" (or whatever you want).</p> <p>Under 'Styles' add our 'Code Block (Lua)' style.</p> <p>Check the 'Treat as raw markup' box.</p> <p>Set 'Prefix/suffix:' to <code>\\n```lua\\n</code> and <code>\\n```\\n</code>. Enter the new line by pressing Opt + Enter in the input fields.</p> <p>Todo</p> <ul> <li>https://iandol.github.io/scrivomatic/ , resp. https://github.com/iandol/scrivomatic</li> <li>https://michalwyrwa.org/posts/2019-06-08-pandocscripts/</li> </ul> <p>Document content in Scrivener is stored in RTF (Rich Text Format). <pre><code>open Sources/Kernfusion.scriv/Files/Data/59587C22-40EF-4FD1-8674-595E763625CB/content.rtf\n</code></pre></p> <p>Pandoc comes already with a reader for RDF. To show the internal (native) pandoc representation (abstract syntax tree): <pre><code>pandoc -s -t native 'Sources/Kernfusion.scriv/Files/Data/59587C22-40EF-4FD1-8674-595E763625CB/content.rtf'\n</code></pre></p> <p>Binder and styles are defined in XML. All the things are then tied together with UUIDs ... so if nothing else works, I could read that raw data.</p> <p>Todo</p> <ul> <li>http://lit-n-lat.blogspot.com/2010/02/coding-xml-formats-in-cocoa_05.html#links</li> <li>https://blog.jayway.com/2020/01/23/attributed-strings-and-rich-text-files/</li> </ul> <p>It would make total sense to apply more semantic markup in Scrivener. I managed to define 'Styles' (for example for \"Code Block (Lua)\", \"Code Block (Python)\") and to create my own 'Format' (for Multimarkdown and Pandoc) to apply the respective Markdown formatting. But this process is pretty tedious and very limited in the resulting markup we can achieve with it.</p> <p>Internal links, 'Title' Style, and many more gets lost when exporting from Scrivener to (Pandoc) Markdown</p>"},{"location":"Lab/Conversion/#mkdocs","title":"MkDocs","text":"<p>MkDocs generates static HTML sites out of Markdown sources and a single configuration YAML file.</p> <p>MkDocs uses Python-Markdown, which is almost completely compliant with the original Markdown reference implementation. But MkDocs includes support for extending the Markdown syntax with Python-Markdown extensions.</p> <p>Todo</p> <ul> <li>Could be an option to creating other output formats from an MkDocs source using pandoc: mkdocs-combine</li> </ul> <p>Currently the image paths are sometimes broken!?!</p> <ul> <li>https://stackoverflow.com/questions/71074662/configuring-image-filepaths-correctly-in-mkdocs</li> </ul>"},{"location":"Lab/Conversion/#pandoc","title":"Pandoc","text":"<ul> <li>Guter Artikel: https://ulriklyngs.com/post/2019/02/20/how-to-use-pandoc-filters-for-advanced-customisation-of-your-r-markdown-documents/</li> <li>Auch umfangreich: https://jmablog.com/post/pandoc-filters/</li> </ul> <p>Pandoc uses by default its own Pandocs Markdown flavor.</p> <p>Scrivener includes MultiMarkdown support.</p> <p>Check for interoperability options for Pandoc and Obsidian</p> <ul> <li>Obsidian &amp; Pandoc.</li> <li>Maybe do my own lua-filter, and custom-writer to read Obsidian Markdown and/or to create MkDocs markdown</li> </ul> <p>Pandoc could in particular be the tool of choice to make convert the Obsidian Markdown files into WikiMarkup, MkDocs Narkdown, etc.</p>"},{"location":"Lab/Conversion/#obsidian","title":"Obsidian","text":"<p>Markdown: https://www.markdownguide.org/tools/obsidian/</p> <p>Todo</p> <ul> <li>https://obsidian-publisher.netlify.app</li> <li>https://github.com/ObsidianPublisher/obsidian-mkdocs-publisher-template</li> <li>https://github.com/ObsidianPublisher/obsidian-mkdocs-publisher-python</li> <li>https://github.com/ObsidianPublisher/obsidian-github-publisher</li> <li>https://github.com/jobindj/obsidian-publish-mkdocs</li> <li>https://github.com/jobindjohn/obsidian-publish-mkdocs</li> </ul> <p>Create notes / descriptions / hierarchy for the folders in Obsidian:</p> <ul> <li>https://github.com/xpgo/obsidian-folder-note-plugin</li> <li>https://github.com/akosbalasko/zoottelkeeper-obsidian-plugin</li> </ul> <p>Index files - https://github.com/aidenlx/alx-folder-note - https://forum.obsidian.md/t/folder-link-default-load-readme-md-file-just-like-github/41335</p> <p></p> <p></p>"},{"location":"Lab/Crash%20Course/","title":"Crash Course","text":"<p>You'll find tons of excellent and thorough documentation on the different formats and tools ... and you can spend hours on each to find out what functionalities it provides. Intention of this section is not to rewrite the user manuals and enthusiasts' blog posts, but to hopefully give a good idea what you could use the different tools for and if they are worth a closer look - here with as much information as needed at as little text to read as possible.</p>"},{"location":"Lab/Crash%20Course/#pandoc","title":"Pandoc","text":"Currently used to convert Scrivener exports <p>Not making much use of it - finding the first headline, finding all images, and (main part und really helpful) changing the formatting of image links. But Pandoc seems pretty versatile and powerful and could be of use for many other situations. And my usage so far shows a template, a filter and a writer.</p> <p>Pandoc is a tool for transforming documents from one format to another, e.g. from Word to HTML. Install on macOS e.g. via <code>brew install pandoc</code>.</p> <p>Example: <pre><code># Convert from Mardown to a Word document\npandoc document.md -o document.doc\n</code></pre></p> <p>It comes with 'readers' for the different input formats that parse the respective format into an abstract syntax tree (short: AST). The AST is pandoc's internal representation of a document's content. On the other end the 'writers' implement the conversion from the AST into the different output formats. Additionally there is the option to provide 'filters' that manipulate the AST after it has been read by a reader and before it gets processed by a writer. The writer's output can be further manipulated by 'templates' before it is written. The whole process is controlled by various command line parameters.</p> <pre><code>flowchart LR\n  INPUT --&gt; reader\n  reader --&gt; AST\n  AST --&gt; 'filter'\n  'filter' --&gt; AST\n  AST --&gt; writer\n  writer --&gt; template\n  template --&gt; OUTPUT\n  writer --&gt; OUTPUT</code></pre> <p>This simple concept allows for lots of conversions from many document formats into many others: If a format is not supported yet, you can implement a reader; if there is a new format, just create a writer and you can convert all supported input formats into that format; a filter once created can be applied to all the input formats for all the output formats. And finally templates can be used for some rough building blocks, e.g. to embed your writers output in some header and footer.</p> <ul> <li>The supported input/output formats are listed under the <code>--from</code>/<code>--to</code> General Options.</li> <li>The AST format is described by the Text-Pandoc-Definition. You can use <code>--to=native</code> to get the internal Haskell representation of an input document.</li> <li>Filtering can be described in JSON or implemented in miscellaneous script languages (see: filters), but preferably Pandoc's integrated Lua interpreter can be used to realize Pandoc Lua Filters.</li> <li>Templates ...</li> </ul> <p>...</p> <p>Pandoc has for example a \u00a0<code>--shift-heading-level-by</code> option which lets you increase or decrease the level of all headers in a document. </p>"},{"location":"Lab/Crash%20Course/#markdown","title":"Markdown","text":"<p>Markdown is a simple, human readable text markup language. It allows for basic text formatting like headlines, sections, code block, links, bullet list, etc. to be done in a text editor. This makes it not only easy to learn, but also simple to parse and process.</p> <p>Example: <pre><code># A headline\n\nNormal text with an *emphasized* word and\na [link](https://www.steakunderwater.com/).\n</code></pre></p> <p>There are various flavors of Markdown (e.g. CommonMark, or GiHub Flavored Markdown) with different features out in the wild.</p>"},{"location":"Lab/Crash%20Course/#multimarkdown","title":"MultiMarkDown","text":"Not used. <p>Seemed at a first glance to be a good alternative to Pandoc's markdown flavour. But turned out to have no advantages.</p> <p>MultiMarkdown is an extension (aka flavor) of Markdown adding support for features often needed for documentation purposes, such as math formulas, image attributes, definition lists, etc.</p> <p>There is a multimarkdown tool (<code>brew install multimarkdown</code>) that can be used to convert multimarkdown files into some other output formats (but probably pandoc is the better choice in this regard).</p> <p>Scriviner includes MultiMarkdown support.</p> <p>Pandoc allows for MultiMarkdown import and export by specifying the format being <code>markdown_mmd</code>.</p> <p>Further reading: - Pandoc-vs-Multimarkdown - Why I switched from MultiMarkdown to Pandoc</p>"},{"location":"Lab/Crash%20Course/#yaml-front-matter","title":"YAML front matter","text":"<p>YAML is a format for structured data. A YAML front matter is a section at the beginning of a (i.e. MarkDown) file used to provide additional information (meta data) in YAML format.</p> <p>Example: <pre><code>---\naliases:\n- Front Matter Demo\ntags: [example, yaml]\n---\n\nHere comes the normal **MarkDown** document.\n</code></pre></p> <p>Obsidian allows the use of YAML front matter for tags and aliases. Scrivener does also output some minimal front matter like title, author, and such.</p>"},{"location":"Lab/Embed%20Videos/","title":"Embed Videos","text":""},{"location":"Lab/Embed%20Videos/#see-also","title":"See also","text":"<ul> <li>https://pypi.org/project/mkdocs-video/</li> <li>https://patrickberry.medium.com/embed-youtube-video-in-obsidian-efc6f78e35e6</li> <li>https://www.reddit.com/r/ObsidianMD/comments/oumqda/responsive_youtube_embed_video_in_obsidian/</li> <li></li> </ul>"},{"location":"Lab/Embed%20Videos/#thumbnails","title":"Thumbnails","text":""},{"location":"Lab/Embed%20Videos/#could-try-to-replace-this","title":"Could try to replace this","text":"<ul> <li>https://forum.obsidian.md/t/list-of-internally-supported-icons/36377</li> <li>https://help.obsidian.md/How+to/Use+callouts</li> </ul> Costa RicaCosta Rica"},{"location":"Lab/Embed%20Videos/#html-iframe","title":"HTML iFrame","text":"Costa Rica"},{"location":"Lab/Embed%20Videos/#obsidian-wiki-markup","title":"Obsidian Wiki Markup","text":""},{"location":"Lab/Experiments/","title":"Experiments","text":""},{"location":"Lab/Experiments/#scrivener-to-obsidian-obsolete","title":"Scrivener to Obsidian (obsolete!)","text":"<pre><code># setup\ncd Kernfusion\nmkdir -p temp\nsource venv/bin/activate\n\nBRANCH=\"$(whoami)_export\"\ngit switch main\ngit pull\ngit branch $BRANCH\ngit switch $BRANCH\ngit push origin branch\n\n\n# In Scrivener compile some document.\n# Forman should me a paddoc markdown\n# format - but you must make sure that\n# \"layouts assigned for section types\"\n# or whatsoever (did not really get this)\n# preserve headlines and text. Save for\n# example es temp/scrivener_export.md\n\n\n\n# process for obsidian\n./Tools/scrivener_to_obsidian.sh temp/scrivener_example.md\n\n\n# You can now review and edit the output\n# in Obsidian. But make sure to not run\n# scrivener_to_obsidian.sh for the same\n# export again because this will delete\n# all your changes!\n\n\n# process for mkdoks\n./Tools/obsidian_to_mkdocs.sh\n\n# review on http://localhost:8000/\nmkdocs serve\n\n\n\n# If everything looks good remove the\n# trailing slash from the folder that\n# had been created in 'Wiki/'. Now you\n# can push your newly generated articles\n# to the remote:\n\ngit add .\ngit commit -m 'Scrivener export added'\ngit push\n</code></pre>"},{"location":"Lab/Experiments/#own","title":"Own ...","text":"<p>Embed: Reactor is released - GET IT NOW!</p>"},{"location":"Lab/Lab/","title":"Lab","text":"<p>This folder is just meant to experiment with the different inputs, outputs, scripts, formats, etc.</p> <p>Some (first/personal) notes on writing (technical) documentation and converting between different formats using Markdown, Pandoc, MkDocs, etc:</p> <ul> <li>Crash Course ... collecting some information about potentially useful tools and formats</li> <li>Lab/Conversion ... notes on how to use the tools to convert between the different formats just chaos</li> <li>Experiments ...</li> </ul>"},{"location":"Lab/Folder%20Zero/","title":"Folder 0","text":""},{"location":"Lab/Folder%20Zero/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/","title":"Folder 1","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/","title":"Folder 2","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/","title":"Folder 3","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/img/","title":"Folder 3/img","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/img/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/img/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/Folder%20Three/img/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/img/","title":"Folder 2/img","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/img/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/img/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/Folder%20Two/img/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Lab/Folder%20Zero/Folder%20One/img/","title":"Folder 1/img","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/img/#folder","title":"Folder","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/img/#image","title":"Image","text":""},{"location":"Lab/Folder%20Zero/Folder%20One/img/#parent","title":"Parent","text":"<ul> <li><ul> <li></li> <li><ul> <li></li> <li><ul> <li></li> <li></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Plugins/Plugins/","title":"Plugins","text":"<p>A <code>.plugin</code> file is a C++ compiled shared library, similar to a .dll file. Such plugins are a way to create new Fusion 3<sup>rd</sup> party nodes (aka Tools). </p> <p>Plugins are Fusion Tools written using the FusionSDK. Note that Plugins do work only in the payed Versions of BMD's Software, so you need either Fusion Studio, or DaVinci Resolve Studio. An alternative to native Fusion Plugins are OpenFX Plugins and Fuse.</p>"},{"location":"Plugins/Krokodove/Example%20Compositions/","title":"KKD Example Comps","text":"<p>There is a collection of Krokodove example <code>.comp</code> files that can also be installed using Reactor.</p> <p></p> <p>Select the \"Comps \u2192 Krokodove\" category on the left sidebar. Click on the package named \"Krokodove Showcase\" and then press the \"Install\" button.</p> <p></p> <p>To access the installed KKD example comps, navigate to the \"Reactor &gt; Tools &gt; Show Comps Folder\" menu item in Fusion Studio.</p> <p>This will open up a folder browsing window using Explorer (Windows) or Finder (macOS).</p> <p>The folder window displays the contents of the PathMap based location of \"Reactor:/Deploy/Comps/\".</p> <p>Double-click on the folder labeled \"Krokodove\" to open it.</p> <p>Inside this location you will have access to 35 example comps that use a variety of KKD tools. These examples are stored in categorized sub-folders for quick access.</p> <p></p> <p>Here is a screenshot of the \"Reactor:/Deploy/Comps/Krokodove/Pack/Pack_A_001.comp\" project file:</p> <p></p> <p>For more practical examples see the Node Cookbook.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Plugins/Krokodove/Krokodove/","title":"Krokodove Essentials","text":"<p>Krokodove (KKD) is a cross-platform compatible plugin for Fusion Studio and DaVinci Resolve Studio. It includes 100+ free Fusion tools. Krokodove was created by Raf Schoenmaekers of Komkom Doorn.</p> <p>Compatibility</p> <p>Please note that KKD is a compiled Fusion plugin that was created with the FusionSDK. The KKD tools will not work in Fusion Standalone (free) or Resolve (free). A paid copy of either Fusion Studio or DaVinci Resolve Studio is required to run this plugin.</p> <p>The KKD shape tools allow you to create animatable vector artwork which is excellent for node-based motion graphics projects. See the Krokodove Showcase Vimeo Videos to get an idea of what's possible with Krokodove.</p> <p>The KKD data tools support workflows similar to Houdini CHOPS (short for \"Channel Operators\"; see also HoudiniChops in the cgwiki) through the processing of lists, and sets of arrays.</p>"},{"location":"Plugins/Krokodove/Krokodove/#acknowledgment-resources","title":"Acknowledgment &amp; Resources","text":"<ul> <li>Documentation by Andrew Hazelden \\&lt;andrew@andrewhazelden.com&gt;</li> <li>Krokodove plugin by Raf Schoenmaekers info@komkomdoorn.com</li> <li>Krokodove Vimeo channel: https://vimeo.com/channels/krokodove</li> <li>Krokodove email contact: info@komkomdoorn.com</li> <li>License: Krokodove is distributed for free.</li> </ul>"},{"location":"Plugins/Krokodove/Krokodove/#software-required","title":"Software Required","text":"<p>To run Krokodove on your system you will need ... -  Reactor Package Manager (Free), and either - BMD Fusion Studio (Paid), or - BMD Resolve Studio (Paid)</p>"},{"location":"Plugins/Krokodove/Krokodove/#installation","title":"Installation","text":"<p>The Krokodove plugin can be installed using the Reactor Package Manager for Resolve Studio/Fusion Studio.</p> <p></p> <p>After you have Reactor installed and open, select the \"Tools \u2192 Plugins\" category on the left sidebar. Click on the package named \"Krokodove for Fusion/Resolve Studio 17\" and then press the \"Install\" button.</p> <p></p> <p>Once the installation is complete, restart Resolve Studio or Fusion Studio standalone. This will load the KKD plugin.</p>"},{"location":"Plugins/Krokodove/Krokodove/#accessing-the-kkd-nodes","title":"Accessing the KKD Nodes","text":"<p>Once Fusion Studio has finished loading you will have access to a new \"Tools &gt; Krokodove\" set of menu items.</p> <p></p> <p>You can also right-click in the Nodes view area, and select the \"Add Tool &gt; Krokodove\" contextual menu item to access the KKD tools.</p> <p></p> <p>In Resolve Studio you can access KKD nodes using the Effects Library tab at the top left of the user interface. Expand the \"Tools &gt; Krokodove\" hierarchy to view the nodes.</p> <p></p>"},{"location":"Plugins/Krokodove/Krokodove/#where-to-go-from-here","title":"Where to go from here ...","text":"<p>First you may want to look into the Example Compositions available via Reactor. Then you can get an overview by scanning the Node Categories, the Node Reference Guide, and the Modifier Reference Guide. Finally the Node Cookbook is here to help with practical examples (once it has been written \ud83d\ude1c ).</p>"},{"location":"Plugins/Krokodove/Krokodove/#original-table-of-contents","title":"Original Table of Contents","text":"<ul> <li>Krokodove Essentials (integrated into main aticle)</li> <li>Overview (integrated into main aticle)</li> <li>Resources (integrated into main aticle)</li> <li>License (integrated into main aticle)</li> <li>Compatibility (integrated into main aticle)</li> <li>Software Required (integrated into main aticle)</li> <li>Install KKD (integrated into main aticle)</li> <li>Accessing the KKD Nodes (integrated into main aticle)</li> <li>KKD Example Comps</li> <li>KKD Node Categories</li> <li>KKD Node Reference Guide</li> <li>KKD Modifier Reference Guide</li> <li>KKD Node Cookbook</li> </ul>"},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/","title":"KKD Modifier Reference Guide","text":"<p>For context see Krokodove.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#beat","title":"Beat","text":"<p>Pulse your animation in sync with the beat of your music</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#color-switcher","title":"Color Switcher","text":"<p>A modifier that switches color values</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#formula","title":"Formula","text":"<p>Text formula allows numeric values to be used within text fields, or combines several texts (such as timecode, flow name, ...)</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#from-file","title":"From File","text":"<p>Retrieve text from file</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#source","title":"Source","text":"<p>The \"Source\" control allows you to input your data from an external text file, or by entering the content in the \"Text\" input field on the modifier node itself.</p> <p></p> <p>The \"Format\" control options are \"Each line a frame\", \"Startframe and text\", and \"Line on frame\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#line-on-frame","title":"Line on Frame","text":"<p>Setting the \"Format\" control to the \"Line on Frame\" option exposes an additional \"Line\" slider element which can be used to directly select the exact line number from the text file that is displayed.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#each-line-a-frame","title":"Each line a frame","text":"<p>Setting the \"Format\" control to the default \"Each line a frame\" option syncs the line being read from the external text file with the current frame number in the timeline.</p> <p></p> <p>The \"Loop\" checkbox allows you to replay the contents of the external text file, line by line, once the end of the document is reached.</p> <p>The \"Hold frames\" control allows you to delay the start of the text file playback for a user specified amount of frames.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#startframe-and-text","title":"Startframe and text","text":"<p>Setting the \"Format\" control to the \"Startframe and text\" option allows you to customize your timing with very tight precision for pre-defined frame ranges.</p> <p>Each row in the document starts with either a single frame number, or a frame range written with a dash like \"30-60\", followed by a whitespace character, then the text to display. To display an initial message for 120 frames, then to display another message for a subsequent 120 frame duration you would write in:</p> <pre><code>1-120 Hello World!\n121-240 To Be Continued...\n</code></pre>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#juggle","title":"Juggle","text":"<p>Juggle text (characters, words, lines) around</p> <p></p> <p>The \"Juggle Characters\" slider can be adjusted from 0 (no effect) to 1.0 (all characters juggled).</p> <p>If you entered \"Hello World\" into the \"Text\" field of the modifier and set the Juggle Characters control to 1.0 you would get a result of \"llroeHdl Wo\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#random","title":"Random","text":"<p>Random Number</p> <p></p> <p>The Random Modifier is applied to Number input field based values. The randomized number value is animated across the timeline frame range.</p> <p>The \"Minimum value\" control is used to adjust the lowest part of the spline curve generated. The \"Maximum value\" control is used to adjust the highest part of the spline curve generated.</p> <p>If you lift both the minimum and maximum ranges at the same time you can offset the range of values created.</p> <p>It is also possible to split the min/max value range instead of being 0 to 1 to have a min/max value range of -1 to 1, or -0.5 to 0.5 if you need both negative and positive random numbers generated.</p> <p>The \"Seed\" control is used to shift the initial random number starting point. Changing the seed value will result in a different sequence of numbers being generated.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#new-value-for-every-fieldframe","title":"New value for every field/frame","text":"<p>Unchecking the \"[x] New value for every field/frame\" checkbox will display two additional UI elements that provide more control over the frequency of change for the random number generation.</p> <p></p> <p>The additional UI controls are labeled \"New value every ... frames\", along with an \"Interpolation\" control.</p> <p>The \"New value every ... frames\" control lets you define how fast the random number generator output is refreshed. The control unit of measure is in timeline frames.</p> <p>The \"Interpolation\" control options are \"Step\", \"Linear\", and \"Ease-in, Ease-out\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#step-interpolation","title":"Step Interpolation","text":"<p>If you were to set the \"New value every ... frames\" control to 30 (frames), and the \"Interpolation\" control to \"Step\", the resulting number output when displayed in the Splines view would have flat plateau like tangents, positioned at random heights:</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#linear-interpolation","title":"Linear Interpolation","text":"<p>Selecting \"Linear\" interpolation creates a randomized sawtooth like Spline view result:</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#ease-in-ease-out-interpolation","title":"Ease-in, Ease-out interpolation","text":"<p>Selecting \"Ease-in, Ease-out\" interpolation creates a slightly smoothed top and bottom \"cap\" on the peaks of the randomized sawtooth like Spline view result:</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#random-number-use-cases","title":"Random Number Use Cases","text":"<p>The Random number generator is quite versatile. It could help with adding jitter to 2D or 3D transform attributes, or could add an organic feeling of chaos to blurs, glows, exposure, and other filter effects.</p> <p>This could be the missing element needed to make a more lively lightsaber that pulses over time, or it could add a bit of uniqueness to simulated analog onscreen motion graphics composited onto an old CRT monitor that has characteristics like snow, static, glitching effects and lots of glow/flicker.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Modifier%20Reference%20Guide/#write","title":"Write","text":"<p>Easy writing of text</p> <p></p> <p>The Write modifier acts much like an old VT100 text terminal character generator. This effect will typically be applied on a Text+ node. The font size of the text generated by the Write modifier is inherited from the base \"Size\" control on the Text+ node.</p> <p>As you animate the \"Write\" slider control from 0 to 1, the letters entered in the \"Text\" field will be printed on screen, one character at a time.</p> <p>The \"Cursor\" element is placed to the right of the most recently entered letter. The \"Prefix\" element is placed at the start of the line.</p> <p>If you entered the text \"Hello World\" in the Write modifier, enabled the \"[x] Prefix Show\" checkbox, and set the \"Write\" control to 0.45, you would see the output text:</p> <pre><code>//Hello_\n</code></pre> <p>The Write modifier can be applied to any Text based attributes in Fusion. This includes the Fusion 3D workspace based \"Text3D\" node, or the 3<sup>rd</sup> party Vonk \"vText\" class of nodes like \"vTextCreateMultiline\".</p> <p></p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Categories/","title":"KKD Node Categories","text":"<p>The Krokodove nodes (see the Node Reference Guide) are separated into the following categories and sub-categories based upon what data types they work with, and the function they perform:</p> <p>3D</p> <ul> <li>Align 3D</li> <li>Connect 3D</li> <li>Cut 3D</li> <li>Data Duplicate 3D</li> <li>Kill 3D</li> <li>Mapped Duplicate 3D</li> <li>Objectify 3D</li> <li>Poly Play 3D</li> <li>Retime 3D</li> <li>Tool 3D</li> <li>Vertex Play 3D</li> </ul> <p>3D Create</p> <ul> <li>Data Create 3D</li> <li>Fold Create 3D</li> <li>Heightfield Create 3D</li> <li>Object Create 3D</li> <li>Tube Create 3D</li> <li>World Position Create 3D</li> </ul> <p>3D Region</p> <ul> <li>rCube</li> <li>rImage</li> <li>rMerge</li> <li>rModify</li> <li>rNoise</li> <li>rPlane</li> <li>rShape</li> <li>rSphere</li> <li>rTransform</li> </ul> <p>Data</p> <ul> <li>dCopy</li> <li>dDelete</li> <li>dGrow</li> <li>dInfo</li> <li>dMath</li> <li>dMerge</li> <li>dRemap</li> <li>dSelect</li> <li>dSet Constant</li> <li>dSet Manual</li> <li>dSet Ramp</li> <li>dSet Random</li> <li>dSort</li> <li>dTool</li> <li>dTransform</li> </ul> <p>Data Create</p> <ul> <li>dChannels Create</li> <li>dFrom Image Analyzer Create</li> <li>dFrom Image Create</li> <li>dFrom Image Pack Create</li> <li>dFrom Region Create</li> <li>dLoader Create</li> <li>dPattern Create</li> </ul> <p>Image</p> <ul> <li>Analyzer</li> <li>Blur in Space</li> <li>Bounding Box</li> <li>Connect</li> <li>Dither</li> <li>Extend</li> <li>Find</li> <li>Flur</li> <li>Fragments</li> <li>Grow</li> <li>Grow Color</li> <li>Microwaves</li> <li>Pack</li> <li>Painterly</li> <li>Rasterize</li> <li>Smart Field Strobe</li> <li>Spiral</li> <li>Switcher</li> <li>Time Mapper</li> <li>Wireless Link</li> <li>Wireless Linky</li> <li>Worm</li> </ul> <p>Image Color</p> <ul> <li>Color</li> <li>Hue/Saturation</li> <li>Invert</li> <li>Match Color</li> <li>Replace Color</li> <li>Threshold</li> <li>Image Create</li> </ul> <p>Image Create</p> <ul> <li>Blob</li> <li>Lines</li> <li>Pattern</li> <li>Shapes</li> </ul> <p>Image Pixel</p> <ul> <li>Average</li> <li>Beams</li> <li>Bevel</li> <li>Border</li> <li>Canvas</li> <li>Channel Shifter</li> <li>Clean Edges</li> <li>Combine</li> <li>Crop Monsieur</li> <li>Cut and Bleed</li> <li>Deflicker</li> <li>Duplicate</li> <li>Eat</li> <li>Extrude</li> <li>Map Filter</li> <li>Matte Cleaner</li> <li>Merge and Bone</li> <li>Noise</li> <li>Pixel Region</li> <li>Planes</li> <li>Plastic</li> <li>Positioner</li> <li>Push</li> <li>Reassemble</li> <li>Rest</li> <li>Seamless Loop</li> <li>Smear</li> <li>Sort</li> </ul> <p>Image Position</p> <ul> <li>Contour</li> <li>Gradient</li> <li>Shade by Sample</li> </ul> <p>Image Vector</p> <ul> <li>Vector Blur</li> <li>Vector Field</li> <li>Vector Motion</li> <li>Vector Time</li> <li>Vector Visualization</li> </ul> <p>Image Warp</p> <ul> <li>Blend</li> <li>Directional Scale</li> <li>Kaleidoscope</li> <li>Lens Distortion</li> <li>Mirror</li> <li>Morph</li> <li>Offset</li> <li>Radial</li> <li>Relative Transform</li> <li>Ramp</li> <li>Segment Transform</li> <li>Shear</li> <li>Shuffle</li> <li>Spherize</li> <li>Stretch</li> <li>Transform</li> </ul> <p>Shape</p> <ul> <li>sBoolean</li> <li>sKill</li> <li>sMerge</li> <li>sOffset</li> <li>sRender</li> <li>sResample</li> <li>sShading</li> <li>sSmooth</li> <li>sTools</li> <li>sTransform</li> <li>sTriangulate</li> <li>sWriteOn</li> <li>sZigZag</li> </ul> <p>Shape Create</p> <ul> <li>sChart Create</li> <li>sPrimitive Create</li> <li>sSpiral Create</li> <li>sTrace Create</li> </ul> <p>Modifiers</p> <ul> <li>Color Switcher</li> <li>Beat</li> <li>Formula</li> <li>From File</li> <li>Juggle</li> <li>Random</li> <li>Write</li> </ul>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Cookbook/","title":"KKD Node Cookbook","text":"<p>A collection of Fusion node-graph recipes for common KKD techniques.</p> <p>For context see Krokodove (KKD). See also the Example Compositions. Useful references here are KKD Node Reference Guide, the Node Categories, and the Modifier Reference Guide.</p> <p>Content TBD.</p>","tags":["Kartaverse",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/","title":"KKD Node Reference Guide","text":"<p>For context see Krokodove. See also the Node Categories and the Node Cookbook.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#align-3d","title":"Align 3D","text":"<p>Align an object relative to</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#connect-3d","title":"Connect 3D","text":"<p>Connect vertices...</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#cut-3d","title":"Cut 3D","text":"<p>Cuts off an object</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#data-duplicate-3d","title":"Data Duplicate 3D","text":"<p>Create duplicates, fully controlled by data channels.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#kill-3d","title":"Kill 3D","text":"<p>Kills (part of) an object</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#mapped-duplicate-3d","title":"Mapped Duplicate 3D","text":"<p>Create duplicates, fully controlled by image maps.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#objectify-3d","title":"Objectify 3D","text":"<p>Manipulates objects as a whole</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#poly-play-3d","title":"Poly Play 3D","text":"<p>Manipulate objects on a poly level.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#retime-3d","title":"Retime 3D","text":"<p>A 3D retiming tool</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#tool-3d","title":"Tool 3D","text":"<p>Tools to manipulate an object</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vertex-play-3d","title":"Vertex Play 3D","text":"<p>Manipulate objects on a vertex level.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#data-create-3d","title":"Data Create 3D","text":"<p>Creates a height field from a map</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#fold-create-3d","title":"Fold Create 3D","text":"<p>Creates a foldable object</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#heightfield-create-3d","title":"Heightfield Create 3D","text":"<p>Creates a height field from a map</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#object-create-3d","title":"Object Create 3D","text":"<p>Creates an object</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#shape-create-3d","title":"Shape Create 3D","text":"<p>Creates a 3D object from a shape</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#tube-create-3d","title":"Tube Create 3D","text":"<p>Creates some tubes</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#world-position-create-3d","title":"World Position Create 3D","text":"<p>Creates a plane with based on world space coordinates</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rcube","title":"rCube","text":"<p>Region 3D Cube</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rimage","title":"rImage","text":"<p>Region 3D Image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rmerge","title":"rMerge","text":"<p>Region 3D Merge</p> <p></p> <p>The \"Combine\" control can be set to \"Union\", \"Intersect\", \"Add\", \"Subtract\", or \"Exclusive\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rmodify","title":"rModify","text":"<p>Region 3D Modify</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rnoise","title":"rNoise","text":"<p>Region 3D Noise</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rplane","title":"rPlane","text":"<p>Region 3D Plane</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rshape","title":"rShape","text":"<p>Region 3D Shape</p> <p></p> <p>The Mapping control can be set to \"Planar\", \"Spherical\", or \"Cylindrical\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rsphere","title":"rSphere","text":"<p>Region 3D Sphere</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rtransform","title":"rTransform","text":"<p>Region 3D Transform</p> <p></p> <p>The \"Region Transform\" control page has a single checkbox labelled \"Invert\".</p> <p>The \"Transform\" control page can be used to adjust the XYZ Position, Rotation, and Scale attributes.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dcopy","title":"dCopy","text":"<p>Copy data channels</p> <p></p> <p>The \"Type In\" and \"Type Out\" controls can be set to \"Any\", \"Bool\", \"Integer\", \"Float\", \"Vector2\", \"Vector3\", or \"Color\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#ddelete","title":"dDelete","text":"<p>Data Delete</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dgrow","title":"dGrow","text":"<p>Data Grow</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dinfo","title":"dInfo","text":"<p>Data Info</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dmath","title":"dMath","text":"<p>Data Math</p> <p></p> <p>The Operation control can be set to \"None\", \"Add\", \"Subtr\", \"Mult\", \"Div\", \"Power\", or \"Mod\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dmerge","title":"dMerge","text":"<p>Data Merge</p> <p></p> <p>The data merge node has 8 initial input connections named \"Data [1-8] (in)\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dremap","title":"dRemap","text":"<p>Data Remap</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dselect","title":"dSelect","text":"<p>Data Select</p> <p></p> <p>The Operation control can be set to \"None\", \"Add\", \"Subtr\", \"Mult\", \"Div\", \"Power\", or \"Mod\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dset-constant","title":"dSet Constant","text":"<p>Set Constant Data</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dset-manual","title":"dSet Manual","text":"<p>Set Data Manually, one by one</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dset-ramp","title":"dSet Ramp","text":"<p>Set data to follow a ramp or gradient between 2 values</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dset-random","title":"dSet Random","text":"<p>Set/add random data</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dsort","title":"dSort","text":"<p>Data Sorting</p> <p></p> <p>The \"Vector Sort1\" control can be set to \"By X\", \"By Y\", \"By Z\", or \"Distance\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dtool","title":"dTool","text":"<p>Data Tools</p> <p></p> <p>By default the \"Limit Count Start\" and \"Limit Count End\" controls have an initial control range of 0-100.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dtransform","title":"dTransform","text":"<p>Data Transform</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dchannels-create","title":"dChannels Create","text":"<p>Create data channels</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dfrom-image-analyzer-create","title":"dFrom Image Analyzer Create","text":"<p>Sample image and format data</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dfrom-image-create","title":"dFrom Image Create","text":"<p>Sample Image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dfrom-image-pack-create","title":"dFrom Image Pack Create","text":"<p>Sample image using packing method</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dfrom-region-create","title":"dFrom Region Create","text":"<p>Sample Region</p> <p></p> <p>The \"Replace Type\" control can be set to \"Replace in Range\" or \"Replace All\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dloader-create","title":"dLoader Create","text":"<p>Load data</p> <p></p> <p>The \"Channels Direction\" control can be set to \"By Row\" or \"By Column\". The \"First Row\" control can be set to \"Automatic\", \"Channel Names\", or \"Channel Data\". The \"First Column\" control can be set to \"Automatic\", \"Channel Names\", or \"Channel Data\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dpattern-create","title":"dPattern Create","text":"<p>Create a pattern</p> <p></p> <p>The \"Pattern Type\" control can be set to \"Grid\" or \"Ring\". The \"Ring Count Type\" control can be set to \"By Number\", \"By Distance\", or \"By Angle\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#analyzer","title":"Analyzer","text":"<p>Image analysis</p> <p></p> <p>The \"Scale\" control on the Guides control page can be set to \"0.0 ... 1.0\", \"0 ... 255\", \"0 ... 1023\", or \"0 ... 65535\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#blur-in-space","title":"Blur in Space","text":"<p>A mere re-packaging of two basic Fusion tools: color space swapping and blur</p> <p></p> <p>The \"Blur Filter\" control can be set to \"Box\", \"Soften\", \"Bartlett\", \"Gaussian\", or \"Sharpen\"</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#bounding-box","title":"Bounding Box","text":"<p>Bounding Box</p> <p></p> <p>The \"Channel\" control can be set to \"Red\", \"Green\", \"Blue\", \"Alpha\", or \"Lumin.\". The \"Threshold\" control has a default input control range of 0 - 1. The \"Lock\" control can be set to \"All Sides\", \"Vert./Horiz.\", or \"None\". The \"Extend\" control has a default input control range of -0.05 to 0.1. The initial value is 0.0.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#connect","title":"Connect","text":"<p>Connect points with lines or splines</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#dither","title":"Dither","text":"<p>Reduces the number of bits for each color channel and creates a 'logical noise' doing it</p> <p></p> <p>The \"Dither method\" control can be set to \"None\", \"Ordered\", \"Simple error distribution\", or \"Floyd &amp; Steinberg\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#extend","title":"Extend","text":"<p>The \"Direction\" control can be set to \"Horizontal\" or \"Vertical\". The \"Channel\" control can be set to \"Red\", \"Green\", \"Blue\", \"Alpha\", \"Lumin.\", or \"Each\".</p> <p></p> <p>The \"Hold\" control can be set to \"Within range\", \"Minimum\", or \"Maximum\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#find","title":"Find","text":"<p>The \"Channel\" control can be set to \"Red\", \"Green\", \"Blue\", \"Alpha\", or \"Lumin.\". The \"Result\" control can be set to \"Analytic\" or \"Clean\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#flur","title":"Flur","text":"<p>The \"Shape\" control can be set to \"Square\", \"Round\", or \"Axial\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#fragments","title":"Fragments","text":"<p>The \"Channel\" control can be set to \"Red\", \"Green\", \"Blue\", \"Alpha\", or \"Lumin.\".</p> <p></p> <p>The \"Range Curve\" control can be set to \"Linear\", \"Ease In\", \"Ease Out\", or \"Ease In/Out\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#grow","title":"Grow","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#grow-color","title":"Grow Color","text":"<p>Fill transparent parts by extending the edge color</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#microwaves","title":"Microwaves","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#pack","title":"Pack","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#painterly","title":"Painterly","text":"<p>Painterly effects</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rasterize","title":"Rasterize","text":"<p>Half-tone style rasterize</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#smart-field-strobe","title":"Smart Field Strobe","text":"<p>Smart Field Strobe tries to detect motion and only removes fields where there is.</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#spiral","title":"Spiral","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#switcher","title":"Switcher","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#time-mapper","title":"Time Mapper","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#wireless-link","title":"Wireless Link","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#wireless-linky","title":"Wireless Linky","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#worm","title":"Worm","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#color","title":"Color","text":"<p>Simple tool for easy fading to a certain color</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#huesaturation","title":"Hue/Saturation","text":"<p>A simple color correcting tool, operating in HLS color space</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#invert","title":"Invert","text":"<p>Invert color, luminance or hue</p> <p></p> <p>The \"Type\" control can be set to \"Color\", \"Luminance\", or \"Hue\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#match-color","title":"Match Color","text":"<p>Color matching</p> <p></p> <p>The \"Number of colors\" control can be set to \"Single\", \"Low and High\", or \"Low, Mid &amp;&amp; High\".</p> <p></p> <p>The \"Shadows match\" control can be set to \"Full color\", \"Color tint\", or \"Luminance\".</p> <p></p> <p>The \"Highlights match\" control can be set to \"Full color\", \"Color tint\", or \"Luminance\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#replace-color","title":"Replace Color","text":"<p>This color correcting tool replaces a certain color range with another</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#threshold","title":"Threshold","text":"<p>Clips the color in reference to the threshold</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#blobs","title":"Blobs","text":"<p>Create metaball like blob shapes</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#lines","title":"Lines","text":"<p>Line patterns</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#pattern","title":"Pattern","text":"<p>Creation of a wild collection of patterns (assuming you think grids are wild)</p> <p>The \"Type\" control can be set to \"Triangles\", \"Grid\", or \"Honeycomb\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#shapes","title":"Shapes","text":"<p>Shape patterns; circles, squares, ...</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#average","title":"Average","text":"<p>The \"Main Time\" control can be set to \"Flow Time\", or \"Time Speed\", or \"Time Stretch\". The \"Non-existing frames\" control can be set to \"Black\" or \"Ignore\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#beams","title":"Beams","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#bevel","title":"Bevel","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#border","title":"Border","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#canvas","title":"Canvas","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#channel-shifter","title":"Channel Shifter","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#clean-edges","title":"Clean Edges","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#combine","title":"Combine","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#crop-monsieur","title":"Crop Monsieur","text":"<p>Makes multiple copies of an image </p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#cut-and-bleed","title":"Cut and Bleed","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#deflicker","title":"Deflicker","text":"<p>The \"Reference\" control can be set to \"Fixed Time\", \"Time Steps\", \"Average\", or \"External\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#duplicate","title":"Duplicate","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#eat","title":"Eat","text":"<p>Eats out the edges of an image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#extrude","title":"Extrude","text":"<p>The \"Perspective type\" control can be set to \"Parallel\" or \"Radial\". The \"Color type\" control can be set to \"Solid\" or \"Original\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#map-filter","title":"Map Filter","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#matte-cleaner","title":"Matte Cleaner","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#merge-and-bone","title":"Merge and Bone","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#noise","title":"Noise","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#pixel-region","title":"Pixel Region","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#planes","title":"Planes","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#plastic","title":"Plastic","text":"<p>Put a plastic film over your image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#positioner","title":"Positioner","text":"<p>The \"Type of positioner\" control can be set to \"One point\", \"Two point\", \"Three point\", or \"Four point\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#push","title":"Push","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#reassemble","title":"Reassemble","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#rest","title":"Rest","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#seamless-loop","title":"Seamless Loop","text":"<p>Create seamlessly looping sequences easily</p> <p></p> <p>The \"Fade type\" control can be set to either \"Linear\" or \"Smooth\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#smear","title":"Smear","text":"<p>Smears the image horizontally or vertically</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sort","title":"Sort","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#contour","title":"Contour","text":"<p>Draws a nice, anti-aliased contour around an image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#gradient","title":"Gradient","text":"<p>Creation of gradients: linear, radial and spotlight shapes can be created an combined with the background image</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#shade-by-sample","title":"Shade by Sample","text":"<p>Shade an image based on the normals</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vector-blur","title":"Vector Blur","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vector-field","title":"Vector Field","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vector-motion","title":"Vector Motion","text":"<p>The \"Motion analysis direction\" control can be set to \"Backward\", \"Both\", or \"Forward\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vector-time","title":"Vector Time","text":"<p>The \"Adjust\" control can be set to \"Not\", \"Time Speed\", \"Time Stretch\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#vector-visualization","title":"Vector Visualization","text":"<p>The \"Vizualize vector field\" control can be set to \"Grid\" or \"Edges\". The \"Line Color\" control can be set to \"Solid\" or \"Image\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#blend","title":"Blend","text":"<p>Todo</p> <p>Blend missing; or is Blend a Directional Scale; or should Blend be Directional Scale .. ?!?</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#directional-scale","title":"Directional Scale","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#kaleidoscope","title":"Kaleidoscope","text":"<p>The \"Type\" control can be set to \"Classic\" or \"Fancy\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#lens-distortion","title":"Lens Distortion","text":"<p>The \"Type\" control can be set to \"Distort\" or \"Restore\".</p> <p>If you have \"K1\" and \"K2\" lens distortion parameters provided by an external lens calibration tool, those values are entered in the \"Kappa1\" and \"Kappa2\" number-fields.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#mirror","title":"Mirror","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#morph","title":"Morph","text":"<p>The \"Warp Type\" control can be set to \"Field\" or \"Radial\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#offset","title":"Offset","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#radial","title":"Radial","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#relative-transform","title":"Relative Transform","text":"<p>The \"Center Type\" control can be set to \"Bounding Box\" or \"Weighted Pixels\". The \"Size Type\" control can be set to \"Size X and Size Y\" or \"Size and Aspect\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#remap","title":"Remap","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#segment-transform","title":"Segment Transform","text":"","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#shear","title":"Shear","text":"<p>The \"Input Type\" control can be set to \"By value\" or \"By angle\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#shuffle","title":"Shuffle","text":"<p>The \"Type\" control can be set to \"Slide\" or \"Swap\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#spherize","title":"Spherize","text":"<p>The \"Type\" control can be set to \"Horizontal\", \"Vertical\", \"Sphere\", or \"Rectangle\".</p> <p></p> <p>The \"Algorithm\" control can be set to \"Spherize\", \"Soft in/out\", \"Smooth\", or \"Sinusoid\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#stretch","title":"Stretch","text":"<p>The \"Type\" control can be set to \"Source and Destination\", or \"Source and Offset\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#transform","title":"Transform","text":"<p>The \"Size Type\" control can be set to \"Size X and Size Y\" or \"Size and Aspect\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sboolean","title":"sBoolean","text":"<p>Combines shapes by union, difference or intersection</p> <p></p> <p>The \"Type\" control can be set to \"Intersect\", \"Union\", \"Difference\", or \"Xor\". The \"Fill Type\" can be set to \"Even Odd\" or \"Non Zero\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#skill","title":"sKill","text":"<p>Shape Kill</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#smerge","title":"sMerge","text":"<p>Shape Merge</p> <p></p> <p>The sMerge node has two input connections named \"Shape1\" and \"Shape2\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#soffset","title":"sOffset","text":"<p>Shape Offset</p> <p></p> <p>The \"Join Type\" control can be set to \"Miter\", \"Bevel\", or \"Rounded\". The \"Sides\" control can be set to \"Both\", \"Inside\", or \"Outside\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#srender","title":"sRender","text":"<p>Render out the shape to an image</p> <p></p> <p>The \"Winding\" can be set to \"Even/Odd\" or \"Non-Zero\". The \"Image\" control page can be used to define the dimensions of the rendered image.</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sresample","title":"sResample","text":"<p>Shape Resample</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sshading","title":"sShading","text":"<p>Apply Shading to shape</p> <p></p> <p>The \"Pen Line Type\" control can be set to \"Solid\", \"Dashed\", \"Dotted\", or \"Custom\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#ssmooth","title":"sSmooth","text":"<p>Shape Smooth</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#stools","title":"sTools","text":"<p>Shape Tools</p> <p></p> <p>The \"Open Close\" control can be set to \"Keep\", \"Close All\", \"Open All\", or \"Swap\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#stransform","title":"sTransform","text":"<p>Shape Transform</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#striangulate","title":"sTriangulate","text":"<p>Shape Triangulate</p> <p></p> <p>The \"Type\" control can be set to \"Type 1\" or \"Type 2\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#swriteon","title":"sWriteOn","text":"<p>Shape WriteOn</p> <p></p> <p>The \"Level\" control can be set to \"Global\", \"Shape\", or \"Element\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#szigzag","title":"sZigZag","text":"<p>Shape ZigZag</p> <p></p> <p>The \"Type\" control can be set to \"By Segment\", or \"By distance\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#schart-create","title":"sChart Create","text":"<p>Shape Chart Create</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sprimitive-create","title":"sPrimitive Create","text":"<p>Shape Primitive Create</p> <p></p> <p>The \"Shape Primitive Create\" control page has a \"Type\" control that can be set to \"Cross\", \"Polygon\", \"Rectangle\", or \"Star\".</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#sspiral-create","title":"sSpiral Create","text":"<p>Shape Spiral Create</p> <p></p> <p>The \"Shape Spiral Create\" control page has an \"Angle End Type\" control that can be set to \"None\", \"Type 1\", or \"Type 2\".</p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Plugins/Krokodove/Node%20Reference%20Guide/#strace-create","title":"sTrace Create","text":"<p>Shape Trace Create</p> <p></p>","tags":["Kartaverse","Reference",".scrivener-export"]},{"location":"Reactor/Atom/","title":"Atom","text":"<p>The Reactor package format</p> <p>If you are interested in Writing and publishing packages for Reactor, than you need to know its Atom package format decribed here.</p> <p>Source: Atom Packages Documentation WSL post on how to write a package description.</p>"},{"location":"Reactor/Atom/#creating-atom-packages","title":"Creating Atom Packages","text":"<p>An atom package is used to define a new installable item that is accessible in the Reactor package manager.\u00a0  </p> <p>This is a visual image of what a new atom package folder could look like: </p> <p>A Reactor atom package is arranged with a basic file hierarchy like this:</p> <ul> <li>\ud83d\udcc2 com.YourCompanyName.YourPackageName (folder)</li> <li>\ud83d\udcc4 com.YourCompanyName.YourPackageName.atom (file)</li> <li>\ud83d\udcc2 Macros  (folder)<ul> <li>\ud83d\udcc1 YourCompanyName (folder)</li> <li>\ud83d\udcc4 your-custom.bmp (file)</li> <li>\ud83d\udcc4 your-custom.setting (file)</li> </ul> </li> <li>\ud83d\udcc2 Fuses (folder)<ul> <li>\ud83d\udcc4 your-custom.fuse (file)</li> </ul> </li> <li>\ud83d\udcc2 Scripts (folder)<ul> <li>\ud83d\udcc2 Comp (folder)</li> <li>\ud83d\udcc1 YourCompanyName (folder)</li> <li>\ud83d\udcc4 your-script.lua (file)</li> </ul> </li> </ul> <p>What's the correct folder structure?!?</p> <p>The folder structure given in the code block of the original post does not correspond to the structure shown in the image?!?</p> <p>The\u00a0<code>com.YourCompanyName.YourPackageName.atom</code>\u00a0file contents would look like this:</p> <pre><code>Atom {\n    Name = \"YourPackageName\",\n    Category = \"Tools\",\n    Author = \"YourCompanyName\",\n    Version = 1.0,\n    Date = {2017-11-18},\n\n    Description = [[A minimal Reactor example atom package.]],\n\n    Deploy = {\n        \"Macros/YourCompanyName/your-custom.setting\",\n        \"Fuses/your-custom.fuse\",\n        \"Scripts/Comp/YourCompanyName/your-script.lua\",\n    },\n\n    Dependencies = {\n        \"com.wesuckless.Switch\",\n    },\n}\n</code></pre> <p>You only need to add the intermediate folders required for the content your atom is installing. This means if you are creating an Atom package for delivering a Macro, you only need to add a \"Macros/\" folder and \"Deploy\" entry for the .setting file and its thumbnail bin icon.</p>"},{"location":"Reactor/Atom/#adding-a-description-to-an-atom-package","title":"Adding a Description to an Atom Package","text":"<p>...</p> <p>Continue the copypasta</p> <p>Did this just to try out what sucn an WSL post would look like. But first it must be asked if and for which of these posts a permission to copy them can be given.</p>"},{"location":"Reactor/Development/","title":"Development","text":"<p>Information for Developers</p> <p>The Reactor article (and in the future maybe others) is addressing the normal Reactor user. This section is meant to provide some background information for people who want to tweak the installation or want to get into Reactor development.</p>"},{"location":"Reactor/Development/#installation-folder","title":"Installation folder","text":"<p>You can set a diferent path during installation. You can change the installed Reactor location later on by modifying the Fusion \"PathMap\" preferences and pointing the \"Reactor:\" PathMap at a new folder path.</p> <p>The standard / default installation folders are:</p> <p>On Apple macOS: - DaVinci Resolve <code>/Library/Application Support/Blackmagic Design/DaVinci Resolve/Fusion/Reactor/</code> - Fusion <code>/Library/Application Support/Blackmagic Design/Fusion/Reactor/</code></p> <p>On Microsoft Windows: - DaVinci Resolve <code>C:\\ProgramData\\Blackmagic Design\\DaVinci Resolve\\Fusion\\Reactor\\</code> - Fusion <code>C:\\ProgramData\\Blackmagic Design\\Fusion\\Reactor\\</code></p> <p>On Linux: - DaVinci Resolve <code>/var/BlackmagicDesign/DaVinci Resolve/Fusion/Reactor/Deploy/</code> - Fusion <code>/var/BlackmagicDesign/Fusion/Reactor/</code></p>"},{"location":"Reactor/Development/#repository","title":"Repository","text":"<p>https://gitlab.com/WeSuckLess/Reactor</p>"},{"location":"Reactor/Development/#atom","title":"Atom","text":"<p>See Atom</p>"},{"location":"Reactor/Reactor/","title":"Reactor","text":"<p>A package manager for Resolve/Fusion</p> <p>Reactor is a community driven package manager that hosts the largest collection of curated content for extending the capabilities of Resolve/Fusion.</p> <p>If you already use Blackmagic Design's Resolve, Resolve Studio, or Fusion Studio software then the singular most important tool you can choose to install is likely the free Reactor Package Manager.</p> <p>The Fusion community developed the Reactor software as a group effort to create a single-stop resource that hosts the largest collection of curated content for extending the capabilities of Resolve/Fusion. Reactor also includes a lot of content that was previously available only on the VFXPedia resource.</p>"},{"location":"Reactor/Reactor/#install-reactor-package-manager","title":"Install Reactor Package Manager","text":"<p>Summary</p> <p>See the Reactor Release Announcement WSL post for the most recent instructions on on how to download and install Reactor.</p> <p>Download the Reactor-Installer.lua file and drag'n'drop it into your Fusion's [[Nodes panel]].</p> <p>YouTube | Reactor is released - GET IT NOW!</p> <p>YouTube | Fusion Reactor now available for BMD Davinci Resolve</p> <p>So far the Reactor Package Manager has been installed over 190,000 times since 2018!</p>"},{"location":"Reactor/Reactor/#download-and-run-the-installer","title":"Download and run the Installer","text":"<p>To start using Reactor, first you need to download the Reactor-Installer.lua script to your computer.\u00a0</p> <p>Start up a new Resolve (Free), Resolve Studio, or Fusion Studio session. Open the Console window. Then simply drag the installer script from your desktop into the Fusion Console tab to run it.\u00a0</p> <p>Shortcut \"Shift + 0\" to open the Console</p> <p>If you are in the Fusion page or using Fusion Studio you can press the \"Shift + 0\" shortcut to display the Console window.</p> <p>If for some reason the drag-and-drop approach to launching the Reactor installer fails to work\u2026 Alternatively, you can also copy/paste the text contents of the script into the Console text entry area.\u00a0</p> <p></p> <p>In the DaVinci Resolve Fusion page and in Fusion Studio you can also drag the script from your desktop into the Nodes view to run it.</p> <p>When the Reactor Installer starts you are presented with the following dialog. If you want to go with the default settings you simply have to press the \"Install and Launch\" button.</p> <p></p> <p>Custom Install Path</p> <p>When installing Reactor you also have the option to choose a \"Custom Install Path\". This button allows you to select a custom location you would like to have the Reactor content installed to. This could be a location like your user account's home folder, or another hard drive on your system, or a mapped network drive mount point for shared usage of Reactor content.\u00a0</p> <p>You can change the installed Reactor location later on by modifying the Fusion \"PathMap\" preferences and pointing the \"Reactor:\" PathMap at a new folder path.</p>"},{"location":"Reactor/Reactor/#reactor-installation-status","title":"Reactor Installation Status","text":"<p>Reactor shows a progress bar while the installation process is underway.</p> <p></p> <p>When the Reactor installation is complete an Explorer (Win), Finder (macOS), or Nautilus (Linux) folder browsing window is displayed. This shows you the location on-disk where new Reactor content is downloaded to. This folder in Fusion terms is called the \"Reactor:\" PathMap location.</p>"},{"location":"Reactor/Reactor/#open-reactor-package-manager","title":"Open Reactor Package Manager","text":"<p>In Fusion Studio you can do this by opening the root-level \"Reactor\" menu, then select the \"Open Reactor\" menu item. </p> <p>In Resolve Studio you can do this by opening the root-level \"Workspaces\" menu, then navigating to the \"Scripts &gt; Comp &gt; Reactor &gt; Open Reactor\u2026\" menu item.</p> <p></p> <p>When the Reactor Package Manager window loads initially you will see a list of all the atom packages that are able to be installed using this user interface.\u00a0</p> <p>Note: The content that is listed in the Reactor window comes from the Reactor GitLab repository. If you have an outgoing firewall, or your country/company/ISP (internet service provider) has network filtering rules that block access to GitLab you will have to use another approach to install the Reactor content on your system.</p>"},{"location":"Reactor/Reactor/#where-to-go-from-here","title":"Where to go from here?","text":"<p>There are currently (as of 2022-11-08) a total of 356 atom packages in the Reactor Package Manager. This means there is likely something interesting for just about any type of Resolve/Fusion user's tastes. You may start having a first look at some Reactor/Essential Reactor Atom Packages/Essential Reactor Atom Packages</p>"},{"location":"Reactor/Writing%20and%20publishing%20packages/","title":"Writing and publishing packages","text":"<p>See Atom for details on the package format itself.</p> <p>And then maybe do an example Fuse/Comp/Whatsoever here to explain the possibilities and the whole process.</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/","title":"AudioWaveform","text":"<p>This Fuse visualizes a 16bit PCM WAV file. The WAV file must not exceed 50 MB. The data can be zoomed and moved.</p> <p>The play point is set in the middle of the picture. Based on the fuse modifier SuckLessAudioModifier by Pieter Van Houte.</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#parameters","title":"Parameters","text":""},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#waveformparameter","title":"Waveformparameter","text":"<p>There are three parameters for setting the waveform's timing: 1) Proxy 2) Zoom 3) Resolution</p> <ol> <li>Proxy: This multiplies the sample pool without increasing the number of pixels shown</li> <li>Zoom: This also multiplies the sample pool, but all values \u00e2\u20ac\u2039\u00e2\u20ac\u2039are also displayed (as far as can be displayed)</li> <li>Resolution: Acts as a divisor for the displayable pixels -&gt; Resolution = 2 with HD -&gt; 1920/2</li> </ol> <p>You can choose left, right and stereo channel. The stereo signal (Both) is generated by maximum formation of the two channels.</p> <p>After loading the data from file, arrays will be filled with nummerical data. The size of the audio file is limited to 50 MB in order not to make the arrays too large.</p> <p>The audio data can be moved forward or backward by up to 50 frames. A crosshair can be shown and two different envelopes can be selected.</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#amplitude-spectrum","title":"Amplitude Spectrum:","text":"<p>An amplitude spectrum of the loaded WAV file can be displayed instead of the waveform (control page spectrum) Attention: The correct settings for the waveform should then be set to 1 for proxy, zoom and resolution. Only then will the FFT display the mathematically correct spectrum. However, interesting effects can also be achieved with this parameters.\u00a0</p> <p>The FFT window is configurable. There are 4 different types of display: raw, bars, smooth and needles. The support points can be set equidistant. Then sections can be combined, which are also shown in the 4 forms. The color of the spectrum can be set via the color control page.</p> <p>If you have selected the display of the spectrum, the \"Elongation\" functionality can be activated. A window above the spectrum can be selected here with offset and width. The selected data are calculated with the \"Operator\" parameter to be set and visualized as a bar. This value \"Elongation\" can be used by other nodes by \"Connect to\".</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#steady-waveform","title":"Steady Waveform:","text":"<p>With the \"Steady Waveform\" functionality, you can determine how much audio data a so-called seed frame is formed from by selecting the number of frames. The seed frames are output directly, the \"missing\" are calculated.</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#filter","title":"Filter:","text":"<p>The Samplingdata can be filtered by three frequency bands: Lowpass 0-300 Hz, Bandpass 300 Hz - 3kHz and Highpass 3kHz-20kHz.</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#elongation-with-schmitt-trigger","title":"Elongation with Schmitt-Trigger:","text":"<p>Elongation can be mapped to On/Off-Values with Hystersis.</p> <p>Elongation for Spectrum has now three Elongations. Each can set to separate Frequencyband with Bandwidth, Offset and Amplify</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/AudioWaveform/#see-also","title":"See also ...","text":"<p>If you like this fuse, I would be happy to receive a message (JiiPii\u00a0). If you can use it very well, it would be great if you supported WSL (WeSuckLess).</p> <p>See also my post in WSL \"/Fusion Studio/Scripting, Fuses and Macros:\u00a0 [Fuse] AudioWaveform</p> <p>And a short Youtube Tutorial:</p>"},{"location":"Reactor/Essential%20Reactor%20Atom%20Packages/Essential%20Reactor%20Atom%20Packages/","title":"Essential Reactor Atom Packages","text":"<p>If you are regularly creating visual effects in Fusion Studio then the following Reactor Atom packages are likely something you would deem essential to maintain your productivity and sanity:</p> <ul> <li>Attribute Spreadsheet (Batch node editing)</li> <li>Append (Modify clip timings in a node-based fashion)</li> <li>AudioWaveform (Visualize .wav audio files)</li> <li>Batch Change Parameters (Batch node editing)</li> <li>ClassBrowser (Undocumented Scripting API browser)</li> <li>Cryptomatte</li> <li>DeleteFileRequesterHistory (Speed up file dialog load time by pruning the recent files list)</li> <li>Eyeon Legacy (Archive Composition Script)</li> <li>Glitch Tools (Create intentional defects / video artifacts in your footage)</li> <li>hos_SplitEXR_Ultra (Helps split apart multi-channel EXR footage)</li> <li>KAK (A powerful node-based keyer)</li> <li>Krokodove (The ultimate Fusion motion-graphics toolset)</li> <li>MultiMerge (Merge imagery with a multi-input like layer stack)</li> <li>ml_LFTools (Lens Flares)</li> <li>nuke2fusion (Helps Nuke Users migrate to Fusion with modified hotkey bindings and node names)</li> <li>ReadEXR Ultra (Multi-Part EXR reader with filename token support)</li> <li>SlashFor (Batch node editing with expressions in the Console)</li> <li>SuckLessAudio (A modifier to import .wav audio files)</li> <li>stx_tools (Custom macros including an optical flow based warp tracker)</li> <li>STMapper (An amazing UV Pass/ST Map warping DCTL Fuse. It's SO FAST!!!)</li> <li>Shadertoys (A wild visual trip with DCTL ports of popular ShaderToy fragment shaders)</li> <li>TimeMachine (Retime nodes)</li> <li>Tintensity (Color Correction)</li> <li>UI Manager Lua &amp; Python Examples (Code examples for creating custom Qt based GUIs in scripts)</li> <li>LifeSaver (Multi-Part EXR writer with filename token support)</li> <li>ParallelIO pioSaver (Multi-Channel EXR writer with filename token support)</li> </ul>"},{"location":"Script/Library/Library/","title":"Library","text":"","tags":["Reference"]},{"location":"Script/Library/Library/#bit","title":"bit","text":"<ul> <li>rol</li> <li>rshift</li> <li>ror</li> <li>bswap</li> <li>bxor</li> <li>bor</li> <li>arshift</li> <li>bnot</li> <li>tobit</li> <li>[[lshift|Script/Library/bit/lshift]]</li> <li>[[tohex|Script/Library/bit/tohex]]</li> <li>[[band|Script/Library/bit/band]]</li> </ul>","tags":["Reference"]},{"location":"Script/Library/Library/#bmd-aka-eyeon","title":"bmd (aka eyeon)","text":"<ul> <li>suspend</li> <li>version</li> <li>getcurrentdir</li> <li>using</li> <li>readdir</li> <li>getclipboard</li> <li>getuptime</li> <li>fileexists</li> <li>removedir</li> <li>fullpath</li> <li>nextstate</li> <li>pinghosts</li> <li>getstateindex</li> <li>tounc</li> <li>fprint</li> <li>setapptitle</li> <li>isin</li> <li>parseFilename</li> <li>sendnotify</li> <li>getextension</li> <li>writestring</li> <li>noise</li> <li>_VERSION</li> <li>defragsequence</li> <li>setclipboard</li> <li>asyncscriptapp</li> <li>trim</li> <li>stripname</li> <li>obtaingloballock</li> <li>convertIDtoChar</li> <li>writefile</li> <li>touserdata</li> <li>getfilename</li> <li>CopyCineonSettings</li> <li>get_table_index</li> <li>split</li> <li>direxists</li> <li>defragfile</li> <li>MoveClip</li> <li>releasegloballock</li> <li>isvalidname</li> <li>trimExtension</li> <li>gettime</li> <li>executebg</li> <li>allocconsole</li> <li>getappname</li> <li>LD_GetFrames</li> <li>SV_GetFrames</li> <li>readstring</li> <li>copyfile</li> <li>trimSequence</li> <li>pathIsMovieFormat</li> <li>startserver</li> <li>createdir</li> <li>getusing</li> <li>setcurrentdir</li> <li>GetLoaders</li> <li>getfilepath</li> <li>scriptapp</li> <li>crash</li> <li>readfile</li> <li>createuuid</li> <li>getpid</li> <li>exit</li> <li>openfileexternal</li> <li>openurl</li> <li>UIDispatcher</li> <li>wait</li> <li>GetSavers</li> <li>getappuuid</li> </ul>","tags":["Reference"]},{"location":"Script/Library/Library/#os","title":"os","text":"<ul> <li>execute</li> <li>rename</li> <li>setlocale</li> <li>getenv</li> <li>difftime</li> <li>remove</li> <li>date</li> <li>exit</li> <li>time</li> <li>clock</li> <li>tmpname</li> </ul>","tags":["Reference"]},{"location":"Script/Library/bmd/bmd/","title":"Bmd","text":""},{"location":"Script/Library/bmd/bmd/#bmd-aka-eyeon","title":"bmd (aka eyeon)","text":"<ul> <li>suspend</li> <li>version</li> <li>getcurrentdir</li> <li>using</li> <li>readdir</li> <li>getclipboard</li> <li>getuptime</li> <li>fileexists</li> <li>removedir</li> <li>fullpath</li> <li>nextstate</li> <li>pinghosts</li> <li>getstateindex</li> <li>tounc</li> <li>fprint</li> <li>setapptitle</li> <li>isin</li> <li>parseFilename</li> <li>sendnotify</li> <li>getextension</li> <li>writestring</li> <li>noise</li> <li>_VERSION</li> <li>defragsequence</li> <li>setclipboard</li> <li>asyncscriptapp</li> <li>trim</li> <li>stripname</li> <li>obtaingloballock</li> <li>convertIDtoChar</li> <li>writefile</li> <li>touserdata</li> <li>getfilename</li> <li>CopyCineonSettings</li> <li>get_table_index</li> <li>split</li> <li>direxists</li> <li>defragfile</li> <li>MoveClip</li> <li>releasegloballock</li> <li>isvalidname</li> <li>trimExtension</li> <li>gettime</li> <li>executebg</li> <li>allocconsole</li> <li>getappname</li> <li>LD_GetFrames</li> <li>SV_GetFrames</li> <li>readstring</li> <li>copyfile</li> <li>trimSequence</li> <li>pathIsMovieFormat</li> <li>startserver</li> <li>createdir</li> <li>getusing</li> <li>setcurrentdir</li> <li>GetLoaders</li> <li>getfilepath</li> <li>scriptapp</li> <li>crash</li> <li>readfile</li> <li>createuuid</li> <li>getpid</li> <li>exit</li> <li>openfileexternal</li> <li>openurl</li> <li>UIDispatcher</li> <li>wait</li> <li>GetSavers</li> <li>getappuuid</li> </ul>"},{"location":"Script/Library/bmd/fileexists/","title":"Fileexists","text":"<p>Note: given a file path in <code>file</code> and directory path in <code>path</code> the following code ... <pre><code>print(\"fileexists( file ) == \".. (bmd.fileexists( file ) and \"true\" or \"false\"))\nprint(\"direxists(  file ) == \".. (bmd.direxists(  file ) and \"true\" or \"false\"))\nprint(\"fileexists( dir  ) == \".. (bmd.fileexists( dir  ) and \"true\" or \"false\"))\nprint(\"direxists(  dir  ) == \".. (bmd.direxists(  dir  ) and \"true\" or \"false\"))\n</code></pre> ... results in ... <pre><code>fileexists( file ) == true\ndirexists(  file ) == false\nfileexists( dir  ) == true\ndirexists(  dir  ) == true\n</code></pre> ... so you should know: <code>fileexists</code> is true, even if the file is actually not a file but a directory.</p>"},{"location":"Tools/Blender/","title":"Blender","text":""},{"location":"Tools/Blender/#blender-for-artists-bforartists","title":"Blender for Artists (bforartists)","text":"<p>https://bforartists.de/</p> <p>Discussions: - https://www.steakunderwater.com/wesuckless/viewtopic.php?p=43219#p43219</p>"},{"location":"Tools/VS%20Code/","title":"VS Code","text":"<p>Visual Studio Code (short: VS Code) is a free, feature rich, cross-platform code editor.</p> <p>...</p>"},{"location":"Tools/VS%20Code/#extensions","title":"Extensions","text":"<p>One of VSCode's strengths is that its functionality can be extended by plugins. Some of those addressing Pipeline Technical Directors, developers in the Davinci Resolve / Fusion space in particular, or VFx programmers in general, shall be listed here. </p>"},{"location":"Tools/VS%20Code/#bmd-specific","title":"BMD Specific","text":"<ul> <li>BMD Fusion Scripting by Ember Light VFX ... is an extension for ... under active development.</li> <li>Davinci Resolve Toolkit by Asher Roland ... no idea.</li> <li>fuse-snippets by Rene 'rne1223' Tellez Rodriguez is a snippet extension to help create Fuses for Fusion and Davinci Resolve ... this is a fantastic extension that would definitely had deserved some support from the community.</li> </ul>"},{"location":"Tools/VS%20Code/#vfx-related","title":"VFx related","text":"<p>Not looked into it yet, but maybe worth a try ... - USD Language Pixar USD Language Extension by Animal Logic - 3D Viewer for VSCode Preview 3D models in VSCode - WebGL GLSL Editor Language support for WebGL GLSL shaders. - WebGL Shader Viewer Visual Studio Code extension for previewing shader files inside the editor.</p>"},{"location":"Tools/VS%20Code/#engineering-in-general","title":"Engineering in general","text":"<p>No idea, but maybe used for plugin development and such ... - CMake Tools Extended CMake support in Visual Studio Code - Jupyter Jupyter notebook support, interactive programming and computing that supports Intellisense, debugging and more. - Code Spell Checker A basic spell checker that works well with code and documents.</p>"},{"location":"Tools/Lua/Lua/","title":"Lua","text":"<p>...</p>"},{"location":"Tools/Lua/LuaJIT/","title":"LuaJIT","text":""},{"location":"Tools/Lua/LuaJIT/#ffi","title":"FFI","text":"<p>https://luajit.org/ext_ffi.html</p>"},{"location":"Categories/","title":"Categories","text":"<p>Tags are intended to become categories in a future MediaWiki. So use them wisely.</p>"},{"location":"Categories/#scrivener-export","title":".scrivener-export","text":"<ul> <li>KartaVision - Node Based Reverse Image Search</li> <li>360VR Stitching Tools</li> <li>ACES Color Management</li> <li>AWS Deadline Deployment</li> <li>About</li> <li>Adding KartaVR via Reactor</li> <li>Adding Vonk Ultra via Reactor</li> <li>Apple Compressor Command Line Syntax</li> <li>Automated Reactor PathMaps in Resolve Studio and Fusion Studio</li> <li>Automation Tools</li> <li>Choosing Your Installation Packages</li> <li>Closing Thoughts</li> <li>Computer Vision and Machine Learning Tools</li> <li>Configuring Fusion Centric Environment Variables</li> <li>Configuring Fusion Render Node PathMaps</li> <li>Display Solutions, GPUs, Video Cables, Converters/Adapters</li> <li>Essential Reactor Atom Packages</li> <li>FFMpeg Command Line Syntax</li> <li>Fulldome</li> <li>Fusion Render Node Customization</li> <li>Hardware Control Surfaces and HID Devices</li> <li>IP Based Video Workflows</li> <li>Immersive Pipeline Integration Guide</li> <li>Install Reactor Package Manager</li> <li>Installing Common Utilities</li> <li>Installing Data Backup and Disaster Recovery Tools</li> <li>Installing Digital Content Creation Apps</li> <li>Installing Hardware Virtualization Tools</li> <li>Installing Operating Systems From Scratch</li> <li>Installing a Local Content Staging Web Server</li> <li>Installing the BMD Resolve / Fusion Software</li> <li>Kartaverse Development Reference Hardware</li> <li>Kartaverse Learning Resources</li> <li>Kartaverse Project Assistance</li> <li>Overview</li> <li>Photogrammetry Tools</li> <li>Pixar Tractor Deployment</li> <li>RAW and HDRI Image Processing Tools</li> <li>Software Packaging and Deployment Tools</li> <li>Spatial Audio Tools</li> <li>System Admin Resources</li> <li>The Karta Development Journey</li> <li>The Kartaverse Packages</li> <li>Using BBEdit on macOS</li> <li>Using Notepad++ for Fusion on Windows</li> <li>Virtual Production</li> <li>Working With Environment Variables</li> <li>Acknowledgements</li> <li>Adding Data Nodes to a Composite</li> <li>Fusion Render Node Customization</li> <li>Install Vonk</li> <li>Software Required</li> <li>Vonk Essentials</li> <li>Vonk Node Cookbook</li> <li>Vonk Node Reference Guide</li> <li>Vonk Scripts</li> <li>Vonk Ultra</li> <li>Creating ST Maps</li> <li>Creating Volumetric NeRFs</li> <li>DEV Building an Effective nVP (Neural Virtual Production) Sound Stage</li> <li>DEV The Ultimate Guide to OpenUSD Pipeline Development</li> <li>Domemaster Photoshop Actions Pack</li> <li>Jupyter Notebook for Resolve/Fusion</li> <li>KickAss ShaderZ for Fusion</li> <li>OpenDisplayXR/VDD</li> <li>Render Fusion Comps in Houdini TOPs</li> <li>SketchFab in VR Via QuestLink</li> <li>Troubleshooting Guide for Fusion Studio Freeze Ups</li> <li>Kartaverse Workflows</li> <li>YouTube 360 to Equirectangular Conversions</li> <li>KKD Example Comps</li> <li>KKD Modifier Reference Guide</li> <li>KKD Node Categories</li> <li>KKD Node Cookbook</li> <li>KKD Node Reference Guide</li> </ul>"},{"location":"Categories/#3d-scan","title":"3D-Scan","text":"<ul> <li>Novel view synthesis</li> </ul>"},{"location":"Categories/#development","title":"Development","text":"<ul> <li>FusionSDK</li> </ul>"},{"location":"Categories/#glossary","title":"Glossary","text":"<ul> <li>Novel view synthesis</li> <li>Video Village</li> <li>Fuse</li> <li>Tool</li> </ul>"},{"location":"Categories/#kartaverse","title":"Kartaverse","text":"<ul> <li>KartaVision - Node Based Reverse Image Search</li> <li>360VR Stitching Tools</li> <li>ACES Color Management</li> <li>AWS Deadline Deployment</li> <li>About</li> <li>Adding KartaVR via Reactor</li> <li>Adding Vonk Ultra via Reactor</li> <li>Apple Compressor Command Line Syntax</li> <li>Automated Reactor PathMaps in Resolve Studio and Fusion Studio</li> <li>Automation Tools</li> <li>Choosing Your Installation Packages</li> <li>Closing Thoughts</li> <li>Computer Vision and Machine Learning Tools</li> <li>Configuring Fusion Centric Environment Variables</li> <li>Configuring Fusion Render Node PathMaps</li> <li>Display Solutions, GPUs, Video Cables, Converters/Adapters</li> <li>Essential Reactor Atom Packages</li> <li>FFMpeg Command Line Syntax</li> <li>Fulldome</li> <li>Fusion Render Node Customization</li> <li>Hardware Control Surfaces and HID Devices</li> <li>IP Based Video Workflows</li> <li>Immersive Pipeline Integration Guide</li> <li>Install Reactor Package Manager</li> <li>Installing Common Utilities</li> <li>Installing Data Backup and Disaster Recovery Tools</li> <li>Installing Digital Content Creation Apps</li> <li>Installing Hardware Virtualization Tools</li> <li>Installing Operating Systems From Scratch</li> <li>Installing a Local Content Staging Web Server</li> <li>Installing the BMD Resolve / Fusion Software</li> <li>Kartaverse Development Reference Hardware</li> <li>Kartaverse Learning Resources</li> <li>Kartaverse Project Assistance</li> <li>Overview</li> <li>Photogrammetry Tools</li> <li>Pixar Tractor Deployment</li> <li>RAW and HDRI Image Processing Tools</li> <li>Software Packaging and Deployment Tools</li> <li>Spatial Audio Tools</li> <li>System Admin Resources</li> <li>The Karta Development Journey</li> <li>The Kartaverse Packages</li> <li>Using BBEdit on macOS</li> <li>Using Notepad++ for Fusion on Windows</li> <li>Virtual Production</li> <li>Working With Environment Variables</li> <li>Acknowledgements</li> <li>Adding Data Nodes to a Composite</li> <li>Fusion Render Node Customization</li> <li>Install Vonk</li> <li>Software Required</li> <li>Vonk Essentials</li> <li>Vonk Node Cookbook</li> <li>Vonk Node Reference Guide</li> <li>Vonk Scripts</li> <li>Vonk Ultra</li> <li>Creating ST Maps</li> <li>Creating Volumetric NeRFs</li> <li>DEV Building an Effective nVP (Neural Virtual Production) Sound Stage</li> <li>DEV The Ultimate Guide to OpenUSD Pipeline Development</li> <li>Domemaster Photoshop Actions Pack</li> <li>Jupyter Notebook for Resolve/Fusion</li> <li>KickAss ShaderZ for Fusion</li> <li>OpenDisplayXR/VDD</li> <li>Render Fusion Comps in Houdini TOPs</li> <li>SketchFab in VR Via QuestLink</li> <li>Troubleshooting Guide for Fusion Studio Freeze Ups</li> <li>Kartaverse Workflows</li> <li>YouTube 360 to Equirectangular Conversions</li> <li>KKD Example Comps</li> <li>KKD Modifier Reference Guide</li> <li>KKD Node Categories</li> <li>KKD Node Cookbook</li> <li>KKD Node Reference Guide</li> </ul>"},{"location":"Categories/#project","title":"Project","text":"<ul> <li>OpenDisplayXR/VDD</li> </ul>"},{"location":"Categories/#reference","title":"Reference","text":"<ul> <li>Fusion built in Tools</li> <li>Class Types</li> <li>Registry Attributes</li> <li>KKD Modifier Reference Guide</li> <li>KKD Node Categories</li> <li>KKD Node Reference Guide</li> <li>Library</li> </ul>"},{"location":"Categories/#research","title":"Research","text":"<ul> <li>Novel view synthesis</li> </ul>"},{"location":"Categories/#resource","title":"Resource","text":"<ul> <li>Resources</li> <li>Scripting Guide</li> </ul>"},{"location":"Categories/#theory","title":"Theory","text":"<ul> <li>Fast Fourier Transform (FFT)</li> <li>Voronoi Diagram</li> </ul>"},{"location":"Categories/#workflow","title":"Workflow","text":"<ul> <li>KartaVision - Node Based Reverse Image Search</li> <li>Creating ST Maps</li> <li>Creating Volumetric NeRFs</li> <li>DEV Building an Effective nVP (Neural Virtual Production) Sound Stage</li> <li>DEV The Ultimate Guide to OpenUSD Pipeline Development</li> <li>Domemaster Photoshop Actions Pack</li> <li>Jupyter Notebook for Resolve/Fusion</li> <li>KickAss ShaderZ for Fusion</li> <li>OpenDisplayXR/VDD</li> <li>Render Fusion Comps in Houdini TOPs</li> <li>SketchFab in VR Via QuestLink</li> <li>Troubleshooting Guide for Fusion Studio Freeze Ups</li> <li>Kartaverse Workflows</li> <li>YouTube 360 to Equirectangular Conversions</li> </ul>"},{"location":"Categories/#glossary_1","title":"glossary","text":"<ul> <li>DCTL</li> </ul>"},{"location":"Categories/#reference_1","title":"reference","text":"<ul> <li>Math Functions</li> </ul>"},{"location":"Categories/#rework","title":"rework","text":"<ul> <li>Fuse Settings</li> </ul>"},{"location":"Categories/#webgl2dctl","title":"webgl2dctl","text":"<ul> <li>Conversion</li> <li>Fuse Settings</li> <li>Links</li> <li>Math Functions</li> <li>Swizzling</li> </ul>"}]}